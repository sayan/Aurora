{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_questions():\n",
    "    \"\"\"\n",
    "    Traverse all subdirectories of \"/workspaces/codespaces-jupyter/output/quarto_content\",\n",
    "    look for files with a \".qmd\" extension, read only their first 15 lines, and search for a\n",
    "    line containing the word \"question\" (case-insensitive). When found, extract the text after\n",
    "    the word \"question\" (ignoring any punctuation or delimiter right after it), trim any leading\n",
    "    special characters/numbers/spaces from the captured text, and store the result.\n",
    "    If no such line is found in a file, the question is recorded as an empty string.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Each dictionary contains:\n",
    "            - 'file_path': The full path to the file.\n",
    "            - 'question': The cleaned question string (or an empty string if not found).\n",
    "    \"\"\"\n",
    "    base_path = \"/workspaces/codespaces-jupyter/output/quarto_content\"\n",
    "    results = []\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".qmd\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                question_text = \"\"  # default if no question is found\n",
    "\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        # Only process the first 15 lines\n",
    "                        for _ in range(15):\n",
    "                            line = f.readline()\n",
    "                            if not line:\n",
    "                                break  # Reached end of file\n",
    "\n",
    "                            # Check if the line contains 'question' (case-insensitive)\n",
    "                            if 'question' in line.lower():\n",
    "                                # Extract characters after the word 'question'\n",
    "                                # This regex looks for the word 'question' (ignoring case),\n",
    "                                # followed by optional whitespace and delimiters like ':' or '-',\n",
    "                                # then captures the rest of the line.\n",
    "                                match = re.search(r'question\\s*[:\\-]*\\s*(.*)', line, re.IGNORECASE)\n",
    "                                if match:\n",
    "                                    question_text = match.group(1).strip()\n",
    "                                    # Remove any leading characters that are not letters (e.g., special characters, numbers, or spaces)\n",
    "                                    question_text = re.sub(r'^[^A-Za-z]+', '', question_text)\n",
    "                                    # Optionally, remove any other special characters from the rest of the text\n",
    "                                    question_text = re.sub(r'[^A-Za-z0-9\\s]', '', question_text)\n",
    "                                # Stop processing further lines once the question is found\n",
    "                                break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file {file_path}: {e}\")\n",
    "\n",
    "                results.append({\n",
    "                    'file_path': file_path,\n",
    "                    'question': question_text\n",
    "                })\n",
    "                \n",
    "    return results\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     extracted_questions = extract_questions()\n",
    "#     for item in extracted_questions:\n",
    "#         print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files 445\n",
      "Files with no questions 1\n"
     ]
    }
   ],
   "source": [
    "extracted_questions = extract_questions()\n",
    "print(f\"Number of files {len(extracted_questions)}\")\n",
    "empty_question_files = [entry for entry in extracted_questions if not entry['question']]\n",
    "print(f\"Files with no questions {len(empty_question_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd',\n",
       "  'question': 'Logistic regression models produce probabilities for binary outcomes How would you calibrate these probabilities if you suspect that they are poorly calibrated and why is calibration important'},\n",
       " {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_6.qmd',\n",
       "  'question': 'Logistic regression is based on certain assumptions What are these assumptions and how can violations of these assumptions affect model performance'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in extracted_questions if 'logistic' in i['file_path'].lower()][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def generate_index_qmd(extracted_questions, output_file=\"/workspaces/codespaces-jupyter/index.qmd\"):\n",
    "#     \"\"\"\n",
    "#     Generate a Quarto index.qmd file using the extracted_questions list.\n",
    "\n",
    "#     The file groups questions by category and subcategory.\n",
    "#     It converts an absolute file path like:\n",
    "#         /workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd\n",
    "#     into a relative path like:\n",
    "#         output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd\n",
    "\n",
    "#     The index.qmd file will be structured as follows:\n",
    "\n",
    "#     ---\n",
    "#     title: \"Data Science interview questions to practice\"\n",
    "#     format:\n",
    "#       html:\n",
    "#         toc: true\n",
    "#     ---\n",
    "\n",
    "#     ## classification\n",
    "\n",
    "#     ### Decision_Trees\n",
    "\n",
    "#     - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_0.qmd)\n",
    "#     - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_1.qmd)\n",
    "#     - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_10.qmd)\n",
    "\n",
    "#     ### Logistic_Regression\n",
    "\n",
    "#     - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd)\n",
    "#     - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_6.qmd)\n",
    "#     - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_4.qmd)\n",
    "#     \"\"\"\n",
    "#     # Group the entries by category and subcategory.\n",
    "#     groups = {}\n",
    "#     for entry in extracted_questions:\n",
    "#         file_path = entry['file_path']\n",
    "#         question = entry['question']\n",
    "#         # Convert to relative path: remove the /workspaces/codespaces-jupyter/ prefix if present.\n",
    "#         base_prefix = \"/workspaces/codespaces-jupyter/\"\n",
    "#         if file_path.startswith(base_prefix):\n",
    "#             relative_path = file_path[len(base_prefix):]\n",
    "#         else:\n",
    "#             relative_path = file_path\n",
    "\n",
    "#         # Split the path into parts using the OS separator.\n",
    "#         parts = file_path.split(os.sep)\n",
    "#         try:\n",
    "#             # Find where 'quarto_content' is located in the path\n",
    "#             idx = parts.index(\"quarto_content\")\n",
    "#             # The next two parts should be the category and subcategory.\n",
    "#             category = parts[idx+1] if idx+1 < len(parts) else \"Unknown\"\n",
    "#             subcategory = parts[idx+2] if idx+2 < len(parts) else \"General\"\n",
    "#         except ValueError:\n",
    "#             # In case the expected folder name is not found\n",
    "#             category, subcategory = \"Unknown\", \"General\"\n",
    "\n",
    "#         groups.setdefault(category, {}).setdefault(subcategory, []).append({\n",
    "#             \"relative_path\": relative_path,\n",
    "#             \"question\": question\n",
    "#         })\n",
    "\n",
    "#     # Build the content for index.qmd\n",
    "#     lines = []\n",
    "#     # YAML front matter\n",
    "#     lines.append(\"---\")\n",
    "#     lines.append('title: \"Data Science interview questions to practice\"')\n",
    "#     lines.append(\"format:\")\n",
    "#     lines.append(\"  html:\")\n",
    "#     lines.append(\"    toc: true\")\n",
    "#     lines.append(\"---\")\n",
    "#     lines.append(\"\")  # Blank line\n",
    "\n",
    "#     # Create the Markdown sections for each category and subcategory.\n",
    "#     for category in sorted(groups.keys()):\n",
    "#         lines.append(f\"## {category}\")\n",
    "#         lines.append(\"\")  # Blank line\n",
    "#         for subcategory in sorted(groups[category].keys()):\n",
    "#             lines.append(f\"### {subcategory}\")\n",
    "#             lines.append(\"\")  # Blank line\n",
    "#             for item in groups[category][subcategory]:\n",
    "#                 relative_path = item[\"relative_path\"]\n",
    "#                 question_text = item[\"question\"]\n",
    "#                 # Use a placeholder if question_text is empty.\n",
    "#                 display_text = question_text if question_text else \"No question text available\"\n",
    "#                 # Add the bullet list item.\n",
    "#                 lines.append(f\"- [{display_text}]({relative_path})\")\n",
    "#             lines.append(\"\")  # Blank line after each subcategory\n",
    "#         lines.append(\"\")  # Blank line after each category\n",
    "\n",
    "#     # Write the generated content to the output file.\n",
    "#     with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(\"\\n\".join(lines))\n",
    "\n",
    "#     print(f\"Index file generated: {output_file}\")\n",
    "\n",
    "# # # Example usage:\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     # Suppose extracted_questions is your list from the previous function.\n",
    "# #     extracted_questions = [\n",
    "# #         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd',\n",
    "# #          'question': 'Logistic regression models produce probabilities for binary outcomes How would you calibrate these probabilities if you suspect that they are poorly calibrated and why is calibration important'},\n",
    "# #         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_6.qmd',\n",
    "# #          'question': 'Logistic regression is based on certain assumptions What are these assumptions and how can violations of these assumptions affect model performance'},\n",
    "# #         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_4.qmd',\n",
    "# #          'question': 'How would you incorporate regularization both L1 and L2 into the logistic regression model What effect does regularization have on the model parameters and overall model performance'},\n",
    "# #         # ... add additional entries as needed\n",
    "# #     ]\n",
    "\n",
    "# #     generate_index_qmd(extracted_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_index(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the numerical index from a file name.\n",
    "    For example, given a file name like \"Logistic_Regression_11.qmd\",\n",
    "    it will return 11 as an integer. If no index is found, it returns 0.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(file_path)\n",
    "    match = re.search(r'_(\\d+)\\.qmd$', base_name, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def generate_index_qmd(extracted_questions, output_file=\"index.qmd\"):\n",
    "    \"\"\"\n",
    "    Generate a Quarto index.qmd file using the extracted_questions list.\n",
    "\n",
    "    The file groups questions by category and subcategory. It converts an absolute file path like:\n",
    "        /workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd\n",
    "    into a relative path like:\n",
    "        output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd\n",
    "\n",
    "    Files under each subcategory are sorted in ascending order based on the numerical index\n",
    "    extracted from the file name (e.g., _11.qmd).\n",
    "\n",
    "    The index.qmd file will be structured as follows:\n",
    "\n",
    "    ---\n",
    "    title: \"Data Science interview questions to practice\"\n",
    "    format:\n",
    "      html:\n",
    "        toc: true\n",
    "    ---\n",
    "\n",
    "    ## classification\n",
    "\n",
    "    ### Decision_Trees\n",
    "\n",
    "    - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_0.qmd)\n",
    "    - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_1.qmd)\n",
    "    - [Question text](output/quarto_content/classification/Decision_Trees/Decision_Trees_10.qmd)\n",
    "\n",
    "    ### Logistic_Regression\n",
    "\n",
    "    - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd)\n",
    "    - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_6.qmd)\n",
    "    - [Question text](output/quarto_content/classification/Logistic_Regression/Logistic_Regression_4.qmd)\n",
    "    \"\"\"\n",
    "    # Group the entries by category and subcategory.\n",
    "    groups = {}\n",
    "    for entry in extracted_questions:\n",
    "        file_path = entry['file_path']\n",
    "        question = entry['question']\n",
    "        # Convert to relative path: remove the '/workspaces/codespaces-jupyter/' prefix if present.\n",
    "        base_prefix = \"/workspaces/codespaces-jupyter/\"\n",
    "        if file_path.startswith(base_prefix):\n",
    "            relative_path = file_path[len(base_prefix):]\n",
    "        else:\n",
    "            relative_path = file_path\n",
    "\n",
    "        # Split the path into parts using the OS separator.\n",
    "        parts = file_path.split(os.sep)\n",
    "        try:\n",
    "            # Find where 'quarto_content' is located in the path.\n",
    "            idx = parts.index(\"quarto_content\")\n",
    "            # The next two parts should be the category and subcategory.\n",
    "            category = parts[idx+1] if idx+1 < len(parts) else \"Unknown\"\n",
    "            subcategory = parts[idx+2] if idx+2 < len(parts) else \"General\"\n",
    "        except ValueError:\n",
    "            # In case the expected folder name is not found.\n",
    "            category, subcategory = \"Unknown\", \"General\"\n",
    "\n",
    "        groups.setdefault(category, {}).setdefault(subcategory, []).append({\n",
    "            \"relative_path\": relative_path,\n",
    "            \"question\": question\n",
    "        })\n",
    "\n",
    "    # Build the content for index.qmd\n",
    "    lines = []\n",
    "    # YAML front matter\n",
    "    lines.append(\"---\")\n",
    "    lines.append('title: \"Data Science interview questions to practice\"')\n",
    "    lines.append(\"format:\")\n",
    "    lines.append(\"  html:\")\n",
    "    lines.append(\"    toc: true\")\n",
    "    lines.append(\"---\")\n",
    "    lines.append(\"\")  # Blank line\n",
    "\n",
    "    # Create the Markdown sections for each category and subcategory.\n",
    "    for category in sorted(groups.keys()):\n",
    "        lines.append(f\"## {category}\")\n",
    "        lines.append(\"\")  # Blank line\n",
    "        for subcategory in sorted(groups[category].keys()):\n",
    "            lines.append(f\"### {subcategory}\")\n",
    "            lines.append(\"\")  # Blank line\n",
    "\n",
    "            # Sort files based on the numerical index in their filename\n",
    "            sorted_items = sorted(groups[category][subcategory],\n",
    "                                  key=lambda item: extract_index(item[\"relative_path\"]))\n",
    "            for item in sorted_items:\n",
    "                relative_path = item[\"relative_path\"]\n",
    "                question_text = item[\"question\"]\n",
    "                # Use a placeholder if question_text is empty.\n",
    "                display_text = question_text if question_text else \"No question text available\"\n",
    "                # Add the bullet list item.\n",
    "                lines.append(f\"- [{display_text}]({relative_path})\")\n",
    "            lines.append(\"\")  # Blank line after each subcategory\n",
    "        lines.append(\"\")  # Blank line after each category\n",
    "\n",
    "    # Write the generated content to the output file.\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "    print(f\"Index file generated: {output_file}\")\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example list of extracted questions.\n",
    "#     extracted_questions = [\n",
    "#         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_11.qmd',\n",
    "#          'question': 'Logistic regression models produce probabilities for binary outcomes How would you calibrate these probabilities if you suspect that they are poorly calibrated and why is calibration important'},\n",
    "#         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_6.qmd',\n",
    "#          'question': 'Logistic regression is based on certain assumptions What are these assumptions and how can violations of these assumptions affect model performance'},\n",
    "#         {'file_path': '/workspaces/codespaces-jupyter/output/quarto_content/classification/Logistic_Regression/Logistic_Regression_4.qmd',\n",
    "#          'question': 'How would you incorporate regularization both L1 and L2 into the logistic regression model What effect does regularization have on the model parameters and overall model performance'},\n",
    "#         # Add additional entries as needed...\n",
    "#     ]\n",
    "\n",
    "#     generate_index_qmd(extracted_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index file generated: /workspaces/codespaces-jupyter/index.qmd\n"
     ]
    }
   ],
   "source": [
    "generate_index_qmd(extracted_questions, output_file=\"/workspaces/codespaces-jupyter/index.qmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
