{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from topic_categories import ml_ai_ds_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the keys\n",
    "openai_key = os.getenv(\"OPENAI_KEY\")\n",
    "gemini_key = os.getenv(\"GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=openai_key)\n",
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATION_SYSTEM_PROMPT = \"\"\"\n",
    "## **Role & Objective**\n",
    "You are an expert AI researcher at a top Silicon Valley tech company. You need to interview **principal-level candidates** for roles in **AI, Data Science, or Machine Learning**. You will be given a specific topic in this domain.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task**\n",
    "- **Generate a list of 10-15 interview questions** that thoroughly test the candidate’s **depth, mathematical understanding, and nuanced thinking** on the given topic.\n",
    "\n",
    "---\n",
    "\n",
    "## **Content Requirements**\n",
    "1. **Question Complexity:**  \n",
    "   - Include a mix of **basic, intermediate, and advanced** questions.  \n",
    "\n",
    "2. **Guidelines for Evaluation:**  \n",
    "   - For each question, provide a short **\"Guideline\"** describing what a good answer should cover or how it should be evaluated.  \n",
    "\n",
    "3. **Edge Cases:**  \n",
    "   - Ensure that **corner cases** and potential **pitfalls** related to the topic are covered.  \n",
    "\n",
    "4. **Practical Application:**  \n",
    "   - Include at least one question that tests the candidate’s ability to handle **real-world challenges**, such as:  \n",
    "     - **Messy data** handling  \n",
    "     - **Scalability** issues  \n",
    "     - **Deployment considerations**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output**\n",
    "Make sure the final list of questions is:\n",
    "- **Comprehensive** (covering all key aspects of the topic)\n",
    "- **Well-structured** (clearly formatted for easy understanding)\n",
    "- **Aligned with principal-level reasoning and expectations** \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATION_SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "## **Role & Objective**\n",
    "You are an expert AI researcher at a top Silicon Valley tech company. You need to interview **principal-level candidates** for roles in **AI, Data Science, or Machine Learning**. You will be given a specific topic in this domain.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task**\n",
    "- **Generate a list of {num_question_string} interview questions** that thoroughly test the candidate’s **depth, mathematical understanding, and nuanced thinking** on the given topic.\n",
    "\n",
    "---\n",
    "\n",
    "## **Content Requirements**\n",
    "1. **Question Complexity:**  \n",
    "   - Include a mix of **basic, intermediate, and advanced** questions.  \n",
    "\n",
    "2. **Guidelines for Evaluation:**  \n",
    "   - For each question, provide a short **\"Guideline\"** describing what a good answer should cover or how it should be evaluated.  \n",
    "\n",
    "3. **Edge Cases:**  \n",
    "   - Ensure that **corner cases** and potential **pitfalls** related to the topic are covered.  \n",
    "\n",
    "4. **Practical Application:**  \n",
    "   - Include at least one question that tests the candidate’s ability to handle **real-world challenges**, such as:  \n",
    "     - **Messy data** handling  \n",
    "     - **Scalability** issues  \n",
    "     - **Deployment considerations**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output**\n",
    "Make sure the final list of questions is:\n",
    "- **Comprehensive** (covering all key aspects of the topic)\n",
    "- **Well-structured** (clearly formatted for easy understanding)\n",
    "- **Aligned with principal-level reasoning and expectations** \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(QUESTION_GENERATION_SYSTEM_PROMPT_TEMPLATE.format(num_question_string=\"4-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATION_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "      \"name\": \"questions_response\",\n",
    "      \"strict\": True,\n",
    "      \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"questions\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"An array of question objects.\",\n",
    "            \"items\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                \"question\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"The question text.\"\n",
    "                },\n",
    "                \"response_guideline\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"Guidelines for responding to the question.\"\n",
    "                }\n",
    "              },\n",
    "              \"required\": [\n",
    "                \"question\",\n",
    "                \"response_guideline\"\n",
    "              ],\n",
    "              \"additionalProperties\": False\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"questions\"\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "      }\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate questions\n",
    "## this function takes a ML topic as input and generates a list of questions and guideline on how to solve it as output\n",
    "\n",
    "\n",
    "def generate_questions(topic, num_questions='10-15'):\n",
    "    response = openai_client.chat.completions.create(\n",
    "      model=\"o3-mini\", ## o3-mini\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": QUESTION_GENERATION_SYSTEM_PROMPT_TEMPLATE.format(num_question_string=num_questions)\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": f\"Topic: {topic}\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      response_format=QUESTION_GENERATION_RESPONSE_FORMAT,\n",
    "      #temperature=0.8,\n",
    "      max_completion_tokens=10000,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_questions(\"AutoEncoder\", num_questions='1 or 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = '/workspaces/codespaces-jupyter/output/'\n",
    "output_dir = '/teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/'\n",
    "\n",
    "question_output_dir = output_dir + 'questions/'\n",
    "classification_dir = output_dir + 'classification/'\n",
    "regression_dir = output_dir + 'regression/'\n",
    "clustering_dir = output_dir + 'clustering/'\n",
    "nlp_dir = output_dir + 'nlp/'\n",
    "time_series_dir = output_dir + 'time_series/'\n",
    "optimisation_dir = output_dir + 'optimisation/'\n",
    "neural_networks_dir = output_dir + 'neural_networks/'\n",
    "transformer_networks_dir = output_dir + 'transformer_networks/'\n",
    "ml_ops = output_dir + 'ml_ops/'\n",
    "auto_var_gan_enc_dir = output_dir + 'auto_var_gan_enc/'\n",
    "\n",
    "classification_topics = [\n",
    "    'Logistic Regression',\n",
    "    'L1 and L2 Regularization',\n",
    "    'Decision Trees',\n",
    "    'Random Forest',\n",
    "    'Gradient Boosting',\n",
    "    'XGBoost',\n",
    "    'Support Vector Machines',\n",
    "    'Naive Bayes',\n",
    "    'K-Nearest Neighbours',\n",
    "    'Ensemble Learning',\n",
    "    'Evaluation Metrics for Classification',\n",
    "    'Imbalanced Data Handling',\n",
    "    'Hyperparameter Tuning for Classification',\n",
    "    'Feature Selection for Classification',\n",
    "    'Model Evaluation and Selection for Classification',\n",
    "    'Bayesian Knowledge Tracing',\n",
    "    'Recommender Systems',\n",
    "    'Matrix Factorization',\n",
    "    'Collaborative Filtering',\n",
    "    'IRT (Item Response Theory)'\n",
    "]\n",
    "\n",
    "\n",
    "transformer_topics = [\n",
    "    \"Historical context and evolution of the Transformer architecture\",\n",
    "    \"Key differences between RNN, CNN-based models and Transformers\",\n",
    "    \"Encoder-Decoder structure in Transformers\",\n",
    "    \"Attention mechanism (Self-Attention, Multi-Head Attention)\",\n",
    "    \"Positional encodings and why they are needed\",\n",
    "    \"Training dynamics (masking, batch sizes, learning rates)\",\n",
    "    \"Scaling laws and model sizes\",\n",
    "    \"Popular Transformer variants (BERT, GPT, T5, XLNet, etc.)\",\n",
    "    \"Pretraining objectives (Masked LM, Next Sentence Prediction, etc.)\",\n",
    "    \"Transfer learning and fine-tuning strategies\",\n",
    "    \"Handling long sequences (Longformer, Big Bird, etc.)\",\n",
    "    \"Efficient Transformers (memory and computational optimizations)\",\n",
    "    \"Practical considerations (tokenization, hardware acceleration, libraries)\",\n",
    "    \"Prompt engineering and in-context learning\"\n",
    "]\n",
    "clustering_topics = [\n",
    "    'K-Means Clustering',\n",
    "    'Hierarchical Clustering',\n",
    "    'DBSCAN',\n",
    "    'Gaussian Mixture Models (GMM)',\n",
    "    'HDBSCAN',\n",
    "    'Cluster Evaluation Metrics (Silhouette Score, etc.)',\n",
    "    'Agglomerative Clustering',\n",
    "    'Mean-Shift Clustering'\n",
    "]\n",
    "\n",
    "regression_topics = [\n",
    "    'Linear Regression',\n",
    "    'Polynomial Regression',\n",
    "    'Ridge Regression',\n",
    "    'Lasso Regression',\n",
    "    'Elastic Net Regression',\n",
    "    'Support Vector Regression',\n",
    "    'Decision Tree Regression',\n",
    "    'Random Forest Regression',\n",
    "    'Gradient Boosting Regression',\n",
    "    'XGBoost Regression',\n",
    "    'Evaluation Metrics for Regression',\n",
    "    'Hyperparameter Tuning for Regression',\n",
    "    'Feature Selection for Regression',\n",
    "    'Model Evaluation and Selection for Regression'\n",
    "]\n",
    "\n",
    "\n",
    "optimisation_topics = [\n",
    "    'Gradient Descent',\n",
    "    'Stochastic Gradient Descent',\n",
    "    'Mini-Batch Gradient Descent',\n",
    "    'Momentum',\n",
    "    'Nesterov Accelerated Gradient',\n",
    "    'Adagrad',\n",
    "    'RMSprop',\n",
    "    'Adam, AdaMax, AdamW',\n",
    "    'Learning Rate Scheduling and Hyperparameter Tuning for Optimisation' #    'Hyperparameter Tuning for Optimisation'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re \n",
    "# for topic in classification_topics[5:9]:\n",
    "#     base_topic = 'classification'\n",
    "#     print(f\"Working for topic: {topic}\")\n",
    "#     questions = generate_questions(topic)\n",
    "#     print(f\"Generated  {len(questions['questions'])} questions for {topic}\")\n",
    "#     topic_str = re.sub(r'[^a-zA-Z0-9]', '_', topic)\n",
    "#     output_json_filename =  f\"{question_output_dir}{base_topic}_{topic_str}.json\"\n",
    "#     print(f\"Dumping to {output_json_filename}\")\n",
    "#     json.dump( questions, open( output_json_filename, 'w' ) , indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re \n",
    "# for topic in clustering_topics:\n",
    "#     base_topic = 'clustering'\n",
    "#     print(f\"Working for topic: {topic}\")\n",
    "#     questions = generate_questions(topic)\n",
    "#     print(f\"Generated  {len(questions['questions'])} questions for {topic}\")\n",
    "#     topic_str = re.sub(r'[^a-zA-Z0-9]', '_', topic)\n",
    "#     output_json_filename =  f\"{question_output_dir}{base_topic}_{topic_str}.json\"\n",
    "#     print(f\"Dumping to {output_json_filename}\")\n",
    "#     json.dump( questions, open( output_json_filename, 'w' ) , indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ML Pipelines (Airflow, Kubeflow)',\n",
       " 'Containerization (Docker) and Orchestration (Kubernetes)',\n",
       " 'Cloud Platforms (AWS, GCP, Azure) for ML',\n",
       " 'Continuous Integration/Continuous Deployment (CI/CD) in ML',\n",
       " 'Model Serving (Flask, FastAPI, TensorFlow Serving, TorchServe)',\n",
       " 'Monitoring and Logging for Deployed Models',\n",
       " 'A/B Testing, Canary Deployments',\n",
       " 'Feature Stores & Data Serving',\n",
       " 'Model Versioning and Governance',\n",
       " 'Tools & Frameworks in the MLOps Ecosystem',\n",
       " 'Model Performance Metrics in Production',\n",
       " 'Explainability & Interpretability in Production',\n",
       " 'Model Monitoring & Drift Detection']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_ops_topics = ml_ai_ds_topics['mlops_and_model_deployment']\n",
    "ml_ops_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_var_gan_topic = ml_ai_ds_topics['autoencoder_var_autoencoder_gan_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for topic: Autoencoders\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated  8 questions for Autoencoders\n",
      "Dumping to /teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/questions/auto_var_gan_enc_Autoencoders.json\n",
      "Working for topic: Variational Autoencoders (VAEs)\n",
      "Generated  6 questions for Variational Autoencoders (VAEs)\n",
      "Dumping to /teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/questions/auto_var_gan_enc_Variational_Autoencoders__VAEs_.json\n",
      "Working for topic: Generative Adversarial Networks (GANs)\n",
      "Generated  6 questions for Generative Adversarial Networks (GANs)\n",
      "Dumping to /teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/questions/auto_var_gan_enc_Generative_Adversarial_Networks__GANs_.json\n",
      "Working for topic: Conditional GANs\n",
      "Generated  6 questions for Conditional GANs\n",
      "Dumping to /teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/questions/auto_var_gan_enc_Conditional_GANs.json\n",
      "Working for topic: CycleGAN, StyleGAN, etc.\n",
      "Generated  7 questions for CycleGAN, StyleGAN, etc.\n",
      "Dumping to /teamspace/studios/this_studio/gitrepo/aurora/Aurora/output/questions/auto_var_gan_enc_CycleGAN__StyleGAN__etc_.json\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "for topic in auto_var_gan_topic:\n",
    "    base_topic = 'auto_var_gan_enc'\n",
    "    print(f\"Working for topic: {topic}\")\n",
    "    questions = generate_questions(topic,  num_questions='4-8')\n",
    "    print(f\"Generated  {len(questions['questions'])} questions for {topic}\")\n",
    "    topic_str = re.sub(r'[^a-zA-Z0-9]', '_', topic)\n",
    "    output_json_filename =  f\"{question_output_dir}{base_topic}_{topic_str}.json\"\n",
    "    print(f\"Dumping to {output_json_filename}\")\n",
    "    json.dump( questions, open( output_json_filename, 'w' ) , indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for topic: Gradient Descent\n",
      "Generated  6 questions for Gradient Descent\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Gradient_Descent.json\n",
      "Working for topic: Stochastic Gradient Descent\n",
      "Generated  6 questions for Stochastic Gradient Descent\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Stochastic_Gradient_Descent.json\n",
      "Working for topic: Mini-Batch Gradient Descent\n",
      "Generated  5 questions for Mini-Batch Gradient Descent\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Mini_Batch_Gradient_Descent.json\n",
      "Working for topic: Momentum\n",
      "Generated  5 questions for Momentum\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Momentum.json\n",
      "Working for topic: Nesterov Accelerated Gradient\n",
      "Generated  6 questions for Nesterov Accelerated Gradient\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Nesterov_Accelerated_Gradient.json\n",
      "Working for topic: Adagrad\n",
      "Generated  6 questions for Adagrad\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Adagrad.json\n",
      "Working for topic: RMSprop\n",
      "Generated  7 questions for RMSprop\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_RMSprop.json\n",
      "Working for topic: Adam, AdaMax, AdamW\n",
      "Generated  5 questions for Adam, AdaMax, AdamW\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Adam__AdaMax__AdamW.json\n",
      "Working for topic: Learning Rate Scheduling and Hyperparameter Tuning for Optimisation\n",
      "Generated  6 questions for Learning Rate Scheduling and Hyperparameter Tuning for Optimisation\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/optimisation_Learning_Rate_Scheduling_and_Hyperparameter_Tuning_for_Optimisation.json\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "for topic in optimisation_topics:\n",
    "    base_topic = 'optimisation'\n",
    "    print(f\"Working for topic: {topic}\")\n",
    "    questions = generate_questions(topic,  num_questions='4-8')\n",
    "    print(f\"Generated  {len(questions['questions'])} questions for {topic}\")\n",
    "    topic_str = re.sub(r'[^a-zA-Z0-9]', '_', topic)\n",
    "    output_json_filename =  f\"{question_output_dir}{base_topic}_{topic_str}.json\"\n",
    "    print(f\"Dumping to {output_json_filename}\")\n",
    "    json.dump( questions, open( output_json_filename, 'w' ) , indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
