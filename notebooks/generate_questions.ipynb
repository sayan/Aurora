{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the keys\n",
    "openai_key = os.getenv(\"OPENAI_KEY\")\n",
    "gemini_key = os.getenv(\"GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=openai_key)\n",
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATION_SYSTEM_PROMPT = \"\"\"\n",
    "## **Role & Objective**\n",
    "You are an expert AI researcher at a top Silicon Valley tech company. You need to interview **principal-level candidates** for roles in **AI, Data Science, or Machine Learning**. You will be given a specific topic in this domain.\n",
    "\n",
    "---\n",
    "\n",
    "## **Task**\n",
    "- **Generate a list of 10-15 interview questions** that thoroughly test the candidate’s **depth, mathematical understanding, and nuanced thinking** on the given topic.\n",
    "\n",
    "---\n",
    "\n",
    "## **Content Requirements**\n",
    "1. **Question Complexity:**  \n",
    "   - Include a mix of **basic, intermediate, and advanced** questions.  \n",
    "\n",
    "2. **Guidelines for Evaluation:**  \n",
    "   - For each question, provide a short **\"Guideline\"** describing what a good answer should cover or how it should be evaluated.  \n",
    "\n",
    "3. **Edge Cases:**  \n",
    "   - Ensure that **corner cases** and potential **pitfalls** related to the topic are covered.  \n",
    "\n",
    "4. **Practical Application:**  \n",
    "   - Include at least one question that tests the candidate’s ability to handle **real-world challenges**, such as:  \n",
    "     - **Messy data** handling  \n",
    "     - **Scalability** issues  \n",
    "     - **Deployment considerations**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Final Output**\n",
    "Make sure the final list of questions is:\n",
    "- **Comprehensive** (covering all key aspects of the topic)\n",
    "- **Well-structured** (clearly formatted for easy understanding)\n",
    "- **Aligned with principal-level reasoning and expectations** \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATION_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "      \"name\": \"questions_response\",\n",
    "      \"strict\": True,\n",
    "      \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"questions\": {\n",
    "            \"type\": \"array\",\n",
    "            \"description\": \"An array of question objects.\",\n",
    "            \"items\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                \"question\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"The question text.\"\n",
    "                },\n",
    "                \"response_guideline\": {\n",
    "                  \"type\": \"string\",\n",
    "                  \"description\": \"Guidelines for responding to the question.\"\n",
    "                }\n",
    "              },\n",
    "              \"required\": [\n",
    "                \"question\",\n",
    "                \"response_guideline\"\n",
    "              ],\n",
    "              \"additionalProperties\": False\n",
    "            }\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"questions\"\n",
    "        ],\n",
    "        \"additionalProperties\": False\n",
    "      }\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate questions\n",
    "## this function takes a ML topic as input and generates a list of questions and guideline on how to solve it as output\n",
    "\n",
    "\n",
    "def generate_questions(topic):\n",
    "    response = openai_client.chat.completions.create(\n",
    "      model=\"o3-mini\", ## o3-mini\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": QUESTION_GENERATION_SYSTEM_PROMPT\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": f\"Topic: {topic}\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      response_format=QUESTION_GENERATION_RESPONSE_FORMAT,\n",
    "      #temperature=0.8,\n",
    "      max_completion_tokens=10000,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/workspaces/codespaces-jupyter/output/'\n",
    "question_output_dir = output_dir + 'questions/'\n",
    "classification_dir = output_dir + 'classification/'\n",
    "regression_dir = output_dir + 'regression/'\n",
    "clustering_dir = output_dir + 'clustering/'\n",
    "nlp_dir = output_dir + 'nlp/'\n",
    "time_series_dir = output_dir + 'time_series/'\n",
    "optimisation_dir = output_dir + 'optimisation/'\n",
    "neural_networks_dir = output_dir + 'neural_networks/'\n",
    "transformer_networks_dir = output_dir + 'transformer_networks/'\n",
    "\n",
    "classification_topics = [\n",
    "    'Logistic Regression',\n",
    "    'L1 and L2 Regularization',\n",
    "    'Decision Trees',\n",
    "    'Random Forest',\n",
    "    'Gradient Boosting',\n",
    "    'XGBoost',\n",
    "    'Support Vector Machines',\n",
    "    'Naive Bayes',\n",
    "    'K-Nearest Neighbours',\n",
    "    'Ensemble Learning',\n",
    "    'Evaluation Metrics for Classification',\n",
    "    'Imbalanced Data Handling',\n",
    "    'Hyperparameter Tuning for Classification',\n",
    "    'Feature Selection for Classification',\n",
    "    'Model Evaluation and Selection for Classification',\n",
    "    'Bayesian Knowledge Tracing',\n",
    "    'Recommender Systems',\n",
    "    'Matrix Factorization',\n",
    "    'Collaborative Filtering',\n",
    "    'IRT (Item Response Theory)'\n",
    "]\n",
    "\n",
    "\n",
    "transformer_topics = [\n",
    "    \"Historical context and evolution of the Transformer architecture\",\n",
    "    \"Key differences between RNN, CNN-based models and Transformers\",\n",
    "    \"Encoder-Decoder structure in Transformers\",\n",
    "    \"Attention mechanism (Self-Attention, Multi-Head Attention)\",\n",
    "    \"Positional encodings and why they are needed\",\n",
    "    \"Training dynamics (masking, batch sizes, learning rates)\",\n",
    "    \"Scaling laws and model sizes\",\n",
    "    \"Popular Transformer variants (BERT, GPT, T5, XLNet, etc.)\",\n",
    "    \"Pretraining objectives (Masked LM, Next Sentence Prediction, etc.)\",\n",
    "    \"Transfer learning and fine-tuning strategies\",\n",
    "    \"Handling long sequences (Longformer, Big Bird, etc.)\",\n",
    "    \"Efficient Transformers (memory and computational optimizations)\",\n",
    "    \"Practical considerations (tokenization, hardware acceleration, libraries)\",\n",
    "    \"Prompt engineering and in-context learning\"\n",
    "]\n",
    "clustering_topics = [\n",
    "    'K-Means Clustering',\n",
    "    'Hierarchical Clustering',\n",
    "    'DBSCAN',\n",
    "    'Gaussian Mixture Models (GMM)',\n",
    "    'HDBSCAN',\n",
    "    'Cluster Evaluation Metrics (Silhouette Score, etc.)',\n",
    "    'Agglomerative Clustering',\n",
    "    'Mean-Shift Clustering'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for topic: K-Means Clustering\n",
      "Generated  13 questions for K-Means Clustering\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_K_Means_Clustering.json\n",
      "Working for topic: Hierarchical Clustering\n",
      "Generated  13 questions for Hierarchical Clustering\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_Hierarchical_Clustering.json\n",
      "Working for topic: DBSCAN\n",
      "Generated  14 questions for DBSCAN\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_DBSCAN.json\n",
      "Working for topic: Gaussian Mixture Models (GMM)\n",
      "Generated  12 questions for Gaussian Mixture Models (GMM)\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_Gaussian_Mixture_Models__GMM_.json\n",
      "Working for topic: HDBSCAN\n",
      "Generated  12 questions for HDBSCAN\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_HDBSCAN.json\n",
      "Working for topic: Cluster Evaluation Metrics (Silhouette Score, etc.)\n",
      "Generated  12 questions for Cluster Evaluation Metrics (Silhouette Score, etc.)\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_Cluster_Evaluation_Metrics__Silhouette_Score__etc__.json\n",
      "Working for topic: Agglomerative Clustering\n",
      "Generated  13 questions for Agglomerative Clustering\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_Agglomerative_Clustering.json\n",
      "Working for topic: Mean-Shift Clustering\n",
      "Generated  12 questions for Mean-Shift Clustering\n",
      "Dumping to /workspaces/codespaces-jupyter/output/questions/clustering_Mean_Shift_Clustering.json\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "for topic in clustering_topics:\n",
    "    base_topic = 'clustering'\n",
    "    print(f\"Working for topic: {topic}\")\n",
    "    questions = generate_questions(topic)\n",
    "    print(f\"Generated  {len(questions['questions'])} questions for {topic}\")\n",
    "    topic_str = re.sub(r'[^a-zA-Z0-9]', '_', topic)\n",
    "    output_json_filename =  f\"{question_output_dir}{base_topic}_{topic_str}.json\"\n",
    "    print(f\"Dumping to {output_json_filename}\")\n",
    "    json.dump( questions, open( output_json_filename, 'w' ) , indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qs = json.load(open(\"/workspaces/codespaces-jupyter/output/questions/L1_and_L2_Regularization.json\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_topics[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
