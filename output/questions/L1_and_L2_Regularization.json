{"questions": [{"question": "1. Basic Concept: Can you explain what L1 and L2 regularization are, and what their primary objectives are in the context of machine learning models?", "response_guideline": "Look for clear definitions: L1 regularization (lasso) adds a penalty equal to the absolute value of the weights, promoting sparsity, while L2 regularization (ridge) adds a penalty equal to the square of the magnitude of weights. A good answer should include how these techniques help prevent overfitting and encourage simpler models."}, {"question": "2. Mathematical Formulations: Derive the cost function for a linear regression model that includes both L1 and L2 regularization terms (Elastic Net). Describe the role of each term in the objective function.", "response_guideline": "Expect a derivation that starts from the standard loss function and adds alpha * ||w||_1 and beta * ||w||^2 terms. The candidate should clearly articulate the balance between promoting sparsity (L1) and controlling weight magnitudes (L2) through mixing parameters."}, {"question": "3. Sparse Solutions: How does L1 regularization lead to sparse model parameters, and in what scenarios might this be beneficial or detrimental?", "response_guideline": "A strong answer should explain that L1 regularization can drive some coefficients exactly to zero, effectively performing feature selection. It should mention benefits like improved model interpretability and potential drawbacks such as excluding features that might contribute subtle information."}, {"question": "4. Optimization Challenges: L1 regularization introduces a non-differentiability at zero. How do modern optimization algorithms handle this issue, and what strategies can be employed when implementing gradient-based methods?", "response_guideline": "Look for mentions of subgradient methods, coordinate descent, and proximal gradient descent. The candidate should highlight techniques such as soft-thresholding and discuss how modern optimizers adapt to non-differentiable points."}, {"question": "5. Gradient Computation: Derive the gradient for a loss function augmented with L2 regularization for a simple linear regression model. How does this differ from the unregularized gradient?", "response_guideline": "The candidate should derive the gradient by differentiating the sum-of-squares error function with an added term lambda * w^2, showing that the gradient for each weight is modified by an additive term 2 * lambda * w. A comparison with the unregularized gradient should be clear."}, {"question": "6. Bias-Variance Trade-off: Discuss how L1 and L2 regularization affect the bias-variance trade-off. In your answer, include what happens as the regularization strength is increased.", "response_guideline": "Look for explanations that increased regularization strength reduces variance but increases bias. They should articulate that while L2 leads to generally small weight estimates, L1 can zero out coefficients, each approach influencing model complexity and prediction variance differently."}, {"question": "7. Feature Scaling: Why is feature scaling important when using L1 and L2 regularization, and what could go wrong if the features are on very different scales?", "response_guideline": "The candidate should mention that regularization penalties assume comparable feature scales. Without scaling, features with larger scales may disproportionately influence the penalty resulting in suboptimal performance, making it harder for the model to learn correctly."}, {"question": "8. Hyperparameter Tuning: How would you approach selecting the optimal regularization parameter(s) in a practical model training scenario, and what challenges might arise if the data is messy or noisy?", "response_guideline": "A good answer should discuss techniques like cross-validation, grid search, or Bayesian optimization for hyperparameter tuning. Challenges such as overfitting, underfitting, and the influence of outliers should be mentioned, as well as strategies to handle noisy or messy data (e.g., robust cross-validation strategies)."}, {"question": "9. Regularization in High-dimensional Settings: In models with a large number of features (possibly greater than the number of observations), how effective are L1 and L2 regularization, and what pitfalls should one be aware of?", "response_guideline": "The response should cover the strengths of L1 regularization for feature selection in high-dimensional spaces, and discuss the potential inability of L2 to perform feature selection. Mention issues related to multicollinearity and the possibility of including irrelevant features."}, {"question": "10. Practical Model Deployment: When deploying a machine learning model in a production environment with non-stationary data, how would you monitor and adjust the regularization to ensure continued model robustness and generalizability?", "response_guideline": "Look for a discussion on model monitoring (drift detection, performance metrics over time), periodic re-validation, the possibility of re-tuning or re-training models, and automated adjustments to regularization parameters based on feedback loops in the deployment pipeline."}, {"question": "11. Comparative Analysis: In what situations might you prefer to use L2 regularization over L1 regularization, and vice versa? Provide examples of applications or datasets where one may outperform the other.", "response_guideline": "A thorough answer should mention that L2 is typically preferred when all features are expected to contribute to the outcome, while L1 is preferred when feature selection is desired or there is redundancy in data. Examples may include signal processing (L2 for noise reduction) versus text classification (L1 for sparse word selection)."}, {"question": "12. Advanced Theoretical Questions: How do the concepts of duality in optimization relate to regularization methods, particularly in the derivation of Lagrange dual problems for setting constraints in the primal formulation?", "response_guideline": "Expect a deep dive into optimization theory. The candidate should link the regularization term to a Lagrange multiplier in the dual formulation, explaining how constraints on the norm of the weights can be equivalently formulated as a regularization penalty in the objective function, and discuss the benefits of this dual perspective."}]}