{
    "questions": [
        {
            "question": "Can you explain the concept of containerization and how Docker differs from traditional virtual machines in terms of architecture and resource utilization?",
            "response_guideline": "A strong answer should detail that containerization isolates applications using lightweight OS-level virtualization, sharing the host OS kernel, and contrast this with VMs which require a full guest OS, leading to higher resource consumption. Mentioning portability, isolation, and efficiency is key."
        },
        {
            "question": "Describe the process of building Docker images. How do the layering and caching mechanisms work, and what best practices would you adopt to optimize image size and build time?",
            "response_guideline": "The candidate should discuss Dockerfile instructions, the concept of image layers, how caching is used to speed up builds, and strategies such as ordering layers, minimizing RUN commands, and removing unnecessary files to optimize image size. Awareness of potential pitfalls in layer ordering and cache invalidation is essential."
        },
        {
            "question": "Outline the key components of the Kubernetes architecture. Can you explain the roles and interactions of the control plane components (like the API server, scheduler, controller manager, and etcd) and the worker nodes?",
            "response_guideline": "A comprehensive response should clearly describe each control plane component and its function, describe how the API server exposes Kubernetes functionalities, how the scheduler assigns pods to nodes, the controller manager maintains cluster state, and etcd serves as the key-value store. Discussion of communication between master and agent nodes will indicate depth."
        },
        {
            "question": "Stateful applications pose unique challenges in a containerized environment. How do StatefulSets, Persistent Volumes (PVs), and Persistent Volume Claims (PVCs) in Kubernetes address these challenges?",
            "response_guideline": "A candidate's answer should emphasize how StatefulSets ensure stable, unique network identities for pods and persistent storage management, detail how PVs and PVCs decouple storage from pods, and touch on potential complications like scaling and recovery. Mention of managing state in dynamic orchestration environments is expected."
        },
        {
            "question": "Consider a scenario where your application experiences unpredictable load spikes. How would you design a Kubernetes deployment to handle auto-scaling, ensure reliability, and manage custom metrics?",
            "response_guideline": "Look for an explanation covering Horizontal Pod Autoscaler (HPA), vertical scaling alternatives if applicable, use of readiness and liveness probes for reliability, integration of custom metrics for specific application needs, and acknowledgement of challenges such as resource contention and rapid scaling latency."
        },
        {
            "question": "Container orchestration in a multi-cloud setup comes with its own challenges. What potential issues might arise when managing Kubernetes clusters across different cloud providers, and how would you address these from a networking, security, and operational standpoint?",
            "response_guideline": "The candidate should mention challenges like heterogeneous networking models, differences in cloud provider services, latency, security policies, and migration complexity. Solutions could include using service meshes, unified deployment tooling, centralized monitoring, and ensuring configuration consistency across clusters."
        },
        {
            "question": "Imagine you are deploying a complex microservices architecture using Kubernetes in production. What strategies would you use for configuration management, secret handling, rolling updates, and fault diagnosis in a messy real-world environment?",
            "response_guideline": "A top-tier answer would include using ConfigMaps and Secrets for configuration, leveraging rolling and blue-green deployments (or canary releases) for updates, implementing robust logging and monitoring systems, and discussing troubleshooting techniques (like kubectl logs, event watchers, or distributed tracing). A discussion on continuous integration/continuous deployment (CI/CD) pipelines and handling rollback processes would also demonstrate real-world experience."
        }
    ]
}