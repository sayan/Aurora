{"questions": [{"question": "Explain how a decision tree works. What are the basic principles behind its structure and decision-making process?", "response_guideline": "A good answer should describe the process of recursive partitioning, the notion of feature splitting, and how the tree represents decisions. The candidate should mention concepts such as nodes, splits, leaves, and the method of arriving at predictions by traversing the tree."}, {"question": "What are the common criteria for splitting nodes in a decision tree? Elaborate on metrics like Information Gain, Gini Impurity, and others.", "response_guideline": "The answer should cover the mathematical formulation for Information Gain (using entropy) and Gini Impurity. The candidate should be able to compare their effects on model behavior and discuss scenarios where one might be preferred over the other."}, {"question": "How do you compute entropy in the context of decision trees, and why is it important?", "response_guideline": "A solid answer will define entropy formally, explain its role in measuring the impurity or disorder of a node, and describe how it guides the selection of splits. Mathematical derivations or examples that compute entropy for a binary outcome are desirable."}, {"question": "Discuss the concept of overfitting in decision trees. What techniques can be used to mitigate it?", "response_guideline": "The answer should discuss how decision trees can overfit due to high complexity, and outline techniques like pruning (cost-complexity pruning, pre-pruning), setting maximum depth, and minimum sample splits. A discussion of the bias-variance trade-off is also expected."}, {"question": "What is the purpose of cost-complexity pruning in decision trees, and how is the optimal subtree selected?", "response_guideline": "The candidate should explain that cost-complexity pruning balances model fit with complexity by introducing a penalty for larger trees. They should detail the process of evaluating a sequence of subtrees and selecting one based on cross-validation or a complexity parameter like alpha."}, {"question": "How do decision trees handle continuous versus categorical variables during the splitting process?", "response_guideline": "The answer should indicate that for continuous variables, decision trees seek an optimal threshold that best splits the data, while for categorical variables they might consider all possible partitions or use more efficient algorithms. A discussion of computational costs and potential issues is expected."}, {"question": "Describe how missing data is typically handled in decision tree algorithms. What are the trade-offs of different approaches?", "response_guideline": "A good answer will mention methods such as surrogate splits, imputation strategies, or treating missing values as a separate category. Discussion should include how these methods impact model performance and how complexity is managed when dealing with messy data."}, {"question": "Discuss the scalability issues faced when training decision trees on very large datasets. What strategies or modifications can be applied to address these challenges?", "response_guideline": "Candidates should address the computational complexity of finding optimal splits and may suggest techniques such as sampling, using distributed implementations, or approximations. They should also mention memory management and algorithmic optimizations such as parallel tree building."}, {"question": "In what ways can decision trees be sensitive to data variations? How would you evaluate the stability of a decision tree model?", "response_guideline": "A comprehensive answer should mention issues like variance in tree structure with small changes in training data (instability), discuss ensemble methods as a remedy, and suggest methods including bootstrapping or analyzing model variance. Discussion about sensitivity analysis and cross-validation is also beneficial."}, {"question": "How would you interpret and visualize a decision tree to make it understandable to non-technical stakeholders?", "response_guideline": "The response should consider methods for visual explanation (using tree diagrams or simplified decision rules), the importance of clarity in node representation, and the use of summary rules. The candidate might also address the balance between model transparency and complexity."}, {"question": "Explain the concept of surrogate splits in decision trees. When and why are they used?", "response_guideline": "The candidate should explain that surrogate splits provide alternative splitting rules when the primary splitter is missing. They should discuss how surrogate splits are determined, their importance in handling missing data, and the potential pitfalls if surrogates do not mimic the primary split well."}, {"question": "Can you discuss potential pitfalls of decision trees, such as bias towards features with more levels, and how you might address them?", "response_guideline": "A strong answer should note that decision trees can be biased towards variables with many levels (high cardinality), leading to overfitting. The candidate should mention possible remedies like feature engineering, using penalization, or adopting methods such as ensemble learning."}, {"question": "Describe how you would deploy a decision tree model in a production environment. What considerations must be taken into account regarding scalability, latency, and interpretability?", "response_guideline": "The answer should cover practical deployment aspects such as model serialization, integration with existing systems, handling of real-time predictions, and scalability using batch processing or APIs. It should also discuss the balance between model complexity and responsiveness, as well as monitoring for drift and performance in the live environment."}]}