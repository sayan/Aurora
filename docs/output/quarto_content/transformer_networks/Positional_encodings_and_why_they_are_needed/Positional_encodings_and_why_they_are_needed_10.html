<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>positional_encodings_and_why_they_are_needed_10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-11.-describe-a-potential-pitfall-when-implementing-positional-encodings-in-a-new-or-hybrid-architecture-for-example-a-cnn-transformer-fusion.-how-would-you-identify-and-mitigate-this-issue" class="level2">
<h2 class="anchored" data-anchor-id="question-11.-describe-a-potential-pitfall-when-implementing-positional-encodings-in-a-new-or-hybrid-architecture-for-example-a-cnn-transformer-fusion.-how-would-you-identify-and-mitigate-this-issue">Question: 11. Describe a potential pitfall when implementing positional encodings in a new or hybrid architecture (for example, a CNN-transformer fusion). How would you identify and mitigate this issue?</h2>
<p><strong>Best Answer</strong></p>
<p>Positional encodings are crucial for enabling transformer models to process sequential data effectively, as the transformer architecture itself is permutation-invariant and does not inherently understand the order of the input sequence. They inject information about the position of each element in the sequence, allowing the model to differentiate between elements based on their location.</p>
<p>However, when integrating positional encodings into new or hybrid architectures, particularly those that fuse CNNs and transformers, several pitfalls can arise. These primarily stem from differences in how CNNs and transformers process positional information and the potential for misalignment or interference between the positional scales.</p>
<p>Here’s a breakdown of potential pitfalls, identification strategies, and mitigation techniques:</p>
<p><strong>1. Pitfall: Positional Scale Mismatch</strong></p>
<ul>
<li><p><strong>Description:</strong> CNNs, especially those with pooling layers, inherently encode positional information through the receptive fields of their filters. The positional information learned by CNNs exists within the spatial arrangement of features. Transformers, on the other hand, explicitly add positional encodings to the input embeddings. If the scales or representations of positional information learned by the CNN and the explicitly injected positional embeddings are significantly different, their fusion can lead to suboptimal performance. The scales are important because the magnitudes of the values could be different, and the range of values could be different, resulting in one having a greater importance over the other.</p></li>
<li><p><strong>Mathematical Intuition:</strong> Let <span class="math inline">\(X_{cnn}\)</span> be the output feature maps of the CNN, where positional information is implicitly encoded. Let <span class="math inline">\(P_{transformer}\)</span> be the explicit positional embeddings added to the transformer inputs. The issue is that directly adding or concatenating these, like <span class="math inline">\(X_{fused} = X_{cnn} + P_{transformer}\)</span> or <span class="math inline">\(X_{fused} = concat(X_{cnn}, P_{transformer})\)</span>, may not be optimal if the “positional scales” are dissimilar. The gradients during backpropagation will be affected by this difference in scale.</p></li>
<li><p><strong>Identification:</strong></p>
<ul>
<li><strong>Ablation studies:</strong> Train the hybrid model with and without the explicit positional embeddings to assess their impact. If removing the explicit embeddings improves performance or shows no significant change, it suggests a mismatch in positional scales.</li>
<li><strong>Visualization:</strong> Visualize the learned representations of both the CNN feature maps and the positional embeddings (e.g., using t-SNE or PCA). Look for differences in the distribution and structure of these representations.</li>
<li><strong>Gradient Analysis:</strong> Examine the gradients flowing through the CNN and positional embeddings. Significantly larger gradients for one component compared to the other may indicate a scale mismatch.</li>
</ul></li>
<li><p><strong>Mitigation:</strong></p>
<ul>
<li><strong>Learnable Scaling Factors:</strong> Introduce learnable scaling factors for both the CNN outputs and the positional embeddings before fusion. This allows the model to automatically adjust the relative importance of each positional source. This can be mathematically written as: <span class="math display">\[X_{fused} = \alpha X_{cnn} + \beta P_{transformer}\]</span> where <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are learnable parameters.</li>
<li><strong>Normalization:</strong> Apply normalization techniques (e.g., layer normalization, batch normalization) to both the CNN outputs and the positional embeddings <em>before</em> fusion. This helps to bring their scales into a similar range.</li>
<li><strong>Projection Layers:</strong> Use linear projection layers to map the CNN outputs and positional embeddings into a common embedding space before fusion. This allows the model to learn a more compatible representation. <span class="math display">\[X_{cnn\_projected} = W_1 X_{cnn} + b_1\]</span> <span class="math display">\[P_{transformer\_projected} = W_2 P_{transformer} + b_2\]</span> <span class="math display">\[X_{fused} = X_{cnn\_projected} + P_{transformer\_projected}\]</span></li>
<li><strong>Gating Mechanisms:</strong> Employ gating mechanisms (e.g., using a sigmoid function) to dynamically weigh the contributions of the CNN and transformer positional information. This allows the model to adaptively control the flow of positional information from each source based on the input.</li>
</ul></li>
</ul>
<p><strong>2. Pitfall: Interference and Redundancy</strong></p>
<ul>
<li><p><strong>Description:</strong> In some cases, the explicit positional embeddings might interfere with the positional information already encoded by the CNN, leading to redundancy or even detrimental effects. The CNN may have already extracted spatial relationships that overlap with the injected positional information, causing confusion for the model.</p></li>
<li><p><strong>Identification:</strong> Similar techniques to scale mismatch, especially ablation studies, can help detect interference. If the performance is significantly better without positional encodings, it suggests interference.</p></li>
<li><p><strong>Mitigation:</strong></p>
<ul>
<li><strong>Careful Architectural Design:</strong> Consider the role of the CNN and transformer in the hybrid architecture. If the CNN is primarily responsible for feature extraction and local context modeling, the transformer might only need coarse-grained positional information. Avoid overly complex positional encodings if the CNN already captures fine-grained positional details.</li>
<li><strong>Conditional Positional Encoding:</strong> Instead of unconditionally adding the positional embeddings, explore methods to make their injection conditional on the CNN features. For example, use the CNN features to modulate the positional embeddings before adding them to the transformer input.</li>
<li><strong>Attention-Based Fusion:</strong> Use attention mechanisms to fuse the CNN features and positional embeddings. The attention mechanism can learn which parts of the CNN features are most relevant for the positional information and vice versa, allowing for more selective integration.</li>
</ul></li>
</ul>
<p><strong>3. Pitfall: Handling Variable Sequence Lengths</strong></p>
<ul>
<li><p><strong>Description:</strong> Positional encodings are often pre-computed for a fixed maximum sequence length. When dealing with variable-length sequences, especially in a hybrid CNN-transformer setting, proper handling of positional information becomes crucial. The model might encounter sequence lengths longer than what the positional encodings were trained on, or the positional information might be inconsistent across different sequence lengths.</p></li>
<li><p><strong>Identification:</strong> Monitor the model’s performance on sequences of varying lengths. A significant drop in performance for longer sequences might indicate issues with positional encoding handling.</p></li>
<li><p><strong>Mitigation:</strong></p>
<ul>
<li><strong>Extrapolation:</strong> Train the positional encodings to extrapolate to longer sequence lengths. This can be achieved by using sinusoidal positional encodings, which can generalize to unseen lengths.</li>
</ul></li>
</ul>
<p><span class="math display">\[PE(pos, 2i) = sin(pos / 10000^{2i/d_{model}})\]</span> <span class="math display">\[PE(pos, 2i+1) = cos(pos / 10000^{2i/d_{model}})\]</span></p>
<pre><code>    where $pos$ is the position and $i$ is the dimension.
*   **Relative Positional Encodings:** Use relative positional encodings, which encode the relative distance between elements instead of absolute positions.  This makes the model less sensitive to the absolute sequence length.
*   **Padding and Masking:** Properly pad shorter sequences and mask the corresponding positional embeddings to avoid introducing noise. Ensure that the attention mechanism in the transformer ignores the padded positions.</code></pre>
<p><strong>4. Pitfall: Domain Mismatch</strong></p>
<ul>
<li><p><strong>Description:</strong> This is a broader issue but relevant. If the positional encodings were pre-trained on a different dataset or task, they might not be directly transferable to the new hybrid architecture. The distribution of positions and their relationships might be different, leading to suboptimal performance.</p></li>
<li><p><strong>Identification:</strong> Analyze the pre-trained positional encodings and compare their characteristics to the new task’s positional distributions.</p></li>
<li><p><strong>Mitigation:</strong></p>
<ul>
<li><strong>Fine-tuning:</strong> Fine-tune the pre-trained positional encodings on the new task. This allows the model to adapt the positional information to the specific requirements of the hybrid architecture.</li>
<li><strong>Training from Scratch:</strong> If the domain mismatch is significant, consider training the positional encodings from scratch along with the rest of the model.</li>
</ul></li>
</ul>
<p>By carefully considering these potential pitfalls, implementing appropriate identification strategies, and applying the recommended mitigation techniques, it is possible to effectively integrate positional encodings into new or hybrid architectures and leverage their benefits for sequential data processing.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to present this information in an interview, maintaining a senior-level tone and ensuring clarity:</p>
<ol type="1">
<li><strong>Start with the Importance (Context):</strong>
<ul>
<li>“Positional encodings are critical for transformers because, unlike RNNs or CNNs, transformers are permutation-invariant. They need a way to understand the order of elements in a sequence.”</li>
<li>“When integrating transformers with other architectures, like CNNs, we need to be careful about how positional information is handled.”</li>
</ul></li>
<li><strong>Introduce the Core Issue: Positional Scale Mismatch</strong>
<ul>
<li>“One of the primary challenges is a potential mismatch in ‘positional scales’ between the CNN and the explicit positional embeddings. CNNs implicitly encode positional information through receptive fields, while transformers use explicit encodings. If these scales are different, their fusion can be detrimental.”</li>
<li>“Mathematically, if we consider the CNN output as <span class="math inline">\(X_{cnn}\)</span> and the transformer positional encoding as <span class="math inline">\(P_{transformer}\)</span>, directly adding or concatenating them (<span class="math inline">\(X_{fused} = X_{cnn} + P_{transformer}\)</span>) might not be optimal without considering their respective scales.”</li>
</ul></li>
<li><strong>Explain Identification Methods (Practical Approach):</strong>
<ul>
<li>“To identify this, I’d start with ablation studies – training with and without the explicit embeddings. If removing them improves performance, it indicates a mismatch.”</li>
<li>“Visualizing the learned representations using techniques like t-SNE or PCA can also reveal differences in the distribution and structure of the positional information.”</li>
<li>“Another approach is to examine the gradients. If one component has significantly larger gradients, it suggests a scale imbalance.”</li>
</ul></li>
<li><strong>Present Mitigation Strategies (Depth and Control):</strong>
<ul>
<li>“The mitigation strategies involve adjusting the relative importance of each positional source. We can introduce learnable scaling factors, such as <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> in the equation <span class="math inline">\(X_{fused} = \alpha X_{cnn} + \beta P_{transformer}\)</span>.”</li>
<li>“Normalization techniques like layer normalization or batch normalization can also bring the scales into a similar range.”</li>
<li>“Projection layers, as well as gating mechanisms, can further help in learning the compatible representations.”</li>
</ul></li>
<li><strong>Discuss Other Pitfalls (Breadth of Knowledge):</strong>
<ul>
<li>“Beyond scale mismatch, we need to consider potential interference and redundancy. The explicit embeddings might interfere with the CNN’s inherent positional understanding.”</li>
<li>“Handling variable sequence lengths is also critical. If the model encounters sequences longer than the maximum length used during training, we need to use techniques like extrapolation with sinusoidal positional encodings (show the formulas).”</li>
<li>“Finally, domain mismatch. Fine-tuning the pre-trained positional encodings might be necessary to adapt them to the new task.”</li>
</ul></li>
<li><strong>Conclude with Synthesis (Senior Perspective):</strong>
<ul>
<li>“In summary, effectively integrating positional encodings into hybrid architectures requires careful consideration of positional scales, potential interference, sequence length handling, and domain adaptation. By applying the right identification and mitigation strategies, we can leverage the benefits of both CNNs and transformers.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace:</strong> Slow down when explaining equations. Don’t rush through them.</li>
<li><strong>Emphasis:</strong> Highlight the practical aspects – how you would <em>actually</em> identify and fix the problem.</li>
<li><strong>Engagement:</strong> Ask the interviewer if they have any questions or would like you to elaborate on a specific point.</li>
<li><strong>Confidence:</strong> Speak confidently about the challenges and solutions. This is a senior-level discussion, so project your expertise.</li>
<li><strong>Adaptability:</strong> If the interviewer seems less mathematically inclined, focus on the conceptual explanations and practical identification/mitigation strategies.</li>
</ul>
<p>By following this guide, you can deliver a comprehensive and insightful answer that showcases your senior-level expertise in positional encodings and hybrid architectures.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>