<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>positional_encodings_and_why_they_are_needed_0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-1.-what-are-positional-encodings-in-the-context-of-transformer-models-and-why-are-they-necessary" class="level2">
<h2 class="anchored" data-anchor-id="question-1.-what-are-positional-encodings-in-the-context-of-transformer-models-and-why-are-they-necessary">Question: 1. What are positional encodings in the context of transformer models, and why are they necessary?</h2>
<p><strong>Best Answer</strong></p>
<p>Positional encodings are crucial components in Transformer models, primarily because Transformers, unlike Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs), inherently lack a mechanism to understand the order or position of elements within a sequence. This order-agnostic property stems from the self-attention mechanism, which processes all input tokens in parallel and treats them equally, regardless of their sequential arrangement.</p>
<p><strong>The Problem: Order Agnosticism</strong></p>
<p>Consider a sentence “cat sat mat” and a permutation of it “mat cat sat.” Without positional information, a Transformer would process these identically, which is clearly undesirable for most natural language processing tasks. Traditional sequence models like RNNs implicitly encode positional information through their sequential processing. CNNs capture local dependencies, giving some sense of relative position. Transformers, by design, discard this information for the sake of parallelization and computational efficiency.</p>
<p><strong>The Solution: Positional Encodings</strong></p>
<p>Positional encodings are vectors added to the input embeddings at the bottom of the encoder and decoder stacks. These vectors provide information about the position of each token in the sequence. By adding these encodings, we inject information about the relative or absolute position of the tokens, enabling the Transformer to differentiate between tokens at different positions.</p>
<p><strong>Mathematical Formulation</strong></p>
<p>Positional encodings, denoted as <span class="math inline">\(PE\)</span>, are typically a function of the token’s position <span class="math inline">\(pos\)</span> and the dimension <span class="math inline">\(i\)</span> of the encoding vector. Two common approaches exist: learned positional embeddings and fixed positional encodings. The original Transformer paper introduced fixed sinusoidal positional encodings.</p>
<ul>
<li><p><strong>Sinusoidal Positional Encodings:</strong> The original Transformer paper by Vaswani et al.&nbsp;(2017) proposed using sine and cosine functions of different frequencies. The positional encoding <span class="math inline">\(PE(pos, i)\)</span> is defined as:</p>
<p><span class="math display">\[
PE(pos, 2i) = sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)
\]</span></p>
<p><span class="math display">\[
PE(pos, 2i+1) = cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(pos\)</span> is the position of the token in the sequence.</li>
<li><span class="math inline">\(i\)</span> is the dimension of the positional encoding vector (<span class="math inline">\(0 \le i &lt; d_{model}/2\)</span>).</li>
<li><span class="math inline">\(d_{model}\)</span> is the dimensionality of the input embedding and positional encoding vectors. The frequency decreases as the dimension <span class="math inline">\(i\)</span> increases.</li>
</ul></li>
<li><p><strong>Learned Positional Embeddings:</strong></p>
<p>In this approach, positional embeddings are learned during training, similar to word embeddings. A positional embedding matrix <span class="math inline">\(E \in \mathbb{R}^{L \times d_{model}}\)</span> is created, where <span class="math inline">\(L\)</span> is the maximum sequence length and <span class="math inline">\(d_{model}\)</span> is the embedding dimension. The <span class="math inline">\(pos\)</span>-th row of <span class="math inline">\(E\)</span> represents the positional encoding for position <span class="math inline">\(pos\)</span>. These embeddings are directly learned from the data.</p></li>
</ul>
<p><strong>Why Sinusoidal Encodings?</strong></p>
<p>The original paper provided justification for using sinusoidal functions. One key property is that they allow the model to attend to relative positions. For any fixed offset <span class="math inline">\(k\)</span>, <span class="math inline">\(PE_{pos+k}\)</span> can be represented as a linear function of <span class="math inline">\(PE_{pos}\)</span>. This allows the model to easily learn to attend to positions at a certain offset. This can be shown using trigonometric identities:</p>
<p><span class="math inline">\(sin(a + b) = sin(a)cos(b) + cos(a)sin(b)\)</span> <span class="math inline">\(cos(a + b) = cos(a)cos(b) - sin(a)sin(b)\)</span></p>
<p>Therefore,</p>
<p><span class="math inline">\(PE(pos+k, 2i) = sin(\frac{pos+k}{10000^{2i/d_{model}}}) = sin(\frac{pos}{10000^{2i/d_{model}}})cos(\frac{k}{10000^{2i/d_{model}}}) + cos(\frac{pos}{10000^{2i/d_{model}}})sin(\frac{k}{10000^{2i/d_{model}}})\)</span></p>
<p><span class="math inline">\(PE(pos+k, 2i+1) = cos(\frac{pos+k}{10000^{2i/d_{model}}}) = cos(\frac{pos}{10000^{2i/d_{model}}})cos(\frac{k}{10000^{2i/d_{model}}}) - sin(\frac{pos}{10000^{2i/d_{model}}})sin(\frac{k}{10000^{2i/d_{model}}})\)</span></p>
<p>Hence, <span class="math inline">\(PE(pos+k)\)</span> can be expressed as a linear transformation of <span class="math inline">\(PE(pos)\)</span>.</p>
<p><strong>Adding Positional Encodings</strong></p>
<p>The positional encoding <span class="math inline">\(PE\)</span> is added to the word embeddings <span class="math inline">\(WE\)</span> to create the input to the Transformer:</p>
<p><span class="math display">\[
X = WE + PE
\]</span></p>
<p>This summation allows the model to leverage both the semantic information from the word embeddings and the positional information from the positional encodings.</p>
<p><strong>Advantages and Disadvantages</strong></p>
<ul>
<li><strong>Sinusoidal Positional Encodings:</strong>
<ul>
<li><em>Advantages:</em> Can generalize to sequence lengths longer than those seen during training, as the functions are defined for any position. No parameters to learn.</li>
<li><em>Disadvantages:</em> Potentially less flexible than learned embeddings.</li>
</ul></li>
<li><strong>Learned Positional Embeddings:</strong>
<ul>
<li><em>Advantages:</em> Can be optimized during training, potentially learning more task-specific positional representations.</li>
<li><em>Disadvantages:</em> Cannot generalize to sequence lengths longer than the maximum length used during training, unless extrapolation techniques are used. Require additional parameters.</li>
</ul></li>
</ul>
<p><strong>Real-World Considerations</strong></p>
<ul>
<li><strong>Sequence Length:</strong> The choice between fixed and learned encodings often depends on the expected maximum sequence length. For tasks with variable-length sequences or very long sequences, sinusoidal encodings may be preferred.</li>
<li><strong>Task Specificity:</strong> For specific tasks with fixed sequence lengths, learned embeddings might provide a performance boost.</li>
<li><strong>Extrapolation:</strong> Techniques exist to extrapolate learned positional embeddings to longer sequence lengths, such as relative positional encodings or kernel extrapolation methods.</li>
<li><strong>Relative Positional Encodings:</strong> Instead of encoding absolute positions, relative positional encodings encode the offset between tokens. This approach can improve generalization and robustness.</li>
</ul>
<p>In summary, positional encodings are essential for Transformer models to effectively process sequential data by providing information about the position of each token. Both fixed and learned positional encodings are viable options, each with its own advantages and disadvantages depending on the specific application.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to explain positional encodings in an interview:</p>
<ol type="1">
<li><strong>Start with the “Why”:</strong> Begin by emphasizing why positional encodings are necessary. “Transformers, unlike RNNs or CNNs, process input in parallel and are inherently order-agnostic. This means they don’t know the position of words in a sentence.” Illustrate this with a simple example, like “cat sat mat” versus “mat sat cat.”</li>
<li><strong>Define Positional Encodings:</strong> “Positional encodings are vectors added to the input embeddings that provide information about the position of each token in the sequence. They inject sequential information into the model.”</li>
<li><strong>Explain the Two Main Types:</strong> “There are two main ways to create these encodings: fixed sinusoidal encodings and learned embeddings.”</li>
<li><strong>Describe Sinusoidal Encodings (with caution):</strong> “The original Transformer paper used sinusoidal functions. The positional encoding for a position <em>pos</em> and dimension <em>i</em> is calculated using sine and cosine functions with different frequencies. The formulas are: <span class="math inline">\(&lt;PE(pos, 2i) = sin(\frac{pos}{10000^{2i/d_{model}}})&gt;\)</span> and <span class="math inline">\(&lt;PE(pos, 2i+1) = cos(\frac{pos}{10000^{2i/d_{model}}})&gt;\)</span>. Importantly, I can derive how the positional encodings can then represent the relative position.” <strong>STOP</strong>. Only proceed with the derivation if the interviewer seems interested and engaged. Don’t just launch into the math without prompting.</li>
<li><strong>Explain Learned Encodings:</strong> “Alternatively, we can learn positional embeddings directly from the data, similar to how we learn word embeddings. This involves creating a positional embedding matrix and training it along with the rest of the model.”</li>
<li><strong>Discuss the Trade-offs:</strong> “Sinusoidal encodings can generalize to longer sequences because they are based on mathematical functions. Learned encodings can be more task-specific but might not generalize as well to longer sequences than seen during training.”</li>
<li><strong>Mention Real-World Considerations:</strong> “The choice depends on the application. For very long sequences, sinusoidal encodings are often preferred. For tasks with fixed-length sequences, learned embeddings might be better.” Also, mentioning relative positional encodings show a good grasp of the topic and its variations.</li>
<li><strong>Interaction Tips:</strong>
<ul>
<li><strong>Gauge Interest:</strong> Pay attention to the interviewer’s body language and questions. If they seem particularly interested in the mathematical details, provide more depth. If they seem less interested, focus on the high-level concepts.</li>
<li><strong>Pause for Questions:</strong> After explaining each key concept, pause and ask if they have any questions. This shows that you are engaged and want to ensure they understand.</li>
<li><strong>Avoid Jargon:</strong> While it’s important to use technical terms, avoid unnecessary jargon. Explain concepts clearly and concisely.</li>
<li><strong>Relate to Practical Applications:</strong> If possible, relate the concepts to real-world applications or projects you’ve worked on. This demonstrates your practical understanding.</li>
<li><strong>Be Confident, but Humble:</strong> Speak with confidence, but be open to feedback and questions. Acknowledge that there are different approaches and that the best approach depends on the specific problem.</li>
</ul></li>
<li><strong>End with:</strong></li>
</ol>
<ul>
<li>Summing <span class="math inline">\(WE\)</span> and <span class="math inline">\(PE\)</span> allows the model to incorporate both the semantic information from the word embeddings and the positional information from the positional encodings and the Transformer can differentiate between the tokens at different positions.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>