<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>practical_considerations__tokenization__hardware_acceleration__libraries__6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-when-building-scalable-nlp-systems-how-do-you-manage-the-integration-and-compatibility-issues-between-various-libraries-handling-tokenization-and-hardware-acceleration" class="level2">
<h2 class="anchored" data-anchor-id="question-when-building-scalable-nlp-systems-how-do-you-manage-the-integration-and-compatibility-issues-between-various-libraries-handling-tokenization-and-hardware-acceleration">Question: When building scalable NLP systems, how do you manage the integration and compatibility issues between various libraries handling tokenization and hardware acceleration?</h2>
<p><strong>Best Answer</strong></p>
<p>Building scalable NLP systems requires careful consideration of the interactions between various components, especially libraries for tokenization and hardware acceleration. Incompatibilities can arise due to different versions, dependencies, or underlying assumptions, hindering performance and scalability. Here’s a detailed approach to managing these issues:</p>
<p><strong>1. Modular Architecture:</strong></p>
<ul>
<li><strong>Rationale:</strong> Decompose the NLP system into loosely coupled, independent modules. This reduces the impact of changes in one module on others. For instance, the tokenization module should ideally expose a clear, well-defined API, allowing it to be swapped out without affecting the downstream components.</li>
<li><strong>Implementation:</strong> Use architectural patterns like microservices or a layered architecture. Define clear interfaces and data contracts between modules. For example, a tokenization service could expose an API that accepts raw text and returns a list of tokens in a standardized format (e.g., JSON, Protocol Buffers).</li>
<li><strong>Example:</strong> Consider three modules: <code>TokenizationService</code>, <code>EmbeddingService</code>, and <code>ClassificationService</code>. Each service communicates using well-defined data structures, minimizing direct dependency.</li>
</ul>
<p><strong>2. Dependency Management:</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Explicitly define and manage all library dependencies to ensure consistent environments across development, testing, and production.</p></li>
<li><p><strong>Implementation:</strong> Utilize tools like <code>pip</code> (with <code>requirements.txt</code>), <code>conda</code>, <code>poetry</code>, or containerization technologies like Docker. Pin library versions (e.g., <code>transformers==4.30.2</code>, <code>torch==2.0.1</code>) to avoid unexpected behavior caused by automatic updates.</p></li>
<li><p><strong>Why Pinning Matters:</strong> A seemingly minor update in a library like <code>transformers</code> can drastically change the tokenization scheme or the expected input format of models, leading to unpredictable results. Pinned versions guarantee consistency.</p></li>
<li><p><strong>Example:</strong> A <code>requirements.txt</code> file might look like this:</p>
<pre><code>transformers==4.30.2
torch==2.0.1
sentencepiece==0.1.99
accelerate==0.21.0
protobuf==3.20.0</code></pre></li>
</ul>
<p><strong>3. Version Control and Branching Strategy:</strong></p>
<ul>
<li><strong>Rationale:</strong> Track all code changes, configurations, and dependency definitions using version control. Use a well-defined branching strategy (e.g., Gitflow) to manage development, testing, and release cycles.</li>
<li><strong>Implementation:</strong> Use Git to manage the codebase. Create separate branches for new features, bug fixes, and releases. Tag releases with specific version numbers. Store dependency files (e.g., <code>requirements.txt</code>, <code>poetry.lock</code>) in version control.</li>
<li><strong>Benefits:</strong> Version control allows you to easily revert to a previous stable state if a new change introduces compatibility issues. Branching facilitates parallel development and testing.</li>
</ul>
<p><strong>4. Continuous Integration and Continuous Deployment (CI/CD):</strong></p>
<ul>
<li><strong>Rationale:</strong> Automate the build, test, and deployment process to ensure that changes are thoroughly tested and integrated before being deployed to production.</li>
<li><strong>Implementation:</strong> Use CI/CD tools like Jenkins, GitHub Actions, GitLab CI, or CircleCI. Define automated tests that cover different aspects of the system, including unit tests, integration tests, and end-to-end tests. Run these tests on every commit or pull request.</li>
<li><strong>Importance of Testing:</strong> Specifically, integration tests should verify that the tokenization module correctly interacts with other modules, and that the hardware acceleration is functioning as expected.</li>
<li><strong>Example Test Scenarios:</strong>
<ul>
<li>Tokenize a diverse set of text inputs and compare the output against known correct tokenizations.</li>
<li>Measure the inference speed with and without hardware acceleration (e.g., GPU) to confirm that acceleration is working.</li>
<li>Test different batch sizes to ensure that the system scales appropriately.</li>
</ul></li>
</ul>
<p><strong>5. Abstraction Layers:</strong></p>
<ul>
<li><strong>Rationale:</strong> Create abstraction layers to isolate the core logic of the NLP system from the specific details of the underlying libraries.</li>
<li><strong>Implementation:</strong> Define interfaces or abstract classes that represent the functionality you need from tokenization and hardware acceleration libraries. Implement concrete classes that wrap the specific libraries you are using.</li>
<li><strong>Benefits:</strong> Abstraction layers make it easier to switch between different libraries or versions without affecting the rest of the system. They also improve code maintainability and testability.</li>
<li><strong>Example:</strong> Create an <code>AbstractTokenizer</code> class with methods like <code>tokenize(text)</code> and <code>detokenize(tokens)</code>. Implement concrete subclasses like <code>HFTokenizer</code> (wrapping Hugging Face Transformers tokenizers) and <code>SpacyTokenizer</code> (wrapping spaCy tokenizers). This allows easy switching of tokenizers by changing configuration.</li>
</ul>
<p><strong>6. Containerization (Docker):</strong></p>
<ul>
<li><strong>Rationale:</strong> Package the NLP system and its dependencies into a container. Containers provide a consistent and isolated environment that can be easily deployed to different platforms.</li>
<li><strong>Implementation:</strong> Create a Dockerfile that specifies the base image, installs the required dependencies, and configures the system. Use Docker Compose to manage multi-container applications.</li>
<li><strong>Benefits:</strong> Containerization eliminates dependency conflicts and ensures that the system runs consistently regardless of the underlying infrastructure. It also simplifies deployment and scaling.</li>
</ul>
<p><strong>7. Monitoring and Logging:</strong></p>
<ul>
<li><strong>Rationale:</strong> Monitor the performance and behavior of the NLP system in production to detect and diagnose issues. Log relevant events and metrics to facilitate troubleshooting.</li>
<li><strong>Implementation:</strong> Use monitoring tools like Prometheus, Grafana, or Datadog to track key metrics like CPU usage, memory usage, GPU utilization, and request latency. Implement logging to record errors, warnings, and informational messages.</li>
<li><strong>Importance:</strong> Monitor tokenization speeds and hardware acceleration effectiveness in real-time to detect regressions caused by library updates or configuration changes.</li>
</ul>
<p><strong>8. Virtual Environments and Environment Variables:</strong></p>
<ul>
<li><strong>Rationale:</strong> Using virtual environments provides isolation for each project and can prevent dependency conflicts across different projects. Environment variables allow configuration parameters to be managed separately from the code.</li>
<li><strong>Implementation:</strong> Use tools like <code>virtualenv</code> or <code>conda env</code> to create isolated environments. Employ environment variables for sensitive information such as API keys or model paths. Use configuration files (e.g., YAML, JSON) for non-sensitive parameters.</li>
</ul>
<p><strong>9. Testing Hardware Acceleration:</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Hardware acceleration, such as GPU usage, can be heavily reliant on drivers and compatibility. It’s crucial to test this.</p></li>
<li><p><strong>Implementation:</strong> Design tests that explicitly verify GPU usage and measure its impact on performance. Monitor GPU utilization during these tests. For instance, using <code>torch.cuda.is_available()</code> to confirm CUDA is properly installed and accessible, and measure the time taken for operations on GPU vs CPU.</p></li>
<li><p><strong>Example Test Code (PyTorch):</strong></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a large tensor</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>size <span class="op">=</span> (<span class="dv">1000</span>, <span class="dv">1000</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(size, device<span class="op">=</span>device)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(size, device<span class="op">=</span>device)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform matrix multiplication</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.matmul(a, b)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Time taken on </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>end_time <span class="op">-</span> start_time<span class="sc">:.4f}</span><span class="ss"> seconds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
<p><strong>10. Example Scenario: Dealing with Tokenizer Incompatibilities in Transformers Library</strong></p>
<p>Suppose you have a model trained with <code>transformers==4.20.0</code> using the <code>BertTokenizerFast</code>. You decide to upgrade to <code>transformers==4.35.0</code>. However, the tokenization process is changed slightly in the new version, causing a mismatch between the tokens the model expects and the tokens it receives.</p>
<p><strong>Mitigation Steps:</strong></p>
<ol type="1">
<li><strong>Pin Versions:</strong> Stick to <code>transformers==4.20.0</code> until you can retrain or fine-tune the model.</li>
<li><strong>Test Thoroughly:</strong> Before upgrading, run a comprehensive suite of tests on a representative sample of data.</li>
<li><strong>Tokenizer Alignment:</strong> If an upgrade is necessary, investigate changes in the tokenizer’s behavior using the library’s documentation and example code.</li>
<li><strong>Fine-tuning or retraining:</strong> Fine-tune/retrain the model using the new tokenizer to accommodate for token differences.</li>
</ol>
<p>By implementing these practices, you can effectively manage integration and compatibility issues between libraries, ensuring the reliability, scalability, and maintainability of your NLP systems.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide to delivering this answer verbally:</p>
<ol type="1">
<li><strong>Start with the Big Picture:</strong>
<ul>
<li>“Managing integration and compatibility between NLP libraries like those for tokenization and hardware acceleration is crucial for building scalable systems. Incompatibilities can really hamper performance and cause instability.”</li>
</ul></li>
<li><strong>Highlight Modular Architecture:</strong>
<ul>
<li>“One key approach is to design a modular architecture. This means breaking down the system into independent, loosely coupled components. A well-defined API between these modules allows you to swap out implementations, like different tokenizers, with minimal impact on the rest of the system.”</li>
</ul></li>
<li><strong>Emphasize Dependency Management and Version Control:</strong>
<ul>
<li>“Dependency management is critical. I would use tools like <code>pip</code> or <code>conda</code> and <em>always</em> pin library versions. For example, <code>transformers==4.30.2</code>. This ensures a consistent environment across development, testing, and production. Changes can break things easily.”</li>
<li>“Relatedly, version control using Git is essential. It allows you to track all code, config changes and library dependencies, enabling easy rollbacks if something goes wrong.”</li>
</ul></li>
<li><strong>Explain CI/CD and Testing:</strong>
<ul>
<li>“Then, a Continuous Integration/Continuous Deployment (CI/CD) pipeline is vital. This automates testing and deployment. Automated tests should cover unit, integration, and end-to-end testing.”</li>
<li>“Specifically, make sure to include integration tests that verify tokenization modules interact properly and hardware acceleration works as expected.”</li>
</ul></li>
<li><strong>Introduce Abstraction Layers:</strong>
<ul>
<li>“Creating abstraction layers to isolate core NLP logic from the specific library implementations is useful. For example, create an abstract Tokenizer class and use it as the single point of contact within your code. It gives you the flexibility to switch tokenizers in the future.”</li>
</ul></li>
<li><strong>Describe Containerization:</strong>
<ul>
<li>“Containerization using Docker is another important tool. It packages the system and all its dependencies into a consistent environment, eliminating dependency conflicts.”</li>
</ul></li>
<li><strong>Discuss Monitoring and Logging:</strong>
<ul>
<li>“Monitoring and Logging of the system’s performance after deployment are crucial. It ensures that you catch compatibility or performance issues early. You can monitor metrics such as CPU and GPU usage.</li>
</ul></li>
<li><strong>Give a Real-World Example:</strong>
<ul>
<li>“For example, say I am upgrading the version of the ‘transformers’ library that I am using. It is crucial to run tests and, if possible, to fine-tune the model with the new version of the tokenizer. Otherwise, I can simply stick to using the old version of the transformer that I had and not face the issue.”</li>
</ul></li>
<li><strong>Summarize and Invite Questions:</strong>
<ul>
<li>“So, by combining these strategies – modularity, dependency management, CI/CD, abstraction, containerization, and monitoring – you can build robust and scalable NLP systems that are resilient to library updates and compatibility issues. Do you have any questions about any of these aspects?”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush. Take your time to explain each concept clearly.</li>
<li><strong>Use Examples:</strong> Concrete examples make the concepts easier to understand.</li>
<li><strong>Engage the Interviewer:</strong> Ask if they have any questions throughout your explanation. This shows that you are interested in their understanding and that you can communicate complex ideas effectively.</li>
<li><strong>Avoid Jargon Overload:</strong> While demonstrating your expertise is important, avoid using excessive jargon. Explain technical terms clearly.</li>
<li><strong>Focus on Practicality:</strong> Emphasize the practical benefits of each strategy. Explain <em>why</em> it is important and <em>how</em> it helps solve real-world problems.</li>
<li><strong>Be Confident but Humble:</strong> Present your answer confidently, but be open to feedback and suggestions. Acknowledge that there are often multiple ways to solve a problem.</li>
<li><strong>Handle Mathematical Sections Carefully:</strong> Avoid diving too deeply into the mathematical details unless specifically asked. Focus on the high-level concepts and their practical implications. If the interviewer asks for more detail, be prepared to provide it.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>