<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>scaling_laws_and_model_sizes_9</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-10.-how-do-you-reconcile-the-insights-provided-by-scaling-laws-with-deployment-constraints-like-latency-memory-usage-and-energy-efficiency-especially-in-real-world-systems" class="level2">
<h2 class="anchored" data-anchor-id="question-10.-how-do-you-reconcile-the-insights-provided-by-scaling-laws-with-deployment-constraints-like-latency-memory-usage-and-energy-efficiency-especially-in-real-world-systems">Question: 10. How do you reconcile the insights provided by scaling laws with deployment constraints like latency, memory usage, and energy efficiency, especially in real-world systems?</h2>
<p><strong>Best Answer</strong></p>
<p>Scaling laws provide invaluable insights into the relationship between model size, dataset size, and performance. They generally suggest that, up to a point, increasing model and data scale leads to predictable improvements in metrics like accuracy and loss. However, the relentless pursuit of scale often clashes with real-world deployment constraints, such as:</p>
<ul>
<li><strong>Latency:</strong> Larger models require more computation, leading to higher latency, which is unacceptable in many applications (e.g., real-time systems).</li>
<li><strong>Memory Usage:</strong> Larger models require more memory to store parameters and intermediate activations, potentially exceeding the capacity of edge devices or GPUs.</li>
<li><strong>Energy Efficiency:</strong> Increased computation and memory access translate to higher energy consumption, which is a critical concern for battery-powered devices and data centers.</li>
</ul>
<p>Reconciling these insights and constraints necessitates a multi-faceted approach, leveraging techniques that allow us to harness the benefits of scaling laws while mitigating their downsides.</p>
<p>Here’s a breakdown of key strategies:</p>
<ol type="1">
<li><p><strong>Model Compression Techniques:</strong></p>
<ul>
<li><p><strong>Pruning:</strong> This involves removing redundant or less important connections (weights) from the network. There are two main types:</p>
<ul>
<li><em>Unstructured Pruning:</em> Removes individual weights, leading to sparse weight matrices. This can be effective but requires specialized hardware/software to fully exploit the sparsity.</li>
<li><em>Structured Pruning:</em> Removes entire neurons, filters, or even layers. This is generally more hardware-friendly as it results in smaller, dense models.</li>
</ul>
<p>Let <span class="math inline">\(W\)</span> be the weight matrix of a layer. Pruning aims to find a mask <span class="math inline">\(M\)</span> such that <span class="math inline">\(W' = W \odot M\)</span> (element-wise multiplication), where <span class="math inline">\(M\)</span> contains 0s for pruned connections and 1s for retained connections. The objective is to minimize the performance degradation while maximizing the sparsity (number of 0s in <span class="math inline">\(M\)</span>). We want to minimize:</p>
<p><span class="math display">\[L(W') + \lambda \cdot ||M||_0\]</span></p>
<p>Where <span class="math inline">\(L(W')\)</span> is the loss function on the pruned network, <span class="math inline">\(\lambda\)</span> is a regularization parameter controlling the sparsity, and <span class="math inline">\(||M||_0\)</span> represents the L0 norm (number of non-zero elements) which reflects the number of connections we kept (i.e.&nbsp;number of 1s in mask <span class="math inline">\(M\)</span>).</p></li>
<li><p><strong>Quantization:</strong> Reduces the precision of model weights and activations. For instance, instead of using 32-bit floating-point numbers (FP32), we can use 16-bit (FP16), 8-bit integers (INT8), or even binary values (binary neural networks).</p>
<p>Quantization reduces memory footprint and can significantly speed up computation on hardware that supports low-precision arithmetic. It can be formulated as:</p>
<p><span class="math display">\[Q(x) = scale \cdot round(x/scale + bias)\]</span></p>
<p>Where <span class="math inline">\(x\)</span> is the original value, <span class="math inline">\(Q(x)\)</span> is the quantized value, <span class="math inline">\(scale\)</span> is a scaling factor, and <span class="math inline">\(bias\)</span> is an offset. The choice of <code>scale</code> and <code>bias</code> is crucial for minimizing the quantization error.</p></li>
<li><p><strong>Knowledge Distillation:</strong> Transfers knowledge from a large, accurate “teacher” model to a smaller, faster “student” model. The student is trained to mimic the teacher’s outputs (both hard labels and soft probabilities).</p>
<p>The distillation loss can be expressed as:</p>
<p><span class="math display">\[L_{distillation} = \alpha L_{CE}(y, p_{student}) + (1 - \alpha) L_{KL}(p_{teacher}, p_{student})\]</span></p>
<p>Where <span class="math inline">\(L_{CE}\)</span> is the cross-entropy loss between the student’s predictions <span class="math inline">\(p_{student}\)</span> and the ground truth labels <span class="math inline">\(y\)</span>, <span class="math inline">\(L_{KL}\)</span> is the Kullback-Leibler divergence between the teacher’s predictions <span class="math inline">\(p_{teacher}\)</span> and the student’s predictions, and <span class="math inline">\(\alpha\)</span> is a weighting factor. This allows the student to learn from the teacher’s “dark knowledge” (the probabilities assigned to incorrect classes), leading to better generalization.</p></li>
</ul></li>
<li><p><strong>Efficient Model Architectures:</strong></p>
<ul>
<li><strong>MobileNets, EfficientNets, SqueezeNets:</strong> These architectures are specifically designed for resource-constrained environments. They utilize techniques like depthwise separable convolutions to reduce the number of parameters and computations while maintaining accuracy.</li>
<li><strong>Neural Architecture Search (NAS):</strong> Automates the process of finding optimal model architectures for a given task and resource constraints. NAS algorithms can explore a vast search space of possible architectures, identifying those that offer the best trade-off between accuracy and efficiency.</li>
</ul></li>
<li><p><strong>Hardware Acceleration:</strong></p>
<ul>
<li><strong>GPUs:</strong> Offer massive parallelism for training and inference but are power-hungry.</li>
<li><strong>TPUs (Tensor Processing Units):</strong> Google’s custom ASICs designed specifically for deep learning, offering high throughput and energy efficiency.</li>
<li><strong>Edge AI Accelerators (e.g., Intel Movidius, NVIDIA Jetson):</strong> Specialized hardware for running AI models on edge devices with low latency and power consumption.</li>
<li><strong>FPGAs (Field-Programmable Gate Arrays):</strong> Reconfigurable hardware that can be customized to accelerate specific deep learning operations.</li>
</ul></li>
<li><p><strong>Algorithmic Optimizations:</strong></p>
<ul>
<li><strong>Layer Fusion:</strong> Combines multiple operations into a single kernel, reducing memory access and improving performance.</li>
<li><strong>Winograd Transformation:</strong> A fast convolution algorithm that reduces the number of multiplications at the cost of increased additions. This can be beneficial on hardware where multiplications are more expensive than additions.</li>
<li><strong>Loop Optimization:</strong> Techniques to improve the efficiency of loops in the inference code.</li>
</ul></li>
<li><p><strong>Trade-off Analysis and System-Level Optimization:</strong></p>
<ul>
<li>It’s crucial to perform a thorough trade-off analysis to determine the optimal balance between accuracy, latency, memory usage, and energy consumption for a specific application.</li>
<li>This involves profiling the model on the target hardware, identifying bottlenecks, and applying the appropriate optimization techniques.</li>
<li>System-level optimizations, such as optimizing data loading and pre-processing pipelines, can also contribute to overall performance improvements.</li>
</ul></li>
</ol>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Deployment Platform:</strong> The choice of deployment platform (e.g., cloud, edge device) significantly impacts the available resources and performance constraints.</li>
<li><strong>Application Requirements:</strong> The specific requirements of the application (e.g., real-time processing, batch processing) dictate the acceptable latency and accuracy levels.</li>
<li><strong>Hardware-Software Co-design:</strong> Optimizing both the model architecture and the underlying hardware is crucial for achieving the best performance.</li>
<li><strong>Continual Learning:</strong> Adapting models to new data and changing environments without retraining from scratch can improve efficiency and reduce the need for large models.</li>
</ul>
<p>In conclusion, reconciling scaling laws with deployment constraints is an ongoing challenge. By combining model compression techniques, efficient architectures, hardware acceleration, and algorithmic optimizations, we can strive to unlock the benefits of large models while meeting the practical requirements of real-world systems. The key is to understand the specific constraints of the target environment and to choose the most appropriate techniques for addressing them.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested approach to narrate this answer in an interview:</p>
<ol type="1">
<li><strong>Start by Acknowledging the Tension:</strong>
<ul>
<li>“Scaling laws show increasing model size improves performance, but deployment constraints like latency, memory, and energy present challenges.”</li>
</ul></li>
<li><strong>Outline the Key Constraints:</strong>
<ul>
<li>“Specifically, larger models lead to higher latency, require more memory, and consume more energy, which can be problematic for real-time applications and resource-constrained devices.”</li>
</ul></li>
<li><strong>Present the Multi-faceted Approach:</strong>
<ul>
<li>“To reconcile this, we need a multi-faceted approach, leveraging several techniques.” Briefly mention the main categories: model compression, efficient architectures, hardware acceleration, and algorithmic optimizations.</li>
</ul></li>
<li><strong>Delve into Model Compression (with appropriate depth):</strong>
<ul>
<li>“Model compression techniques are crucial. Let’s start with Pruning. We can prune individual connections or entire neurons. Explain <em>unstructured</em> and <em>structured</em> pruning briefly. If asked for detail, provide the equation for minimizing the loss.”</li>
<li>“Quantization reduces the precision of weights and activations, decreasing memory footprint and potentially speeding up computation.” Briefly mention the formula without dwelling on details unless prompted.</li>
<li>“Knowledge Distillation involves training a smaller student model to mimic a larger teacher model. The distillation loss has two components, the loss of student compared to the training labels plus the loss of student mimicking the teacher’s prediction. KL divergence is often used to capture that mimicking.”</li>
<li><strong>Pause and Gauge Interest:</strong> After explaining one or two compression techniques, pause to see if the interviewer wants more detail on a specific technique.</li>
</ul></li>
<li><strong>Briefly Cover Other Areas:</strong>
<ul>
<li>“Efficient architectures, like MobileNets, are designed for resource-constrained environments.”</li>
<li>“Hardware acceleration, using GPUs, TPUs, or edge AI accelerators, can significantly improve performance.”</li>
<li>“Algorithmic optimizations, like layer fusion and Winograd transformations, further optimize performance.” Give a short example of what those algorithmic optimizations achieve.</li>
</ul></li>
<li><strong>Emphasize Trade-off Analysis:</strong>
<ul>
<li>“Ultimately, it’s about trade-offs. We need to analyze the specific application requirements and platform constraints to choose the optimal combination of techniques.”</li>
</ul></li>
<li><strong>Real-World Considerations:</strong>
<ul>
<li>“Consider the deployment platform, the specific application requirements, and potentially co-design the hardware and software.”</li>
</ul></li>
<li><strong>Conclude with a Summary:</strong>
<ul>
<li>“In summary, balancing scaling benefits with deployment realities requires a comprehensive strategy, combining model compression, efficient architectures, hardware acceleration, and careful trade-off analysis.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Be Concise:</strong> Avoid overly technical jargon unless the interviewer seems receptive.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you’re in a virtual interview, consider sharing your screen to display diagrams or equations (prepare them in advance).</li>
<li><strong>Gauge Interest:</strong> Pay attention to the interviewer’s body language and questions. If they seem confused or uninterested, move on to a different topic.</li>
<li><strong>Provide Examples:</strong> Whenever possible, illustrate your points with real-world examples of how these techniques are used in practice.</li>
<li><strong>Express Enthusiasm:</strong> Show your passion for the field and your interest in solving these challenging problems.</li>
<li><strong>Mathematical Notation:</strong> Present equations when appropriate, but do not linger on them unless asked for more detail. The key is to demonstrate you understand the underlying concepts without overwhelming the interviewer. Explain the terms in the equation clearly.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>