<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>prompt_engineering_and_in_context_learning_10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-11.-can-you-illustrate-with-an-example-how-you-would-use-few-shot-examples-within-a-prompt-to-improve-in-context-learning-across-different-tasks" class="level2">
<h2 class="anchored" data-anchor-id="question-11.-can-you-illustrate-with-an-example-how-you-would-use-few-shot-examples-within-a-prompt-to-improve-in-context-learning-across-different-tasks">Question: 11. Can you illustrate with an example how you would use few-shot examples within a prompt to improve in-context learning across different tasks?</h2>
<p><strong>Best Answer</strong></p>
<p>Few-shot learning is a powerful technique where a model learns to perform a new task given only a handful of labeled examples in the prompt itself. This leverages the pre-trained knowledge of large language models (LLMs) and allows them to generalize to new tasks with minimal training. The key is crafting a prompt that effectively guides the LLM to understand the task and the desired output format. Let’s consider a couple of examples to illustrate this:</p>
<p><strong>Example 1: Sentiment Classification</strong></p>
<p>Suppose we want to perform sentiment classification on product reviews. Without few-shot learning, we might just ask the model:</p>
<p><code>Review: "This product was terrible. The quality was awful, and it broke after only a week." Sentiment:</code></p>
<p>The model might produce any number of responses, possibly even a helpfulness score, because the instructions aren’t specific enough.</p>
<p>With few-shot learning, we can provide the LLM with a few examples of reviews and their corresponding sentiments within the prompt. This helps the model understand what we mean by “sentiment” and what format we expect. A prompt with few-shot examples could look like this:</p>
<pre><code>Review: "I absolutely loved this phone! The camera is amazing, and the battery lasts all day."
Sentiment: Positive

Review: "The instructions were confusing, and the product didn't work as advertised."
Sentiment: Negative

Review: "This is the best purchase I've made all year!  So easy to use and reliable."
Sentiment: Positive

Review: "This product was terrible. The quality was awful, and it broke after only a week."
Sentiment:</code></pre>
<p>The model is now much more likely to respond with “Negative” because it has been shown the kind of reviews that should have the <code>Negative</code> label. The quality of these examples makes a huge difference, however!</p>
<p><strong>Mathematical Intuition (Simplified):</strong></p>
<p>We can conceptually think of the LLM as performing a nearest-neighbor search in a high-dimensional embedding space. Each review (or more generally, each input) is mapped to a point in this space. The few-shot examples act as “anchors” that define regions of the embedding space corresponding to different sentiment classes. When the LLM encounters a new review, it finds the closest anchor points (the few-shot examples) and predicts the sentiment based on the majority sentiment of its nearest neighbors.</p>
<p>More formally, consider a similarity function <span class="math inline">\(s(x, x')\)</span>, where <span class="math inline">\(x\)</span> is the input review and <span class="math inline">\(x'\)</span> is one of the few-shot example reviews. The probability of a sentiment class <span class="math inline">\(c\)</span> can be approximated as:</p>
<p><span class="math display">\[P(c|x) \approx \frac{\sum_{x' \in S_c} s(x, x')}{\sum_{x' \in S} s(x, x')}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(S_c\)</span> is the set of few-shot examples with sentiment class <span class="math inline">\(c\)</span>.</li>
<li><span class="math inline">\(S\)</span> is the entire set of few-shot examples.</li>
<li><span class="math inline">\(s(x, x')\)</span> could be based on cosine similarity of the embeddings of the reviews.</li>
</ul>
<p>In practice, LLMs use more sophisticated mechanisms (attention, transformers) but this provides a simplified conceptual model.</p>
<p><strong>Example 2: Translation</strong></p>
<p>Let’s say we want to translate English to French. A basic prompt might look like this:</p>
<p><code>Translate "Hello, how are you?" to French.</code></p>
<p>But without context, the translation might not be what we expect. With few-shot learning, we provide examples of English phrases and their French translations:</p>
<pre><code>English: "Hello, how are you?"
French: "Bonjour, comment allez-vous ?"

English: "Thank you very much."
French: "Merci beaucoup."

English: "What time is it?"
French: "Quelle heure est-il ?"

English: "Goodbye."
French: "Au revoir."

English: "Nice to meet you."
French: "Enchanté(e)."

English: "Where is the bathroom?"
French: "Où sont les toilettes ?"

English: "I need help."
French: "J'ai besoin d'aide."

English: "I am from America."
French: "Je suis américain."

English: "This is my card"
French: "Voici ma carte"

English: "Have a nice day."
French: "Passez une bonne journée."

English: "The weather is nice today."
French: "Il fait beau aujourd'hui."

English: "Can you help me carry this."
French: "Pouvez-vous m'aider à porter ceci"

English: "How much does this cost?"
French: "Combien coûte ceci?"

English: "I would like a coffee"
French: "Je voudrais un café"

English: "I want to eat"
French: "Je veux manger"

English: "Lets go to the mall"
French: "Allons au centre commercial"

English: "Translate 'Where is the train station?' to French."</code></pre>
<p>The model is now much more likely to provide an accurate translation, using the style and vocabulary established by the few-shot examples.</p>
<p><strong>Key Considerations for Selecting Few-Shot Examples:</strong></p>
<ul>
<li><strong>Relevance:</strong> The examples should be highly relevant to the task and the type of input you expect.</li>
<li><strong>Diversity:</strong> Include a range of examples to cover different aspects of the task and avoid biasing the model towards a specific subset of the input space. In the sentiment analysis example, include both strongly positive and negative reviews, as well as more nuanced or neutral reviews.</li>
<li><strong>Clarity:</strong> The examples should be clear and unambiguous. Avoid examples that could be interpreted in multiple ways.</li>
<li><strong>Format Consistency:</strong> Maintain a consistent format between the examples and the final query. If the examples use a “Review: …: …” format, the query should follow the same format.</li>
<li><strong>Number of Examples:</strong> Experiment with the number of examples. Too few examples may not provide enough context, while too many examples can increase the prompt length and potentially degrade performance (especially with models that have context length limits). This will become a trade-off as some APIs charge per token.</li>
</ul>
<p><strong>Why Few-Shot Learning Works:</strong></p>
<ul>
<li><strong>Meta-Learning:</strong> LLMs are trained on massive datasets that expose them to a wide variety of tasks and data distributions. This enables them to learn how to learn – a process called meta-learning. When presented with few-shot examples, the LLM can quickly adapt its internal representations and inference mechanisms to the new task.</li>
<li><strong>In-Context Learning:</strong> The transformer architecture allows the LLM to attend to different parts of the input, including the few-shot examples. The attention mechanism allows the model to identify the relevant patterns and relationships between the examples and the query.</li>
<li><strong>Bias Adjustment:</strong> Few-shot examples help to adjust any biases that the LLM may have learned during pre-training. For example, if the LLM has a bias towards positive sentiment, the few-shot examples can help to counteract this bias by providing examples of negative sentiment.</li>
</ul>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Prompt Length Limits:</strong> Many LLMs have limits on the length of the input prompt. Carefully select the most informative few-shot examples to maximize the information content within the available context window.</li>
<li><strong>Example Ordering:</strong> The order of the few-shot examples can sometimes influence the model’s performance. Experiment with different orderings to see what works best.</li>
<li><strong>Prompt Engineering is Iterative:</strong> Few-shot learning often requires experimentation and iteration to find the optimal prompt structure and examples. It’s important to monitor the model’s performance and adjust the prompt accordingly.</li>
<li><strong>Cost:</strong> Remember that the longer the prompts, the more tokens used, which translates into higher costs with many LLM APIs.</li>
</ul>
<p><strong>Best practices for writing effective few-shot prompts</strong></p>
<ul>
<li><strong>Understand the task requirements:</strong> What are the inputs and outputs? What kind of relationship are you looking for?</li>
<li><strong>Choose representative examples:</strong> The examples should be relevant to the task and cover the range of possible inputs and outputs. They should be clearly labeled and easy to understand.</li>
<li><strong>Use a consistent format:</strong> The input and output format should be consistent throughout the prompt. This will help the model learn the desired pattern.</li>
<li><strong>Experiment with different prompt structures:</strong> Try different ways of organizing the prompt to see what works best. You can try using different delimiters, labels, and instructions.</li>
<li><strong>Evaluate the results:</strong> Test the prompt with a variety of inputs to see how well it performs. If the results are not satisfactory, revise the prompt and try again.</li>
</ul>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with the Definition:</strong>
<ul>
<li>“Few-shot learning is a technique that enables language models to perform new tasks by providing only a small number of labeled examples within the prompt itself. It leverages the model’s pre-existing knowledge, rather than requiring extensive retraining.”</li>
</ul></li>
<li><strong>Introduce the First Example (Sentiment Analysis):</strong>
<ul>
<li>“Let’s take sentiment analysis as an example. If we simply ask the model to classify the sentiment of a review without any context, the results can be unpredictable.”</li>
<li>“However, if we provide a few example reviews paired with their corresponding sentiments (Positive/Negative), the model quickly learns the task and format. For instance, I’d include examples like ‘Review: I loved it. Sentiment: Positive’ followed by a few more diverse examples.”</li>
</ul></li>
<li><strong>Explain the Intuition (Simplified Math, Optional):</strong>
<ul>
<li>“Conceptually, you can imagine the LLM as finding the ‘nearest neighbors’ to the input review based on how similar it is to the example reviews. This is done in a high dimensional vector space. The sentiment is determined according to the sentiments of its nearest neighbors.”</li>
<li>“For those familiar, you could even think of it as the model calculating something akin to a weighted average of the sentiment classes of nearby examples, where the weights are based on the similarity between the input and the examples, but it happens in the transformer architecture.” <strong>(Only say this if the interviewer seems technically inclined and gives you an opening; otherwise skip the mathematical aside.)</strong></li>
</ul></li>
<li><strong>Introduce the Second Example (Translation):</strong>
<ul>
<li>“Another example is translation. Instead of just providing the sentence to translate, I could provide example translations of other common phrases and sentences. This allows the model to pick up on the desired nuances and overall style of translation.”</li>
</ul></li>
<li><strong>Highlight Key Considerations for Example Selection:</strong>
<ul>
<li>“The success of few-shot learning hinges on the quality of the examples. I would carefully consider the following factors:”
<ul>
<li>“Relevance: The examples must be relevant to the specific inputs expected.”</li>
<li>“Diversity: They should cover a range of cases to avoid biasing the model.”</li>
<li>“Clarity: The examples must be unambiguous to avoid confusing the model.”</li>
<li>“Format Consistency: It’s crucial to maintain a consistent format across all examples and the final query.”</li>
<li>“Number of Examples: It requires tuning the number of example as too few or too many may degrade performance.”</li>
</ul></li>
</ul></li>
<li><strong>Briefly Explain Why it Works (Meta-Learning, In-Context Learning):</strong>
<ul>
<li>“The reason few-shot learning works well is that LLMs have been trained on massive datasets. This helps them understand how to learn new tasks from limited examples.”</li>
<li>“The attention mechanism in transformers also helps by identifying the most important patterns and relationships between the input and the examples provided.”</li>
</ul></li>
<li><strong>Discuss Real-World Considerations:</strong>
<ul>
<li>“In a real-world setting, prompt length limits are a major constraint, so careful example selection is critical. Also, it’s an iterative process to find the best prompt structure.”</li>
<li>“In addition, the cost of the API will increase as prompts get longer. So, there is a trade-off between performance and cost.”</li>
</ul></li>
<li><strong>End with Iteration:</strong>
<ul>
<li>“Ultimately, effective few-shot learning is achieved through systematic experimentation and prompt engineering to fine-tune the prompt and examples for optimal results.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Speak clearly and deliberately, especially when explaining complex concepts.</li>
<li><strong>Gauge the Interviewer’s Understanding:</strong> Watch for cues that they are following (or not following) your explanation.</li>
<li><strong>Provide Just Enough Detail:</strong> Don’t overwhelm the interviewer with technical jargon. Focus on the core ideas and provide more detail only if they ask for it.</li>
<li><strong>Use Visual Aids (If Allowed):</strong> If you’re doing a virtual interview, consider sharing your screen to display example prompts or diagrams.</li>
<li><strong>Engage the Interviewer:</strong> Ask if they have any questions along the way to ensure they are engaged and understanding your points.</li>
<li><strong>Express Enthusiasm:</strong> Let your enthusiasm for the topic shine through. This shows that you’re not just knowledgeable but also passionate about the field.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>