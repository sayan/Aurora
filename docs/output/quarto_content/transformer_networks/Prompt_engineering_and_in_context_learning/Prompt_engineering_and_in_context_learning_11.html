<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>prompt_engineering_and_in_context_learning_11</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-12.-discuss-the-potential-ethical-and-reliability-considerations-in-deploying-prompt-engineered-models-especially-given-that-prompts-can-sometimes-inadvertently-induce-biased-or-misleading-outputs." class="level2">
<h2 class="anchored" data-anchor-id="question-12.-discuss-the-potential-ethical-and-reliability-considerations-in-deploying-prompt-engineered-models-especially-given-that-prompts-can-sometimes-inadvertently-induce-biased-or-misleading-outputs.">Question: 12. Discuss the potential ethical and reliability considerations in deploying prompt-engineered models, especially given that prompts can sometimes inadvertently induce biased or misleading outputs.</h2>
<p><strong>Best Answer</strong></p>
<p>Prompt engineering, while powerful, introduces unique ethical and reliability considerations when deploying Large Language Models (LLMs). The core issue is that even carefully crafted prompts can inadvertently elicit biased, misleading, or otherwise undesirable outputs from the model. This stems from several factors:</p>
<ul>
<li><p><strong>Bias Amplification:</strong> LLMs are trained on massive datasets that inherently contain societal biases related to gender, race, religion, etc. Prompt engineering can unintentionally <em>amplify</em> these biases. A seemingly neutral prompt might trigger the model to generate responses that perpetuate harmful stereotypes or discriminate against certain groups.</p>
<ul>
<li><strong>Example:</strong> Consider a prompt like “Describe a successful CEO.” If the training data predominantly associates CEOs with male figures, the model might disproportionately generate descriptions featuring male characteristics and pronouns.</li>
</ul></li>
<li><p><strong>Lack of Transparency and Auditability:</strong> Prompts can be complex and subtle, making it difficult to understand exactly <em>why</em> a particular prompt leads to a specific (problematic) output. This lack of transparency hinders debugging and mitigation efforts. It also makes it hard to determine which components of the prompt are causing the unintended effects.</p></li>
<li><p><strong>Adversarial Prompting:</strong> Malicious actors can craft adversarial prompts designed to elicit harmful or misleading information, circumvent safety mechanisms, or cause the model to generate inappropriate content.</p></li>
<li><p><strong>Prompt Sensitivity:</strong> LLMs can be highly sensitive to minor variations in the wording or structure of prompts. This sensitivity can lead to inconsistent or unpredictable behavior, making it difficult to ensure reliability in real-world applications. Even seemingly innocuous changes can significantly alter the model’s output and potentially introduce unintended consequences.</p></li>
<li><p><strong>Data Poisoning via Prompts:</strong> If the LLM is continuously learning from its interactions (e.g., through fine-tuning on user-provided prompts and responses), malicious prompts could be used to “poison” the model’s knowledge and bias it towards certain viewpoints or behaviors.</p></li>
</ul>
<p>To address these ethical and reliability concerns, several strategies are crucial:</p>
<ul>
<li><p><strong>Bias Detection and Mitigation:</strong></p>
<ul>
<li><p><strong>Data Auditing:</strong> Conduct thorough audits of the training data to identify and mitigate potential sources of bias. This is a continuous process, as datasets evolve.</p></li>
<li><p><strong>Fairness Testing:</strong> Systematically evaluate the model’s performance across different demographic groups using specifically designed test prompts. Employ metrics like <em>disparate impact</em> and <em>equal opportunity difference</em> to quantify bias in generated outputs. For example, <em>disparate impact</em> is computed as follows:</p>
<p><span class="math display">\[
\text{Disparate Impact} = \frac{P(\text{Positive Outcome} \mid \text{Group A})}{P(\text{Positive Outcome} \mid \text{Group B})}
\]</span></p>
<p>where Group A and Group B are different demographic groups, and “Positive Outcome” represents the desired outcome (e.g., loan approval, job interview). A disparate impact value significantly less than 1 indicates potential bias against Group B.</p></li>
<li><p><strong>Debiasing Techniques:</strong> Apply debiasing techniques to the training data or the model’s output. This might involve re-weighting the data, modifying the model’s architecture, or post-processing the generated text.</p></li>
</ul></li>
<li><p><strong>Prompt Engineering Best Practices:</strong></p>
<ul>
<li><strong>Clear and Unambiguous Prompts:</strong> Design prompts that are as clear, specific, and unambiguous as possible to minimize the risk of misinterpretation or unintended biases.</li>
<li><strong>Contextual Awareness:</strong> Incorporate contextual information into the prompt to guide the model towards generating more relevant and appropriate responses.</li>
<li><strong>Red Teaming:</strong> Engage diverse teams to “red team” the prompts by attempting to elicit undesirable behavior or uncover hidden biases. Red teaming involves actively trying to find flaws and vulnerabilities in the system by using adversarial prompts.</li>
</ul></li>
<li><p><strong>Output Monitoring and Filtering:</strong></p>
<ul>
<li><p><strong>Content Moderation:</strong> Implement robust content moderation systems to detect and filter out harmful, offensive, or misleading outputs.</p></li>
<li><p><strong>Anomaly Detection:</strong> Use anomaly detection techniques to identify unusual or unexpected outputs that might indicate a problem with the prompt or the model. This may involve monitoring metrics like perplexity or semantic similarity.</p></li>
<li><p><strong>Human-in-the-Loop Review:</strong> Incorporate human reviewers to evaluate the quality and appropriateness of the model’s outputs, especially for sensitive or high-stakes applications. This is essential for validating the automated filtering mechanisms.</p></li>
</ul></li>
<li><p><strong>Explainable AI (XAI) Techniques:</strong></p>
<ul>
<li><strong>Prompt Attribution:</strong> Develop methods to attribute the model’s output to specific parts of the prompt. This can help identify which aspects of the prompt are contributing to problematic outputs.</li>
<li><strong>Sensitivity Analysis:</strong> Perform sensitivity analysis to understand how the model’s output changes in response to small variations in the prompt.</li>
</ul></li>
<li><p><strong>Ethical Guidelines and Governance:</strong></p>
<ul>
<li><strong>Establish clear ethical guidelines</strong> for the development and deployment of prompt-engineered models.</li>
<li><strong>Implement a governance framework</strong> to ensure that these guidelines are followed and that potential risks are adequately addressed.</li>
<li><strong>Transparency and Disclosure:</strong> Be transparent about the limitations of the model and the potential for biased or misleading outputs. Provide users with clear disclaimers and explanations.</li>
</ul></li>
<li><p><strong>Model Fine-tuning:</strong> Fine-tune the LLM on a dataset that is specifically designed to mitigate biases and improve reliability. This fine-tuning process can involve techniques like reinforcement learning from human feedback (RLHF), where human annotators provide feedback on the model’s outputs and the model is trained to align with human preferences.</p></li>
</ul>
<p>In conclusion, deploying prompt-engineered models requires a proactive and multi-faceted approach to address the ethical and reliability challenges. This includes careful prompt design, rigorous testing, robust monitoring, and a commitment to transparency and ethical principles. Continuous vigilance is essential to mitigate potential harms and ensure that these powerful tools are used responsibly.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with the core problem:</strong> “Prompt engineering introduces fascinating possibilities, but also serious ethical and reliability challenges. The main issue is that even seemingly benign prompts can lead to biased or misleading outputs from large language models.”</p></li>
<li><p><strong>Explain Bias Amplification:</strong> “LLMs are trained on vast datasets which inevitably contain societal biases. Prompt engineering can unintentionally <em>amplify</em> these biases.” Give the CEO example. “For instance, a prompt asking the model to describe a successful CEO might, due to biases in the training data, disproportionately generate descriptions that are male.”</p></li>
<li><p><strong>Highlight Lack of Transparency:</strong> “Another key challenge is the lack of transparency. It’s often difficult to understand exactly <em>why</em> a particular prompt leads to a problematic output. This makes it hard to debug and fix issues.”</p></li>
<li><p><strong>Mention Adversarial Prompting:</strong> “Malicious actors can create adversarial prompts to trick the model into generating harmful or misleading content.”</p></li>
<li><p><strong>Stress Prompt Sensitivity:</strong> “LLMs are also incredibly sensitive to slight changes in the wording of prompts, which can lead to unpredictable behavior.”</p></li>
<li><p><strong>Introduce Mitigation Strategies:</strong> “To address these concerns, we need a multi-pronged approach. This includes bias detection and mitigation techniques.</p></li>
<li><p><strong>Discuss Bias Detection and Mitigation:</strong> “First, data auditing. We need to continuously audit the training data to identify and reduce biases. Then, fairness testing - systematically evaluating the model’s performance across different demographic groups. We can use metrics like <em>disparate impact</em> to quantify bias.” When mentioning disparate impact, write it down using LaTeX on a whiteboard (if available): <span class="math display">\[ \text{Disparate Impact} = \frac{P(\text{Positive Outcome} \mid \text{Group A})}{P(\text{Positive Outcome} \mid \text{Group B})} \]</span>. “If disparate impact is significantly less than one, that means bias is present.”</p></li>
<li><p><strong>Explain Prompt Engineering Best Practices:</strong> “We also need to focus on prompt engineering best practices, such as using clear and unambiguous prompts and red teaming with diverse teams to identify potential issues.”</p></li>
<li><p><strong>Describe Output Monitoring and Filtering:</strong> “Robust output monitoring and filtering are essential. This involves content moderation to detect and remove harmful content, as well as anomaly detection to identify unexpected outputs.”</p></li>
<li><p><strong>Mention Ethical Guidelines and Governance:</strong> “Finally, establishing clear ethical guidelines and a governance framework is crucial to ensure responsible development and deployment.”</p></li>
<li><p><strong>Summarize:</strong> “In summary, deploying prompt-engineered models requires a proactive approach focused on careful prompt design, rigorous testing, robust monitoring, and a commitment to ethical principles. It’s an ongoing process.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Speak clearly and deliberately.</li>
<li><strong>Use examples:</strong> Illustrate your points with concrete examples to make them more relatable.</li>
<li><strong>Use whiteboard:</strong> Using a whiteboard to write out key equations or concepts will show your understanding.</li>
<li><strong>Check for understanding:</strong> Periodically ask the interviewer if they have any questions or if they would like you to elaborate on a particular point.</li>
<li><strong>Acknowledge complexity:</strong> “This is a complex area, and there’s no single solution to these problems.”</li>
<li><strong>End on a positive note:</strong> “Despite the challenges, prompt engineering offers tremendous potential, and by addressing these ethical and reliability concerns, we can unlock its full benefits responsibly.”</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>