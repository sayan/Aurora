<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>historical_context_and_evolution_of_the_transformer_architecture_10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-11.-discuss-the-interpretability-challenges-associated-with-transformer-models.-how-can-attention-maps-and-other-techniques-be-used-or-misinterpreted-in-explaining-model-decisions" class="level2">
<h2 class="anchored" data-anchor-id="question-11.-discuss-the-interpretability-challenges-associated-with-transformer-models.-how-can-attention-maps-and-other-techniques-be-used-or-misinterpreted-in-explaining-model-decisions">Question: 11. Discuss the interpretability challenges associated with Transformer models. How can attention maps and other techniques be used or misinterpreted in explaining model decisions?</h2>
<p><strong>Best Answer</strong></p>
<p>Transformer models, while achieving state-of-the-art performance in numerous NLP and other tasks, present significant challenges in interpretability. The inherent complexity arising from multiple layers, attention mechanisms, and non-linear transformations makes it difficult to understand <em>why</em> a Transformer model makes a particular decision.</p>
<p>Here’s a breakdown of the challenges and techniques:</p>
<section id="complexity-and-black-box-nature" class="level3">
<h3 class="anchored" data-anchor-id="complexity-and-black-box-nature">1. Complexity and Black Box Nature</h3>
<p>Transformers are fundamentally “black boxes.” The large number of parameters (often billions) and the intricate interactions between them render a direct, intuitive understanding of their decision-making process nearly impossible. Unlike simpler models like linear regression, there isn’t a clear mapping between input features and output predictions that can be easily articulated.</p>
</section>
<section id="limitations-of-attention-maps" class="level3">
<h3 class="anchored" data-anchor-id="limitations-of-attention-maps">2. Limitations of Attention Maps</h3>
<p>Attention maps are often presented as a primary tool for interpreting Transformer models. The attention mechanism assigns weights to different input tokens, purportedly indicating their relevance to a specific output. However, relying solely on attention maps can be misleading due to several reasons:</p>
<ul>
<li><strong>Attention != Importance:</strong> Attention weights don’t necessarily equate to importance. A token may receive high attention for various reasons, including capturing dependencies unrelated to the final prediction. For example, in machine translation, attention might highlight function words (“the”, “a”) which are crucial for grammatical structure but less important for semantic content.</li>
<li><strong>Spurious Correlations:</strong> Attention can capture spurious correlations in the training data. If a specific word is often associated with a particular outcome (even if the association is coincidental), the attention mechanism might consistently highlight it, leading to incorrect interpretations.</li>
<li><strong>Lack of Granularity:</strong> Attention maps often provide a coarse-grained view. They show which tokens are attended to but not <em>how</em> they influence the decision. They don’t explain the nature of the interaction.</li>
<li><strong>Attention is not Explanation:</strong> Attention maps are diagnostic tools at best. They can point to potentially relevant input components, but they do not provide a causal explanation of the model’s decision-making process.</li>
<li><strong>Multi-Head Attention Aggregation:</strong> Transformers use multi-head attention, and aggregating attention weights from all heads into a single map can obscure the nuances of individual attention patterns. Different heads might capture different types of relationships, and averaging them can lead to a loss of information.</li>
</ul>
<p>Mathematically, the attention mechanism is defined as:</p>
<p><span class="math display">\[
Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V
\]</span></p>
<p>where <span class="math inline">\(Q\)</span> is the query, <span class="math inline">\(K\)</span> is the key, <span class="math inline">\(V\)</span> is the value, and <span class="math inline">\(d_k\)</span> is the dimension of the key vectors. The <span class="math inline">\(softmax\)</span> function normalizes the scores, producing the attention weights. However, understanding the meaning of these learned <span class="math inline">\(Q, K, V\)</span> vectors is highly non-trivial, and simply visualizing the resulting attention weights provides only a superficial understanding.</p>
</section>
<section id="alternative-interpretability-techniques" class="level3">
<h3 class="anchored" data-anchor-id="alternative-interpretability-techniques">3. Alternative Interpretability Techniques</h3>
<p>Given the limitations of attention maps, several alternative techniques have been developed to provide more robust interpretations:</p>
<ul>
<li><p><strong>Probing Methods:</strong> Probing involves training auxiliary classifiers to predict specific properties from the hidden states of the Transformer. This helps to understand what information is encoded at different layers. For example, one might train a classifier to predict part-of-speech tags from the hidden states. The accuracy of this classifier indicates the extent to which the Transformer has learned syntactic information.</p>
<p>Formally, let <span class="math inline">\(H_l\)</span> be the hidden state at layer <span class="math inline">\(l\)</span>. A probing classifier <span class="math inline">\(g\)</span> is trained to predict a target variable <span class="math inline">\(y\)</span> from <span class="math inline">\(H_l\)</span>:</p>
<p><span class="math display">\[
\hat{y} = g(H_l; \theta_g)
\]</span></p>
<p>where <span class="math inline">\(\theta_g\)</span> are the parameters of the probing classifier. The performance of <span class="math inline">\(g\)</span> on a held-out dataset is used to assess the information encoded in <span class="math inline">\(H_l\)</span>.</p></li>
<li><p><strong>Gradient-based Methods:</strong> These methods compute the gradients of the output with respect to the input. The magnitude of the gradient indicates the sensitivity of the output to changes in the input. Examples include:</p>
<ul>
<li><strong>Saliency Maps:</strong> Visualize the magnitude of the gradient of the output class with respect to the input tokens.</li>
<li><strong>Integrated Gradients:</strong> Accumulate the gradients along a path from a baseline input (e.g., all zeros) to the actual input. This provides a more robust estimate of feature importance.</li>
<li><strong>SmoothGrad:</strong> Adding noise to the input and averaging gradients over multiple noisy samples.</li>
</ul>
<p>For example, given an input <span class="math inline">\(x\)</span> and a model <span class="math inline">\(f\)</span>, the gradient-based saliency map is:</p>
<p><span class="math display">\[
S(x) = |\frac{\partial f(x)}{\partial x}|
\]</span></p></li>
<li><p><strong>Perturbation-based Methods:</strong> Systematically perturb the input (e.g., masking words) and observe the effect on the output. By measuring the change in prediction, one can infer the importance of the perturbed elements.</p></li>
<li><p><strong>Attention Flow:</strong> Instead of looking at individual attention weights, analyze the flow of information through the attention mechanism. This involves tracking how information propagates from one layer to the next.</p></li>
<li><p><strong>Counterfactual Explanations:</strong> Generate alternative inputs that would have led to a different prediction. These “what-if” scenarios can provide insights into the model’s decision boundaries.</p></li>
<li><p><strong>Layer-wise Relevance Propagation (LRP):</strong> LRP is a technique that decomposes the model’s prediction backward through the layers, assigning relevance scores to each input feature.</p></li>
<li><p><strong>Concept Activation Vectors (CAVs):</strong> CAVs identify the directions in the model’s hidden space that correspond to specific high-level concepts. This allows one to quantify the influence of these concepts on the model’s predictions.</p></li>
<li><p><strong>Causal Mediation Analysis:</strong> A more advanced statistical method borrowed from the social sciences. This involves using causal inference techniques to determine the extent to which a specific input feature mediates the relationship between another input feature and the output.</p></li>
</ul>
</section>
<section id="misinterpretations-and-caveats" class="level3">
<h3 class="anchored" data-anchor-id="misinterpretations-and-caveats">4. Misinterpretations and Caveats</h3>
<p>It’s crucial to be aware of the potential for misinterpretations when using any interpretability technique:</p>
<ul>
<li><strong>Correlation vs.&nbsp;Causation:</strong> Interpretability methods often highlight correlations but don’t establish causal relationships. A feature might be highlighted simply because it is correlated with the target variable, not because it directly influences the prediction.</li>
<li><strong>Instability:</strong> Some interpretability methods are sensitive to small changes in the input or model parameters. This instability can make it difficult to draw reliable conclusions.</li>
<li><strong>Subjectivity:</strong> Interpretations are often subjective and depend on the user’s prior knowledge and biases.</li>
<li><strong>Evaluation:</strong> It’s important to evaluate the quality of interpretations. This can be done by asking humans to assess the plausibility of the explanations or by using automatic metrics to measure the consistency and completeness of the interpretations.</li>
</ul>
</section>
<section id="the-need-for-rigorous-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="the-need-for-rigorous-evaluation">5. The Need for Rigorous Evaluation</h3>
<p>Interpretability techniques should not be used in isolation. They should be combined with rigorous evaluation to ensure that the explanations are accurate and reliable. This can involve:</p>
<ul>
<li><strong>Human evaluation:</strong> Asking experts to assess the quality of the explanations.</li>
<li><strong>Ablation studies:</strong> Removing or perturbing features that are identified as important and observing the effect on the model’s performance.</li>
<li><strong>Consistency checks:</strong> Verifying that the explanations are consistent across different inputs and model parameters.</li>
</ul>
<p>In conclusion, interpreting Transformer models is a challenging but essential task. While attention maps can provide some insights, they should be used with caution and complemented by other, more robust techniques. A critical understanding of both the potential and limitations of these methods is crucial for responsible AI development.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to structure your answer in an interview:</p>
<ol type="1">
<li><strong>Start Broadly (30 seconds):</strong>
<ul>
<li>“Transformer models are incredibly powerful, but their complexity makes them difficult to understand. While they excel in performance, achieving interpretability is a significant challenge.”</li>
<li>Acknowledge that you will be discussing the challenges and potential pitfalls along with some solutions.</li>
</ul></li>
<li><strong>Explain the Complexity (1 minute):</strong>
<ul>
<li>“Transformers are essentially black boxes due to their massive number of parameters and intricate interactions. Unlike simpler models, there isn’t a straightforward mapping between input and output.”</li>
<li>Emphasize the non-linearity and depth of the model as key contributors to the challenge.</li>
</ul></li>
<li><strong>Discuss Attention Maps (2 minutes):</strong>
<ul>
<li>“Attention maps are often touted as interpretability tools, and while they can be helpful, they have limitations. I’d like to discuss those.”</li>
<li>“The core issue is that attention doesn’t necessarily equal importance. A token might receive high attention for grammatical reasons, spurious correlations, or other factors unrelated to the prediction’s core logic.”</li>
<li>Briefly explain the formula <span class="math inline">\(Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\)</span>, emphasizing that learned Q, K, and V vectors are complex to understand. Don’t get bogged down in the details; just show familiarity.</li>
<li>Mention that multi-head attention can further complicate matters because aggregating the outputs can dilute the importance of heads that may be capturing more specific nuanced relationships.</li>
<li>“The issue is that attention maps are diagnostic tools at best, not necessarily explanations.”</li>
</ul></li>
<li><strong>Introduce Alternative Techniques (2 minutes):</strong>
<ul>
<li>“Because of the limitations of attention maps, researchers have developed other techniques that provide more robust interpretations.”</li>
<li>Briefly explain probing methods (e.g., training classifiers to predict part-of-speech tags from hidden states) - explaining $ = g(H_l; _g)$ with <span class="math inline">\(g\)</span> being the trained classifer.</li>
<li>Gradient-based methods (mentioning saliency maps and integrated gradients) explaining <span class="math inline">\(S(x) = |\frac{\partial f(x)}{\partial x}|\)</span> with <span class="math inline">\(x\)</span> being the input and <span class="math inline">\(f\)</span> the model.</li>
<li>Perturbation-based methods (masking or modifying inputs).</li>
<li>Mention Layer-wise Relevance Propagation and/or Concept Activation Vectors.</li>
<li>State that “Each of these techniques offers a different lens through which to understand the model’s behavior.”</li>
</ul></li>
<li><strong>Address Potential Misinterpretations (1 minute):</strong>
<ul>
<li>“It’s crucial to be aware of potential misinterpretations, regardless of which interpretability technique is used.”</li>
<li>“For example, correlation doesn’t imply causation, and many methods are sensitive to small input changes leading to instability. Interpretations are also subjective.”</li>
<li>“The key is to avoid overconfidence in any single interpretation method.”</li>
</ul></li>
<li><strong>Emphasize Rigorous Evaluation (30 seconds):</strong>
<ul>
<li>“Ultimately, interpretability techniques should be used in conjunction with rigorous evaluation. This includes human evaluation, ablation studies, and consistency checks.”</li>
<li>“By combining these approaches, we can increase our confidence in the reliability and accuracy of the explanations.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush, especially when explaining mathematical concepts.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you have access to a whiteboard or screen, sketching a simple diagram of a Transformer can be helpful.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask, “Does that make sense?” or “Would you like me to elaborate on that point?”</li>
<li><strong>Be Honest About Limitations:</strong> If you don’t know the answer to a specific question, be upfront. You can say, “That’s an interesting question. While I’m not an expert in that specific area, my understanding is…”</li>
<li><strong>Maintain a Conversational Tone:</strong> Avoid sounding like you’re reciting a script. Engage with the interviewer and make it a discussion.</li>
<li><strong>Show Enthusiasm:</strong> Your passion for the topic will make a positive impression.</li>
</ul>
<p>By following this guide, you can deliver a comprehensive and insightful answer that demonstrates your senior-level knowledge of interpretability challenges in Transformer models.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>