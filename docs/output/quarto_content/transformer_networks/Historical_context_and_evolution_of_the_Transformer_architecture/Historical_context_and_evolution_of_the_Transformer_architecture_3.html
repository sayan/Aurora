<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>historical_context_and_evolution_of_the_transformer_architecture_3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-trace-the-evolution-of-transformer-architectures-from-the-original-paper-to-later-developments-such-as-bert-gpt-and-other-variants.-what-were-the-major-improvements-and-challenges-introduced-in-these-models" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-trace-the-evolution-of-transformer-architectures-from-the-original-paper-to-later-developments-such-as-bert-gpt-and-other-variants.-what-were-the-major-improvements-and-challenges-introduced-in-these-models">Question: 4. Trace the evolution of Transformer architectures from the original paper to later developments such as BERT, GPT, and other variants. What were the major improvements and challenges introduced in these models?</h2>
<p><strong>Best Answer</strong></p>
<p>The Transformer architecture, introduced in the seminal paper “Attention is All You Need” (Vaswani et al., 2017), revolutionized Natural Language Processing (NLP) and has since become the foundation for many state-of-the-art models. The core innovation was the attention mechanism, which allows the model to weigh the importance of different parts of the input sequence when processing it. This replaced recurrent layers (like LSTMs) entirely, enabling greater parallelization and better handling of long-range dependencies.</p>
<p>Here’s a breakdown of the evolution from the original Transformer to subsequent architectures like BERT and GPT:</p>
<p><strong>1. The Original Transformer (Vaswani et al., 2017):</strong></p>
<ul>
<li><p><strong>Key Features:</strong></p>
<ul>
<li><strong>Attention Mechanism:</strong> The heart of the Transformer. Self-attention allows the model to relate different positions of the input sequence to each other, capturing dependencies.</li>
<li><strong>Encoder-Decoder Structure:</strong> The original Transformer was designed for sequence-to-sequence tasks like machine translation. The encoder processes the input sequence, and the decoder generates the output sequence.</li>
<li><strong>Multi-Head Attention:</strong> Multiple attention heads allow the model to attend to different aspects of the input sequence simultaneously. This enhances the model’s capacity to capture complex relationships.</li>
<li><strong>Positional Encoding:</strong> Since Transformers lack inherent recurrence, positional encodings are added to the input embeddings to provide information about the position of tokens in the sequence. These can be learned or fixed (e.g., sinusoidal functions).</li>
<li><strong>Residual Connections and Layer Normalization:</strong> These techniques help with training deep networks by mitigating vanishing gradients.</li>
</ul></li>
<li><p><strong>Mathematical Representation (Self-Attention):</strong></p>
<p>The attention mechanism can be mathematically described as follows:</p>
<ol type="1">
<li><p><strong>Query, Key, and Value:</strong> The input is transformed into three matrices: Query (<span class="math inline">\(Q\)</span>), Key (<span class="math inline">\(K\)</span>), and Value (<span class="math inline">\(V\)</span>). These are obtained by multiplying the input embedding by weight matrices: <span class="math display">\[Q = XW_Q\]</span> <span class="math display">\[K = XW_K\]</span> <span class="math display">\[V = XW_V\]</span> where <span class="math inline">\(X\)</span> is the input embedding matrix, and <span class="math inline">\(W_Q\)</span>, <span class="math inline">\(W_K\)</span>, and <span class="math inline">\(W_V\)</span> are learned weight matrices.</p></li>
<li><p><strong>Attention Weights:</strong> The attention weights are computed by taking the dot product of the Query and Key matrices, scaling by the square root of the dimension of the Key vectors (<span class="math inline">\(d_k\)</span>), and then applying a softmax function: <span class="math display">\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span></p></li>
</ol>
<p>The scaling factor <span class="math inline">\(\sqrt{d_k}\)</span> is used to prevent the dot products from becoming too large, which can lead to vanishing gradients after the softmax.</p></li>
<li><p><strong>Advantages:</strong></p>
<ul>
<li>Parallelization: Attention mechanisms allow for parallel processing of the input sequence, unlike recurrent networks.</li>
<li>Long-Range Dependencies: Handles long-range dependencies more effectively than RNNs.</li>
</ul></li>
<li><p><strong>Limitations:</strong></p>
<ul>
<li>Computational Cost: The computational complexity of the attention mechanism is <span class="math inline">\(O(n^2)\)</span>, where <span class="math inline">\(n\)</span> is the sequence length. This can be a bottleneck for very long sequences.</li>
<li>Lack of Contextualized Word Embeddings: The original Transformer produced static word embeddings, meaning that the same word always has the same representation regardless of the context.</li>
</ul></li>
</ul>
<p><strong>2. BERT (Bidirectional Encoder Representations from Transformers) (Devlin et al., 2018):</strong></p>
<ul>
<li><strong>Key Improvements:</strong>
<ul>
<li><strong>Bidirectional Context:</strong> BERT uses a bidirectional encoder, meaning it considers both the left and right context of a word when generating its representation. This is crucial for understanding the meaning of a word in a given sentence.</li>
<li><strong>Pre-training Tasks:</strong> BERT is pre-trained on two tasks: Masked Language Modeling (MLM) and Next Sentence Prediction (NSP).
<ul>
<li><strong>MLM:</strong> Randomly masks some of the words in the input sequence and trains the model to predict the masked words. This forces the model to learn deep bidirectional representations.</li>
<li><strong>NSP:</strong> Trains the model to predict whether two given sentences are consecutive in the original document. This helps the model understand relationships between sentences.</li>
</ul></li>
<li><strong>Fine-tuning:</strong> BERT can be fine-tuned for a wide range of downstream tasks, such as text classification, question answering, and named entity recognition.</li>
</ul></li>
<li><strong>Advantages:</strong>
<ul>
<li>Superior Performance: BERT achieved state-of-the-art results on many NLP tasks.</li>
<li>Contextualized Word Embeddings: BERT generates contextualized word embeddings, meaning that the representation of a word depends on its context.</li>
<li>Transfer Learning: BERT’s pre-trained weights can be transferred to other tasks, reducing the need for large amounts of task-specific data.</li>
</ul></li>
<li><strong>Challenges:</strong>
<ul>
<li>Computational Cost: BERT is computationally expensive to train.</li>
<li>Masking Artifacts: The masking procedure used in MLM can introduce artifacts, as the model only sees the masked words during pre-training.</li>
<li>NSP Task Effectiveness: The NSP task was later found to be less effective than originally believed and has been removed in some subsequent models.</li>
</ul></li>
</ul>
<p><strong>3. GPT (Generative Pre-trained Transformer) (Radford et al., 2018; Brown et al., 2020):</strong></p>
<ul>
<li><strong>Key Improvements:</strong>
<ul>
<li><strong>Autoregressive Modeling:</strong> GPT uses a decoder-only Transformer to model the probability distribution of text. It predicts the next word in a sequence given the previous words.</li>
<li><strong>Unidirectional Context:</strong> GPT only considers the left context when generating text. This makes it well-suited for text generation tasks.</li>
<li><strong>Scale:</strong> Later versions of GPT (e.g., GPT-3) have been scaled up to enormous sizes, with hundreds of billions of parameters.</li>
<li><strong>Few-shot Learning:</strong> GPT-3 demonstrated the ability to perform well on many tasks with only a few examples (or even zero examples).</li>
</ul></li>
<li><strong>Advantages:</strong>
<ul>
<li>Text Generation: GPT excels at generating realistic and coherent text.</li>
<li>Few-shot Learning: GPT can perform well on new tasks with very little training data.</li>
</ul></li>
<li><strong>Challenges:</strong>
<ul>
<li>Unidirectional Context: The unidirectional context can be a limitation for tasks that require bidirectional understanding.</li>
<li>Computational Cost: Training and running large GPT models is very expensive.</li>
<li>Bias: GPT models can be biased due to the data they are trained on.</li>
<li>Control: Controlling the output of GPT models can be difficult. They can sometimes generate nonsensical or offensive text.</li>
</ul></li>
</ul>
<p><strong>4. Other Variants and Developments:</strong></p>
<ul>
<li><strong>RoBERTa (Robustly Optimized BERT Approach) (Liu et al., 2019):</strong> An improved version of BERT that uses a larger training dataset, longer training time, and removes the NSP task.</li>
<li><strong>DistilBERT (Sanh et al., 2019):</strong> A distilled version of BERT that is smaller and faster to run. It achieves similar performance to BERT with fewer parameters.</li>
<li><strong>T5 (Text-to-Text Transfer Transformer) (Raffel et al., 2019):</strong> A unified framework that casts all NLP tasks as text-to-text problems.</li>
<li><strong>DeBERTa (Decoding-enhanced BERT with Disentangled Attention) (He et al., 2020):</strong> An improvement over BERT that uses disentangled attention and an enhanced mask decoder.</li>
<li><strong>Vision Transformer (ViT) (Dosovitskiy et al., 2020):</strong> Applies the Transformer architecture to computer vision tasks by treating images as sequences of patches.</li>
<li><strong>Longformer (Beltagy et al., 2020):</strong> Designed to handle longer sequences than the original Transformer by using a combination of global and local attention mechanisms. This addresses the <span class="math inline">\(O(n^2)\)</span> complexity challenge of standard attention.</li>
<li><strong>BigBird (Zaheer et al., 2020):</strong> Another approach to handling long sequences, using a sparse attention mechanism that reduces the computational complexity to <span class="math inline">\(O(n)\)</span>.</li>
</ul>
<p><strong>Major Improvements and Challenges (Summary):</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Improvement</th>
<th>Challenge</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Transformer</td>
<td>Attention mechanism, Parallelization</td>
<td><span class="math inline">\(O(n^2)\)</span> complexity, Static word embeddings</td>
</tr>
<tr class="even">
<td>BERT</td>
<td>Bidirectional context, Contextualized embeddings</td>
<td>Computational cost, Masking artifacts</td>
</tr>
<tr class="odd">
<td>GPT</td>
<td>Autoregressive modeling, Few-shot learning</td>
<td>Unidirectional context, Bias, Control</td>
</tr>
<tr class="even">
<td>RoBERTa</td>
<td>Improved training procedure</td>
<td>Still computationally expensive</td>
</tr>
<tr class="odd">
<td>DistilBERT</td>
<td>Reduced size and faster inference</td>
<td>Slight performance degradation compared to BERT</td>
</tr>
<tr class="even">
<td>Longformer</td>
<td>Handling longer sequences</td>
<td>Increased model complexity</td>
</tr>
</tbody>
</table>
<p>The evolution of the Transformer architecture continues to be an active area of research. Future directions include developing more efficient attention mechanisms, improving the ability to handle long sequences, reducing bias, and improving the control over text generation.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested way to present this information in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Big Picture:</strong> “The Transformer architecture revolutionized NLP with its attention mechanism, offering parallelization and better handling of long-range dependencies compared to recurrent networks. It’s important to understand how subsequent models built upon this foundation.”</p></li>
<li><p><strong>Explain the Original Transformer:</strong> “The original Transformer, introduced in the ‘Attention is All You Need’ paper, used an encoder-decoder structure for sequence-to-sequence tasks. The key innovation was the attention mechanism, which allows the model to weigh the importance of different parts of the input. Mathematically, this involves transforming the input into Query, Key, and Value matrices, then calculating attention weights using a softmax function…</p>
<ul>
<li><em>If the interviewer seems comfortable with math, you can briefly show the equation</em> “The core of the attention mechanism can be summarized as: <span class="math inline">\(Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\)</span>. The scaling factor helps prevent vanishing gradients.”</li>
<li><em>If the interviewer is less technical, simplify:</em> “The attention mechanism essentially figures out how much each word in the input should ‘pay attention’ to every other word.”</li>
<li>Continue by explaining positional encoding, multi-head attention, and residual connections.</li>
</ul></li>
<li><p><strong>Introduce BERT:</strong> “BERT took the Transformer encoder and pre-trained it bidirectionally using Masked Language Modeling and Next Sentence Prediction. This allows BERT to understand the context of a word from both sides, leading to better contextualized word embeddings. The downside is the computational cost of pre-training and potential artifacts from the masking procedure.”</p></li>
<li><p><strong>Introduce GPT:</strong> “GPT, on the other hand, uses a decoder-only Transformer and is pre-trained autoregressively to generate text. It excels at text generation and few-shot learning, but it’s unidirectional, and large GPT models can be computationally expensive and biased.”</p></li>
<li><p><strong>Mention Other Variants:</strong> “Many variants have emerged, each addressing specific limitations or focusing on particular applications. For example, RoBERTa improves BERT’s training procedure, DistilBERT creates a smaller, faster version, and Longformer tackles long sequence lengths. ViT applies Transformers to vision tasks.”</p></li>
<li><p><strong>Summarize with Trade-offs:</strong> “In summary, each model offers improvements over its predecessors but also introduces new challenges. The trade-offs often involve computational cost, bias, and the ability to handle different types of tasks. The ongoing research focuses on addressing these trade-offs to create more efficient, robust, and controllable models.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Allow the interviewer time to process the information.</li>
<li><strong>Use clear language:</strong> Avoid jargon unless you’re sure the interviewer understands it.</li>
<li><strong>Check for understanding:</strong> Pause occasionally and ask if the interviewer has any questions.</li>
<li><strong>Highlight the key concepts:</strong> Focus on the core ideas and avoid getting bogged down in unnecessary details.</li>
<li><strong>Tailor your explanation to the interviewer’s background:</strong> If the interviewer is more technically inclined, you can go into more detail. If they’re less technical, focus on the high-level concepts.</li>
<li><strong>Be enthusiastic:</strong> Show that you’re passionate about the topic.</li>
<li><strong>Be prepared to answer follow-up questions:</strong> The interviewer will likely have questions about specific models or techniques.</li>
<li><strong>Don’t be afraid to say “I don’t know”:</strong> If you don’t know the answer to a question, it’s better to be honest than to try to bluff your way through it.</li>
</ul>
<p>By following these guidelines, you can effectively communicate your knowledge of Transformer architectures and their evolution in a clear, concise, and engaging manner.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>