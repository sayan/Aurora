<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>handling_long_sequences__longformer__big_bird__etc___10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-11.-discuss-how-attention-visualization-tools-can-assist-in-debugging-or-improving-models-that-handle-long-sequences.-what-specific-indicators-would-you-look-for" class="level2">
<h2 class="anchored" data-anchor-id="question-11.-discuss-how-attention-visualization-tools-can-assist-in-debugging-or-improving-models-that-handle-long-sequences.-what-specific-indicators-would-you-look-for">Question: 11. Discuss how attention visualization tools can assist in debugging or improving models that handle long sequences. What specific indicators would you look for?</h2>
<p><strong>Best Answer</strong></p>
<p>Attention mechanisms have become a cornerstone of modern sequence processing, particularly in handling long sequences. However, understanding <em>what</em> an attention mechanism has learned can be challenging. Attention visualization tools provide a window into this “black box,” offering crucial insights for debugging and improving models like Transformers, Longformers, and Big Bird. These visualizations essentially show the learned dependencies between different parts of the input sequence.</p>
<p><strong>Why Attention Visualization Matters</strong></p>
<ul>
<li><p><strong>Model Interpretability:</strong> Visualizing attention weights sheds light on which input tokens the model deems most relevant when processing a particular token. This aids in understanding the model’s reasoning.</p></li>
<li><p><strong>Debugging:</strong> Attention visualizations can reveal errors in the model’s attention patterns, such as attending to irrelevant tokens or failing to capture important dependencies.</p></li>
<li><p><strong>Model Improvement:</strong> By identifying weaknesses in the attention mechanism, developers can refine the model architecture, training data, or training process to improve performance.</p></li>
</ul>
<p><strong>Common Attention Visualization Techniques</strong></p>
<ol type="1">
<li><p><strong>Attention Heatmaps:</strong> These are the most common type. They represent the attention weights as a matrix, where each cell <span class="math inline">\((i, j)\)</span> corresponds to the attention weight <span class="math inline">\(a_{ij}\)</span> given to the <span class="math inline">\(j\)</span>-th token when processing the <span class="math inline">\(i\)</span>-th token. The weights are typically normalized such that <span class="math inline">\(\sum_j a_{ij} = 1\)</span> for each <span class="math inline">\(i\)</span>. A color gradient represents the magnitude of the attention weight. <span class="math display">\[
a_{ij} = \frac{\exp(e_{ij})}{\sum_k \exp(e_{ik})}
\]</span> Here, <span class="math inline">\(e_{ij}\)</span> represents an attention score, often computed as a scaled dot-product between the query vector for the <span class="math inline">\(i\)</span>-th token and the key vector for the <span class="math inline">\(j\)</span>-th token. For instance: <span class="math inline">\(e_{ij} = \frac{q_i^T k_j}{\sqrt{d_k}}\)</span> where <span class="math inline">\(d_k\)</span> is the dimension of the key vectors.</p></li>
<li><p><strong>Attention Rollout:</strong> This technique recursively propagates attention weights through the layers of the network to determine the overall influence of each input token on the final output. For a network with <span class="math inline">\(L\)</span> layers, the rollout score <span class="math inline">\(R_{ij}\)</span> between tokens <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is computed as follows:</p>
<p><span class="math display">\[
R_{ij}^{(l)} = \begin{cases}
    A_{ij}^{(l)} &amp; \text{if } l = 1 \\
    \sum_k A_{ik}^{(l)} R_{kj}^{(l-1)} &amp; \text{if } l &gt; 1
\end{cases}
\]</span> Where <span class="math inline">\(A_{ij}^{(l)}\)</span> is the attention weight from token <span class="math inline">\(j\)</span> to token <span class="math inline">\(i\)</span> in layer <span class="math inline">\(l\)</span>. The final rollout score after <span class="math inline">\(L\)</span> layers is <span class="math inline">\(R_{ij}^{(L)}\)</span>.</p></li>
<li><p><strong>Attention Flows:</strong> Visualizes the flow of information across different tokens in the sequence. This is often represented as a directed graph, where nodes are tokens, and edges represent the attention weights between them.</p></li>
</ol>
<p><strong>Specific Indicators to Look For in Attention Visualizations</strong></p>
<p>When examining attention visualizations, look for these key indicators to understand the model’s behavior and identify potential issues:</p>
<ul>
<li><p><strong>Attention to Key Tokens:</strong> The model should attend strongly to semantically important tokens (e.g., keywords, entities, verbs) when processing related parts of the sequence. Lack of attention to these tokens suggests the model might be missing crucial information. Check for head diversity, if some heads are picking up on import features or tokens that others are not. This may signify the need for further training or ensembling.</p></li>
<li><p><strong>Drop-off in Long-Range Dependencies:</strong> In long sequences, attention weights might decay rapidly with distance, hindering the model’s ability to capture long-range dependencies. This can be seen as progressively weaker color intensities in the heatmap as the distance between tokens increases. The model needs to give an adequate level of attention to these tokens, however, this depends on the structure of the sentence, document, etc.</p>
<ul>
<li><em>Potential Solutions:</em> Use architectures specifically designed for long sequences, like Longformer (with sliding window and global attention), Big Bird (with random, global, and windowed attention), or sparse attention mechanisms. Training with longer sequence lengths and increasing the depth of the attention mechanism can also help.</li>
</ul></li>
<li><p><strong>Misallocation of Attention:</strong> The model might attend to irrelevant or noisy tokens, indicating a failure to understand the relationships between tokens. For instance, attending to punctuation or stop words instead of content words.</p>
<ul>
<li><em>Potential Solutions:</em> Improve data preprocessing, filter out noise, or add attention regularization terms to penalize attention to irrelevant tokens. Also, investigate if adversarial examples have influenced the training.</li>
</ul></li>
<li><p><strong>Head Diversity:</strong> In multi-head attention, different heads should ideally learn different attention patterns. If all heads exhibit similar patterns, it indicates redundancy, meaning not all heads are contributing effectively. <span class="math display">\[
\text{MultiHead}(Q, K, V) = \text{Concat}(head_1, ..., head_h)W^O \\
\text{where } head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)
\]</span> where <span class="math inline">\(W_i^Q, W_i^K, W_i^V\)</span> are the projection matrices for the i-th head and <span class="math inline">\(W^O\)</span> is the output projection matrix.</p>
<ul>
<li><em>Potential Solutions:</em> Encourage diversity through regularization techniques or by designing loss functions that explicitly promote different attention patterns across heads.</li>
</ul></li>
<li><p><strong>Unexpected Attention Patterns:</strong> Visualizations might reveal attention patterns that contradict linguistic intuition or domain knowledge. This can point to biases in the training data or limitations in the model’s ability to capture complex relationships. For example, if a model is supposed to translate English to French, and when attending to the french word “le” it attends more to nouns than articles.</p>
<ul>
<li><em>Potential Solutions:</em> Examine the training data for biases. Refine the model architecture or incorporate external knowledge sources to guide attention patterns.</li>
</ul></li>
<li><p><strong>Instability During Training:</strong> Monitoring attention patterns during training can reveal instabilities or oscillations in the attention mechanism. This can suggest issues with the learning rate, optimization algorithm, or model architecture.</p>
<ul>
<li><em>Potential Solutions:</em> Experiment with different learning rate schedules, optimizers, or regularization techniques to stabilize training.</li>
</ul></li>
</ul>
<p><strong>Real-World Considerations</strong></p>
<ul>
<li><p><strong>Scalability:</strong> Visualizing attention for very long sequences can be computationally expensive and challenging to interpret. Consider using techniques like attention pooling or summarization to reduce the amount of data visualized.</p></li>
<li><p><strong>Tooling:</strong> Various libraries and tools facilitate attention visualization, including TensorBoard, AllenNLP, and dedicated visualization packages. Select tools that align with your framework and visualization needs.</p></li>
<li><p><strong>Qualitative vs.&nbsp;Quantitative Evaluation:</strong> While attention visualization provides qualitative insights, it’s crucial to complement these insights with quantitative metrics (e.g., accuracy, perplexity) to assess the impact of any model changes. For example, if attention becomes more sparse after some fine tuning, how does that impact model performance on some benchmark dataset.</p></li>
</ul>
<p>In summary, attention visualization tools are indispensable for understanding, debugging, and improving models that handle long sequences. By carefully analyzing attention patterns, developers can gain valuable insights into the model’s behavior and guide targeted improvements to architecture, training, and data.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide for delivering this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Importance:</strong> Begin by highlighting the core problem: understanding what attention mechanisms learn is challenging. Emphasize that attention visualization tools provide interpretability and debugging capabilities for long-sequence models.</p>
<p><em>“Attention mechanisms are fundamental for handling long sequences, but they’re essentially black boxes. Attention visualization tools help us understand and debug these mechanisms.”</em></p></li>
<li><p><strong>Explain <em>Why</em> Visualization is Valuable:</strong> Briefly explain <em>why</em> these visualizations are helpful: model interpretability, debugging errors, and guiding model improvements.</p>
<p><em>“These visualizations are valuable because they allow us to interpret what the model is focusing on, debug errors in attention patterns, and improve the model’s overall performance.”</em></p></li>
<li><p><strong>Introduce Common Techniques (Heatmaps, Rollout):</strong> Describe the main visualization techniques. Start with the most common (heatmaps) and then briefly mention others (rollout, flows). For the heatmap, briefly explain how the attention weights are obtained (softmax).</p>
<p><em>“The most common technique is attention heatmaps, which show the attention weights between tokens. Each cell in the matrix represents how much the model is attending to one token when processing another. The weights are obtained using a softmax function. Another approach is attention rollout…”</em></p></li>
<li><p><strong>Focus on Key Indicators (Prioritize):</strong> Spend the most time on the “indicators” section. Pick the most critical indicators (e.g., attention to key tokens, drop-off in long-range dependencies, misallocation of attention) and explain them clearly. Provide examples of what these issues might look like and potential solutions.</p>
<p><em>“When looking at these visualizations, there are several key indicators to watch out for. One is whether the model is attending to semantically important tokens. For instance, if the model is supposed to be attending strongly to keywords, but it is not, this indicates a problem. Another key indicator is the drop off in long-range dependencies. The model might fail to capture long-range dependencies when processing long documents. In such cases, using specialized architectures such as Longformer is important.”</em></p></li>
<li><p><strong>Equations (Handle with Care):</strong> When presenting equations, avoid diving into excessive detail unless prompted. Explain the general purpose of the equation and the meaning of the main symbols. Use simple language to convey the underlying idea.</p>
<p><em>“For example, the attention weights can be written as… [write the softmax attention equation]. Essentially, this equation calculates the weight assigned to each token based on its relevance to the current token being processed.”</em></p></li>
<li><p><strong>Real-World Considerations (Practicality):</strong> Briefly touch on real-world challenges like scalability and tooling. Emphasize the need to combine qualitative insights with quantitative metrics.</p>
<p><em>“In practice, visualizing attention for very long sequences can be computationally expensive. Also, it’s important to complement these visualizations with quantitative metrics to ensure that any changes are actually improving performance.”</em></p></li>
<li><p><strong>Engage with the Interviewer:</strong> Encourage questions throughout your explanation. This shows your willingness to explain and clarify. Pause after explaining each major point to give the interviewer a chance to ask questions.</p>
<p><em>“Does that make sense so far? Are there any particular aspects you’d like me to elaborate on?”</em></p></li>
</ol>
<p><strong>Communication Tips</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Allow time for the interviewer to process the information.</li>
<li><strong>Use Visual Aids (if Possible):</strong> If you’re in a virtual interview, consider sharing your screen and showing example attention heatmaps.</li>
<li><strong>Be Confident:</strong> Project confidence in your knowledge. Even if you don’t know every detail, demonstrate that you understand the core concepts and can apply them to real-world problems.</li>
<li><strong>Be Ready to Elaborate:</strong> The interviewer may ask follow-up questions about specific techniques, indicators, or solutions. Be prepared to provide more details or examples.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>