<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>handling_long_sequences__longformer__big_bird__etc___6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-7.-how-might-the-choice-of-positional-encodings-differ-or-need-modification-when-working-with-long-sequences-in-models-like-longformer-and-big-bird" class="level2">
<h2 class="anchored" data-anchor-id="question-7.-how-might-the-choice-of-positional-encodings-differ-or-need-modification-when-working-with-long-sequences-in-models-like-longformer-and-big-bird">Question: 7. How might the choice of positional encodings differ or need modification when working with long sequences in models like Longformer and Big Bird?</h2>
<p><strong>Best Answer</strong></p>
<p>When dealing with long sequences, the choice of positional encodings becomes a critical factor in the performance of Transformer-based models like Longformer and Big Bird. Standard positional encodings, such as sinusoidal encodings or learned embeddings, face challenges when applied to sequences exceeding their designed or trained lengths. These challenges stem from issues with distinguishability, computational complexity, and generalization.</p>
<p>Here’s a breakdown of the issues and the modifications/alternatives used in models like Longformer and Big Bird:</p>
<p><strong>1. Limitations of Standard Positional Encodings for Long Sequences:</strong></p>
<ul>
<li><p><strong>Distinguishability Degradation:</strong> In standard positional encodings, especially sinusoidal ones, as the sequence length increases, the encodings for distant positions can become less distinguishable. This means the model struggles to accurately differentiate the positions of tokens that are far apart, hindering its ability to learn long-range dependencies effectively. This is partly because sinusoidal functions are periodic. While their frequencies are chosen to minimize overlap, extremely long sequences will inevitably lead to repetitions or near-repetitions of encodings.</p></li>
<li><p><strong>Computational Complexity:</strong> For learned positional embeddings, the memory and computational cost grow linearly with the sequence length. If the model is trained only on shorter sequences and then deployed on longer sequences, the positional embeddings for the extended positions are essentially random, potentially disrupting the attention mechanism and leading to poor performance.</p></li>
<li><p><strong>Generalization Issues:</strong> Models trained with a fixed maximum sequence length using standard positional encodings might not generalize well to sequences longer than what they were trained on. Extrapolating positional embeddings to unseen lengths can introduce artifacts and hurt performance.</p></li>
</ul>
<p><strong>2. Alternative Positional Encoding Strategies for Long Sequences:</strong></p>
<ul>
<li><p><strong>Relative Positional Encodings:</strong> Instead of encoding the absolute position of each token, relative positional encodings encode the <em>relative distance</em> between tokens. This is particularly beneficial for long sequences because the relative distance between any two tokens remains within a manageable range, regardless of the overall sequence length. Several variations exist:</p>
<ul>
<li><p><strong>Transformer-XL’s Relative Positional Encodings:</strong> Introduced in Transformer-XL, this method redefines the attention mechanism to incorporate relative positional information. The attention score calculation is modified to include terms that depend on the relative distance <span class="math inline">\(i-j\)</span> between the query at position <span class="math inline">\(i\)</span> and the key at position <span class="math inline">\(j\)</span>. The key and value projections are modified as follows: <span class="math display">\[
a_{ij} = q_i^T k_j = (E_{x_i}W_q)^T (E_{x_j}W_k + a_{i-j}W_k^R)
\]</span> <span class="math display">\[
v_{ij} = E_{x_j} W_v + e_{i-j}W_v^R
\]</span></p>
<p>Here, <span class="math inline">\(E_{x_i}\)</span> and <span class="math inline">\(E_{x_j}\)</span> are the input embeddings for tokens at positions i and j, <span class="math inline">\(W_q\)</span>, <span class="math inline">\(W_k\)</span> and <span class="math inline">\(W_v\)</span> are the query, key and value projection matrices, respectively. <span class="math inline">\(a_{i-j}\)</span> and <span class="math inline">\(e_{i-j}\)</span> are the relative positional embeddings, and <span class="math inline">\(W_k^R\)</span> and <span class="math inline">\(W_v^R\)</span> are learnable parameter matrices. The attention score <span class="math inline">\(a_{ij}\)</span> now depends on both the content of tokens <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>, <em>and</em> their relative position <span class="math inline">\(i-j\)</span>.</p></li>
<li><p><strong>T5’s Relative Positional Bias:</strong> In T5, relative position embeddings are used as bias terms added to the attention logits. These biases are learned and quantized, making them efficient and effective. <span class="math display">\[
Attention(Q, K, V) = softmax(\frac{QK^T + B}{\sqrt{d_k}})V
\]</span> Where <span class="math inline">\(B\)</span> is the relative positional bias matrix, and <span class="math inline">\(d_k\)</span> is the dimension of the keys.</p></li>
</ul></li>
<li><p><strong>Sparse Attention Mechanisms:</strong> Models like Longformer and Big Bird employ sparse attention mechanisms to reduce computational complexity. These mechanisms selectively attend to certain tokens instead of all tokens. Positional encodings play a role here by informing the sparse attention patterns:</p>
<ul>
<li><strong>Longformer:</strong> Combines a sliding window attention (each token attends to a fixed-size window around it), global attention (certain tokens attend to all tokens, useful for tasks like classification), and task-specific attention. Relative positional encodings can enhance the sliding window attention by providing information about the tokens within the window.</li>
<li><strong>Big Bird:</strong> Uses a combination of random attention, window attention, and global attention to approximate the full attention mechanism. Positional encodings influence how these sparse attention patterns are structured.</li>
</ul></li>
<li><p><strong>Learned Positional Encodings with Fine-tuning or Transfer Learning:</strong> Rather than relying on fixed sinusoidal embeddings, learned embeddings can be adapted. One approach is to pre-train on shorter sequences and then fine-tune on longer sequences. This allows the model to learn to extrapolate the positional embeddings more effectively.</p></li>
</ul>
<p><strong>3. Considerations and Trade-offs:</strong></p>
<ul>
<li><strong>Computational Cost:</strong> Relative positional encodings generally add a constant overhead to the attention mechanism, but this is often outweighed by the benefits for long sequences. Sparse attention mechanisms significantly reduce the computational cost of the attention operation, making it feasible to process very long sequences.</li>
<li><strong>Memory Footprint:</strong> Learned positional embeddings can consume significant memory, especially for very long sequences. Techniques like quantization or low-rank approximations can help reduce the memory footprint.</li>
<li><strong>Implementation Complexity:</strong> Implementing relative positional encodings and sparse attention mechanisms can be more complex than using standard positional encodings.</li>
<li><strong>Task-Specific Performance:</strong> The optimal choice of positional encoding and attention mechanism depends on the specific task and dataset. Empirical evaluation is crucial to determine which approach works best.</li>
</ul>
<p><strong>4. Mathematical Representation of Sinusoidal Positional Encoding:</strong></p>
<p>The standard sinusoidal positional encoding is defined as:</p>
<p><span class="math display">\[
PE(pos, 2i) = sin(\frac{pos}{10000^{2i/d_{model}}})
\]</span></p>
<p><span class="math display">\[
PE(pos, 2i+1) = cos(\frac{pos}{10000^{2i/d_{model}}})
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(pos\)</span> is the position of the token in the sequence.</li>
<li><span class="math inline">\(i\)</span> is the dimension index.</li>
<li><span class="math inline">\(d_{model}\)</span> is the dimensionality of the embeddings.</li>
</ul>
<p>As <span class="math inline">\(pos\)</span> increases, the argument of the sine and cosine functions increases, potentially leading to the distinguishability issues mentioned earlier.</p>
<p>In summary, handling positional information in long sequences requires careful consideration of the limitations of standard positional encodings and the advantages of alternative strategies like relative positional encodings and sparse attention mechanisms. Models like Longformer and Big Bird demonstrate how these techniques can be effectively combined to process very long sequences while maintaining computational efficiency and generalization ability.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide to delivering this answer effectively in an interview:</p>
<ol type="1">
<li><strong>Start with the Problem (0:30 - 1:00):</strong>
<ul>
<li>“When we move to extremely long sequences, the standard approaches to positional encoding that work well for shorter sequences start to break down. This is because…”</li>
<li>“Specifically, there are three key issues with standard positional encodings like sinusoidal embeddings or learned embeddings. First, the encodings become less distinguishable over very long distances. Second, the memory and computational costs can become prohibitive. And third, models trained on short sequences often don’t generalize well to much longer sequences.”</li>
<li>Briefly mention the goal: “Models like Longformer and Big Bird address these limitations through modifications to the positional encodings and attention mechanisms.”</li>
</ul></li>
<li><strong>Explain Relative Positional Encodings (2:00 - 3:00):</strong>
<ul>
<li>“One powerful alternative is <em>relative positional encodings</em>. Instead of encoding the absolute position, we encode the distance <em>between</em> tokens. Think about it this way: knowing how far apart two words are is often more relevant than their absolute positions in a giant document.”</li>
<li>“Transformer-XL introduced a clever way to incorporate relative positions directly into the attention calculation by modifying how keys and values are projected. T5 uses relative position embeddings as biases to the attention logits.”</li>
<li>Optional: You can mention specific formulas like <span class="math display">\[a_{ij} = q_i^T k_j = (E_{x_i}W_q)^T (E_{x_j}W_k + a_{i-j}W_k^R)\]</span>, but <em>only</em> if the interviewer seems very interested and you’re comfortable explaining it clearly. Briefly state that the equation shows how the attention score depends not only on the tokens themselves, but also on their relative position. Avoid diving too deep into the notation unless asked.</li>
</ul></li>
<li><strong>Discuss Sparse Attention and its relation to Position (1:00 - 1:30):</strong>
<ul>
<li>“Models like Longformer and Big Bird also use <em>sparse attention</em> to handle the computational cost of long sequences. Instead of every token attending to every other token, they use clever strategies to attend to only a subset.”</li>
<li>“The positional encodings play a role here, influencing how the sparse attention patterns are structured. For example, Longformer uses sliding window attention, and relative positional encodings can improve the attention within the window.”</li>
</ul></li>
<li><strong>Highlight Trade-offs and Practical Considerations (0:30 - 1:00):</strong>
<ul>
<li>“Of course, there are trade-offs. Relative positional encodings add some complexity, and sparse attention requires careful design. The best choice depends on the task, the data, and the available resources.”</li>
<li>“Implementation can be tricky, and you need to be mindful of memory footprint, especially for very, very long sequences.”</li>
<li>End by reiterating the importance of empirical evaluation: “Ultimately, you need to experiment and see what works best in practice.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pause and Check In:</strong> After explaining a complex concept like relative positional encodings, pause and ask, “Does that make sense so far?” This ensures the interviewer is following along.</li>
<li><strong>Use Analogies:</strong> Whenever possible, use analogies to simplify the explanation. For example, you could compare relative positional encodings to how we read a book: we’re more concerned with the relationship between the current sentence and the previous one than with its absolute page number.</li>
<li><strong>Gauge the Interviewer’s Level:</strong> Pay attention to the interviewer’s body language and questions. If they seem confused, simplify your explanation. If they seem very knowledgeable, you can go into more technical detail.</li>
<li><strong>Focus on Understanding, Not Memorization:</strong> Don’t just rattle off formulas. Explain the <em>intuition</em> behind the concepts.</li>
<li><strong>Be Enthusiastic:</strong> Show that you’re genuinely interested in the topic.</li>
</ul>
<p>By following these steps, you can deliver a comprehensive and engaging answer that demonstrates your deep understanding of positional encodings and their role in handling long sequences.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>