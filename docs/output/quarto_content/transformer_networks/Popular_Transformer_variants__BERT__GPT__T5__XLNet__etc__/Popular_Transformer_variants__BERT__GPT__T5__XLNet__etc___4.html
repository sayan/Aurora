<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>popular_transformer_variants__bert__gpt__t5__xlnet__etc___4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-in-what-scenarios-would-you-prefer-using-an-autoregressive-model-like-gpt-over-a-bidirectional-model-like-bert-and-vice-versa" class="level2">
<h2 class="anchored" data-anchor-id="question-5.-in-what-scenarios-would-you-prefer-using-an-autoregressive-model-like-gpt-over-a-bidirectional-model-like-bert-and-vice-versa">Question: 5. In what scenarios would you prefer using an autoregressive model like GPT over a bidirectional model like BERT, and vice versa?</h2>
<p><strong>Best Answer</strong></p>
<p>The choice between autoregressive models like GPT (Generative Pre-trained Transformer) and bidirectional models like BERT (Bidirectional Encoder Representations from Transformers) hinges primarily on the specific task and the nature of the information flow required. Here’s a breakdown of when each model type excels:</p>
<p><strong>Autoregressive Models (e.g., GPT)</strong></p>
<ul>
<li><p><strong>Core Principle:</strong> Autoregressive models predict the next token (or element) in a sequence given the preceding tokens. They are inherently unidirectional, processing text from left to right. Mathematically, the probability of a sequence <span class="math inline">\(x = (x_1, x_2, ..., x_n)\)</span> is factorized as:</p>
<p><span class="math display">\[P(x) = \prod_{i=1}^{n} P(x_i | x_1, x_2, ..., x_{i-1})\]</span></p></li>
<li><p><strong>Best Use Cases:</strong></p>
<ul>
<li><strong>Generative Tasks:</strong> GPT shines when the goal is to generate new content, such as text completion, creative writing, code generation, and dialogue. The unidirectional nature aligns perfectly with the sequential generation process. It can generate sequences conditioned on a prompt (prefix) <span class="math inline">\(x_{&lt;i}\)</span> , thus finding the next token: <span class="math display">\[x_i = argmax_{x_i} P(x_i | x_1, x_2, ..., x_{i-1})\]</span></li>
<li><strong>Language Modeling:</strong> As GPT is trained to predict the next word, it learns a strong language model that captures the statistical relationships between words and phrases.</li>
<li><strong>Few-Shot Learning:</strong> GPT models, especially larger variants, have demonstrated remarkable few-shot learning capabilities, adapting to new tasks with minimal training examples.</li>
<li><strong>Text summarization</strong> when it can be framed as a generation task</li>
</ul></li>
<li><p><strong>Limitations:</strong></p>
<ul>
<li><strong>Contextual Understanding:</strong> The unidirectional context can be a limitation when full contextual understanding is crucial. For example, filling in the blank in a sentence might be better addressed with bidirectional context.</li>
<li><strong>Task-Specific Fine-tuning:</strong> While few-shot capabilities are impressive, fine-tuning GPT on specific datasets can still yield significant performance improvements for specialized tasks.</li>
</ul></li>
</ul>
<p><strong>Bidirectional Models (e.g., BERT)</strong></p>
<ul>
<li><p><strong>Core Principle:</strong> Bidirectional models consider the entire input sequence when encoding each token. BERT uses a masked language modeling (MLM) objective, where some tokens are masked, and the model learns to predict the masked tokens based on the surrounding context. BERT is trained to minimize the negative log-likelihood of the masked tokens <span class="math inline">\(x_m\)</span>:</p>
<p><span class="math display">\[L = -log P(x_m | x_{\setminus m})\]</span></p>
<p>where <span class="math inline">\(x_{\setminus m}\)</span> denotes the unmasked tokens. This forces the model to understand the relationships between words from both directions.</p></li>
<li><p><strong>Best Use Cases:</strong></p>
<ul>
<li><strong>Natural Language Understanding (NLU) Tasks:</strong> BERT excels in tasks that require a deep understanding of the context, such as:
<ul>
<li><strong>Question Answering:</strong> Understanding the question and the context passage to extract or generate the correct answer.</li>
<li><strong>Sentiment Analysis:</strong> Determining the sentiment expressed in a text.</li>
<li><strong>Named Entity Recognition (NER):</strong> Identifying and classifying named entities in a text.</li>
<li><strong>Text Classification:</strong> Categorizing text into predefined classes.</li>
</ul></li>
<li><strong>Sentence Similarity:</strong> Determining the semantic similarity between two sentences.</li>
<li><strong>Tasks Benefiting from Full Context:</strong> Any task where knowing the words before <em>and</em> after a given word is important for understanding its meaning.</li>
<li><strong>Interpretability:</strong> Attention mechanisms in BERT provide insights into which words the model focuses on when making predictions, enhancing interpretability.</li>
</ul></li>
<li><p><strong>Limitations:</strong></p>
<ul>
<li><strong>Text Generation:</strong> BERT is not inherently designed for text generation. While it can be adapted for generative tasks, it is not as natural or efficient as autoregressive models. Generating text with BERT often involves more complex techniques.</li>
<li><strong>Inability to generate sequences conditioned on a prompt:</strong> It must process the entire sequence at once.</li>
</ul></li>
</ul>
<p><strong>Trade-offs and Considerations:</strong></p>
<ul>
<li><strong>Computational Cost:</strong> BERT, with its bidirectional attention, can be computationally more expensive than GPT, especially for very long sequences. However, optimized implementations and hardware acceleration mitigate this to some degree. During inference, GPT only needs to recompute the attention weights for the new tokens that are generated, while BERT has to recompute the attention weights for the entire input sequence.</li>
<li><strong>Fine-tuning Data:</strong> Both model types benefit from fine-tuning on task-specific data. The amount of data required often depends on the similarity between the pre-training data and the target task.</li>
<li><strong>Hybrid Approaches:</strong> There are also hybrid approaches that combine the strengths of both autoregressive and bidirectional models. For example, some models use BERT for encoding the input and GPT for decoding and generating the output.</li>
<li><strong>Alternatives:</strong> Other transformer architectures, like T5 (Text-to-Text Transfer Transformer) and XLNet, offer different trade-offs and are suitable for specific scenarios. T5, for example, frames all NLP tasks as text-to-text problems, making it versatile for both understanding and generation. XLNet attempts to combine the advantages of both autoregressive and permutation-based approaches.</li>
</ul>
<p><strong>In Summary:</strong></p>
<p>Choose GPT when you need to <em>generate</em> text. Choose BERT when you need to <em>understand</em> text. The specific choice depends on the task at hand and the desired balance between generation quality, contextual understanding, and computational efficiency. The continuous evolution of transformer architectures means that these guidelines are constantly being refined.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to present this answer in an interview:</p>
<ol type="1">
<li><strong>Start with the Core Difference:</strong>
<ul>
<li>“The fundamental difference lies in their approach to context. GPT is <em>autoregressive</em>, meaning it predicts the next word based on the preceding words, processing text in one direction. BERT, on the other hand, is <em>bidirectional</em>, considering the entire sequence simultaneously to understand the context of each word.”</li>
</ul></li>
<li><strong>Highlight GPT Use Cases (Generation):</strong>
<ul>
<li>“GPT is ideal for tasks where we want to <em>generate</em> text, such as text completion, creative writing, or dialogue. Its unidirectional nature makes it well-suited for generating coherent and contextually relevant sequences.”</li>
<li>“Mathematically, we can think of it as predicting each token <span class="math inline">\(x_i\)</span> given the history <span class="math inline">\(x_1\)</span> through <span class="math inline">\(x_{i-1}\)</span>: <span class="math inline">\(P(x_i | x_1, x_2, ..., x_{i-1})\)</span>. It’s all about predicting the next step in the sequence.”</li>
</ul></li>
<li><strong>Highlight BERT Use Cases (Understanding):</strong>
<ul>
<li>“BERT excels in tasks that require a deep <em>understanding</em> of language, like question answering, sentiment analysis, and named entity recognition. It leverages the bidirectional context to capture the nuances of language more effectively.”</li>
<li>“BERT uses a ‘masked language modeling’ objective. Imagine we hide some words in a sentence and ask the model to guess them based on the rest of the sentence. This forces BERT to understand the relationships between words from both sides, which significantly improves its understanding capabilities. <span class="math inline">\(L = -log P(x_m | x_{\setminus m})\)</span> where we minimize the loss of predicting the masked token.”</li>
</ul></li>
<li><strong>Address Limitations:</strong>
<ul>
<li>“GPT’s unidirectional approach can be a limitation when full context is required. BERT isn’t designed for native text generation; it needs extra workarounds.”</li>
</ul></li>
<li><strong>Discuss Trade-offs:</strong>
<ul>
<li>“There are trade-offs in terms of computational cost and fine-tuning requirements. BERT can be more computationally intensive, especially for long sequences. Both models typically benefit from fine-tuning on task-specific data.”</li>
</ul></li>
<li><strong>Mention Alternatives (Optional):</strong>
<ul>
<li>“It’s also worth noting that there are other transformer architectures, like T5 and XLNet, that offer different advantages and can be suitable for specific scenarios. T5, for instance, treats all NLP tasks as text-to-text, offering a unified approach.”</li>
</ul></li>
<li><strong>Conclude with a Summary:</strong>
<ul>
<li>“In essence, choose GPT when you need to <em>generate</em> text, and BERT when you need to <em>understand</em> it. The best choice depends on the specific requirements of your task and the balance you need between generation quality, contextual understanding, and computational efficiency.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Use Simple Language:</strong> Avoid jargon where possible. Explain concepts clearly and concisely.</li>
<li><strong>Visual Aids (If Available):</strong> If you’re in a virtual interview, consider sharing your screen to show diagrams or illustrations of the model architectures.</li>
<li><strong>Engage the Interviewer:</strong> Pause periodically to ask if they have any questions or if they’d like you to elaborate on a particular point.</li>
<li><strong>Highlight Key Words:</strong> Emphasize the key differences, such as “autoregressive” vs.&nbsp;“bidirectional,” and “generation” vs.&nbsp;“understanding.”</li>
<li><strong>Mathematical Notations:</strong> Use mathematical notations, but don’t get bogged down in the details. Explain the intuition behind the formulas rather than just reciting them. Acknowledge that the detailed derivations are extensive, but you can provide the underlying principles. Mentioning log-likelihood loss or conditional probabilities would be a plus.</li>
<li><strong>Be Confident:</strong> Project confidence in your knowledge and understanding of the concepts.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>