<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>training_dynamics__masking__batch_sizes__learning_rates__9</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-10.-in-the-context-of-distributed-training-what-challenges-might-arise-related-to-batch-size-and-learning-rate-adjustments-and-how-would-you-address-them" class="level2">
<h2 class="anchored" data-anchor-id="question-10.-in-the-context-of-distributed-training-what-challenges-might-arise-related-to-batch-size-and-learning-rate-adjustments-and-how-would-you-address-them">Question: 10. In the context of distributed training, what challenges might arise related to batch size and learning rate adjustments, and how would you address them?</h2>
<p><strong>Best Answer</strong></p>
<p>Distributed training introduces several challenges related to batch size and learning rate adjustments, primarily stemming from the increased parallelism and potential inconsistencies in gradient estimation. These challenges can significantly impact convergence speed and model performance.</p>
<p>Here’s a breakdown of the issues and potential solutions:</p>
<ol type="1">
<li><p><strong>Effective Batch Size and Learning Rate Scaling:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> In distributed training, the <em>effective</em> batch size is the batch size per worker multiplied by the number of workers. Naively using the same learning rate as in single-machine training with this larger batch size can lead to instability and slower convergence. This happens because the gradient updates become more “confident” due to being averaged over a larger batch, potentially causing the optimizer to overshoot the optimal solution. The increased batch size reduces the variance of the gradient estimate, and therefore a larger learning rate becomes possible without divergence.</p></li>
<li><p><strong>Addressing the Challenge:</strong> Learning rate scaling is crucial. A common approach is the <em>Linear Scaling Rule</em>, which suggests scaling the learning rate linearly with the number of workers:</p>
<p><span class="math display">\[
\eta' = \eta \cdot K
\]</span></p>
<p>where <span class="math inline">\(\eta'\)</span> is the new learning rate, <span class="math inline">\(\eta\)</span> is the original (single-machine) learning rate, and <span class="math inline">\(K\)</span> is the number of workers (or the factor by which the batch size is increased).</p>
<p>However, linear scaling is a heuristic and may not always be optimal. Other strategies include:</p>
<ul>
<li><p><strong>Square Root Scaling:</strong> <span class="math inline">\(\eta' = \eta \cdot \sqrt{K}\)</span></p></li>
<li><p><strong>Warmup:</strong> Gradually increasing the learning rate from a small value to the scaled value over a few epochs. This helps to stabilize training in the initial stages. A typical warmup function could look like this:</p>
<p><span class="math display">\[
\eta(t) = \eta_{max} \cdot \frac{t}{t_{warmup}} \quad \text{for } t \le t_{warmup}
\]</span> <span class="math display">\[
\eta(t) = \eta_{max} \quad \text{for } t &gt; t_{warmup}
\]</span></p>
<p>where <span class="math inline">\(\eta_{max}\)</span> is the scaled learning rate (e.g., using linear scaling), <span class="math inline">\(t\)</span> is the current training step, and <span class="math inline">\(t_{warmup}\)</span> is the number of warmup steps.</p></li>
<li><p><strong>Learning Rate Schedules:</strong> Adapting the learning rate during training using techniques such as step decay, exponential decay, or cosine annealing (discussed in more detail later).</p></li>
</ul></li>
</ul></li>
<li><p><strong>Gradient Staleness:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> In asynchronous distributed training, workers may operate on slightly outdated model parameters. This “gradient staleness” can lead to divergence or oscillations, especially with a large number of workers or slow communication.</p></li>
<li><p><strong>Addressing the Challenge:</strong></p>
<ul>
<li><strong>Synchronous Training:</strong> Waiting for all workers to complete their gradient computations before updating the model. This eliminates gradient staleness but can be slower if some workers are significantly slower than others (straggler problem).</li>
<li><strong>Gradient Compression:</strong> Reducing the size of gradients transmitted between workers and the parameter server using techniques like quantization or sparsification. This speeds up communication but introduces approximation errors.</li>
<li><strong>Staleness-Aware Optimization Algorithms:</strong> Using optimization algorithms designed to handle stale gradients, such as:
<ul>
<li><strong>Elastic Averaging SGD (EASGD):</strong> Allows workers to deviate from the central parameter server but adds a penalty term that encourages them to stay close.</li>
<li><strong>Asynchronous SGD with Momentum Correction:</strong> Corrects the momentum term to account for gradient staleness.</li>
<li><strong>Delay-Compensated Algorithms:</strong> Explicitly estimate and compensate for the delay in gradient updates.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>Variance in Gradient Estimates:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> While larger batch sizes <em>generally</em> reduce the variance of gradient estimates, distributed training can introduce new sources of variance. For example, if the data is not perfectly shuffled across workers, each worker might be trained on a slightly different distribution, leading to inconsistent gradients.</p></li>
<li><p><strong>Addressing the Challenge:</strong></p>
<ul>
<li><strong>Careful Data Shuffling:</strong> Ensuring that the data is thoroughly shuffled before being distributed to workers. This can be achieved using a distributed shuffling algorithm.</li>
<li><strong>Batch Normalization Synchronization:</strong> In distributed training, the statistics used for batch normalization (mean and variance) should ideally be synchronized across all workers. This can be done using <em>synchronized batch normalization</em> (SyncBN), which aggregates statistics from all workers before normalizing the data. Without SyncBN, the model might learn different representations on different workers, leading to performance degradation.</li>
<li><strong>Gradient Clipping:</strong> Limiting the magnitude of gradients to prevent large updates that can destabilize training.</li>
</ul></li>
</ul></li>
<li><p><strong>Communication Overhead:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> Communicating gradients between workers and the parameter server (or among workers in an all-reduce setting) can be a significant bottleneck, especially with large models and a high number of workers.</p></li>
<li><p><strong>Addressing the Challenge:</strong></p>
<ul>
<li><strong>Gradient Compression:</strong> As mentioned earlier, reducing the size of gradients can significantly reduce communication overhead.</li>
<li><strong>Model Parallelism:</strong> Dividing the model itself across multiple workers. This reduces the amount of data that each worker needs to store and process, but it also introduces new communication challenges.</li>
<li><strong>Using High-Bandwidth Interconnects:</strong> Employing fast network connections (e.g., InfiniBand) between workers.</li>
</ul></li>
</ul></li>
<li><p><strong>Adaptive Learning Rate Methods:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> Adaptive learning rate methods like Adam or AdaGrad adjust the learning rate per parameter based on past gradients. In distributed settings, the accumulated statistics (e.g., the exponentially decaying average of squared gradients in Adam) can become inconsistent across workers, especially with asynchronous updates.</p></li>
<li><p><strong>Addressing the Challenge:</strong> Careful synchronization or approximation of the adaptive learning rate statistics is needed. Strategies include:</p>
<ul>
<li><strong>Centralized Adaptive Learning Rate Computation:</strong> Accumulate the statistics on a central server and then distribute the updated learning rates to the workers. This is often impractical due to communication costs.</li>
<li><strong>Layer-wise Adaptive Rate Scaling (LARS):</strong> Normalizes the gradients of each layer independently before applying the learning rate. This makes training less sensitive to the batch size and learning rate, especially with large batch sizes. LARS computes a layer-specific learning rate <span class="math inline">\(\eta_l\)</span> for each layer <span class="math inline">\(l\)</span> as follows:</li>
</ul>
<p><span class="math display">\[
\eta_l = \eta \cdot \frac{||\mathbf{w}_l||}{||\mathbf{g}_l|| + \lambda ||\mathbf{w}_l||}
\]</span></p>
<p>where <span class="math inline">\(\eta\)</span> is the global learning rate, <span class="math inline">\(\mathbf{w}_l\)</span> is the weight vector of layer <span class="math inline">\(l\)</span>, <span class="math inline">\(\mathbf{g}_l\)</span> is the gradient of layer <span class="math inline">\(l\)</span>, and <span class="math inline">\(\lambda\)</span> is a weight decay parameter.</p></li>
</ul></li>
<li><p><strong>Heterogeneous Resources:</strong></p>
<ul>
<li><p><strong>Challenge:</strong> In some distributed training environments, the workers may have different computational capabilities (e.g., different GPUs or CPUs). This heterogeneity can lead to imbalances in workload and slower overall training.</p></li>
<li><p><strong>Addressing the Challenge:</strong></p>
<ul>
<li><strong>Dynamic Load Balancing:</strong> Assigning more work to the faster workers and less work to the slower ones. This can be done dynamically during training based on the observed performance of each worker.</li>
<li><strong>Gradient Aggregation Strategies:</strong> Implementing gradient aggregation strategies that are robust to stragglers. For example, using techniques that can tolerate some workers being delayed or even failing.</li>
</ul></li>
</ul></li>
</ol>
<p><strong>Mathematical Notation Summary:</strong></p>
<ul>
<li><span class="math inline">\(\eta\)</span>: Original (single-machine) learning rate</li>
<li><span class="math inline">\(\eta'\)</span>: Scaled learning rate</li>
<li><span class="math inline">\(K\)</span>: Number of workers</li>
<li><span class="math inline">\(t\)</span>: Current training step</li>
<li><span class="math inline">\(t_{warmup}\)</span>: Number of warmup steps</li>
<li><span class="math inline">\(\eta_{max}\)</span>: Maximum learning rate during warmup</li>
<li><span class="math inline">\(\mathbf{w}_l\)</span>: Weight vector of layer <span class="math inline">\(l\)</span></li>
<li><span class="math inline">\(\mathbf{g}_l\)</span>: Gradient of layer <span class="math inline">\(l\)</span></li>
<li><span class="math inline">\(\lambda\)</span>: Weight decay parameter</li>
<li><span class="math inline">\(\eta_l\)</span>: Layer-specific learning rate</li>
</ul>
<p>In summary, successfully addressing batch size and learning rate challenges in distributed training requires careful consideration of the interplay between parallelism, communication, and gradient estimation. Appropriate learning rate scaling, gradient staleness mitigation, batch normalization synchronization, and robust optimization algorithms are essential for achieving efficient and stable training.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview:</strong> “Distributed training introduces complexities related to batch size and learning rate due to increased parallelism and potential inconsistencies in gradient estimation. The core challenge revolves around maintaining training stability and convergence speed as we scale up the training process.”</p></li>
<li><p><strong>Explain Effective Batch Size and Learning Rate Scaling:</strong> “One key challenge is that the effective batch size increases linearly with the number of workers. Simply using the same learning rate as in single-machine training will often lead to instability. Therefore, we need to scale the learning rate. A common heuristic is the Linear Scaling Rule, where you multiply the original learning rate by the number of workers. I can write the equation if you would like: <span class="math inline">\(\eta' = \eta \cdot K\)</span>.” <em>[Optionally, write the equation and briefly explain the variables.]</em> “However, this is a heuristic, and sometimes Square Root Scaling (<span class="math inline">\(\eta' = \eta \cdot \sqrt{K}\)</span>) or a warmup strategy might work better. A warmup involves gradually increasing the learning rate, preventing initial instability and can be especially effective. I can go into the specifics of warmup strategies if that would be helpful.”</p></li>
<li><p><strong>Address Gradient Staleness:</strong> “Another challenge arises from gradient staleness, especially in asynchronous training. Because workers may be operating with slightly out-of-date model parameters, it can introduce divergence.” <em>[Pause to gauge understanding.]</em> “To combat this, one option is synchronous training where all workers complete before updating parameters. However, this can be limited by stragglers (slow workers). Gradient compression to reduce communication or staleness-aware optimization algorithms like EASGD can help. I am familiar with the mathematical details behind EASGD if you’d like me to delve into that area.”</p></li>
<li><p><strong>Explain Variance in Gradient Estimates:</strong> “Increased batch sizes tend to reduce the variance in gradient estimates, which is beneficial. But distribution issues in data across the workers can increase the variance. Using SyncBN can ensure consistent normalization across the workers. Furthermore, gradient clipping provides regularization and avoids overshooting the optimal solution.”</p></li>
<li><p><strong>Mention Communication Overhead (If Time Allows):</strong> “Communication overhead can also become a bottleneck. Gradient compression techniques can mitigate this. Model parallelism is another approach but introduces its own complexities.”</p></li>
<li><p><strong>Discuss Adaptive Learning Rate Challenges:</strong> “Adaptive learning rate methods like Adam can be tricky in distributed settings due to inconsistent statistics across workers. Using techniques like Layer-wise Adaptive Rate Scaling (LARS) can help by normalizing gradients per layer. If useful, I can elaborate on the mathematics of LARS (Layer-wise Adaptive Rate Scaling), which computes a layer-specific learning rate <span class="math inline">\(\eta_l\)</span> for each layer <span class="math inline">\(l\)</span> as follows: <span class="math inline">\(\eta_l = \eta \cdot \frac{||\mathbf{w}_l||}{||\mathbf{g}_l|| + \lambda ||\mathbf{w}_l||}\)</span>” <em>[Optionally, write the equation and briefly explain the variables.]</em></p></li>
<li><p><strong>Address Heterogeneous Resources (If Time Allows):</strong> “Finally, in heterogeneous environments where workers have different capabilities, dynamic load balancing becomes crucial to ensure efficient utilization of all resources.”</p></li>
<li><p><strong>Summarize:</strong> “In summary, tackling these challenges requires a holistic approach that considers learning rate scaling, gradient staleness, data distribution, communication overhead, adaptive learning rate behavior, and resource heterogeneity. Carefully tuning these aspects is critical to achieving successful distributed training.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Allow the interviewer time to process the information.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you are in a virtual interview, consider using a shared whiteboard or document to write down key equations or diagrams.</li>
<li><strong>Check for Understanding:</strong> Periodically pause and ask the interviewer if they have any questions or if they would like you to elaborate on a specific point.</li>
<li><strong>Be Ready to Dive Deeper:</strong> The interviewer may ask follow-up questions about specific techniques or algorithms. Be prepared to provide more detailed explanations or even code examples if asked.</li>
<li><strong>Be Honest About Your Knowledge:</strong> If you are unsure about something, it is better to be honest than to try to bluff your way through it. You can say something like, “I am not an expert in that particular area, but I am familiar with the basic concepts.”</li>
<li><strong>Tailor to the Audience:</strong> Adapt your explanation to the interviewer’s level of expertise. If they are not familiar with the technical details, focus on the high-level concepts and avoid jargon.</li>
<li><strong>Focus on Practicality:</strong> Emphasize the practical implications of these challenges and how they can be addressed in real-world distributed training scenarios.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>