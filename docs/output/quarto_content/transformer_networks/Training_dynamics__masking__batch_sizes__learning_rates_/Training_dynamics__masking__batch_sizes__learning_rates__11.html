<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>training_dynamics__masking__batch_sizes__learning_rates__11</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-12.-can-you-elaborate-on-how-the-interplay-between-masking-batch-sizes-and-learning-rates-might-influence-model-generalization-and-overfitting" class="level2">
<h2 class="anchored" data-anchor-id="question-12.-can-you-elaborate-on-how-the-interplay-between-masking-batch-sizes-and-learning-rates-might-influence-model-generalization-and-overfitting">Question: 12. Can you elaborate on how the interplay between masking, batch sizes, and learning rates might influence model generalization and overfitting?</h2>
<p><strong>Best Answer</strong></p>
<p>The interplay between masking, batch sizes, and learning rates is crucial in determining a neural network’s generalization ability and its susceptibility to overfitting. These three components interact in complex ways to shape the training dynamics and the resulting model performance.</p>
<p><strong>1. Masking</strong></p>
<p>Masking, in the context of neural networks, refers to techniques that selectively ignore or suppress certain inputs or activations during training. This can take various forms, including:</p>
<ul>
<li><strong>Input Masking:</strong> Setting certain input features to zero. This can be used to handle missing data or to encourage the model to learn more robust representations by forcing it to rely on a subset of the available features.</li>
<li><strong>Attention Masking:</strong> In attention mechanisms, masking prevents the model from attending to certain parts of the input sequence (e.g., padding tokens).</li>
<li><strong>Dropout:</strong> Randomly setting activations to zero during training. Dropout can be viewed as a form of masking that adds noise to the hidden layers.</li>
<li><strong>Weight Masking/Pruning:</strong> Removing connections (setting weights to zero) in the network. This aims to reduce model complexity and improve generalization by preventing the model from memorizing the training data.</li>
</ul>
<p>The effect of masking on generalization and overfitting depends on the masking strategy and its intensity.</p>
<ul>
<li><p><strong>Regularization Effect:</strong> Masking, especially techniques like dropout and weight masking, acts as a regularizer. By randomly dropping out neurons or connections, masking prevents the network from relying too heavily on specific features or connections, which can lead to overfitting. This forces the network to learn more robust and distributed representations.</p></li>
<li><p><strong>Bias Introduction:</strong> Overly aggressive masking can lead to underfitting by removing too much information. If critical features are consistently masked, the model might fail to learn the underlying patterns in the data. Attention masking if not designed carefully, may prevent model from discovering longer range dependencies in the data.</p></li>
</ul>
<p><strong>2. Batch Size</strong></p>
<p>The batch size is the number of training examples used in each iteration of gradient descent. The choice of batch size affects the training dynamics and the quality of the learned model.</p>
<ul>
<li><strong>Large Batch Size:</strong>
<ul>
<li><strong>Computational Efficiency:</strong> Larger batches often lead to better hardware utilization (e.g., GPU parallelism) and faster training times per epoch.</li>
<li><strong>Smoother Gradients:</strong> Larger batches provide more accurate estimates of the true gradient, reducing the variance in the gradient updates.</li>
<li><strong>Potential for Overfitting:</strong> Because of the smoother gradients, large batch sizes can lead to convergence to sharp minima in the loss landscape. Sharp minima tend to have poor generalization performance.</li>
<li><strong>Learning Rate Sensitivity:</strong> Large batches often require careful tuning of the learning rate. A too-large learning rate can lead to instability, while a too-small learning rate can slow down convergence.</li>
</ul></li>
<li><strong>Small Batch Size:</strong>
<ul>
<li><strong>Noisy Gradients:</strong> Small batches introduce more noise into the gradient estimates, which can help the model escape local minima and explore the loss landscape more effectively.</li>
<li><strong>Regularization Effect:</strong> The noise in the gradients acts as a form of regularization, preventing the model from overfitting the training data.</li>
<li><strong>Slower Convergence:</strong> Small batches can lead to slower convergence and more fluctuations in the training loss.</li>
<li><strong>Better Generalization:</strong> Empirically, small batch sizes often lead to better generalization performance, especially for complex models and datasets.</li>
</ul></li>
</ul>
<p>The impact of batch size on generalization is often explained in terms of the sharpness of the minima the model converges to. Models trained with large batch sizes tend to converge to sharp minima, while models trained with small batch sizes tend to converge to flatter minima. Flatter minima are generally associated with better generalization.</p>
<p><strong>3. Learning Rate</strong></p>
<p>The learning rate controls the step size taken during gradient descent. It is a critical hyperparameter that must be carefully tuned to achieve good performance.</p>
<ul>
<li><strong>High Learning Rate:</strong>
<ul>
<li><strong>Faster Convergence:</strong> A high learning rate can lead to faster initial convergence.</li>
<li><strong>Instability:</strong> If the learning rate is too high, the training process can become unstable, leading to oscillations or divergence.</li>
<li><strong>Poor Generalization:</strong> A high learning rate can prevent the model from settling into a good minimum, resulting in poor generalization.</li>
<li><strong>Skipping over minima:</strong> The update steps are too big and could cause the optimization to simply skip over optimal areas.</li>
</ul></li>
<li><strong>Low Learning Rate:</strong>
<ul>
<li><strong>Slower Convergence:</strong> A low learning rate can lead to slow convergence, requiring more iterations to reach a good solution.</li>
<li><strong>Stuck in Local Minima:</strong> A too-low learning rate might get the model stuck in local minima and cause it to take a very long time to come out of it.</li>
<li><strong>Stable Training:</strong> A low learning rate generally leads to more stable training.</li>
<li><strong>Potential for Better Generalization:</strong> If the learning rate is appropriately chosen, it can allow the model to converge to a good minimum with better generalization performance.</li>
</ul></li>
</ul>
<p><strong>Interplay and Impact on Generalization/Overfitting</strong></p>
<p>The interplay between these three factors can be summarized as follows:</p>
<ul>
<li><p><strong>Masking and Batch Size:</strong> Strong masking (e.g., high dropout rate, aggressive pruning) can be used to regularize models trained with large batch sizes, mitigating the risk of overfitting to sharp minima. Conversely, less aggressive masking might be sufficient for models trained with small batch sizes due to the inherent regularization effect of noisy gradients.</p></li>
<li><p><strong>Masking and Learning Rate:</strong> The learning rate needs to be adjusted based on the masking strategy. If the masking is aggressive, a smaller learning rate might be necessary to prevent instability and allow the model to converge to a good solution. If the masking is less aggressive, a larger learning rate might be used to speed up convergence.</p></li>
<li><p><strong>Batch Size and Learning Rate:</strong> This is a well-studied interaction. As batch size increases, the learning rate typically needs to be increased as well to maintain stable and efficient training. However, the optimal learning rate scaling strategy is not always straightforward. Linear scaling (increasing the learning rate proportionally to the batch size) is a common starting point, but more sophisticated techniques like learning rate warmup and adaptive learning rate methods (e.g., Adam, AdaGrad) are often necessary to achieve optimal performance.</p></li>
</ul>
<p><strong>Mathematical Formulation (Illustrative)</strong></p>
<p>While a full mathematical derivation is beyond the scope, we can illustrate the concepts with simplified equations.</p>
<p>Consider the gradient descent update rule:</p>
<p><span class="math display">\[
\theta_{t+1} = \theta_t - \eta \nabla L(\theta_t; B_t)
\]</span></p>
<p>where: * <span class="math inline">\(\theta_t\)</span> is the model parameters at iteration <span class="math inline">\(t\)</span>. * <span class="math inline">\(\eta\)</span> is the learning rate. * <span class="math inline">\(\nabla L(\theta_t; B_t)\)</span> is the gradient of the loss function <span class="math inline">\(L\)</span> with respect to the parameters <span class="math inline">\(\theta_t\)</span>, computed on batch <span class="math inline">\(B_t\)</span>.</p>
<p><strong>Impact of Batch Size:</strong> The variance of the gradient estimate depends on the batch size <span class="math inline">\(|B_t|\)</span>. A larger batch size reduces the variance, leading to smoother updates.</p>
<p><strong>Impact of Masking (Dropout):</strong> Dropout can be approximated as adding a regularization term to the loss function:</p>
<p><span class="math display">\[
L_{dropout}(\theta) = L(\theta) + \lambda \Omega(\theta)
\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is a hyperparameter controlling the strength of the regularization, and <span class="math inline">\(\Omega(\theta)\)</span> is a regularization term (e.g., L2 regularization) that depends on the dropout rate and the network architecture.</p>
<p><strong>Practical Considerations</strong></p>
<ul>
<li><p><strong>Hyperparameter Tuning:</strong> Finding the optimal combination of masking strategy, batch size, and learning rate requires careful hyperparameter tuning. Techniques like grid search, random search, and Bayesian optimization can be used to explore the hyperparameter space.</p></li>
<li><p><strong>Adaptive Learning Rate Methods:</strong> Adaptive learning rate methods (e.g., Adam, AdaGrad, RMSProp) automatically adjust the learning rate for each parameter based on the history of its gradients. These methods can be less sensitive to the initial learning rate and can often lead to faster convergence.</p></li>
<li><p><strong>Learning Rate Scheduling:</strong> Using learning rate schedules (e.g., step decay, cosine annealing) can further improve performance. These schedules reduce the learning rate over time, allowing the model to fine-tune its parameters and converge to a better solution.</p></li>
<li><p><strong>Early Stopping:</strong> Monitoring the performance of the model on a validation set and stopping the training process when the validation performance starts to degrade can prevent overfitting.</p></li>
</ul>
<p>In summary, masking, batch size, and learning rate are intertwined parameters that significantly influence the training dynamics and the generalization performance of neural networks. Careful selection and tuning of these parameters are crucial for achieving optimal results.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to present this information in an interview setting:</p>
<ol type="1">
<li><p><strong>Start with the Importance:</strong> Begin by emphasizing that the interplay of masking, batch sizes, and learning rates is a <em>critical</em> aspect of training neural networks effectively. It directly impacts how well a model generalizes and its vulnerability to overfitting.</p></li>
<li><p><strong>Define Masking:</strong></p>
<ul>
<li>Briefly explain what masking is. “Masking is a technique where we selectively ignore certain inputs or activations during training.”</li>
<li>Give examples: “This can include things like dropout, input masking, attention masking in transformers, or pruning weights.”</li>
<li>Explain its purpose: “Masking often acts as a regularizer, preventing the model from relying too heavily on specific features, but too much masking can cause underfitting.”</li>
</ul></li>
<li><p><strong>Discuss Batch Size:</strong></p>
<ul>
<li>Explain the concept. “Batch size refers to the number of training examples used in each update step.”</li>
<li>Contrast large and small batch sizes:
<ul>
<li>“Large batch sizes can lead to faster training due to better hardware utilization and smoother gradients, but they may converge to sharp minima and lead to overfitting.”</li>
<li>“Small batch sizes introduce more noise, which can help escape local minima and improve generalization, but they may also result in slower and more unstable training.”</li>
</ul></li>
</ul></li>
<li><p><strong>Explain Learning Rate:</strong></p>
<ul>
<li>Define the role: “The learning rate controls the step size during gradient descent. It’s a critical hyperparameter.”</li>
<li>Explain the trade-off: “A high learning rate can lead to faster convergence but also instability. A low learning rate can be more stable but may take a very long time to converge or get the model stuck. Adaptive learning rates are often used.”</li>
</ul></li>
<li><p><strong>Discuss the Interplay (This is Key):</strong></p>
<ul>
<li>Emphasize that these parameters <em>don’t</em> work in isolation.</li>
<li>Give examples of how they interact:
<ul>
<li>“For instance, if we’re using aggressive masking techniques, like high dropout, we might want to use a smaller batch size or a lower learning rate to prevent instability.”</li>
<li>“Conversely, if we’re using large batch sizes, we might need to increase the learning rate, possibly using techniques like linear scaling or a learning rate warmup.”</li>
<li>“The amount of masking used may affect the optimal learning rate or batch size needed.”</li>
</ul></li>
</ul></li>
<li><p><strong>Mathematical Illustration (Use Judiciously):</strong></p>
<ul>
<li>Mention the gradient descent update rule: “We can think about it mathematically with the gradient descent update rule: <span class="math inline">\(\theta_{t+1} = \theta_t - \eta \nabla L(\theta_t; B_t)\)</span>”</li>
<li>Explain the terms briefly: “Where <span class="math inline">\(\theta\)</span> represents the parameters, <span class="math inline">\(\eta\)</span> is the learning rate, and the gradient is calculated on the batch <span class="math inline">\(B_t\)</span>.”</li>
<li>Avoid going into deep derivations unless explicitly asked. The goal is to demonstrate awareness, not to overwhelm the interviewer.</li>
</ul></li>
<li><p><strong>Real-World Considerations:</strong></p>
<ul>
<li>Mention hyperparameter tuning: “Finding the right combination of masking strategy, batch size, and learning rate often requires careful hyperparameter tuning, using methods like grid search or Bayesian optimization.”</li>
<li>Talk about adaptive learning rates: “Adaptive methods like Adam or AdaGrad can simplify the process by automatically adjusting the learning rates for each parameter.”</li>
<li>Mention learning rate scheduling and early stopping as additional techniques.</li>
</ul></li>
<li><p><strong>Concluding Remarks:</strong></p>
<ul>
<li>Reiterate the importance of understanding these interactions for effective neural network training.</li>
<li>Show confidence that you can use your knowledge to create high-performance machine learning models in real-world scenarios.</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush. Explain the concepts clearly and deliberately.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you’re in a virtual interview, consider having a simple diagram or equations ready to share if needed.</li>
<li><strong>Check for Understanding:</strong> Pause periodically and ask, “Does that make sense?” or “Would you like me to elaborate on any of those points?”</li>
<li><strong>Be Ready to Dig Deeper:</strong> The interviewer might ask follow-up questions on specific aspects. Be prepared to provide more details or examples.</li>
<li><strong>Stay Practical:</strong> While mathematical understanding is important, emphasize the practical implications and how you would apply these concepts in real-world projects.</li>
<li><strong>Confidence:</strong> Speak confidently and show that you have a strong grasp of the material.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>