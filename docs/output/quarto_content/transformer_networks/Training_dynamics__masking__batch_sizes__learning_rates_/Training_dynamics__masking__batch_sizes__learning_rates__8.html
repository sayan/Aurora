<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>training_dynamics__masking__batch_sizes__learning_rates__8</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-9.-suppose-you-are-tasked-with-deploying-a-model-trained-on-large-scale-data-using-noisy-and-unstructured-inputs.-how-would-you-adapt-your-training-dynamics-batch-size-learning-rate-and-masking-strategies-to-accommodate-real-world-challenges" class="level2">
<h2 class="anchored" data-anchor-id="question-9.-suppose-you-are-tasked-with-deploying-a-model-trained-on-large-scale-data-using-noisy-and-unstructured-inputs.-how-would-you-adapt-your-training-dynamics-batch-size-learning-rate-and-masking-strategies-to-accommodate-real-world-challenges">Question: 9. Suppose you are tasked with deploying a model trained on large-scale data using noisy and unstructured inputs. How would you adapt your training dynamics (batch size, learning rate, and masking strategies) to accommodate real-world challenges?</h2>
<p><strong>Best Answer</strong></p>
<p>Deploying a model trained on large-scale data with noisy and unstructured inputs presents significant challenges. Adapting training dynamics—specifically batch size, learning rate, and masking strategies—is crucial for building a robust and generalizable model. Here’s a breakdown of how I would approach these adaptations:</p>
<section id="data-preprocessing-and-noise-handling" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-and-noise-handling">1. Data Preprocessing and Noise Handling:</h3>
<p>Before diving into training dynamics, thorough data preprocessing is essential. This includes:</p>
<ul>
<li><strong>Data Cleaning:</strong> Implement techniques to handle inconsistencies, errors, and outliers in the data. This may involve rule-based cleaning, statistical methods (e.g., IQR for outlier removal), or using external knowledge bases.</li>
<li><strong>Normalization/Standardization:</strong> Scale numerical features to a similar range to prevent features with larger values from dominating the learning process. Common methods include Min-Max scaling and Z-score standardization. For example, Z-score standardization scales the data as follows: <span class="math display">\[ x_{normalized} = \frac{x - \mu}{\sigma} \]</span> where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation of the feature.</li>
<li><strong>Handling Missing Values:</strong> Impute missing values using appropriate methods. Simple methods like mean/median imputation can be a starting point. More sophisticated techniques include k-Nearest Neighbors imputation or model-based imputation.</li>
<li><strong>Data Transformation:</strong> Apply transformations to address skewness or non-normality in the data. Common transformations include logarithmic transformations, square root transformations, or Box-Cox transformations.</li>
<li><strong>Structured Representation:</strong> For unstructured data (e.g., text, images), convert them into suitable numerical representations using techniques like word embeddings (Word2Vec, GloVe, BERT), image feature extraction (CNNs), or other domain-specific methods.</li>
</ul>
</section>
<section id="batch-size-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="batch-size-adaptation">2. Batch Size Adaptation:</h3>
<ul>
<li><strong>Smaller Batch Sizes:</strong> In the presence of noisy data, using smaller batch sizes can be beneficial. Smaller batches introduce more stochasticity into the gradient updates, which can help the model escape local minima and generalize better. However, very small batch sizes can lead to unstable training.</li>
<li><strong>Batch Size Scheduling:</strong> Consider a batch size schedule that starts with a smaller batch size and gradually increases it as training progresses. This allows the model to initially explore the parameter space more thoroughly and then fine-tune with larger batches for more stable convergence.</li>
<li><strong>Impact on Gradient Variance:</strong> Smaller batch sizes lead to higher variance in gradient estimates. The variance is approximately inversely proportional to the batch size: <span class="math inline">\(Var(\nabla_{\theta}L) \propto \frac{1}{B}\)</span>, where <span class="math inline">\(B\)</span> is the batch size.</li>
<li><strong>Memory Considerations:</strong> Smaller batch sizes reduce memory consumption, which is particularly important when working with large models and datasets.</li>
</ul>
</section>
<section id="learning-rate-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate-adaptation">3. Learning Rate Adaptation:</h3>
<ul>
<li><strong>Adaptive Learning Rate Methods:</strong> Employ adaptive learning rate methods like Adam, RMSprop, or Adagrad. These methods adjust the learning rate for each parameter based on its historical gradient information, making them more robust to noisy data and varying feature scales.
<ul>
<li><strong>Adam:</strong> Adam combines the benefits of RMSprop and momentum. It updates the learning rate for each parameter based on estimates of both the first and second moments of the gradients. The update rule is: <span class="math display">\[
\begin{aligned}
m_t &amp;= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\
v_t &amp;= \beta_2 v_{t-1} + (1 - \beta_2) g_t^2 \\
\hat{m}_t &amp;= \frac{m_t}{1 - \beta_1^t} \\
\hat{v}_t &amp;= \frac{v_t}{1 - \beta_2^t} \\
\theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
\end{aligned}
\]</span> where <span class="math inline">\(m_t\)</span> is the first moment estimate, <span class="math inline">\(v_t\)</span> is the second moment estimate, <span class="math inline">\(g_t\)</span> is the gradient at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are decay rates, <span class="math inline">\(\eta\)</span> is the learning rate, and <span class="math inline">\(\epsilon\)</span> is a small constant to prevent division by zero.</li>
<li><strong>RMSprop:</strong> RMSprop adapts the learning rate based on the exponentially decaying average of squared gradients: <span class="math display">\[
\begin{aligned}
v_t &amp;= \beta v_{t-1} + (1 - \beta) g_t^2 \\
\theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{v_t} + \epsilon} g_t
\end{aligned}
\]</span> where <span class="math inline">\(v_t\)</span> is the exponentially decaying average of squared gradients, <span class="math inline">\(g_t\)</span> is the gradient at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\beta\)</span> is the decay rate, <span class="math inline">\(\eta\)</span> is the learning rate, and <span class="math inline">\(\epsilon\)</span> is a small constant.</li>
</ul></li>
<li><strong>Learning Rate Scheduling:</strong> Use a learning rate schedule to decay the learning rate during training. This can help the model converge to a better solution and prevent oscillations. Common schedules include:
<ul>
<li><strong>Step Decay:</strong> Reduce the learning rate by a factor (e.g., 0.1) every few epochs.</li>
<li><strong>Exponential Decay:</strong> Decay the learning rate exponentially with each epoch: <span class="math inline">\(\eta_t = \eta_0 e^{-kt}\)</span>, where <span class="math inline">\(\eta_0\)</span> is the initial learning rate, <span class="math inline">\(k\)</span> is the decay rate, and <span class="math inline">\(t\)</span> is the epoch number.</li>
<li><strong>Cosine Annealing:</strong> Vary the learning rate following a cosine function.</li>
</ul></li>
<li><strong>Cyclical Learning Rates (CLR):</strong> Explore cyclical learning rates, where the learning rate cyclically varies between a minimum and maximum value. This can help the model escape local minima and find broader, more robust solutions.</li>
<li><strong>Smaller Initial Learning Rate:</strong> Start with a smaller initial learning rate. Noisy data can cause large gradient updates early in training, which can destabilize the model. A smaller learning rate provides more stability.</li>
</ul>
</section>
<section id="masking-strategies" class="level3">
<h3 class="anchored" data-anchor-id="masking-strategies">4. Masking Strategies:</h3>
<ul>
<li><strong>Input Masking:</strong> Randomly mask out some input features during training. This forces the model to learn more robust representations that are less sensitive to individual features. This is particularly useful when dealing with missing or unreliable data.</li>
<li><strong>Dropout:</strong> Apply dropout to the hidden layers of the neural network. Dropout randomly sets a fraction of the neurons to zero during each forward pass, preventing the model from relying too heavily on any single neuron and improving generalization. The dropout rate (e.g., 0.5) controls the probability of a neuron being dropped.</li>
<li><strong>Adversarial Training:</strong> Inject small, carefully crafted perturbations to the input data during training. These perturbations are designed to fool the model, forcing it to learn more robust decision boundaries.</li>
<li><strong>Noise Injection:</strong> Add random noise to the input data or hidden layers. This can help the model become more resilient to noise in the real world.</li>
<li><strong>Attention Mechanisms with Masking:</strong> If using attention mechanisms, incorporate masking to ignore certain parts of the input sequence. This is particularly useful for handling variable-length sequences or noisy segments in sequence data.</li>
</ul>
</section>
<section id="regularization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="regularization-techniques">5. Regularization Techniques:</h3>
<ul>
<li><strong>L1 and L2 Regularization:</strong> Apply L1 or L2 regularization to the model’s weights to prevent overfitting. L1 regularization encourages sparsity in the weights, while L2 regularization penalizes large weights. The regularization terms are added to the loss function: <span class="math display">\[
\begin{aligned}
L_{L1} &amp;= L_0 + \lambda \sum_{i=1}^n |w_i| \\
L_{L2} &amp;= L_0 + \lambda \sum_{i=1}^n w_i^2
\end{aligned}
\]</span> where <span class="math inline">\(L_0\)</span> is the original loss function, <span class="math inline">\(\lambda\)</span> is the regularization strength, and <span class="math inline">\(w_i\)</span> are the model’s weights.</li>
<li><strong>Early Stopping:</strong> Monitor the performance of the model on a validation set and stop training when the validation performance starts to degrade. This prevents the model from overfitting to the training data.</li>
</ul>
</section>
<section id="robust-loss-functions" class="level3">
<h3 class="anchored" data-anchor-id="robust-loss-functions">6. Robust Loss Functions:</h3>
<ul>
<li><strong>Huber Loss:</strong> Use Huber loss, which is less sensitive to outliers than squared error loss. Huber loss is defined as: <span class="math display">\[
L_\delta(a) =
\begin{cases}
\frac{1}{2} a^2 &amp; \text{for } |a| \le \delta \\
\delta (|a| - \frac{1}{2} \delta) &amp; \text{otherwise}
\end{cases}
\]</span> where <span class="math inline">\(a\)</span> is the difference between the predicted and actual values, and <span class="math inline">\(\delta\)</span> is a threshold.</li>
<li><strong>Quantile Loss:</strong> Use quantile loss to model different quantiles of the target variable. This can be useful when the data has skewed distributions or when different prediction errors have different costs.</li>
</ul>
</section>
<section id="validation-and-monitoring" class="level3">
<h3 class="anchored" data-anchor-id="validation-and-monitoring">7. Validation and Monitoring:</h3>
<ul>
<li><strong>Validation Set:</strong> Maintain a separate validation set to monitor the model’s performance during training. Use this set to tune hyperparameters and evaluate the model’s generalization ability.</li>
<li><strong>Monitoring Metrics:</strong> Track relevant metrics (e.g., accuracy, precision, recall, F1-score, AUC) on the validation set to detect overfitting or underfitting.</li>
<li><strong>Visualization:</strong> Visualize the training process using tools like TensorBoard to monitor the learning curves, gradient magnitudes, and other relevant statistics.</li>
</ul>
</section>
<section id="implementation-details-and-corner-cases" class="level3">
<h3 class="anchored" data-anchor-id="implementation-details-and-corner-cases">8. Implementation Details and Corner Cases:</h3>
<ul>
<li><strong>Gradient Clipping:</strong> Implement gradient clipping to prevent exploding gradients, which can occur when training deep neural networks with noisy data.</li>
<li><strong>Mixed Precision Training:</strong> Use mixed precision training (e.g., FP16) to reduce memory consumption and speed up training.</li>
<li><strong>Distributed Training:</strong> If the dataset is very large, consider using distributed training to parallelize the training process across multiple GPUs or machines.</li>
<li><strong>Regular Evaluation:</strong> Regular evaluation of the model on a held-out test set is crucial to ensure that the model generalizes well to unseen data.</li>
</ul>
<p>By carefully considering these factors and adapting the training dynamics accordingly, it is possible to build a robust and generalizable model that can effectively handle noisy and unstructured data in real-world deployment scenarios.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to present this information effectively in an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview:</strong></p>
<ul>
<li>“Handling noisy and unstructured data in large-scale deployments requires a multi-faceted approach. It’s not just about a single trick, but rather a combination of careful data preprocessing, adaptive training techniques, and robust evaluation strategies.”</li>
</ul></li>
<li><p><strong>Data Preprocessing (2-3 minutes):</strong></p>
<ul>
<li>“First and foremost, robust data preprocessing is critical. This involves cleaning the data by addressing inconsistencies and outliers, normalizing features to ensure fair contribution during learning, and handling missing values using appropriate imputation techniques.”</li>
<li>“For unstructured data like text or images, we need to convert them into numerical representations using methods like word embeddings or CNN-based feature extraction.”</li>
</ul></li>
<li><p><strong>Training Dynamics - Batch Size (2-3 minutes):</strong></p>
<ul>
<li>“Now, let’s talk about adapting the training dynamics. Smaller batch sizes can be beneficial with noisy data because they introduce more stochasticity, helping the model escape local minima. However, you have to be careful not to make them <em>too</em> small, as that increases gradient variance.”</li>
<li>“A good approach is often a batch size schedule, starting small and gradually increasing it as training progresses.”</li>
</ul></li>
<li><p><strong>Training Dynamics - Learning Rate (3-4 minutes):</strong></p>
<ul>
<li>“Adaptive learning rate methods are essential. Algorithms like Adam or RMSprop dynamically adjust the learning rate for each parameter, making them more resilient to noisy data and varying feature scales. For example, Adam uses estimates of both the first and second moments of the gradients to adapt the learning rate.” (You can briefly show the Adam update rule if the interviewer seems engaged.)</li>
<li>“Learning rate scheduling is also key. Decreasing the learning rate over time, either through step decay, exponential decay, or cosine annealing, helps the model converge to a better solution.”</li>
</ul></li>
<li><p><strong>Training Dynamics - Masking (2-3 minutes):</strong></p>
<ul>
<li>“Masking strategies are crucial for dealing with missing or unreliable data. Input masking involves randomly masking out some input features during training, forcing the model to learn more robust representations.”</li>
<li>“Dropout, a common regularization technique, can also be viewed as a form of masking applied to hidden layers.”</li>
</ul></li>
<li><p><strong>Regularization, Loss Functions, and Monitoring (2 minutes):</strong></p>
<ul>
<li>“To prevent overfitting, we can use L1 or L2 regularization. We can also use more robust loss functions like Huber Loss. Don’t forget to monitor the validation set.”</li>
</ul></li>
<li><p><strong>Implementation and Corner Cases (1-2 minutes):</strong></p>
<ul>
<li>“Finally, in terms of implementation, techniques like gradient clipping and mixed-precision training can be beneficial for stability and efficiency. For very large datasets, distributed training is often necessary.”</li>
</ul></li>
<li><p><strong>Conclude with a Summary:</strong></p>
<ul>
<li>“In summary, deploying a model trained on noisy and unstructured data requires a holistic approach. By carefully adapting the training dynamics – batch size, learning rate, and masking strategies – and incorporating robust data preprocessing and evaluation techniques, we can build a model that generalizes well to real-world scenarios.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pause and Check for Understanding:</strong> After explaining a complex concept (e.g., Adam, masking), pause and ask the interviewer if they have any questions before moving on.</li>
<li><strong>Use Visual Aids (if possible):</strong> If interviewing remotely, consider sharing your screen and showing relevant diagrams or equations (prepare these beforehand).</li>
<li><strong>Relate to Real-World Examples:</strong> If you have experience applying these techniques to specific projects, briefly mention them to illustrate your practical knowledge.</li>
<li><strong>Avoid Jargon Overload:</strong> Use technical terms appropriately, but avoid overwhelming the interviewer with excessive jargon. Explain concepts clearly and concisely.</li>
<li><strong>Be Prepared to Go Deeper:</strong> The interviewer may ask follow-up questions about any of the topics you discuss. Be prepared to provide more detailed explanations or examples.</li>
<li><strong>Demonstrate Enthusiasm:</strong> Show genuine interest in the topic and a willingness to learn and adapt.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>