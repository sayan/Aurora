<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>training_dynamics__masking__batch_sizes__learning_rates__2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-3.-describe-the-relationship-between-learning-rate-and-batch-size.-how-might-one-modify-the-learning-rate-when-changing-the-batch-size" class="level2">
<h2 class="anchored" data-anchor-id="question-3.-describe-the-relationship-between-learning-rate-and-batch-size.-how-might-one-modify-the-learning-rate-when-changing-the-batch-size">Question: 3. Describe the relationship between learning rate and batch size. How might one modify the learning rate when changing the batch size?</h2>
<p><strong>Best Answer</strong></p>
<p>The learning rate and batch size are crucial hyperparameters in training neural networks, and they exhibit a complex relationship that significantly affects the training dynamics, convergence speed, and generalization performance of the model. Intuitively, the batch size determines how much data is used to compute the gradient in each update step, while the learning rate controls the step size taken in the direction of the negative gradient. Changing one often necessitates adjusting the other to maintain optimal training.</p>
<p>Here’s a breakdown of their relationship and how to modify the learning rate when altering the batch size:</p>
<p><strong>1. The Impact of Batch Size</strong></p>
<ul>
<li><strong>Smaller Batch Size:</strong>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>Provides more frequent updates to the model parameters, which can lead to faster initial learning and potentially escape sharp local minima.</li>
<li>Introduces more noise into the gradient estimation, which can act as a regularizer, improving generalization.</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li>Noisier gradient estimates can lead to oscillations during training and slower convergence overall.</li>
<li>Less efficient use of hardware due to lower parallelism, especially on GPUs.</li>
</ul></li>
</ul></li>
<li><strong>Larger Batch Size:</strong>
<ul>
<li><strong>Pros:</strong>
<ul>
<li>More stable and accurate gradient estimates, leading to smoother convergence.</li>
<li>Better utilization of hardware (GPUs, TPUs) resulting in faster training times <em>per epoch</em>.</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li>Potentially slower initial learning as updates are less frequent.</li>
<li>Risk of getting stuck in sharp local minima due to the averaging effect of the larger batch, which can hurt generalization performance.</li>
<li>May require more memory.</li>
</ul></li>
</ul></li>
</ul>
<p><strong>2. The Relationship and Linear Scaling Rule</strong></p>
<p>The core idea is that with a larger batch size, each update is based on more data, resulting in a more accurate estimate of the true gradient. Therefore, we can afford to take larger steps (i.e., increase the learning rate) without destabilizing the training process.</p>
<p>The <strong>Linear Scaling Rule</strong> is a common heuristic for adjusting the learning rate when changing the batch size. It suggests that if you multiply the batch size by a factor of <span class="math inline">\(k\)</span>, you should also multiply the learning rate by the same factor <span class="math inline">\(k\)</span>.</p>
<p>Mathematically, if we have an initial learning rate <span class="math inline">\(\eta_0\)</span> and an initial batch size <span class="math inline">\(B_0\)</span>, and we change the batch size to <span class="math inline">\(B_1 = kB_0\)</span>, then the new learning rate <span class="math inline">\(\eta_1\)</span> should be:</p>
<p><span class="math display">\[\eta_1 = k\eta_0\]</span></p>
<p><strong>Rationale:</strong> The gradient update rule can be written as:</p>
<p><span class="math display">\[\theta_{t+1} = \theta_t - \eta \nabla L(\theta_t; B)\]</span></p>
<p>where: * <span class="math inline">\(\theta_t\)</span> are the model parameters at iteration <span class="math inline">\(t\)</span> * <span class="math inline">\(\eta\)</span> is the learning rate * <span class="math inline">\(\nabla L(\theta_t; B)\)</span> is the gradient of the loss function <span class="math inline">\(L\)</span> with respect to the parameters <span class="math inline">\(\theta_t\)</span>, computed using a batch of size <span class="math inline">\(B\)</span>.</p>
<p>If we increase the batch size by a factor of <span class="math inline">\(k\)</span>, the new gradient will be:</p>
<p><span class="math display">\[\nabla L(\theta_t; kB) \approx k \nabla L(\theta_t; B)\]</span></p>
<p>Assuming the loss function is roughly linear within the region spanned by the increased batch size, the gradient magnitude increases proportionally to the batch size. To compensate for this increase, we scale the learning rate proportionally:</p>
<p><span class="math display">\[ \theta_{t+1} = \theta_t - (k\eta) \frac{1}{k} \nabla L(\theta_t; kB) = \theta_t - \eta \nabla L(\theta_t; B)\]</span></p>
<p><strong>3. Considerations and Caveats</strong></p>
<ul>
<li><strong>Empirical Verification:</strong> The linear scaling rule is a good starting point, but it’s not a guaranteed solution. It’s crucial to empirically validate the new learning rate and adjust it further based on the observed training behavior (e.g., loss curves, validation performance).</li>
<li><strong>Learning Rate Warmup:</strong> When significantly increasing the batch size and learning rate, it’s often beneficial to use a learning rate warmup strategy. This involves gradually increasing the learning rate from a small value to the target value over a few epochs. This helps to stabilize training at the beginning.</li>
<li><strong>Non-Linear Scaling:</strong> In some cases, a non-linear scaling rule may be more appropriate. For example, the <em>square root rule</em> scales the learning rate by the square root of the batch size ratio: <span class="math inline">\(\eta_1 = \sqrt{k} \eta_0\)</span>. This is often found to perform better than the linear scaling rule for very large batch sizes.</li>
<li><strong>Adaptive Optimizers:</strong> Adaptive optimizers like Adam, RMSprop, and AdaGrad adjust the learning rate for each parameter individually based on its historical gradients. While they are less sensitive to the initial learning rate, they still benefit from proper tuning and may require adjustments when the batch size changes significantly. It is worth noting that even with adaptive optimizers, the linear scaling rule can provide a good starting point for tuning the learning rate.</li>
<li><strong>Batch Normalization:</strong> Batch Normalization (BN) can also affect the relationship between learning rate and batch size. BN layers normalize the activations within each batch, which can reduce the sensitivity to the learning rate. However, with very small batch sizes, the statistics estimated by BN can be unreliable, so larger batch sizes are often preferred when using BN.</li>
<li><strong>Optimization Landscape:</strong> The relationship between learning rate, batch size, and the shape of the loss landscape is intricate. Larger batch sizes tend to “flatten” the loss landscape, making it easier for the optimizer to find a good solution, but potentially at the cost of generalization. Smaller batch sizes, with their inherent noise, can help the optimizer escape sharp local minima and find broader, flatter minima that generalize better.</li>
</ul>
<p><strong>4. References to Empirical Observations</strong></p>
<ul>
<li><strong>Goyal et al.&nbsp;(2017) “Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour”</strong>: This paper demonstrated that it’s possible to train ImageNet with large batch sizes by carefully adjusting the learning rate using the linear scaling rule and a warmup strategy. They also explored the limitations of linear scaling and the need for further tuning.</li>
</ul>
<p><strong>In summary:</strong> The relationship between learning rate and batch size is complex and influenced by multiple factors, including the optimization algorithm, the architecture of the neural network, and the characteristics of the dataset. The linear scaling rule provides a useful starting point for adjusting the learning rate when changing the batch size, but empirical validation and further tuning are essential to achieve optimal performance.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with the Basic Definition:</strong> “The learning rate and batch size are two fundamental hyperparameters in neural network training. The learning rate determines the step size during optimization, while the batch size controls the amount of data used in each update.”</p></li>
<li><p><strong>Explain the Trade-offs:</strong> “Smaller batch sizes offer more frequent updates and can help escape sharp local minima, but they introduce more noise. Larger batch sizes provide more stable gradients and better hardware utilization, but can potentially get stuck in suboptimal solutions.” <em>Pause briefly to let this sink in.</em></p></li>
<li><p><strong>Introduce the Linear Scaling Rule:</strong> “A common guideline for adjusting the learning rate when changing the batch size is the Linear Scaling Rule. It suggests that if you increase the batch size by a factor of ‘k’, you should also increase the learning rate by the same factor ‘k’.” <em>Write the equation <span class="math inline">\(\eta_1 = k\eta_0\)</span> on a whiteboard if available.</em></p></li>
<li><p><strong>Explain the Rationale (Optional, depending on the interviewer’s interest):</strong> “The reasoning behind this is that a larger batch provides a more accurate estimate of the gradient. Assuming the loss function is roughly linear within the expanded batch region, the gradient magnitude increases proportionally to the batch size. Scaling the learning rate compensates for this increase, theoretically keeping the update magnitude consistent.” <em>You can mention the gradient update equations if the interviewer seems mathematically inclined.</em></p></li>
<li><p><strong>Discuss the Caveats:</strong> “However, the Linear Scaling Rule is not a silver bullet. It’s crucial to validate the new learning rate empirically and adjust it further based on the observed training behavior. Other factors like learning rate warmups, adaptive optimizers (Adam, RMSprop), and Batch Normalization also influence the training dynamics.”</p></li>
<li><p><strong>Mention Non-Linear Scaling (If Applicable):</strong> “In some scenarios, especially with very large batch sizes, non-linear scaling rules, such as the square root rule, <span class="math inline">\(\eta_1 = \sqrt{k} \eta_0\)</span>, can be more effective.”</p></li>
<li><p><strong>Refer to Research:</strong> “A seminal paper by Goyal et al.&nbsp;(2017) demonstrated the effectiveness of large batch training with careful learning rate adjustments and warmup strategies. It’s a good reference point for understanding the practical considerations.”</p></li>
<li><p><strong>Conclude with a Summary:</strong> “In summary, the relationship between learning rate and batch size is nuanced. While the linear scaling rule provides a useful starting point, empirical validation, and consideration of other factors are crucial for optimal performance.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation, especially when discussing the mathematics.</li>
<li><strong>Use Visual Aids:</strong> If you have a whiteboard, use it to write down key equations or diagrams to illustrate the concepts.</li>
<li><strong>Check for Understanding:</strong> Periodically ask the interviewer if they have any questions or if they’d like you to elaborate on a particular point. “Does that make sense so far?”</li>
<li><strong>Tailor Your Response:</strong> Pay attention to the interviewer’s body language and questions. If they seem particularly interested in a specific aspect, delve deeper into that area. If they seem less interested in the math, focus more on the practical implications.</li>
<li><strong>Be Confident but Humble:</strong> Demonstrate your expertise without being arrogant. Acknowledge the complexity of the topic and the importance of empirical validation.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>