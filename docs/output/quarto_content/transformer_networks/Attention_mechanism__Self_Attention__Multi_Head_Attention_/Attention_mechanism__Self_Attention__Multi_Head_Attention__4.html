<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>attention_mechanism__self_attention__multi_head_attention__4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-what-are-the-computational-challenges-associated-with-self-attention-particularly-as-sequence-length-increases-and-what-strategies-might-you-employ-to-mitigate-these-issues" class="level2">
<h2 class="anchored" data-anchor-id="question-5.-what-are-the-computational-challenges-associated-with-self-attention-particularly-as-sequence-length-increases-and-what-strategies-might-you-employ-to-mitigate-these-issues">Question: 5. What are the computational challenges associated with self-attention, particularly as sequence length increases, and what strategies might you employ to mitigate these issues?</h2>
<p><strong>Best Answer</strong></p>
<p>Self-attention, while powerful, suffers from significant computational challenges as the sequence length increases. The core issue stems from its quadratic complexity, making it computationally expensive and memory-intensive for long sequences. Let’s delve into the challenges and mitigation strategies:</p>
<p><strong>1. Computational Complexity of Self-Attention:</strong></p>
<p>The self-attention mechanism computes attention weights between every pair of tokens in a sequence. Given an input sequence <span class="math inline">\(X \in \mathbb{R}^{n \times d}\)</span>, where <span class="math inline">\(n\)</span> is the sequence length and <span class="math inline">\(d\)</span> is the embedding dimension, self-attention involves the following steps:</p>
<ul>
<li><p><strong>Linear Projections:</strong> The input <span class="math inline">\(X\)</span> is projected into queries <span class="math inline">\(Q\)</span>, keys <span class="math inline">\(K\)</span>, and values <span class="math inline">\(V\)</span> using learned linear transformations:</p>
<p><span class="math display">\[Q = XW_Q, \quad K = XW_K, \quad V = XW_V\]</span></p>
<p>where <span class="math inline">\(W_Q, W_K, W_V \in \mathbb{R}^{d \times d}\)</span> are the projection matrices.</p></li>
<li><p><strong>Attention Weights:</strong> The attention weights <span class="math inline">\(A\)</span> are computed as:</p>
<p><span class="math display">\[A = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right)\]</span></p>
<p>where <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>. The term <span class="math inline">\(\sqrt{d}\)</span> is used to scale the dot products, preventing them from becoming too large and pushing the softmax function into a region where gradients are very small.</p></li>
<li><p><strong>Weighted Sum:</strong> The output <span class="math inline">\(Z\)</span> is a weighted sum of the values <span class="math inline">\(V\)</span> using the attention weights <span class="math inline">\(A\)</span>:</p>
<p><span class="math display">\[Z = AV\]</span></p>
<p>where <span class="math inline">\(Z \in \mathbb{R}^{n \times d}\)</span>.</p></li>
</ul>
<p>The computational bottleneck lies in the matrix multiplication <span class="math inline">\(QK^T\)</span>, which has a complexity of <span class="math inline">\(O(n^2d)\)</span>. This quadratic complexity with respect to sequence length <span class="math inline">\(n\)</span> makes self-attention impractical for very long sequences. The memory requirement is also <span class="math inline">\(O(n^2)\)</span>, due to the attention matrix <span class="math inline">\(A\)</span>.</p>
<p><strong>2. Challenges with Long Sequences:</strong></p>
<ul>
<li><strong>Memory Constraints:</strong> Storing the attention matrix <span class="math inline">\(A\)</span> becomes infeasible for long sequences, leading to out-of-memory errors, especially when training large models with significant batch sizes.</li>
<li><strong>Computational Cost:</strong> The quadratic computation cost dramatically slows down training and inference, making experimentation and deployment challenging.</li>
<li><strong>Limited Context:</strong> While self-attention theoretically allows each token to attend to all other tokens, in practice, the model might struggle to capture dependencies between distant tokens due to vanishing gradients or limitations in representational capacity.</li>
</ul>
<p><strong>3. Mitigation Strategies:</strong></p>
<p>Several strategies have been developed to address the computational challenges of self-attention for long sequences:</p>
<ul>
<li><p><strong>Sparse Attention:</strong> Instead of computing attention weights between all pairs of tokens, sparse attention mechanisms restrict attention to a subset of tokens. This can be achieved through various patterns:</p>
<ul>
<li><strong>Fixed Patterns:</strong> Each token attends to a fixed number of neighboring tokens. This reduces the complexity to <span class="math inline">\(O(n)\)</span>.</li>
<li><strong>Learnable Patterns:</strong> The attention pattern is learned during training. Examples include:
<ul>
<li><strong>Longformer:</strong> Uses a combination of sliding window attention, dilated sliding window attention, and global attention for specific tokens. It achieves <span class="math inline">\(O(n)\)</span> complexity.</li>
<li><strong>Big Bird:</strong> Employs random attention, global attention, and window attention to approximate full attention.</li>
</ul></li>
</ul></li>
<li><p><strong>Low-Rank Approximations:</strong> Instead of computing the full attention matrix <span class="math inline">\(A\)</span>, we can approximate it using low-rank matrices. This technique reduces the computational complexity.</p>
<ul>
<li><p><strong>Linformer:</strong> Projects the key and value matrices <span class="math inline">\(K\)</span> and <span class="math inline">\(V\)</span> to a lower-dimensional space using linear projections. This reduces the complexity to <span class="math inline">\(O(nd)\)</span>. Specifically:</p>
<p><span class="math display">\[K' = KP, \quad V' = VP\]</span></p>
<p>where <span class="math inline">\(P \in \mathbb{R}^{n \times k}\)</span> is a projection matrix and <span class="math inline">\(k &lt;&lt; n\)</span>. The attention is then computed using <span class="math inline">\(Q\)</span>, <span class="math inline">\(K'\)</span>, and <span class="math inline">\(V'\)</span>.</p></li>
</ul></li>
<li><p><strong>Memory-Efficient Attention:</strong> Techniques like gradient checkpointing and operator fusion can reduce the memory footprint of self-attention without sacrificing accuracy. The idea is to recompute activations during the backward pass, trading computation for memory. This is used to train models with very long sequences.</p></li>
<li><p><strong>Attention with Linear Computational Cost:</strong> This approach focuses on approximating the attention mechanism with linear complexity by refactoring the softmax operation and using kernel methods.</p>
<ul>
<li><strong>Transformers with linear attention</strong>: This method reformulates the attention matrix as a product of row-wise kernel functions, resulting in a linear complexity with sequence length.</li>
</ul></li>
<li><p><strong>Blockwise Attention/Chunking:</strong> Dividing the input sequence into smaller blocks and applying self-attention within each block, with some form of cross-block attention, can reduce the quadratic cost.</p></li>
<li><p><strong>Recurrence:</strong> Using recurrence-based models (e.g., RNNs, LSTMs) or state-space models that have linear complexity in sequence length can be an alternative, though they often lack the parallelization capabilities of Transformers.</p></li>
<li><p><strong>FlashAttention:</strong> FlashAttention reorders the attention computation to perform fewer reads/writes to slower memory, reducing the overall runtime. It exploits the parallelism of modern GPUs and reduces the memory footprint by avoiding storing the intermediate attention matrix.</p></li>
</ul>
<p><strong>4. Real-World Considerations:</strong></p>
<ul>
<li><strong>Hardware Limitations:</strong> The choice of mitigation strategy often depends on the available hardware resources (e.g., GPU memory).</li>
<li><strong>Accuracy Trade-offs:</strong> Many of the approximation techniques involve trade-offs between computational efficiency and accuracy. It is important to evaluate the impact of these trade-offs on the performance of the model.</li>
<li><strong>Implementation Complexity:</strong> Some of the more advanced techniques can be complex to implement and require careful tuning.</li>
</ul>
<p>In summary, self-attention’s quadratic complexity poses a significant challenge for long sequences. Strategies like sparse attention, low-rank approximations, and memory-efficient techniques are essential to scale self-attention to handle such sequences effectively, balancing computational cost and model accuracy.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Core Problem:</strong></p>
<ul>
<li>“The main challenge with self-attention is its quadratic complexity with respect to the sequence length. This means that the computational cost and memory requirements grow quadratically as the sequence gets longer.”</li>
<li>“Specifically, the <span class="math inline">\(QK^T\)</span> operation, where <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span> are the query and key matrices, has a complexity of <span class="math inline">\(O(n^2d)\)</span>, where <span class="math inline">\(n\)</span> is the sequence length and <span class="math inline">\(d\)</span> is the embedding dimension.”</li>
</ul></li>
<li><p><strong>Explain the Impact of Quadratic Complexity:</strong></p>
<ul>
<li>“This quadratic complexity becomes a bottleneck for long sequences, leading to memory constraints and slow training times. Storing the attention matrix <span class="math inline">\(A\)</span>, which is <span class="math inline">\(n \times n\)</span>, can quickly exhaust GPU memory.”</li>
<li>“The computational cost also impacts experimentation and deployment, making it difficult to iterate on models or use them in real-time applications.”</li>
</ul></li>
<li><p><strong>Introduce Mitigation Strategies (Categorize):</strong></p>
<ul>
<li>“To address these challenges, several strategies have been developed. These can broadly be categorized into:”
<ul>
<li>“<strong>Sparse Attention:</strong> Reducing the number of attention calculations.”</li>
<li>“<strong>Low-Rank Approximations:</strong> Approximating the attention matrix with lower-rank representations.”</li>
<li>“<strong>Memory-Efficient Attention:</strong> Optimizing memory usage during training.”</li>
</ul></li>
</ul></li>
<li><p><strong>Elaborate on Key Techniques (Provide Depth):</strong></p>
<ul>
<li><p><strong>(Sparse Attention - Longformer):</strong> “For instance, Longformer uses a combination of sliding window attention and global attention to reduce the complexity to linear. It’s particularly useful for tasks where local context is important, but some tokens need to attend globally.”</p></li>
<li><p><strong>(Low-Rank - Linformer):</strong> “Linformer projects the key and value matrices to a lower-dimensional space, effectively reducing the complexity. The projection matrices are learned during training.” If the interviewer is interested, you can explain the equations. “Specifically: <span class="math display">\[K' = KP, \quad V' = VP\]</span> where <span class="math inline">\(P \in \mathbb{R}^{n \times k}\)</span> is a projection matrix and <span class="math inline">\(k &lt;&lt; n\)</span>.”</p></li>
<li><p><strong>(Memory Efficient Attention)</strong>” Techniques like gradient checkpointing reduces the memory footprint of self-attention.”</p></li>
</ul></li>
<li><p><strong>Highlight Real-World Considerations:</strong></p>
<ul>
<li>“The choice of mitigation strategy depends on the available hardware resources and the specific task. There are often trade-offs between computational efficiency and accuracy.”</li>
<li>“It’s crucial to evaluate these trade-offs and choose the approach that provides the best balance for the application.”</li>
<li>“More recent techniques like FlashAttention exploit parallelism in modern GPUs and greatly reduce memory access. This is usually the best approach when hardware allows.”</li>
</ul></li>
<li><p><strong>Engage the Interviewer (Check for Understanding):</strong></p>
<ul>
<li>Pause after explaining each technique and ask if the interviewer has any questions.</li>
<li>Use phrases like, “Does that make sense?” or “Would you like me to elaborate on any of these techniques?”</li>
</ul></li>
<li><p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Take your time to explain the concepts clearly and concisely.</li>
<li><strong>Use Visual Aids:</strong> If you are in a virtual interview, consider using a whiteboard or screen sharing to illustrate the concepts or equations.</li>
<li><strong>Focus on High-Level Concepts:</strong> Avoid getting bogged down in unnecessary details. Focus on explaining the core ideas and the trade-offs involved.</li>
<li><strong>Tailor Your Response:</strong> Adapt your response to the interviewer’s level of understanding. If they seem unfamiliar with a particular concept, provide a brief explanation before diving into the details.</li>
<li><strong>Be Prepared to Answer Follow-Up Questions:</strong> The interviewer will likely have follow-up questions about the different mitigation strategies or their implementation details. Be prepared to answer these questions confidently and accurately.</li>
<li><strong>Conclude with a Summary:</strong> Briefly summarize the main points of your response. For example, “In summary, self-attention’s quadratic complexity poses a significant challenge for long sequences, and strategies like sparse attention and low-rank approximations are essential to address this challenge.”</li>
</ul></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>