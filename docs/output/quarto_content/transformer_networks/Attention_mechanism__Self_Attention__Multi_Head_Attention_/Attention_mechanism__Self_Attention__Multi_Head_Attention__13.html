<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>attention_mechanism__self_attention__multi_head_attention__13</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-14.-explain-how-gradient-flow-is-managed-in-transformer-networks-that-use-attention-mechanisms.-what-challenges-can-arise-and-how-might-you-address-them" class="level2">
<h2 class="anchored" data-anchor-id="question-14.-explain-how-gradient-flow-is-managed-in-transformer-networks-that-use-attention-mechanisms.-what-challenges-can-arise-and-how-might-you-address-them">Question: 14. Explain how gradient flow is managed in transformer networks that use attention mechanisms. What challenges can arise and how might you address them?</h2>
<p><strong>Best Answer</strong></p>
<p>Transformer networks, especially those leveraging attention mechanisms like self-attention and multi-head attention, revolutionized sequence modeling. However, their very depth and the nature of the attention mechanism itself pose significant challenges to gradient flow during training. Managing this gradient flow is crucial for the successful training of deep transformer models.</p>
<p>Here’s a breakdown of how gradient flow is managed, challenges that arise, and mitigation strategies:</p>
<p><strong>1. Mechanisms for Managing Gradient Flow:</strong></p>
<ul>
<li><p><strong>Residual Connections (Skip Connections):</strong> This is arguably the most critical technique. Residual connections, introduced in ResNets, provide a direct path for gradients to flow through the network, bypassing potentially problematic layers. In a transformer block, the input <span class="math inline">\(x\)</span> is added to the output of a sub-layer (e.g., attention or feedforward network):</p>
<p><span class="math display">\[
y = \text{SubLayer}(x)
\]</span></p>
<p>The residual connection then adds the original input:</p>
<p><span class="math display">\[
\text{Output} = x + y = x + \text{SubLayer}(x)
\]</span></p>
<p>During backpropagation, the gradient with respect to <span class="math inline">\(x\)</span> becomes:</p>
<p><span class="math display">\[
\frac{\partial \text{Output}}{\partial x} = 1 + \frac{\partial \text{SubLayer}(x)}{\partial x}
\]</span></p>
<p>The crucial ‘1’ ensures that gradients can flow backward without being excessively diminished, even if <span class="math inline">\(\frac{\partial \text{SubLayer}(x)}{\partial x}\)</span> is small. This mitigates the vanishing gradient problem, especially in very deep networks.</p></li>
<li><p><strong>Layer Normalization:</strong> Transformers heavily rely on layer normalization. Unlike batch normalization, which normalizes activations across the batch dimension, layer normalization normalizes across the feature dimension <em>within each layer</em>. For a given layer’s activation vector <span class="math inline">\(a\)</span>, layer normalization computes:</p>
<p><span class="math display">\[
\mu = \frac{1}{H} \sum_{i=1}^{H} a_i
\]</span></p>
<p><span class="math display">\[
\sigma^2 = \frac{1}{H} \sum_{i=1}^{H} (a_i - \mu)^2
\]</span></p>
<p><span class="math display">\[
\hat{a_i} = \frac{a_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
\]</span></p>
<p><span class="math display">\[
\text{LayerNorm}(a) = \gamma \hat{a} + \beta
\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the number of features, <span class="math inline">\(\mu\)</span> is the mean, <span class="math inline">\(\sigma^2\)</span> is the variance, <span class="math inline">\(\epsilon\)</span> is a small constant for numerical stability, and <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span> are learnable scale and shift parameters.</p>
<p>Layer normalization stabilizes the activations during training. By centering and scaling the inputs to each layer, it makes the optimization landscape smoother and reduces the sensitivity to the scale of the weights. This, in turn, helps prevent exploding gradients. Crucially, it operates independently of the batch size, making it suitable for various sequence lengths.</p></li>
<li><p><strong>Scaled Dot-Product Attention:</strong> The attention mechanism itself involves scaling the dot products of queries (<span class="math inline">\(Q\)</span>), keys (<span class="math inline">\(K\)</span>), and values (<span class="math inline">\(V\)</span>) by the square root of the dimension of the keys (<span class="math inline">\(d_k\)</span>):</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>The scaling factor <span class="math inline">\(\sqrt{d_k}\)</span> prevents the dot products from becoming too large, which could push the softmax function into a region where gradients are very small (vanishing gradient problem). Large dot products can lead to one-hot encoded softmax outputs, where the gradient is close to zero for all but one element. The scaling ensures a more diffuse probability distribution and more meaningful gradients.</p></li>
</ul>
<p><strong>2. Challenges to Gradient Flow:</strong></p>
<ul>
<li><strong>Vanishing Gradients:</strong> In very deep transformers, especially before the widespread adoption of residual connections and layer normalization, vanishing gradients could still occur, particularly in the earlier layers. The gradients become increasingly smaller as they propagate backward, making it difficult for the initial layers to learn effectively. Even with the mitigations above, extremely deep networks can still suffer from some degree of gradient vanishing.</li>
<li><strong>Exploding Gradients:</strong> Although less common than vanishing gradients in well-designed transformers, exploding gradients can still arise, particularly if the weights are initialized poorly or if the learning rate is too high. This leads to unstable training and can cause the loss to diverge.</li>
<li><strong>Attention Bottleneck:</strong> In some cases, the attention mechanism itself can become a bottleneck. If the attention weights become too peaked (i.e., focusing on only a small subset of the input), the network might struggle to capture the full context of the input sequence. This can hinder the flow of information and gradients.</li>
<li><strong>Long-Range Dependencies:</strong> While attention is designed to capture long-range dependencies, training very deep transformers to effectively model these dependencies can still be challenging. The gradients need to propagate through many layers to connect distant parts of the sequence.</li>
</ul>
<p><strong>3. Mitigation Strategies:</strong></p>
<ul>
<li><p><strong>Careful Weight Initialization:</strong> Proper weight initialization is crucial. Techniques like Xavier/Glorot initialization or He initialization are often used to ensure that the initial weights are neither too large nor too small. These methods aim to keep the variance of the activations consistent across layers during the initial forward passes.</p>
<ul>
<li><strong>Xavier/Glorot Initialization:</strong> For layers with <span class="math inline">\(n_{in}\)</span> inputs and <span class="math inline">\(n_{out}\)</span> outputs, the weights are initialized from a uniform distribution: <span class="math display">\[
W \sim U\left(-\sqrt{\frac{6}{n_{in} + n_{out}}}, \sqrt{\frac{6}{n_{in} + n_{out}}}\right)
\]</span></li>
<li><strong>He Initialization:</strong> For ReLU activations, He initialization is often preferred: <span class="math display">\[
W \sim \mathcal{N}\left(0, \sqrt{\frac{2}{n_{in}}}\right)
\]</span></li>
</ul></li>
<li><p><strong>Learning Rate Scheduling:</strong> Adaptive learning rate schedulers like Adam, AdaGrad, or learning rate warm-up strategies (increasing the learning rate gradually at the beginning of training) can help stabilize training and prevent oscillations. A common approach is to use a learning rate scheduler with a warm-up period followed by a decay. For example, the learning rate might increase linearly for the first <span class="math inline">\(k\)</span> steps and then decrease proportionally to the inverse square root of the step number.</p></li>
<li><p><strong>Gradient Clipping:</strong> Gradient clipping is a simple but effective technique to prevent exploding gradients. If the norm of the gradient exceeds a certain threshold, the gradient is scaled down to that threshold. This prevents the weights from being updated by excessively large amounts. <span class="math display">\[
\text{if } ||g|| &gt; \text{threshold:  } g = \frac{\text{threshold}}{||g||} g
\]</span> where <span class="math inline">\(g\)</span> is the gradient vector.</p></li>
<li><p><strong>Regularization:</strong> Techniques like L1 or L2 regularization can help prevent overfitting and stabilize training. Dropout, which randomly sets some activations to zero during training, can also act as a regularizer and improve generalization. Weight decay (L2 regularization) penalizes large weights, which can contribute to exploding gradients.</p></li>
<li><p><strong>Pre-Layer Normalization vs.&nbsp;Post-Layer Normalization:</strong> Original Transformer paper uses Post-Layer Normalization (LayerNorm is applied after attention/feedforward block). However, Pre-Layer Normalization (LayerNorm is applied before attention/feedforward block) is now found to be more stable and easier to train for very deep transformers. Pre-LN helps to smooth the loss landscape.</p></li>
<li><p><strong>DeepNorm &amp; other advanced Normalization Techniques:</strong> DeepNorm is a more advanced normalization technique specifically designed for training very deep Transformers. It involves scaling the residual connections based on the depth of the network, ensuring a more stable gradient flow even in extremely deep models. Other techniques include RMSNorm, and more.</p></li>
<li><p><strong>Activation Functions:</strong> Using well-behaved activation functions like ReLU, GELU, or Swish can help with gradient flow compared to sigmoid or tanh, especially when used without normalization layers.</p></li>
<li><p><strong>Mixed Precision Training:</strong> Using mixed precision training (e.g., with FP16) can speed up training and reduce memory consumption. However, it can also exacerbate gradient issues, so care must be taken to ensure that gradients are properly scaled and that underflow is avoided. Automatic Mixed Precision (AMP) tools can help with this.</p></li>
</ul>
<p>In summary, managing gradient flow in transformer networks requires a combination of architectural choices (residual connections, layer normalization), careful initialization, appropriate learning rate schedules, and regularization techniques. Understanding the potential challenges and applying the right mitigation strategies is essential for training deep and effective transformer models.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Importance:</strong> Begin by highlighting that managing gradient flow is crucial for training deep transformer networks and that their architecture presents unique challenges.</p></li>
<li><p><strong>Explain Residual Connections:</strong></p>
<ul>
<li>Clearly state that residual connections are the <em>most important</em> mechanism.</li>
<li>Explain how they provide a direct path for gradients to flow.</li>
<li>Show the formula: mention that the derivative contains a ‘+1’ which prevents gradients from vanishing. You can write the equation down on a whiteboard, if available.</li>
</ul></li>
<li><p><strong>Explain Layer Normalization:</strong></p>
<ul>
<li>Explain what layer normalization is and how it differs from batch normalization.</li>
<li>Emphasize that it stabilizes activations and makes the optimization landscape smoother. Briefly explain the formulas, if the interviewer seems interested.</li>
<li>Mention its independence from batch size.</li>
</ul></li>
<li><p><strong>Explain Scaled Dot-Product Attention:</strong></p>
<ul>
<li>Explain that attention scales the dot products by <span class="math inline">\(\sqrt{d_k}\)</span>.</li>
<li>Explain <em>why</em> this scaling is important: to prevent the softmax from becoming too peaked and gradients from vanishing.</li>
</ul></li>
<li><p><strong>Discuss Challenges (one by one):</strong></p>
<ul>
<li>“Despite these mechanisms, we can still encounter challenges such as…”</li>
<li><strong>Vanishing Gradients:</strong> Explain how these can still occur in very deep networks.</li>
<li><strong>Exploding Gradients:</strong> Explain when they might occur and their consequences.</li>
<li><strong>Attention Bottleneck:</strong> How the attention mechanism can, counterintuitively, become a limitation.</li>
<li><strong>Long-Range Dependencies:</strong> The inherent difficulty in capturing these due to depth.</li>
</ul></li>
<li><p><strong>Discuss Mitigation Strategies (a few key ones):</strong></p>
<ul>
<li>“To address these challenges, we can employ several mitigation strategies, including…”</li>
<li><strong>Careful Weight Initialization:</strong> Mention Xavier/Glorot or He initialization. No need to go into extreme detail unless asked.</li>
<li><strong>Learning Rate Scheduling:</strong> Emphasize the use of adaptive learning rates and warmup periods.</li>
<li><strong>Gradient Clipping:</strong> Explain how it prevents exploding gradients. Show the clipping formula if whiteboard is available.</li>
<li><strong>Regularization:</strong> Explain that L1/L2 or Dropout can help.</li>
<li><strong>Pre-Layer Normalization</strong>: Mention it as a refinement over the original Post-Layer Normalization.</li>
<li><strong>DeepNorm</strong>: Bring up this advanced technique briefly to showcase knowledge of the cutting edge, but do not dwell on details without prompting.</li>
</ul></li>
<li><p><strong>Concluding Remarks:</strong></p>
<ul>
<li>Summarize by stating that managing gradient flow in transformers requires a multi-faceted approach.</li>
<li>Conclude by emphasizing that a good understanding of these mechanisms is crucial for building and training successful transformer models.</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Check for Understanding:</strong> Periodically ask if the interviewer has any questions or if they would like you to elaborate on a particular point.</li>
<li><strong>Adapt to the Audience:</strong> If the interviewer seems less familiar with the mathematical details, focus on the conceptual understanding. If they seem more technically inclined, delve deeper into the equations.</li>
<li><strong>Be Confident, Not Arrogant:</strong> Present your knowledge with confidence, but avoid sounding condescending or boastful. Frame your answers as contributions to the discussion.</li>
<li><strong>Whiteboard Use (Optional):</strong> If a whiteboard is available, use it to illustrate the formulas and diagrams. This can help the interviewer visualize the concepts. But only do so if it enhances clarity, not to just show off.</li>
<li><strong>Real-World Examples:</strong> If possible, relate the concepts to real-world applications or research papers.</li>
<li><strong>Listen Carefully:</strong> Pay close attention to the interviewer’s questions and tailor your answers accordingly. If they ask for more detail on a specific technique, provide it.</li>
<li><strong>Show Enthusiasm:</strong> Demonstrate your passion for the topic. This can make a big difference in how your answer is perceived.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>