<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>attention_mechanism__self_attention__multi_head_attention__14</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-15.-there-is-debate-about-whether-attention-weights-provide-meaningful-interpretability-for-model-decisions.-what-is-your-perspective-on-this-and-how-can-we-better-understand-the-decision-making-process-of-these-models" class="level2">
<h2 class="anchored" data-anchor-id="question-15.-there-is-debate-about-whether-attention-weights-provide-meaningful-interpretability-for-model-decisions.-what-is-your-perspective-on-this-and-how-can-we-better-understand-the-decision-making-process-of-these-models">Question: 15. There is debate about whether attention weights provide meaningful interpretability for model decisions. What is your perspective on this, and how can we better understand the decision-making process of these models?</h2>
<p><strong>Best Answer</strong></p>
<p>The interpretability of attention weights is a nuanced topic, and my perspective is that while they offer a <em>glimpse</em> into the model’s decision-making process, they are often insufficient on their own for true understanding. They should be viewed as one piece of a larger interpretability puzzle rather than a complete solution.</p>
<p>Here’s a breakdown of why attention weights are not always directly interpretable and what other methods can be used in conjunction:</p>
<p><strong>1. Limitations of Attention as Direct Explanation:</strong></p>
<ul>
<li><strong>Correlation vs.&nbsp;Causation:</strong> Attention weights highlight which parts of the input the model <em>attended</em> to, but this doesn’t necessarily imply causation. A high attention weight might indicate correlation rather than a genuine causal relationship in the model’s reasoning.</li>
<li><strong>Attention is Task-Dependent:</strong> The meaning of “attention” changes drastically depending on the task. In machine translation, high attention to a specific word in the source sentence might directly translate to its importance for generating the corresponding target word. However, in more complex tasks like image captioning or question answering, the relationship is less direct.</li>
<li><strong>Spurious Correlations:</strong> Models can learn to attend to features that are spuriously correlated with the target variable but are not actually relevant to the underlying task. This is particularly problematic in biased datasets.</li>
<li><strong>Attention is a Learned Representation:</strong> Attention weights themselves are learned parameters optimized for task performance, not necessarily for human interpretability. They represent the model’s internal processing, which may not align with how humans intuitively reason.</li>
<li><strong>Multi-Head Attention Complexity:</strong> The standard Transformer architecture utilizes multi-head attention. While each head focuses on potentially different aspects of the input, aggregating and interpreting the combined attention patterns across all heads can be challenging. It becomes difficult to discern which head contributed most to the final decision and why.</li>
</ul>
<p><strong>2. Why Attention Can Still Be Useful (But Needs Context):</strong></p>
<ul>
<li><strong>Initial Diagnostic Tool:</strong> Attention weights can serve as a first-pass diagnostic tool. If attention patterns are completely nonsensical (e.g., focusing on irrelevant parts of the input), it suggests potential problems with the model, the data, or the training process.</li>
<li><strong>Identifying Important Features:</strong> In some cases, high attention weights can legitimately highlight important input features. For example, in a sentiment analysis task, attention focusing on strongly positive or negative words is often a good sign.</li>
<li><strong>Qualitative Analysis:</strong> Visualizing attention patterns can help researchers qualitatively understand how the model processes different inputs. This can lead to insights that inform model improvements or data augmentation strategies.</li>
</ul>
<p><strong>3. Complementary Interpretability Methods:</strong></p>
<p>To get a more complete understanding of model decisions, we should use attention weights in conjunction with other interpretability techniques:</p>
<ul>
<li><p><strong>Gradient-Based Methods (e.g., Grad-CAM, Integrated Gradients):</strong> These methods calculate the gradients of the output with respect to the input features. They provide a sensitivity map highlighting which input features have the most influence on the model’s prediction.</p>
<ul>
<li>Grad-CAM (Gradient-weighted Class Activation Mapping): <span class="math display">\[L_{Grad-CAM} = ReLU(\sum_k \alpha_k A^k)\]</span> where <span class="math inline">\(\alpha_k\)</span> are the neuron importance weights, and <span class="math inline">\(A^k\)</span> represents the feature maps of a convolutional layer.</li>
<li>Integrated Gradients: <span class="math inline">\(IG_i(x) = (x_i - x'_i) \times \int_{\alpha=0}^1 \frac{\partial F(x' + \alpha \times (x - x'))}{\partial x_i} d\alpha\)</span> where <span class="math inline">\(x\)</span> is the input, <span class="math inline">\(x'\)</span> is a baseline input, and <span class="math inline">\(F\)</span> is the model.</li>
</ul></li>
<li><p><strong>Influence Functions:</strong> These methods estimate how training examples influenced the model’s prediction for a specific test example. This can reveal which data points were most crucial in shaping the model’s behavior.</p>
<ul>
<li>Influence Function: <span class="math display">\[I(z, z_{test}) = -\nabla_\theta L(z_{test}, \hat{\theta})^T H_{\hat{\theta}}^{-1} \nabla_\theta L(z, \hat{\theta})\]</span> where <span class="math inline">\(z\)</span> is a training example, <span class="math inline">\(z_{test}\)</span> is a test example, <span class="math inline">\(\hat{\theta}\)</span> are the learned parameters, <span class="math inline">\(L\)</span> is the loss function, and <span class="math inline">\(H\)</span> is the Hessian matrix of the loss function.</li>
</ul></li>
<li><p><strong>LIME (Local Interpretable Model-agnostic Explanations):</strong> LIME approximates the model locally with a simpler, interpretable model (e.g., a linear model). This provides insights into how the model behaves in the vicinity of a specific input.</p></li>
<li><p><strong>SHAP (SHapley Additive exPlanations):</strong> SHAP uses game-theoretic Shapley values to assign each feature a contribution to the prediction. This provides a more comprehensive and fair assessment of feature importance.</p>
<ul>
<li>Shapley Value: <span class="math inline">\(\phi_i(f) = \sum_{S \subseteq N\setminus\{i\}} \frac{|S|!(n-|S|-1)!}{n!} [f(S \cup \{i\}) - f(S)]\)</span> where <span class="math inline">\(N\)</span> is the set of all features, <span class="math inline">\(S\)</span> is a subset of features, and <span class="math inline">\(f\)</span> is the prediction function.</li>
</ul></li>
<li><p><strong>Counterfactual Explanations:</strong> These methods generate minimally modified inputs that would change the model’s prediction. By examining these counterfactuals, we can understand what factors the model considers crucial for its decision.</p></li>
<li><p><strong>Probing Tasks:</strong> Train auxiliary classifiers to predict properties of the input from the internal representations of the model (including attention weights). This can reveal what kind of information is encoded in these representations.</p></li>
<li><p><strong>Causal Interventions:</strong> Experimentally manipulate the input and observe how the attention weights and the model’s prediction change. This can help establish causal relationships between input features, attention, and the output.</p></li>
</ul>
<p><strong>4. The Importance of Evaluation:</strong></p>
<p>Any interpretability method, including the interpretation of attention weights, should be rigorously evaluated. This can involve:</p>
<ul>
<li><strong>Human Evaluation:</strong> Ask humans to assess the quality of the explanations and their agreement with human intuition.</li>
<li><strong>Faithfulness Metrics:</strong> Quantify how well the explanation reflects the model’s actual reasoning process.</li>
<li><strong>Sanity Checks:</strong> Ensure that the explanation is robust to small perturbations of the input.</li>
</ul>
<p>In conclusion, attention weights can be a useful starting point for understanding model decisions, but they are not a silver bullet. A comprehensive approach to interpretability requires combining attention with other methods and rigorously evaluating the resulting explanations. We should focus on developing techniques that provide <em>faithful</em> explanations of the model’s behavior rather than simply visually appealing attention maps.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to present this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with a Balanced Perspective:</strong> “That’s a great question. My view is that attention weights can be helpful for initial insights, but we shouldn’t rely on them as the sole source of interpretability. They offer a <em>glimpse</em> but not necessarily a <em>complete picture</em> of the model’s decision-making process.”</p></li>
<li><p><strong>Highlight Limitations (Key Point):</strong> “There are several reasons why attention weights alone can be misleading. For example, they show <em>correlation</em> but not necessarily <em>causation</em>. The model might attend to something that’s correlated with the target but not actually driving the decision. Also, in the case of multi-head attention, the interactions between different heads can make it hard to interpret what’s really going on.”</p></li>
<li><p><strong>Acknowledge Usefulness (But With Caveats):</strong> “That being said, attention can be useful. It can be a good initial diagnostic tool. If the attention patterns are completely random, it suggests something is wrong with the model or the data. Also, in simpler tasks, high attention to specific features <em>might</em> indicate importance – for example, in sentiment analysis, attending to positive words.”</p></li>
<li><p><strong>Introduce Complementary Methods (Most Important):</strong> “To get a more comprehensive understanding, I believe it’s crucial to combine attention with other interpretability techniques. For example, gradient-based methods like Grad-CAM or Integrated Gradients show which input features have the most influence on the output.”</p></li>
<li><p><strong>Briefly Explain a Couple of Methods (Without Overwhelming):</strong> “For example, Grad-CAM uses the gradients flowing into the final convolutional layer to create a heatmap highlighting the most important regions of the image. Another useful technique is SHAP values, which apply game theory to fairly distribute the contribution of each feature to the prediction. We can even delve into influence functions, but those calculations become computationally intensive.”</p></li>
<li><p><strong>Emphasize Evaluation (Very Important):</strong> “Crucially, any interpretation, including attention, needs to be evaluated. We can do this through human evaluations or by using metrics that measure how faithfully the explanation reflects the model’s behavior.”</p></li>
<li><p><strong>Conclude with a Forward-Looking Statement:</strong> “Ultimately, the goal is to develop interpretability techniques that provide faithful and actionable insights, not just visually appealing attention maps. This is an active area of research, and combining multiple methods is often the best approach.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> When explaining methods like Grad-CAM or SHAP, take your time and explain the core idea without getting bogged down in the mathematical details.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you’re in a virtual interview, consider sharing your screen and showing examples of attention maps or Grad-CAM visualizations.</li>
<li><strong>Engage the Interviewer:</strong> Ask if they have any questions as you go along to ensure they’re following your explanation.</li>
<li><strong>Avoid Jargon:</strong> While it’s important to demonstrate your technical expertise, avoid using excessive jargon that might confuse the interviewer.</li>
<li><strong>Stay Humble:</strong> Acknowledge that interpretability is a challenging problem and that there’s no single perfect solution.</li>
</ul>
<p>By following this approach, you can demonstrate your understanding of the nuances of attention mechanisms and your ability to critically evaluate interpretability techniques, showcasing your senior-level expertise.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>