<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>attention_mechanism__self_attention__multi_head_attention__6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-7.-discuss-potential-pitfalls-when-implementing-attention-mechanisms-in-real-world-deployments-especially-when-dealing-with-noisy-or-messy-data." class="level2">
<h2 class="anchored" data-anchor-id="question-7.-discuss-potential-pitfalls-when-implementing-attention-mechanisms-in-real-world-deployments-especially-when-dealing-with-noisy-or-messy-data.">Question: 7. Discuss potential pitfalls when implementing attention mechanisms in real-world deployments, especially when dealing with noisy or messy data.</h2>
<p><strong>Best Answer</strong></p>
<p>Attention mechanisms have become a cornerstone of modern deep learning, especially in NLP and computer vision. They allow models to focus on the most relevant parts of the input when making predictions. However, deploying attention mechanisms in real-world scenarios, particularly with noisy or messy data, can present several pitfalls. These pitfalls stem from issues related to robustness, overfitting, interpretability, and computational complexity.</p>
<p><strong>1. Robustness to Noise and Outliers:</strong></p>
<ul>
<li><p><strong>Problem:</strong> Attention weights are learned from the data. In noisy or messy datasets, spurious correlations can lead the attention mechanism to focus on irrelevant or incorrect input features. This can severely degrade the model’s performance. Noise can manifest in various forms: incorrect labels, corrupted data points, or irrelevant features.</p></li>
<li><p><strong>Mathematical Intuition:</strong> The attention mechanism typically involves computing attention weights <span class="math inline">\(a_i\)</span> for each input element <span class="math inline">\(x_i\)</span> based on some similarity function <span class="math inline">\(f\)</span> between a query <span class="math inline">\(q\)</span> and the input element:</p>
<p><span class="math display">\[
a_i = \frac{\exp(f(q, x_i))}{\sum_{j=1}^{n} \exp(f(q, x_j))}
\]</span></p>
<p>Noise in <span class="math inline">\(x_i\)</span> can corrupt the similarity scores <span class="math inline">\(f(q, x_i)\)</span>, leading to incorrect attention weights. If the similarity function is very sensitive to small variations in input, even minimal noise can result in disproportionate effects.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Data Cleaning and Preprocessing:</strong> Cleaning the data through techniques like outlier removal, noise reduction (e.g., using filters), and data imputation can improve the quality of the input.</li>
<li><strong>Robust Attention Mechanisms:</strong> Explore robust similarity functions that are less sensitive to noise. For instance, using a trimmed mean or median instead of the mean in the attention-weighted sum can reduce the impact of outliers.</li>
<li><strong>Regularization:</strong> Applying regularization techniques, like L1 or L2 regularization on the attention weights, can prevent the model from overly relying on specific noisy features.</li>
</ul></li>
</ul>
<p><strong>2. Overfitting:</strong></p>
<ul>
<li><p><strong>Problem:</strong> Attention mechanisms introduce additional parameters to the model, increasing its capacity. This can lead to overfitting, especially when the training data is limited or noisy. The model may memorize the noise patterns in the training data instead of learning generalizable features.</p></li>
<li><p><strong>Mathematical Intuition:</strong> A model with high capacity (lots of parameters) is more prone to overfitting, in other words, performs well on training data, but poorly on unseen data. Attention mechanisms enhance capacity by allowing the model to weigh and combine different input elements in a more flexible manner. If the attention weights are not properly regularized, they can adapt too closely to the specifics of the training set.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Dropout:</strong> Applying dropout to the attention weights or the attention-weighted outputs can prevent the model from relying too heavily on specific features, promoting generalization.</li>
<li><strong>Weight Decay:</strong> Implementing L1 or L2 regularization on the attention mechanism’s parameters can constrain the model’s capacity and reduce overfitting.</li>
<li><strong>Early Stopping:</strong> Monitoring the performance on a validation set and stopping training when the performance starts to degrade can prevent overfitting.</li>
<li><strong>Data Augmentation:</strong> Increasing the size and diversity of the training data through techniques like random cropping, rotation, or noise injection can improve generalization.</li>
</ul></li>
</ul>
<p><strong>3. Interpretability Challenges:</strong></p>
<ul>
<li><p><strong>Problem:</strong> While attention weights are often touted as a way to interpret model decisions, they don’t always provide a clear and accurate explanation. In noisy environments, attention weights can highlight irrelevant features or exhibit instability, making it difficult to understand the model’s reasoning. Attention weights may reflect correlations rather than true causal relationships.</p></li>
<li><p><strong>Mathematical Intuition:</strong> Attention weights <span class="math inline">\(a_i\)</span> quantify the relative importance of each input element <span class="math inline">\(x_i\)</span>. However, if two elements <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> are highly correlated, the attention mechanism might arbitrarily assign high weights to one and low weights to the other, even if both are equally important or neither is causally related to the outcome.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Attention Visualization Techniques:</strong> Visualizing attention weights using heatmaps or other techniques can help to identify patterns and potential issues. However, always be cautious about drawing causal inferences from visualizations.</li>
<li><strong>Attention Regularization:</strong> Encourage attention weights to be more sparse and focused through regularization techniques. This can make them easier to interpret. For example, use L1 regularization to promote sparsity.</li>
<li><strong>Perturbation-Based Methods:</strong> Systematically perturbing the input and observing how the attention weights change can help to identify the most influential features.</li>
<li><strong>Post-hoc Explanation Methods:</strong> Complement attention weights with other explanation methods, such as LIME or SHAP, to provide a more comprehensive understanding of the model’s decisions.</li>
</ul></li>
</ul>
<p><strong>4. Computational Complexity:</strong></p>
<ul>
<li><p><strong>Problem:</strong> Attention mechanisms, especially self-attention in Transformers, can have a high computational cost, especially for long input sequences. The computational complexity is typically <span class="math inline">\(O(n^2)\)</span>, where <span class="math inline">\(n\)</span> is the length of the input sequence. This can be a significant bottleneck in real-world deployments, particularly when dealing with large datasets or limited computational resources.</p></li>
<li><p><strong>Mathematical Intuition:</strong> The quadratic complexity arises from the need to compute pairwise similarity scores between all input elements. In a self-attention mechanism, each input element acts as both a query and a key, requiring comparisons between every pair of elements. This leads to <span class="math inline">\(n \times n\)</span> similarity computations.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Sparse Attention:</strong> Reduce the computational complexity by only computing attention weights for a subset of the input elements. Techniques like local attention, global attention, or approximate attention can be used to sparsify the attention matrix.</li>
<li><strong>Low-Rank Approximations:</strong> Use low-rank approximations of the attention matrix to reduce the computational cost. For instance, decompose the attention matrix into a product of two smaller matrices.</li>
<li><strong>Kernel Methods:</strong> Employ kernel methods to approximate the attention mechanism with lower computational complexity.</li>
<li><strong>Quantization and Pruning:</strong> Reduce the memory footprint and computational cost of the attention mechanism by quantizing the attention weights or pruning less important connections.</li>
<li><strong>Hardware Acceleration:</strong> Utilize specialized hardware, such as GPUs or TPUs, to accelerate the computation of attention weights.</li>
</ul></li>
</ul>
<p><strong>5. Data Bias Amplification:</strong></p>
<ul>
<li><p><strong>Problem:</strong> If the training data contains biases, the attention mechanism can amplify these biases, leading to unfair or discriminatory outcomes. The attention mechanism may learn to focus on features that are correlated with the biased attributes, further reinforcing the bias.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Bias Detection and Mitigation:</strong> Identify and mitigate biases in the training data before training the model. This can involve re-sampling the data, re-weighting the data, or using adversarial debiasing techniques.</li>
<li><strong>Fairness-Aware Regularization:</strong> Incorporate fairness constraints into the training objective to prevent the model from learning biased attention weights.</li>
<li><strong>Adversarial Training:</strong> Train the model to be robust to adversarial examples that are designed to exploit the biases in the attention mechanism.</li>
<li><strong>Bias Auditing:</strong> Evaluate the model’s performance across different demographic groups to identify potential biases.</li>
</ul></li>
</ul>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Online Learning:</strong> In real-world deployments, the data distribution can change over time. This can lead to a degradation in the performance of the attention mechanism. Consider using online learning techniques to adapt the attention mechanism to the changing data distribution.</li>
<li><strong>Cold Start Problem:</strong> When deploying a new attention mechanism, it may not have enough data to learn accurate attention weights. Consider using transfer learning or meta-learning to initialize the attention mechanism with pre-trained weights.</li>
<li><strong>Debugging and Monitoring:</strong> Implement robust monitoring systems to detect and diagnose issues with the attention mechanism. Monitor metrics like attention weight distributions, performance on different subsets of the data, and the stability of the attention weights over time.</li>
</ul>
<p>By carefully considering these potential pitfalls and implementing appropriate mitigation strategies, it is possible to deploy attention mechanisms successfully in real-world scenarios, even when dealing with noisy or messy data.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to structure your answer in an interview, ensuring clarity and demonstrating your expertise:</p>
<ol type="1">
<li><strong>Introduction (30 seconds):</strong>
<ul>
<li>“Attention mechanisms are crucial in modern deep learning for focusing on relevant input parts. However, deploying them in real-world scenarios, especially with noisy data, has specific challenges.”</li>
<li>Briefly mention the main pitfalls you’ll address: robustness, overfitting, interpretability, and computational complexity.</li>
</ul></li>
<li><strong>Robustness to Noise and Outliers (2 minutes):</strong>
<ul>
<li>“One key challenge is the sensitivity to noise. Spurious correlations in noisy data can cause the attention mechanism to focus on irrelevant features, degrading performance.”</li>
<li>Present the equation: “<span class="math inline">\(a_i = \frac{\exp(f(q, x_i))}{\sum_{j=1}^{n} \exp(f(q, x_j))}\)</span>”. Explain that noise can corrupt the similarity score <span class="math inline">\(f(q,x_i)\)</span>.</li>
<li>“To mitigate this, we can use data cleaning, robust similarity functions, or regularization.” Give a brief example for each one, for example “We can use a trimmed mean instead of the mean in the attention-weighted sum”.</li>
</ul></li>
<li><strong>Overfitting (2 minutes):</strong>
<ul>
<li>“Attention mechanisms increase model capacity, making them prone to overfitting, especially with limited or noisy data.”</li>
<li>Explain how attention weights can adapt too closely to the specifics of the training set.</li>
<li>“We can mitigate overfitting using dropout, weight decay, early stopping, or data augmentation.” Briefly explain one or two of these mitigation strategies.</li>
</ul></li>
<li><strong>Interpretability Challenges (2 minutes):</strong>
<ul>
<li>“While attention weights are often seen as interpretable, they don’t always provide a clear explanation, especially with noisy data.”</li>
<li>Explain that attention weights can reflect correlations rather than causal relationships.</li>
<li>“To improve interpretability, we can use attention visualization, regularization to promote sparsity, perturbation-based methods, or complement attention with other explanation methods like LIME or SHAP.”</li>
</ul></li>
<li><strong>Computational Complexity (2 minutes):</strong>
<ul>
<li>“Attention mechanisms, especially self-attention, can be computationally expensive, with a complexity of <span class="math inline">\(O(n^2)\)</span> for sequence length <span class="math inline">\(n\)</span>.”</li>
<li>Explain the origin of the quadratic complexity: the need to compute pairwise similarity scores between all input elements.</li>
<li>“We can reduce complexity using sparse attention, low-rank approximations, kernel methods, quantization, pruning, or hardware acceleration.”</li>
</ul></li>
<li><strong>Data Bias Amplification (1 minute):</strong>
<ul>
<li>“If the training data contains biases, the attention mechanism can amplify these biases, leading to unfair outcomes.”</li>
<li>Mention mitigation strategies such as bias detection, fairness-aware regularization, and adversarial training.</li>
</ul></li>
<li><strong>Real-World Considerations and Conclusion (1 minute):</strong>
<ul>
<li>Briefly touch upon online learning, the cold start problem, and the importance of robust monitoring.</li>
<li>“By addressing these pitfalls and implementing mitigation strategies, attention mechanisms can be successfully deployed in real-world scenarios.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Speak clearly and deliberately.</li>
<li><strong>Explain the math intuitively:</strong> When presenting equations, avoid getting bogged down in technical details. Focus on the high-level idea and how it relates to the problem. For example, when presenting the attention mechanism, explain what <span class="math inline">\(a_i\)</span>, <span class="math inline">\(q\)</span>, and <span class="math inline">\(x_i\)</span> represent.</li>
<li><strong>Use real-world examples:</strong> Whenever possible, illustrate your points with concrete examples from your experience or from published research.</li>
<li><strong>Engage the interviewer:</strong> Ask if they have any questions or if they’d like you to elaborate on a particular point.</li>
<li><strong>Don’t be afraid to admit what you don’t know:</strong> If you’re unsure about something, it’s better to be honest than to try to bluff your way through it.</li>
<li><strong>Stay high-level:</strong> Since you’re a senior candidate, avoid dwelling on basic concepts. Focus on demonstrating your deep understanding of the challenges and solutions.</li>
<li><strong>Highlight practical experience:</strong> Emphasize your experience applying these techniques in real-world projects and the lessons you’ve learned.</li>
</ul>
<p>By following these guidelines, you can deliver a comprehensive and compelling answer that showcases your expertise and impresses the interviewer.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>