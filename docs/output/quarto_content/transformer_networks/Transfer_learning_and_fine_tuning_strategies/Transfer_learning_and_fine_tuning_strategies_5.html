<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>transfer_learning_and_fine_tuning_strategies_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-how-can-transfer-learning-be-applied-in-unsupervised-or-self-supervised-learning-settings-and-what-challenges-might-arise" class="level2">
<h2 class="anchored" data-anchor-id="question-how-can-transfer-learning-be-applied-in-unsupervised-or-self-supervised-learning-settings-and-what-challenges-might-arise">Question: How can transfer learning be applied in unsupervised or self-supervised learning settings, and what challenges might arise?</h2>
<p><strong>Best Answer</strong></p>
<p>Transfer learning, in its essence, involves leveraging knowledge gained from solving one problem and applying it to a different but related problem. In the context of unsupervised or self-supervised learning (SSL), transfer learning becomes particularly powerful because it allows us to pretrain models on large unlabeled datasets and then fine-tune them for specific downstream tasks, even when labeled data is scarce. This is crucial because acquiring large labeled datasets can be prohibitively expensive or time-consuming.</p>
<p>Here’s a breakdown of how transfer learning works with SSL and the challenges involved:</p>
<p><strong>1. Self-Supervised Pretraining:</strong></p>
<ul>
<li><strong>The Core Idea:</strong> SSL aims to create pseudo-labels from the data itself, thus circumventing the need for manual annotation. This is achieved by defining a pretext task.</li>
<li><strong>Common Pretext Tasks:</strong> Examples include:
<ul>
<li><strong>Contrastive Learning:</strong> The model learns to distinguish between similar (“positive”) and dissimilar (“negative”) pairs of data points. Examples include SimCLR, MoCo, and BYOL. The InfoNCE loss is a common objective function used here. The basic idea of InfoNCE loss is to maximize the mutual information between different views of the same data. Let <span class="math inline">\(x_i\)</span> represent an anchor data point, and <span class="math inline">\(x_j\)</span> represents a positive sample (i.e., a different view of the same data point as <span class="math inline">\(x_i\)</span>). Let <span class="math inline">\(x_k\)</span> (where <span class="math inline">\(k \neq i, j\)</span>) represents negative samples. The InfoNCE loss for <span class="math inline">\(x_i\)</span> is given by: <span class="math display">\[L_i = -log\frac{exp(sim(z_i, z_j)/\tau)}{\sum_{k=1}^{K} exp(sim(z_i, z_k)/\tau)}\]</span> where:
<ul>
<li><span class="math inline">\(z_i, z_j, z_k\)</span> are the representations of <span class="math inline">\(x_i, x_j, x_k\)</span> respectively.</li>
<li><span class="math inline">\(sim(a, b)\)</span> is a similarity function (e.g., cosine similarity) between vectors <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</li>
<li><span class="math inline">\(\tau\)</span> is a temperature parameter that controls the concentration of the distribution.</li>
<li><span class="math inline">\(K\)</span> is the number of negative samples.</li>
</ul></li>
<li><strong>Image Jigsaw Puzzles:</strong> The model is trained to rearrange shuffled patches of an image back into their original configuration.</li>
<li><strong>Rotation Prediction:</strong> The model predicts the angle by which an image has been rotated.</li>
<li><strong>Context Prediction:</strong> The model predicts the surrounding patches of a given patch in an image.</li>
<li><strong>Masked Autoencoders (MAE):</strong> Randomly mask patches of the image and train the model to reconstruct those masked patches.</li>
</ul></li>
<li><strong>Encoder Training:</strong> During pretraining, the model learns to extract meaningful features from the input data based on the pretext task. The architecture typically involves an encoder network, <span class="math inline">\(f_\theta\)</span>, parameterized by <span class="math inline">\(\theta\)</span>. The goal is to learn good representations <span class="math inline">\(z = f_\theta(x)\)</span> without any human labels.</li>
</ul>
<p><strong>2. Transfer to Downstream Tasks:</strong></p>
<ul>
<li><strong>Feature Extraction:</strong> The pretrained encoder <span class="math inline">\(f_\theta\)</span> can be used as a fixed feature extractor. The output of the encoder (the learned representations) is fed into a simple classifier trained on the labeled downstream data. This approach is useful when the downstream dataset is very small.</li>
<li><strong>Fine-tuning:</strong> The entire pretrained model (encoder and potentially task-specific layers) is trained on the labeled downstream dataset. This allows the model to adapt the learned features to the specifics of the target task. This is generally preferred when enough labeled data is available. In fine-tuning, we update the parameters <span class="math inline">\(\theta\)</span> of the pretrained encoder, along with any added task-specific layers.</li>
<li><strong>Linear Probing:</strong> Freeze the encoder and train a linear classifier on top of the representations learned by the encoder. This evaluates the quality of the learned representations.</li>
</ul>
<p><strong>3. Challenges in SSL Transfer Learning:</strong></p>
<ul>
<li><strong>Domain Mismatch:</strong> The distribution of the pretraining data may differ significantly from the distribution of the downstream task data. For example, a model pretrained on ImageNet might not perform well on medical images.</li>
<li><strong>Pretext Task Relevance:</strong> The choice of pretext task can significantly impact transfer performance. If the pretext task is not well-aligned with the downstream task, the learned features may not be useful.</li>
<li><strong>Negative Transfer:</strong> In some cases, pretraining can actually <em>hurt</em> performance on the downstream task. This can happen if the pretraining data is noisy or if the pretext task encourages the model to learn irrelevant features.</li>
<li><strong>Catastrophic Forgetting:</strong> During fine-tuning, the model may “forget” the knowledge it acquired during pretraining, especially if the downstream task is very different from the pretext task or if the fine-tuning learning rate is too high. Techniques like elastic weight consolidation (EWC) can help mitigate this. EWC penalizes changes to parameters that were important during the pretraining phase. The EWC loss term is: <span class="math display">\[L_{EWC}(\theta) = \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{i,old})^2\]</span> where: * <span class="math inline">\(\lambda\)</span> is a hyperparameter controlling the strength of the regularization. * <span class="math inline">\(F_i\)</span> is the Fisher information for parameter <span class="math inline">\(\theta_i\)</span>, indicating the importance of that parameter to the original task. * <span class="math inline">\(\theta_{i,old}\)</span> is the value of parameter <span class="math inline">\(\theta_i\)</span> before fine-tuning.</li>
<li><strong>Hyperparameter Tuning:</strong> Fine-tuning often requires careful hyperparameter tuning, including the learning rate, batch size, and regularization strength. The optimal hyperparameters for the pretraining phase may not be optimal for fine-tuning.</li>
<li><strong>Subtle Data Distribution Differences:</strong> Even seemingly small differences in data distributions between the pretraining and downstream datasets can significantly impact transfer performance. For instance, changes in image resolution, lighting conditions, or camera angles can affect the learned features.</li>
<li><strong>Bias Amplification:</strong> Pretraining on biased data can amplify biases in the downstream task. It’s important to be aware of potential biases in the pretraining data and to mitigate them.</li>
<li><strong>Computational Cost:</strong> While pretraining can reduce the amount of labeled data needed, it can be computationally expensive, especially for large models and datasets.</li>
</ul>
<p><strong>4. Mitigation Strategies:</strong></p>
<ul>
<li><strong>Domain Adaptation Techniques:</strong> Use domain adaptation techniques to align the feature distributions of the pretraining and downstream datasets.</li>
<li><strong>Curriculum Learning:</strong> Gradually increase the difficulty of the downstream task during fine-tuning.</li>
<li><strong>Regularization:</strong> Use regularization techniques (e.g., weight decay, dropout) to prevent overfitting during fine-tuning.</li>
<li><strong>Careful Hyperparameter Tuning:</strong> Perform a thorough hyperparameter search to find the optimal hyperparameters for fine-tuning.</li>
<li><strong>Data Augmentation:</strong> Augment the downstream dataset to increase its size and diversity.</li>
<li><strong>Semi-Supervised Learning:</strong> Combine SSL with a small amount of labeled data on the downstream task.</li>
<li><strong>Selecting Appropriate Pretext Tasks:</strong> Carefully select pretext tasks that are relevant to the downstream task.</li>
</ul>
<p>In conclusion, transfer learning from SSL models is a powerful technique for leveraging unlabeled data to improve performance on downstream tasks. However, it’s important to be aware of the challenges that can arise and to employ appropriate mitigation strategies. Careful consideration of the domain mismatch, pretext task relevance, and potential for negative transfer is crucial for successful transfer learning.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with the Basics (0-1 minute):</strong></p>
<ul>
<li>Begin by defining transfer learning in the context of unsupervised/self-supervised learning. Emphasize the motivation: leveraging unlabeled data to solve downstream tasks with limited labels.</li>
<li>Briefly mention the expense/difficulty of acquiring labeled data. “The core idea here is to pretrain a model on a large, unlabeled dataset and then adapt it to a task with limited labels. This is extremely valuable, because obtaining large labeled datasets can be a major bottleneck.”</li>
<li>“I’ll explain how this pretraining works in self-supervised settings, then discuss the main challenges and how we can address them.”</li>
</ul></li>
<li><p><strong>Explain Self-Supervised Pretraining (2-3 minutes):</strong></p>
<ul>
<li><p>Introduce the concept of pretext tasks. Explain that SSL uses data itself to generate labels.</p></li>
<li><p>Provide 2-3 concrete examples of pretext tasks (e.g., contrastive learning, jigsaw puzzles, rotation prediction).</p></li>
<li><p>For one chosen pretext task (e.g., contrastive learning with InfoNCE loss), explain the underlying objective (maximizing agreement between views) and the intuition behind it.</p></li>
<li><p>Present the InfoNCE loss function. “A very common loss function used in contrastive learning is called InfoNCE. It basically tries to maximize agreement between different augmented views of the same input.”</p></li>
<li><p>Equation Presentation: “The InfoNCE loss looks a little like this:” <span class="math display">\[L_i = -log\frac{exp(sim(z_i, z_j)/\tau)}{\sum_{k=1}^{K} exp(sim(z_i, z_k)/\tau)}\]</span> “Here, we have <span class="math inline">\(z_i\)</span> and <span class="math inline">\(z_j\)</span> as embeddings of two different views of the same data point, and the goal is to maximize the similarity between them while minimizing the similarity to negative samples <span class="math inline">\(z_k\)</span>. The temperature parameter <span class="math inline">\(\tau\)</span> controls how sharp the distribution is.”</p></li>
</ul></li>
<li><p><strong>Describe Transfer to Downstream Tasks (1-2 minutes):</strong></p>
<ul>
<li>Explain the two main approaches: feature extraction and fine-tuning.</li>
<li>Clearly differentiate between them: feature extraction uses the pretrained model as is; fine-tuning adapts it to the downstream task.</li>
<li>Mention linear probing as a way to evaluate the learned representations.</li>
</ul></li>
<li><p><strong>Discuss Challenges (3-5 minutes):</strong></p>
<ul>
<li><p>Emphasize that transfer learning isn’t always straightforward; challenges exist.</p></li>
<li><p>Focus on 3-4 key challenges: domain mismatch, pretext task relevance, potential for negative transfer, and catastrophic forgetting.</p></li>
<li><p>Provide a specific example for each challenge to illustrate the point (e.g., pretraining on ImageNet and applying to medical images for domain mismatch).</p></li>
<li><p>For catastrophic forgetting, mention techniques like elastic weight consolidation (EWC) and briefly explain its purpose.</p></li>
<li><p>Equation Presentation: “To address catastrophic forgetting, techniques like EWC are used. The EWC loss looks something like this:” <span class="math display">\[L_{EWC}(\theta) = \frac{\lambda}{2} \sum_i F_i (\theta_i - \theta_{i,old})^2\]</span> “This loss penalizes changes to the parameters that were important during the pretraining phase. The Fisher information <span class="math inline">\(F_i\)</span> tells us how important each parameter is.”</p></li>
</ul></li>
<li><p><strong>Outline Mitigation Strategies (2-3 minutes):</strong></p>
<ul>
<li>For each challenge discussed, present a corresponding mitigation strategy (e.g., domain adaptation for domain mismatch, careful pretext task selection for pretext task relevance).</li>
<li>Briefly explain how each strategy helps to address the corresponding challenge.</li>
</ul></li>
<li><p><strong>Concluding Remarks (30 seconds):</strong></p>
<ul>
<li>Summarize the key takeaways: transfer learning is powerful but requires careful consideration of potential challenges and mitigation strategies.</li>
<li>Reiterate the importance of aligning the pretext task with the downstream task and addressing potential biases in the data.</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace:</strong> Speak clearly and at a moderate pace. Avoid rushing through complex concepts or equations.</li>
<li><strong>Emphasis:</strong> Highlight key terms and concepts (e.g., pretext task, domain mismatch, InfoNCE loss).</li>
<li><strong>Simplification:</strong> When explaining mathematical concepts, avoid overly technical jargon. Focus on the intuition behind the equations. Use relatable analogies.</li>
<li><strong>Interaction:</strong> Encourage interaction by asking the interviewer if they have any questions or if they would like you to elaborate on any specific point.</li>
<li><strong>Enthusiasm:</strong> Demonstrate your enthusiasm for the topic and your understanding of its practical implications.</li>
<li><strong>Confidence:</strong> Project confidence in your knowledge and abilities.</li>
</ul>
<p>By following these guidelines, you can effectively communicate your understanding of transfer learning in unsupervised settings, demonstrate your expertise, and impress the interviewer.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>