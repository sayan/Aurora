<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>transfer_learning_and_fine_tuning_strategies_8</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-how-would-you-evaluate-if-a-fine-tuned-model-has-overfitted-the-new-tasks-dataset-what-metrics-or-validation-strategies-would-you-use" class="level2">
<h2 class="anchored" data-anchor-id="question-how-would-you-evaluate-if-a-fine-tuned-model-has-overfitted-the-new-tasks-dataset-what-metrics-or-validation-strategies-would-you-use">Question: How would you evaluate if a fine-tuned model has overfitted the new task’s dataset? What metrics or validation strategies would you use?</h2>
<p><strong>Best Answer</strong></p>
<p>Overfitting in the context of fine-tuning a pre-trained model occurs when the model learns the training data too well, capturing noise and specific details that don’t generalize to unseen data for the new task. Evaluating and mitigating overfitting is crucial for ensuring the fine-tuned model performs well in real-world scenarios. Here’s a breakdown of strategies and metrics:</p>
<p><strong>1. Data Splitting and Cross-Validation:</strong></p>
<ul>
<li><strong>Train/Validation/Test Split:</strong> The most basic approach is to divide the dataset into three subsets:
<ul>
<li><strong>Training set:</strong> Used to update the model’s weights.</li>
<li><strong>Validation set:</strong> Used to monitor the model’s performance during training and tune hyperparameters. Crucially, the validation set is <em>not</em> used for gradient descent.</li>
<li><strong>Test set:</strong> Used for a final, unbiased evaluation of the model’s performance after training is complete. This should only be looked at one time after the model is finalized.</li>
</ul></li>
<li><strong>K-Fold Cross-Validation:</strong> When the dataset is small, K-fold cross-validation provides a more robust estimate of the model’s generalization performance. The dataset is divided into K folds. In each of K iterations, K-1 folds are used for training, and the remaining fold is used for validation. The results are averaged across all K folds. A common choice is K=5 or K=10.
<ul>
<li>For example, with K=5, the model is trained and validated five times, each time using a different 20% of the data for validation and the remaining 80% for training. The validation scores are then averaged to give an estimate of model performance.</li>
<li><strong>Stratified K-Fold:</strong> If the dataset has imbalanced classes, stratified K-fold ensures that each fold has a representative distribution of each class.</li>
</ul></li>
</ul>
<p><strong>2. Metrics:</strong></p>
<p>The choice of metric depends on the nature of the task (classification, regression, etc.).</p>
<ul>
<li><strong>Classification:</strong>
<ul>
<li><strong>Accuracy:</strong> Overall correct predictions. Can be misleading with imbalanced classes. <span class="math display">\[Accuracy = \frac{Number\ of\ Correct\ Predictions}{Total\ Number\ of\ Predictions}\]</span></li>
<li><strong>Precision:</strong> Of all the instances predicted as positive, how many are actually positive? <span class="math display">\[Precision = \frac{True\ Positives}{True\ Positives + False\ Positives}\]</span></li>
<li><strong>Recall:</strong> Of all the actual positive instances, how many were predicted correctly? <span class="math display">\[Recall = \frac{True\ Positives}{True\ Positives + False\ Negatives}\]</span></li>
<li><strong>F1-score:</strong> Harmonic mean of precision and recall. Provides a balanced measure. <span class="math display">\[F1 = 2 * \frac{Precision * Recall}{Precision + Recall}\]</span></li>
<li><strong>Area Under the ROC Curve (AUC-ROC):</strong> Measures the ability of the classifier to distinguish between classes, regardless of class balance.</li>
<li><strong>Log Loss (Cross-Entropy Loss):</strong> Measures the difference between predicted probabilities and actual labels. A lower log loss indicates better performance.</li>
</ul></li>
<li><strong>Regression:</strong>
<ul>
<li><strong>Mean Squared Error (MSE):</strong> Average squared difference between predicted and actual values. <span class="math display">\[MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2\]</span></li>
<li><strong>Root Mean Squared Error (RMSE):</strong> Square root of MSE. More interpretable as it’s in the same units as the target variable. <span class="math display">\[RMSE = \sqrt{MSE}\]</span></li>
<li><strong>Mean Absolute Error (MAE):</strong> Average absolute difference between predicted and actual values. More robust to outliers than MSE/RMSE. <span class="math display">\[MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y_i}|\]</span></li>
<li><strong>R-squared (Coefficient of Determination):</strong> Proportion of variance in the dependent variable that is predictable from the independent variables. Ranges from 0 to 1, with higher values indicating a better fit. <span class="math display">\[R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y_i})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</span> where <span class="math inline">\(\bar{y}\)</span> is the mean of the actual values.</li>
</ul></li>
</ul>
<p><strong>3. Identifying Overfitting:</strong></p>
<ul>
<li><strong>Gap between Training and Validation Performance:</strong> The key indicator of overfitting. If the model performs significantly better on the training set than on the validation set, it is likely overfitting. This should be viewed across training epochs.</li>
<li><strong>Validation Loss Plateau or Increase:</strong> The validation loss should generally decrease during training. If the validation loss plateaus or starts to <em>increase</em> while the training loss continues to decrease, this is a strong sign of overfitting. This is also known as a U-shaped learning curve.</li>
<li><strong>Visual Inspection of Predictions:</strong> Examine examples where the model makes incorrect predictions on the validation set. Look for patterns or specific types of instances that the model struggles with. This can give clues about the nature of the overfitting.</li>
</ul>
<p><strong>4. Regularization Techniques:</strong></p>
<p>Regularization methods are used <em>during</em> training to prevent overfitting. If overfitting is detected, these can be implemented, and training can be restarted from a previous checkpoint.</p>
<ul>
<li><strong>L1 and L2 Regularization:</strong> Add a penalty term to the loss function based on the magnitude of the weights.
<ul>
<li>L1 regularization (LASSO) encourages sparsity in the weights (some weights become exactly zero). <span class="math display">\[Loss = Original\ Loss + \lambda \sum_{i=1}^{n} |w_i|\]</span></li>
<li>L2 regularization (Ridge Regression) penalizes large weights. <span class="math display">\[Loss = Original\ Loss + \lambda \sum_{i=1}^{n} w_i^2\]</span></li>
<li><span class="math inline">\(\lambda\)</span> is the regularization strength (hyperparameter).</li>
</ul></li>
<li><strong>Dropout:</strong> Randomly drops out (sets to zero) some neurons during training. This prevents neurons from becoming too specialized to specific features.</li>
<li><strong>Batch Normalization:</strong> Normalizes the activations of each layer, making the training process more stable and less sensitive to the choice of hyperparameters. It also has a slight regularization effect.</li>
<li><strong>Early Stopping:</strong> Monitor the validation loss during training and stop training when the validation loss starts to increase. This prevents the model from overfitting to the training data.</li>
</ul>
<p><strong>5. Data Augmentation:</strong></p>
<p>Increasing the size and diversity of the training data can help to reduce overfitting.</p>
<ul>
<li><strong>Image Augmentation:</strong> Apply random transformations to images (e.g., rotations, flips, crops, zooms, color jittering).</li>
<li><strong>Text Augmentation:</strong> Apply random transformations to text (e.g., synonym replacement, random insertion/deletion).</li>
</ul>
<p><strong>6. Statistical Significance Testing:</strong></p>
<p>To ensure that the observed performance differences between models (e.g., a fine-tuned model vs.&nbsp;a baseline model) are statistically significant and not due to chance, perform statistical significance tests.</p>
<ul>
<li><strong>Paired t-test:</strong> If you have multiple predictions from both models for the same data points, a paired t-test can determine if the difference in means is statistically significant.</li>
<li><strong>McNemar’s test:</strong> For comparing the performance of two classifiers on the same set of data, especially when dealing with binary classification.</li>
</ul>
<p><strong>7. Deployment Trials (A/B Testing):</strong></p>
<p>The ultimate test of overfitting is how the model performs in a real-world setting.</p>
<ul>
<li><strong>A/B Testing:</strong> Deploy the fine-tuned model alongside the existing model (or a baseline model) and compare their performance on real-world data. Monitor key metrics (e.g., conversion rate, click-through rate, customer satisfaction). Ensure that the A/B test is designed with statistical rigor to draw valid conclusions.</li>
</ul>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Computational Resources:</strong> Cross-validation and extensive hyperparameter tuning can be computationally expensive.</li>
<li><strong>Time Constraints:</strong> Balancing the need for thorough evaluation with time-to-market pressures.</li>
<li><strong>Data Privacy:</strong> When dealing with sensitive data, ensure that all evaluation and deployment procedures comply with privacy regulations.</li>
<li><strong>Concept Drift:</strong> Over time, the distribution of the data may change, leading to a decline in model performance. Continuously monitor the model’s performance and retrain it as needed.</li>
</ul>
<p>In summary, detecting and mitigating overfitting requires a combination of rigorous validation strategies, appropriate metrics, and regularization techniques. The key is to monitor the gap between training and validation performance and to take steps to prevent the model from learning noise in the training data.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the definition of overfitting in the context of fine-tuning:</strong> “Overfitting in fine-tuning occurs when the model learns the training data too well, capturing noise and specific details that don’t generalize well to unseen data. It’s crucial to evaluate and prevent overfitting to ensure the model performs well in real-world scenarios.”</p></li>
<li><p><strong>Introduce the validation strategy (Train/Validation/Test split):</strong> “The foundation for detecting overfitting is to properly split your data into training, validation, and test sets. The training set updates weights. The validation set is used to monitor performance <em>during</em> training, and the test set provides an unbiased, final evaluation.” Explain why the validation set is so critical.</p></li>
<li><p><strong>Explain K-fold cross-validation (especially if the dataset is small):</strong> “When dealing with smaller datasets, K-fold cross-validation offers a more robust evaluation. We divide the data into K folds, train on K-1, and validate on the remaining one, repeating this K times and averaging the results. For imbalanced datasets, stratified K-fold is essential.”</p></li>
<li><p><strong>Discuss metrics relevant to the specific task:</strong> “The metrics used depend on the task. For classification, we look at accuracy, precision, recall, F1-score, AUC-ROC, and log loss. For regression, we consider MSE, RMSE, MAE, and R-squared.” Briefly define 2-3 of the most common metrics relevant to the role you are interviewing for.</p></li>
<li><p><strong>Explain how to identify overfitting:</strong> “The main indicators are a significant gap between training and validation performance, and a plateau or increase in validation loss while the training loss decreases. Visual inspection of predictions can also reveal patterns in errors.” Use the phrase “divergence of training and validation loss”.</p></li>
<li><p><strong>Outline regularization techniques:</strong> “To combat overfitting during training, we can use techniques like L1 and L2 regularization, dropout, and batch normalization. These methods add penalties or noise to prevent the model from becoming too specialized.” For each, give a one sentence explanation.</p></li>
<li><p><strong>Describe data augmentation:</strong> “Increasing the diversity of the training data through data augmentation can also help. This involves applying random transformations to images or text to create new, slightly different examples.”</p></li>
<li><p><strong>Discuss statistical significance testing:</strong> “To ensure that the improvements we observe from fine-tuning are real and not due to random chance, we should apply statistical significance tests, like paired t-tests or McNemar’s test, to compare the performance of the fine-tuned model against a baseline.”</p></li>
<li><p><strong>Conclude with deployment trials (A/B testing):</strong> “Finally, the ultimate test is deployment. A/B testing allows us to compare the fine-tuned model’s performance against the existing model in a real-world setting, monitoring key metrics to ensure it’s truly improving performance.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Use clear and concise language:</strong> Avoid jargon unless you are certain the interviewer is familiar with it.</li>
<li><strong>Provide examples:</strong> Illustrate your points with concrete examples, such as a specific metric or regularization technique.</li>
<li><strong>Check for understanding:</strong> Pause periodically and ask if the interviewer has any questions.</li>
<li><strong>Tailor your response to the interviewer’s level of expertise:</strong> If the interviewer is not a technical expert, focus on the high-level concepts and avoid getting bogged down in the details. If they are a technical expert, you can delve into more technical details.</li>
<li><strong>Show enthusiasm and passion:</strong> Let your enthusiasm for the topic shine through.</li>
<li><strong>For equations:</strong> Do not read the equation character by character. Explain <em>what</em> the equation represents in plain English. For instance: “Mean Squared Error calculates the average of the squared differences between predicted and actual values, giving us a sense of the magnitude of the errors.”</li>
</ul>
<p>By following these steps, you can effectively demonstrate your understanding of overfitting and your ability to address it in the context of fine-tuning.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>