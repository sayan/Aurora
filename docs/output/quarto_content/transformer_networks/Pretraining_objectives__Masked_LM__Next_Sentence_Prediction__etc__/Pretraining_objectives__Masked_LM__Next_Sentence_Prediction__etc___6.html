<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>pretraining_objectives__masked_lm__next_sentence_prediction__etc___6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-7.-pretraining-objectives-used-during-training-are-sometimes-not-well-aligned-with-the-tasks-encountered-during-fine-tuning.-how-would-you-address-this-mismatch-particularly-in-the-context-of-mlm" class="level2">
<h2 class="anchored" data-anchor-id="question-7.-pretraining-objectives-used-during-training-are-sometimes-not-well-aligned-with-the-tasks-encountered-during-fine-tuning.-how-would-you-address-this-mismatch-particularly-in-the-context-of-mlm">Question: 7. Pretraining objectives used during training are sometimes not well-aligned with the tasks encountered during fine-tuning. How would you address this mismatch, particularly in the context of MLM?</h2>
<p><strong>Best Answer</strong></p>
<p>The mismatch between pretraining objectives and fine-tuning tasks is a crucial challenge in transfer learning, especially in the context of Masked Language Modeling (MLM) and other self-supervised pretraining methods. This discrepancy can lead to suboptimal performance during fine-tuning, even after a seemingly successful pretraining phase. Let’s delve into the causes and potential solutions.</p>
<section id="understanding-the-mismatch-in-mlm" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-mismatch-in-mlm">Understanding the Mismatch in MLM</h3>
<p>MLM, exemplified by models like BERT, involves masking a portion of the input tokens and training the model to predict the masked tokens. This objective forces the model to learn contextual representations and relationships between words. However, during fine-tuning, models are typically not presented with masked inputs. This creates a discrepancy between the training and inference environments, which we can break down further:</p>
<ol type="1">
<li><p><strong>Masking Artifacts:</strong> During pre-training, the model learns to rely heavily on the <code>[MASK]</code> token as a strong signal. When this signal is absent during fine-tuning, the model might struggle to adapt. This is particularly problematic when the fine-tuning task involves sequence classification or generation, where no explicit masking is present.</p></li>
<li><p><strong>Objective Differences:</strong> MLM is an auxiliary task designed to learn general language representations. The fine-tuning tasks, such as sentiment analysis, question answering, or text classification, require the model to perform specific tasks with different objectives and loss functions. A large gap between the MLM objective and the fine-tuning objective can hinder performance.</p></li>
<li><p><strong>Data Distribution Shift:</strong> Pre-training often uses a large corpus of general text data, while fine-tuning datasets are usually smaller and domain-specific. This distribution shift can exacerbate the mismatch problem, as the model’s learned representations might not be optimal for the fine-tuning data.</p></li>
</ol>
</section>
<section id="addressing-the-mismatch" class="level3">
<h3 class="anchored" data-anchor-id="addressing-the-mismatch">Addressing the Mismatch</h3>
<p>Several techniques can be employed to mitigate the pretraining-finetuning mismatch in MLM.</p>
<ol type="1">
<li><p><strong>Dynamic Masking During Fine-tuning:</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Introduce masking during fine-tuning to mimic the pretraining environment. This can help the model become less reliant on the absence of mask tokens and improve its generalization.</p></li>
<li><p><strong>Implementation:</strong> Randomly mask tokens during fine-tuning with a certain probability (e.g., 10-15%). The masking strategy (e.g., random, contiguous) can be the same as or different from the pretraining strategy.</p></li>
<li><p><strong>Mathematical Representation:</strong> Let <span class="math inline">\(x = (x_1, x_2, ..., x_n)\)</span> be the input sequence of tokens. During fine-tuning, we create a masked sequence <span class="math inline">\(x'\)</span> where some tokens are replaced with the <code>[MASK]</code> token based on a probability <span class="math inline">\(p_{mask}\)</span>. The fine-tuning objective becomes:</p>
<p><span class="math display">\[ \mathcal{L}_{FT} = \mathbb{E}_{x \sim D_{FT}} \left[  \mathcal{L}(f(x'), y) \right] \]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(D_{FT}\)</span> is the fine-tuning dataset.</li>
<li><span class="math inline">\(f\)</span> is the model.</li>
<li><span class="math inline">\(y\)</span> is the target label.</li>
<li><span class="math inline">\(\mathcal{L}\)</span> is the loss function (e.g., cross-entropy).</li>
</ul></li>
</ul></li>
<li><p><strong>Data Augmentation:</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Augment the fine-tuning dataset to make it more similar to the pretraining data. This can reduce the distribution shift and improve the model’s ability to transfer knowledge.</p></li>
<li><p><strong>Implementation:</strong> Use techniques like:</p>
<ul>
<li><strong>Token Replacement:</strong> Replace tokens with synonyms, random words, or masked tokens.</li>
<li><strong>Back Translation:</strong> Translate the text to another language and back to introduce variations.</li>
<li><strong>Random Insertion/Deletion:</strong> Add or remove tokens randomly.</li>
</ul></li>
<li><p><strong>Mathematical Representation:</strong> Augment the fine-tuning dataset <span class="math inline">\(D_{FT}\)</span> with augmented samples <span class="math inline">\(x_{aug}\)</span>.</p>
<p><span class="math display">\[ D'_{FT} = D_{FT} \cup \{x_{aug} | x \sim D_{FT}, x_{aug} = Augment(x) \} \]</span></p>
<p>where <span class="math inline">\(Augment(x)\)</span> is the augmentation function.</p></li>
</ul></li>
<li><p><strong>Adaptive Pretraining Strategies:</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Modify the pretraining objective to be more aligned with the downstream task. This involves adapting the pretraining task or data to better reflect the characteristics of the fine-tuning task.</p></li>
<li><p><strong>Implementation:</strong></p>
<ul>
<li><strong>Task-Specific Pretraining:</strong> Continue pretraining on a dataset that is more relevant to the fine-tuning task <em>before</em> fine-tuning on your actual labeled dataset for the desired task.. For example, if the fine-tuning task is medical text classification, pretrain on a large corpus of medical texts.</li>
<li><strong>Mixture of Objectives:</strong> Combine MLM with other objectives that are more similar to the fine-tuning task, such as sentence ordering or next sentence prediction (even though the original BERT paper found NSP not to be particularly helpful).</li>
<li><strong>Adversarial Training:</strong> Introduce an adversarial component during pretraining that encourages the model to learn representations that are robust to changes in the input, such as masking.</li>
</ul></li>
<li><p><strong>Mathematical Representation (Task-Specific Pretraining):</strong> Let <span class="math inline">\(D_{ST}\)</span> be a domain-specific dataset for pretraining. The pretraining objective becomes:</p>
<p><span class="math display">\[ \mathcal{L}_{PT} = \mathbb{E}_{x \sim D_{ST}} \left[ \mathcal{L}_{MLM}(f(x)) \right] \]</span></p>
<p>where <span class="math inline">\(\mathcal{L}_{MLM}\)</span> is the MLM loss.</p></li>
</ul></li>
<li><p><strong>Prompt Engineering and Instruction Tuning:</strong></p>
<ul>
<li><strong>Rationale:</strong> Frame the downstream tasks as a masked language modeling problem directly. This can be achieved via prompt engineering techniques.</li>
<li><strong>Implementation:</strong> Craft prompts that contain masked tokens and elicit the desired response from the model, treating fine-tuning as a masked word prediction problem. Combine with instruction tuning where the model is trained on diverse tasks with instructions formatted as text.</li>
<li><strong>Example:</strong> Instead of directly fine-tuning for sentiment classification, create a prompt like: “The sentiment of this movie review: ‘This movie was amazing!’ is [MASK].”</li>
</ul></li>
<li><p><strong>Unmasking During Fine-tuning (Progressive Unmasking):</strong></p>
<ul>
<li><p><strong>Rationale:</strong> Gradually reduce the masking probability during fine-tuning. Start with a high masking probability similar to pretraining and slowly decrease it to zero. This helps the model adapt to the unmasked input gradually.</p></li>
<li><p><strong>Implementation:</strong> Define a schedule for the masking probability <span class="math inline">\(p_{mask}(t)\)</span> that decreases over time (training steps) <span class="math inline">\(t\)</span>.</p></li>
<li><p><strong>Mathematical Representation:</strong> Let <span class="math inline">\(p_{mask}(t)\)</span> be a function that defines the masking probability at training step <span class="math inline">\(t\)</span>. A simple linear decay can be defined as:</p>
<p><span class="math display">\[ p_{mask}(t) = p_{mask}^{initial} - \frac{t}{T} (p_{mask}^{initial} - p_{mask}^{final}) \]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(p_{mask}^{initial}\)</span> is the initial masking probability.</li>
<li><span class="math inline">\(p_{mask}^{final}\)</span> is the final masking probability (usually 0).</li>
<li><span class="math inline">\(T\)</span> is the total number of training steps.</li>
</ul></li>
</ul></li>
<li><p><strong>Deberta-style Disentangled Attention:</strong> DeBERTa improves upon BERT by using two attention mechanisms: one that attends to the content of the words and another that attends to the position. This is helpful because the model doesn’t rely on the mask tokens directly.</p></li>
</ol>
</section>
<section id="real-world-considerations" class="level3">
<h3 class="anchored" data-anchor-id="real-world-considerations">Real-World Considerations</h3>
<ul>
<li><strong>Computational Cost:</strong> Dynamic masking and data augmentation can increase the computational cost of fine-tuning, as each training example needs to be processed with masking or augmentation. Careful consideration of the trade-off between performance and cost is necessary.</li>
<li><strong>Hyperparameter Tuning:</strong> The masking probability, augmentation strategies, and pretraining objectives need to be carefully tuned for each specific task and dataset.</li>
<li><strong>Domain Adaptation:</strong> For domain-specific tasks, using a domain-specific pretraining corpus and adaptive pretraining strategies can significantly improve performance.</li>
<li><strong>Evaluation Metrics:</strong> It’s essential to evaluate the effectiveness of the mismatch mitigation techniques using appropriate evaluation metrics that reflect the downstream task’s goals.</li>
</ul>
<p>By understanding the causes of the pretraining-finetuning mismatch and applying appropriate techniques, we can significantly improve the performance of MLM-based models in various downstream tasks.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with a concise definition:</strong>
<ul>
<li>“The mismatch between pretraining objectives and fine-tuning tasks is a critical issue in transfer learning. This mismatch can lead to suboptimal performance during fine-tuning, despite a seemingly successful pretraining phase. This is particularly important to consider in the context of Masked Language Modeling.”</li>
</ul></li>
<li><strong>Explain the causes of the mismatch in MLM:</strong>
<ul>
<li>“In the context of MLM, the mismatch arises from several factors. First, the model learns to rely on the <code>[MASK]</code> token during pretraining, which is absent during fine-tuning. Second, the MLM objective is a general language understanding task, while fine-tuning tasks are often more specific. Finally, the data distribution between the pretraining corpus and fine-tuning dataset can be different.”</li>
</ul></li>
<li><strong>Present the solutions (choose 2-3 key solutions to highlight):</strong>
<ul>
<li>“To address this mismatch, several techniques can be employed. I can describe a couple approaches in detail.”</li>
<li><strong>Option 1: Dynamic Masking:</strong> “One effective approach is dynamic masking during fine-tuning. This involves randomly masking tokens during fine-tuning to mimic the pretraining environment. The idea is to make the model more robust to the absence of mask tokens. We can represent this mathematically… <briefly explain="" the="" equation="">…but the key idea is that we’re introducing the masking function during the fine-tuning loss.”</briefly></li>
<li><strong>Option 2: Data Augmentation:</strong> “Another useful technique is data augmentation. This involves creating augmented examples to enlarge the finetuning dataset and make it more similar to the pretraining data. The idea is to reduce the distribution shift, which has a similar effect on the performance.”</li>
<li><strong>Option 3: Adaptive Pretraining:</strong> “A more advanced approach is adaptive pretraining, where we modify the pretraining objective to be more aligned with the downstream task. For example, if the fine-tuning task is medical text classification, we can continue pretraining on a large corpus of medical texts before fine-tuning on the labeled task dataset.”</li>
<li><strong>Option 4: Prompt Engineering and Instruction Tuning:</strong> “We can also reframe tasks by employing prompt engineering and instruction tuning to directly formulate tasks as a masked language modeling problem to make tasks similar to pretraining”</li>
</ul></li>
<li><strong>Discuss real-world considerations:</strong>
<ul>
<li>“When applying these techniques in practice, it’s important to consider the computational cost, the need for hyperparameter tuning, and the importance of domain adaptation. Also, it is important to utilize the proper evaluation metrics for success.”</li>
</ul></li>
<li><strong>Concluding statement:</strong>
<ul>
<li>“By understanding the causes of the mismatch and applying appropriate techniques, we can significantly improve the performance of MLM-based models in various downstream tasks.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Speak clearly and avoid rushing through the answer.</li>
<li><strong>Use visuals:</strong> If you’re in a virtual interview, consider sharing your screen and sketching out the equations or diagrams.</li>
<li><strong>Engage the interviewer:</strong> Ask if they have any questions as you go along.</li>
<li><strong>Avoid jargon:</strong> Use technical terms appropriately, but explain them if necessary.</li>
<li><strong>Focus on the ‘why’:</strong> Emphasize the rationale behind each technique and how it addresses the core problem.</li>
</ul>
<p><strong>Handling Mathematical Sections:</strong></p>
<ul>
<li><strong>Don’t dive into excessive detail:</strong> Focus on the key components of the equation and their meaning.</li>
<li><strong>Explain the variables:</strong> Define each variable clearly to avoid confusion.</li>
<li><strong>Use plain language:</strong> Translate the mathematical notation into simple, understandable terms.</li>
<li><strong>Offer to elaborate:</strong> Let the interviewer know that you can provide more details if they’re interested.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>