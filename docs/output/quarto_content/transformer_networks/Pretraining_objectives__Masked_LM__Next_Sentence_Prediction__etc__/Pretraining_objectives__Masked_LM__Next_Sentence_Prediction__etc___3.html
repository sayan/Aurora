<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>pretraining_objectives__masked_lm__next_sentence_prediction__etc___3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-discuss-the-mathematical-formulation-of-the-masked-language-modeling-objective.-how-is-the-loss-computed-over-the-masked-tokens-and-why-is-this-formulation-effective" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-discuss-the-mathematical-formulation-of-the-masked-language-modeling-objective.-how-is-the-loss-computed-over-the-masked-tokens-and-why-is-this-formulation-effective">Question: 4. Discuss the mathematical formulation of the masked language modeling objective. How is the loss computed over the masked tokens, and why is this formulation effective?</h2>
<p><strong>Best Answer</strong></p>
<p>Masked Language Modeling (MLM) is a pre-training objective where some percentage of the input tokens are masked, and the model is tasked with predicting the masked tokens based on the context provided by the unmasked tokens. This technique is particularly prominent in models like BERT. The mathematical formulation centers around minimizing a loss function that quantifies the difference between the model’s predictions for the masked tokens and the actual masked tokens.</p>
<p>Here’s a detailed breakdown:</p>
<ol type="1">
<li><strong>Input Preparation:</strong>
<ul>
<li>Given an input sequence of tokens <span class="math inline">\(X = (x_1, x_2, ..., x_n)\)</span>, we randomly select a subset of tokens to mask. Let <span class="math inline">\(M\)</span> be the set of indices of the masked tokens.</li>
<li>For tokens at indices <span class="math inline">\(i \in M\)</span>, we replace them with a special <code>[MASK]</code> token with probability 0.8. With probability 0.1, we replace them with a random token, and with probability 0.1, we leave them unchanged. This helps the model to be less sensitive to the <code>[MASK]</code> token.</li>
</ul></li>
<li><strong>Model Prediction:</strong>
<ul>
<li>The masked input sequence <span class="math inline">\(X'\)</span> is fed into a transformer model (e.g., BERT).</li>
<li>The model outputs a sequence of contextualized token embeddings <span class="math inline">\(H = (h_1, h_2, ..., h_n)\)</span>, where <span class="math inline">\(h_i\)</span> is the hidden representation for the <span class="math inline">\(i\)</span>-th token.</li>
<li>For each masked token position <span class="math inline">\(i \in M\)</span>, the corresponding hidden vector <span class="math inline">\(h_i\)</span> is passed through a classification layer (a linear layer followed by a softmax) to predict the probability distribution over the vocabulary.</li>
</ul></li>
<li><strong>Loss Function:</strong>
<ul>
<li><p>The objective is to minimize the negative log-likelihood of the correct tokens at the masked positions. This is equivalent to maximizing the probability of the correct tokens given the context.</p></li>
<li><p>Let <span class="math inline">\(V\)</span> be the vocabulary, and let <span class="math inline">\(y_i\)</span> be the true token at position <span class="math inline">\(i\)</span>. The probability predicted by the model for token <span class="math inline">\(v \in V\)</span> at masked position <span class="math inline">\(i\)</span> is given by: <span class="math display">\[
p(x_i = v | X') = \frac{\exp(W_v^T h_i + b_v)}{\sum_{v' \in V} \exp(W_{v'}^T h_i + b_{v'})}
\]</span> where <span class="math inline">\(W_v\)</span> and <span class="math inline">\(b_v\)</span> are the weight vector and bias for token <span class="math inline">\(v\)</span> in the classification layer.</p></li>
<li><p>The loss function <span class="math inline">\(L\)</span> is the average negative log-likelihood over all masked tokens: <span class="math display">\[
L = - \frac{1}{|M|} \sum_{i \in M} \log p(x_i = y_i | X')
\]</span> where <span class="math inline">\(|M|\)</span> is the number of masked tokens. Equivalently, we can express the loss as a cross-entropy loss: <span class="math display">\[
L = \frac{1}{|M|} \sum_{i \in M}  \text{CrossEntropy}(p(x_i | X'), y_i)
\]</span></p></li>
</ul></li>
<li><strong>Optimization:</strong>
<ul>
<li>The model is trained by minimizing the loss function <span class="math inline">\(L\)</span> using gradient descent or a variant thereof (e.g., Adam).</li>
<li>The gradients are computed with respect to the model parameters (weights and biases), and the parameters are updated iteratively.</li>
</ul></li>
</ol>
<p><strong>Why is this formulation effective?</strong></p>
<ul>
<li><strong>Contextual Understanding:</strong> By forcing the model to predict masked tokens based on the surrounding context, the model learns deep bidirectional representations. It must understand the relationships between tokens in both directions (left and right) to accurately predict the masked tokens.</li>
<li><strong>Generalization:</strong> The random masking strategy encourages the model to generalize well to unseen data. It cannot rely on specific tokens being present in specific positions and must learn to infer meaning from various contexts.</li>
<li><strong>Transfer Learning:</strong> The pre-trained model can then be fine-tuned for various downstream tasks such as text classification, question answering, and named entity recognition. The pre-training provides a strong initialization that significantly improves the performance and reduces the amount of task-specific data needed for fine-tuning.</li>
<li><strong>Handling Variable Masking:</strong> The loss function is computed only over the masked tokens, which naturally handles the variability in the number and positions of masked tokens in different input sequences. Backpropagation is performed only on the relevant parts of the network, making it efficient.</li>
<li><strong>Mitigating Pretrain-Finetune Discrepancy:</strong> The deliberate modification of the original input (replacing tokens with [MASK], random tokens, or leaving them unchanged) during pretraining helps to bridge the gap between the pretraining and finetuning stages. This reduces the model’s reliance on seeing specific tokens in specific places, making it more adaptable to a wider range of downstream tasks.</li>
</ul>
<p>In summary, the mathematical formulation of the masked language modeling objective is effective because it encourages the model to learn deep contextual representations, generalize to unseen data, and transfer well to downstream tasks. The loss function, based on minimizing the negative log-likelihood of the correct tokens at the masked positions, provides a clear and efficient way to train the model.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><strong>Start with the basics:</strong>
<ul>
<li>“Masked Language Modeling (MLM) is a pre-training objective where a certain percentage of the input tokens are masked, and the model’s task is to predict these masked tokens based on the surrounding unmasked tokens.”</li>
<li>“This technique is used in models like BERT to learn contextualized word representations.”</li>
</ul></li>
<li><strong>Explain Input Preparation:</strong>
<ul>
<li>“Given an input sequence, we randomly select a subset of tokens to mask. Instead of directly replacing them with ‘[MASK]’, we use a strategy where we replace with [MASK] 80% of the time, a random token 10% of the time, and keep the original token 10% of the time. This helps in better generalization.”</li>
</ul></li>
<li><strong>Describe Model Prediction:</strong>
<ul>
<li>“The masked input is fed into a transformer model. The model outputs contextualized embeddings for each token.”</li>
<li>“For each masked token, the corresponding embedding is passed through a classification layer to predict a probability distribution over the vocabulary.”</li>
</ul></li>
<li><strong>Walk through the Loss Function:</strong>
<ul>
<li>“The objective is to minimize the negative log-likelihood of the correct tokens at the masked positions.”</li>
<li>“The probability predicted by the model is given by the softmax function: <span class="math inline">\(&lt;equation&gt;p(x_i = v | X') = \frac{\exp(W_v^T h_i + b_v)}{\sum_{v' \in V} \exp(W_{v'}^T h_i + b_{v'})}&lt;/equation&gt;\)</span>.”</li>
<li>“The loss function L is then: <span class="math inline">\(&lt;equation&gt;L = - \frac{1}{|M|} \sum_{i \in M} \log p(x_i = y_i | X')&lt;/equation&gt;\)</span>. This is computed only over the masked tokens.”</li>
</ul></li>
<li><strong>Explain Optimization (Briefly):</strong>
<ul>
<li>“The model is trained by minimizing this loss function using gradient descent, updating the model parameters iteratively.”</li>
</ul></li>
<li><strong>Emphasize the effectiveness:</strong>
<ul>
<li>“This formulation is effective because it forces the model to learn deep bidirectional representations by understanding the context around the masked tokens.”</li>
<li>“The random masking strategy encourages generalization and reduces reliance on specific tokens.”</li>
<li>“The pre-trained model can be fine-tuned for various downstream tasks, providing a strong initialization and improving performance.”</li>
<li>“Because the loss is only computed on masked tokens, this naturally handles different mask configurations, and the design also helps to mitigate pretrain-finetune discrepancies.”</li>
</ul></li>
<li><strong>Handle Complex Sections:</strong>
<ul>
<li>When you reach the equations, say something like: “The math formalizes this idea. The model predicts a probability for each word in the vocabulary, and we want to maximize the probability of the correct masked word.”</li>
<li>Don’t rush through the equations. Explain the key components (e.g., “<span class="math inline">\(W_v\)</span> is the weight vector for token v”).</li>
<li>After presenting the loss function, summarize: “So, in essence, we’re summing up the negative log-likelihoods for each masked token and averaging by the number of masked tokens to get the final loss.”</li>
</ul></li>
<li><strong>Communication Tips:</strong>
<ul>
<li>Speak clearly and confidently.</li>
<li>Use hand gestures to emphasize points.</li>
<li>Pause after each key point to allow the interviewer to process the information.</li>
<li>Invite questions from the interviewer to ensure they are following along. For example, “Does that make sense so far?” or “Any questions on that?”</li>
<li>Show enthusiasm for the topic.</li>
</ul></li>
</ol>
<p>By following this approach, you can effectively communicate your understanding of the masked language modeling objective and demonstrate your senior-level expertise.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>