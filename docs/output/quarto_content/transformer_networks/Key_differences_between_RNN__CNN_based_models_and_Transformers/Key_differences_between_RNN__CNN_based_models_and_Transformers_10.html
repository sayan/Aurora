<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>key_differences_between_rnn__cnn_based_models_and_transformers_10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-11.-how-does-the-attention-mechanism-in-transformers-help-in-interpretability-of-model-predictions-and-how-does-this-compare-to-the-interpretability-challenges-faced-with-rnns-and-cnns" class="level2">
<h2 class="anchored" data-anchor-id="question-11.-how-does-the-attention-mechanism-in-transformers-help-in-interpretability-of-model-predictions-and-how-does-this-compare-to-the-interpretability-challenges-faced-with-rnns-and-cnns">Question: 11. How does the attention mechanism in Transformers help in interpretability of model predictions, and how does this compare to the interpretability challenges faced with RNNs and CNNs?</h2>
<p><strong>Best Answer</strong></p>
<p>The attention mechanism in Transformers offers a degree of interpretability that is often lacking in Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). This stems from the fact that attention provides a quantifiable measure of the relevance of different parts of the input sequence when making a prediction. However, it is crucial to acknowledge that attention-based interpretability has limitations and can be misleading if not carefully analyzed.</p>
<p>Let’s break down the interpretability aspects for each architecture:</p>
<p><strong>1. Transformers and Attention:</strong></p>
<ul>
<li><p><strong>How Attention Aids Interpretability:</strong> The attention mechanism calculates weights that indicate how much each input element contributes to the representation of another element. In the context of interpretability, these weights can be viewed as a proxy for the importance of each input token (or sub-word unit) in the sequence when making a prediction for a specific output token. For example, in machine translation, attention weights can highlight which source language words are most relevant when translating a particular target language word.</p></li>
<li><p><strong>Mathematical Formulation:</strong> The attention mechanism can be summarized as follows:</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(Q\)</span> is the query matrix</li>
<li><span class="math inline">\(K\)</span> is the key matrix</li>
<li><span class="math inline">\(V\)</span> is the value matrix</li>
<li><span class="math inline">\(d_k\)</span> is the dimension of the keys.</li>
<li>The softmax output represents the attention weights. These are the values that supposedly give insight into the importance of each input element.</li>
</ul></li>
<li><p><strong>Multi-Head Attention:</strong> Transformers typically use multi-head attention. This means the attention mechanism is applied multiple times in parallel, allowing the model to capture different relationships and dependencies within the input sequence. While this improves performance, it also complicates interpretation, as one must analyze the attention weights from multiple heads to get a more complete picture.</p></li>
<li><p><strong>Limitations of Attention as Explanation:</strong></p>
<ul>
<li><strong>Attention is not necessarily Explanation:</strong> High attention weights do not guarantee that a particular input element is the <em>reason</em> for a model’s prediction. They simply indicate correlation, not causation. The model may be attending to spurious correlations in the data.</li>
<li><strong>Attention can be misleading:</strong> Adversarial examples can be crafted to manipulate attention weights without significantly changing the model’s output. This shows that attention can be decoupled from the actual decision-making process.</li>
<li><strong>Attention is only a partial view:</strong> Attention focuses on the relationships between input elements. It doesn’t directly reveal the complex transformations that occur within the layers of the Transformer.</li>
<li><strong>Granularity:</strong> Attention is usually calculated at the sub-word level, making it more challenging to interpret at a higher semantic level.</li>
</ul></li>
</ul>
<p><strong>2. RNNs (Recurrent Neural Networks):</strong></p>
<ul>
<li><strong>Interpretability Challenges:</strong> RNNs process sequences sequentially, maintaining a hidden state that summarizes the past input. However, this hidden state is a high-dimensional vector that is difficult to interpret directly. There is no clear correspondence between elements of the hidden state and specific parts of the input sequence.</li>
<li><strong>Lack of Direct Attentional Mechanism (in vanilla RNNs):</strong> Traditional RNNs lack an explicit attention mechanism. All inputs contribute to the final prediction through the hidden state transformation, but there’s no direct way to quantify the influence of each input element.</li>
<li><strong>Attempts at Interpretability:</strong>
<ul>
<li><strong>Hidden State Visualization:</strong> Techniques like visualizing the activations of RNN hidden units have been used, but these are often difficult to interpret without extensive domain knowledge.</li>
<li><strong>Sensitivity Analysis:</strong> Methods that perturb the input sequence and observe changes in the output can provide some insights, but they are computationally expensive and don’t directly reveal which parts of the input are most important.</li>
</ul></li>
</ul>
<p><strong>3. CNNs (Convolutional Neural Networks):</strong></p>
<ul>
<li><strong>Interpretability Challenges:</strong> CNNs learn hierarchical features by applying convolutional filters to the input. While CNNs can capture spatial relationships, it’s challenging to understand which input regions are most important for a particular prediction. The learned filters represent abstract features rather than direct relationships to the input.</li>
<li><strong>Receptive Field:</strong> Each convolutional layer has a limited receptive field, meaning it only “sees” a small portion of the input. While techniques like deconvolution and guided backpropagation can highlight which input regions activate specific filters, it’s difficult to interpret the overall decision-making process.</li>
<li><strong>Feature Abstraction:</strong> CNNs learn increasingly abstract features as they go deeper. The features learned in later layers may be highly non-linear combinations of the original input, making it challenging to connect them back to specific input regions.</li>
<li><strong>Techniques for Interpretability:</strong>
<ul>
<li><strong>Saliency Maps:</strong> These methods compute the gradient of the output with respect to the input to identify the most relevant input regions.</li>
<li><strong>Class Activation Maps (CAM):</strong> CAMs highlight the regions of the input that are most discriminative for a particular class.</li>
<li><strong>Filter Visualization:</strong> Visualizing the learned filters can provide some insights into the types of features the CNN is learning, but it doesn’t directly explain how the model makes its predictions.</li>
</ul></li>
</ul>
<p><strong>Comparison Summary:</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 29%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Transformers (with Attention)</th>
<th>RNNs</th>
<th>CNNs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Interpretability</td>
<td>Relatively better (through attention weights)</td>
<td>Limited (hidden state is a black box)</td>
<td>Limited (feature abstraction)</td>
</tr>
<tr class="even">
<td>Attention</td>
<td>Explicit attention mechanism</td>
<td>No explicit attention (in vanilla RNNs)</td>
<td>No explicit attention</td>
</tr>
<tr class="odd">
<td>Key Insight</td>
<td>Attention weights as a proxy for importance</td>
<td>Hidden state summarizes past input</td>
<td>Hierarchical feature learning</td>
</tr>
<tr class="even">
<td>Primary Limitation</td>
<td>Attention != Explanation</td>
<td>Difficult to interpret hidden state</td>
<td>Feature abstraction and receptive field</td>
</tr>
</tbody>
</table>
<p>In conclusion, while attention mechanisms in Transformers offer a potential advantage in terms of interpretability by providing insights into which parts of the input are considered most relevant, it’s crucial to recognize the limitations of attention as a sole explanation of model behavior. RNNs and CNNs present even greater interpretability challenges due to their black-box nature of their hidden states and feature abstraction, respectively. More robust and comprehensive interpretability methods are still an active area of research.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Core Idea:</strong></p>
<ul>
<li>“The attention mechanism in Transformers offers a degree of interpretability that is often lacking in RNNs and CNNs, but it’s important to acknowledge the limitations.” (This sets the stage for a nuanced discussion.)</li>
</ul></li>
<li><p><strong>Explain Attention in Transformers:</strong></p>
<ul>
<li>“Attention weights quantify the relevance of different input parts. You can think of them as indicating which words are most important when making a prediction. The model computes query, key, and value vectors, and attention is essentially a weighted sum of the values, where the weights are determined by the similarity between the query and keys using a softmax function.”</li>
<li>“Mathematically, we can describe attention using the formula: <span class="math inline">\(\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V\)</span>, but the key takeaway is that the softmax output gives us the attention weights.” (Use the equation <em>only</em> if the interviewer probes for it, otherwise avoid directly jumping into math).</li>
<li>“The idea is that higher weights indicate higher relevance of the corresponding inputs.”</li>
</ul></li>
<li><p><strong>Highlight the Limitations of Attention:</strong></p>
<ul>
<li>“However, it’s crucial to remember that attention is not <em>necessarily</em> explanation. Just because the model attends to a word doesn’t mean that word is the <em>reason</em> for the prediction. It indicates correlation but not necessarily causation”</li>
<li>“Adversarial attacks can manipulate attention weights to demonstrate that attention isn’t always aligned with the model’s true reasoning.”</li>
</ul></li>
<li><p><strong>Discuss RNNs’ Interpretability Challenges:</strong></p>
<ul>
<li>“RNNs are more challenging to interpret because their hidden state is a high-dimensional vector representing the entire past input. There’s no clear way to directly map parts of the input to elements of the hidden state.”</li>
<li>“While we can try visualizing hidden state activations, they are often difficult to interpret meaningfully.”</li>
</ul></li>
<li><p><strong>Discuss CNNs’ Interpretability Challenges:</strong></p>
<ul>
<li>“CNNs present a different set of challenges. They learn hierarchical features through convolution. While they capture spatial relationships, the learned filters represent <em>abstract features</em> which are not directly explainable”</li>
<li>“Techniques like saliency maps can highlight important input regions, but connecting these regions to the model’s overall decision-making process is challenging.”</li>
</ul></li>
<li><p><strong>Provide a Concise Comparison:</strong></p>
<ul>
<li>“In summary, Transformers offer a <em>relative</em> advantage in interpretability through attention, but it’s not a perfect solution. RNNs and CNNs are even more challenging due to the black-box nature of their hidden states and abstract feature learning, respectively.”</li>
</ul></li>
<li><p><strong>End with a Forward-Looking Statement:</strong></p>
<ul>
<li>“Developing more robust and comprehensive interpretability methods is an active area of research.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> This is a complex topic, so don’t rush. Speak clearly and deliberately.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you’re in a virtual interview, consider sharing your screen to show diagrams or examples of attention weights, saliency maps, etc.</li>
<li><strong>Check for Understanding:</strong> Pause periodically and ask the interviewer if they have any questions. This shows that you’re engaged and want to ensure they understand your explanation.</li>
<li><strong>Avoid Jargon:</strong> Explain technical terms in a clear and concise manner.</li>
<li><strong>Be Nuanced:</strong> Acknowledge the limitations of attention-based interpretability. This shows that you have a deep understanding of the topic and are not simply regurgitating information.</li>
<li><strong>Be Confident:</strong> Project confidence in your knowledge and abilities. You’ve got this!</li>
</ul>
<p>By following these steps, you can effectively communicate your understanding of the interpretability challenges and advantages of Transformers, RNNs, and CNNs. Good luck!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>