<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>key_differences_between_rnn__cnn_based_models_and_transformers_11</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-12.-what-recent-innovations-or-modifications-in-any-of-these-model-families-have-significantly-improved-their-performance-on-tasks-requiring-a-deep-understanding-of-context" class="level2">
<h2 class="anchored" data-anchor-id="question-12.-what-recent-innovations-or-modifications-in-any-of-these-model-families-have-significantly-improved-their-performance-on-tasks-requiring-a-deep-understanding-of-context">Question: 12. What recent innovations or modifications in any of these model families have significantly improved their performance on tasks requiring a deep understanding of context?</h2>
<p><strong>Best Answer</strong></p>
<p>Recent innovations and modifications across RNNs, CNNs, and Transformers have led to significant improvements in performance on tasks requiring a deep understanding of context. Here’s a breakdown:</p>
<p><strong>1. Transformers:</strong></p>
<p>Transformers have become the dominant architecture for sequence modeling, largely due to their ability to capture long-range dependencies effectively. Several innovations have further improved their performance:</p>
<ul>
<li><p><strong>Efficient Attention Mechanisms:</strong> The original self-attention mechanism has a quadratic complexity <span class="math inline">\(O(n^2)\)</span> with respect to sequence length <span class="math inline">\(n\)</span>, making it computationally expensive for long sequences. Several techniques address this:</p>
<ul>
<li><p><strong>Sparse Attention:</strong> Instead of attending to all positions, sparse attention mechanisms (e.g., Longformer, Big Bird) attend to only a subset of positions. This reduces the complexity to <span class="math inline">\(O(n\sqrt{n})\)</span> or even <span class="math inline">\(O(n)\)</span>. The key is selecting which positions to attend to. For instance, Longformer uses a combination of global attention (to a few predefined tokens), sliding window attention, and dilated sliding window attention.</p></li>
<li><p><strong>Linear Attention:</strong> Methods like Transformers with Linear Attention (Linformer) and Performer approximate the attention matrix, reducing the complexity to <span class="math inline">\(O(n)\)</span>. These methods rely on kernel methods or random feature maps to approximate the softmax attention. The underlying idea is to factorize the attention matrix: <span class="math display">\[
Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V
\]</span> becomes, after approximation: <span class="math display">\[
Attention(Q, K, V) \approx  normalize(Q') normalize(K')^T V
\]</span> where <span class="math inline">\(Q'\)</span> and <span class="math inline">\(K'\)</span> are linear projections of <span class="math inline">\(Q\)</span> and <span class="math inline">\(K\)</span>.</p></li>
<li><p><strong>Low-Rank Approximations:</strong> Decomposing the attention matrix into lower-rank components reduces computational costs.</p></li>
</ul></li>
<li><p><strong>Adaptive Computation Time:</strong> Allow the model to spend more computation on relevant parts of the input sequence. For example, networks equipped with adaptive computation time can dynamically adjust the number of steps they need, allocating more compute to the relevant parts of the input</p></li>
<li><p><strong>Memory-Augmented Transformers:</strong> Transformers can be augmented with external memory modules (e.g., Neural Turing Machines, Memory Networks) to store and retrieve information, allowing them to handle longer contexts than what fits in the fixed-size context window. This is particularly useful in tasks requiring reasoning over large documents.</p></li>
<li><p><strong>Better Positional Encoding:</strong> Standard positional encodings can struggle with extremely long sequences. Relative positional encodings and learned positional embeddings provide alternative ways to incorporate positional information. RoPE (Rotary Position Embedding) encodes absolute positional information with rotation matrices. This allows for expressing relative positional information by simply multiplying the rotated embeddings.</p></li>
<li><p><strong>Normalization Techniques:</strong> Layer Normalization has been a mainstay. However, modifications like DeepNorm and StableNorm aim to improve training stability and allow for scaling to deeper and larger models. These normalization schemes focus on pre-normalization techniques and adaptive gradient clipping.</p></li>
</ul>
<p><strong>2. RNNs:</strong></p>
<p>While Transformers have largely surpassed RNNs, research continues to improve RNN architectures, especially for resource-constrained settings or tasks where sequential processing is inherently beneficial.</p>
<ul>
<li><strong>Gated Recurrent Units (GRUs) and LSTMs:</strong> These are already established improvements, but research continues on more sophisticated gating mechanisms and cell designs. Alternatives to standard LSTM architectures, such as Minimal Gated Unit (MGU), reduce the number of parameters while maintaining competitive performance.</li>
<li><strong>Attention Mechanisms in RNNs:</strong> Integrating attention mechanisms into RNNs allows them to focus on relevant parts of the input sequence, addressing the vanishing gradient problem. This improves their ability to capture long-range dependencies. For example, adding attention to bidirectional LSTMs improves performance in machine translation and speech recognition.</li>
<li><strong>Recurrent Memory Networks:</strong> Combining RNNs with external memory modules (e.g., Memory Networks) enhances their ability to store and retrieve information, improving performance on tasks requiring reasoning over long contexts.</li>
<li><strong>Bidirectional and Multi-Layer RNNs:</strong> These architectures allow RNNs to process information from both past and future contexts, and to learn hierarchical representations of the input sequence, respectively. They are essential for capturing deeper contextual understanding.</li>
</ul>
<p><strong>3. CNNs:</strong></p>
<p>CNNs were initially designed for image processing, but they have been adapted for sequence modeling. They offer advantages in terms of computational efficiency and parallelization.</p>
<ul>
<li><strong>Dilated Convolutions:</strong> Dilated convolutions increase the receptive field of the convolutional filters without increasing the number of parameters. This allows CNNs to capture long-range dependencies more effectively. The dilation rate controls the spacing between the kernel points. For example, a dilation rate of 2 means that every other input value is skipped. This increases the receptive field exponentially with the number of layers.</li>
<li><strong>Causal Convolutions:</strong> Used primarily in sequence generation tasks (e.g., time series forecasting), causal convolutions ensure that the output at time <span class="math inline">\(t\)</span> only depends on inputs up to time <span class="math inline">\(t\)</span>, preventing information leakage from future timesteps.</li>
<li><strong>Temporal Convolutional Networks (TCNs):</strong> TCNs combine dilated convolutions and causal convolutions for sequence modeling. They have shown competitive performance compared to RNNs in various tasks.</li>
<li><strong>Attention Mechanisms in CNNs:</strong> Incorporating attention mechanisms into CNNs allows them to focus on relevant parts of the input sequence, improving their ability to capture long-range dependencies. For example, Self-Attention Convolutions can replace standard convolutional layers and learn to attend to different spatial locations within the feature maps.</li>
<li><strong>Depthwise Separable Convolutions:</strong> These convolutions reduce the number of parameters and computational complexity, making CNNs more efficient for sequence modeling. The convolutions are separated into two layers, a depthwise convolution that performs a convolution for each input channel separately, and a pointwise convolution that combines the output of the depthwise convolution with a 1x1 convolution.</li>
</ul>
<p><strong>Why these improvements are effective and trade-offs involved:</strong></p>
<ul>
<li><strong>Transformers (and improvements):</strong> Excellent at capturing long-range dependencies due to attention. However, original self-attention has quadratic complexity, motivating efficient attention variants. Memory augmented transformers can handle even longer contexts but introduce complexity.</li>
<li><strong>RNNs (and improvements):</strong> Naturally suited for sequential data. Improvements like LSTMs/GRUs address vanishing gradients, and attention further enhances long-range dependency modeling. Still, they are generally less parallelizable than Transformers.</li>
<li><strong>CNNs (and improvements):</strong> Computationally efficient and highly parallelizable. Dilated and causal convolutions expand the receptive field for better context. However, capturing very long-range dependencies can still be challenging compared to Transformers.</li>
</ul>
<p>In summary, each model family has undergone significant improvements to enhance its ability to capture long-range dependencies and understand context. The choice of model depends on the specific task requirements, computational resources, and the length of the input sequences.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to present this information in an interview:</p>
<ol type="1">
<li><strong>Start with a Broad Overview:</strong>
<ul>
<li>“There have been significant advancements across all three model families – RNNs, CNNs, and Transformers – that enable them to better capture context. Transformers have seen the most innovation recently, but improvements in RNNs and CNNs are also noteworthy.”</li>
</ul></li>
<li><strong>Dive into Transformers (Most Important):</strong>
<ul>
<li>“Let’s start with Transformers, as they are currently the dominant architecture for tasks needing strong contextual understanding. The core issue with the original Transformer is the quadratic complexity of self-attention. So I’ll explain how that has been addressed”</li>
<li>“One major area of innovation is in <em>efficient attention mechanisms</em>. The naive self-attention has a complexity of <span class="math inline">\(O(n^2)\)</span> limiting the length of the sequences. Sparse attention methods like Longformer reduce this complexity. For example, Longformer attends to global tokens, uses sliding windows, and dilated sliding windows.” (<em>Write the <span class="math inline">\(O(n^2)\)</span> and <span class="math inline">\(O(n\sqrt{n})\)</span> on the whiteboard, if available.</em>)</li>
<li>“Linear attention mechanisms further reduce complexity to <span class="math inline">\(O(n)\)</span> using approximation techniques. To explain this we can see the attention matrix, using linear projections.” (<em>Write the attention formulas if the interviewer seems engaged with the math; otherwise, just mention the linear projections.</em>)</li>
<li>“Other Transformer improvements include memory augmentation for handling extremely long contexts, better positional encoding schemes and Normalization Techniques for stable training of very deep networks”</li>
</ul></li>
<li><strong>Transition to RNNs:</strong>
<ul>
<li>“While Transformers are often preferred now, RNNs still have their place, especially in resource-constrained scenarios. Improvements here focus on addressing the vanishing gradient problem and incorporating attention.”</li>
<li>“Established techniques like LSTMs and GRUs help mitigate vanishing gradients. Additionally, integrating attention mechanisms into RNNs allows them to focus on relevant parts of the input.”</li>
<li>“RNNs can also be combined with external memory modules, similar to Transformers, for enhanced context handling.”</li>
</ul></li>
<li><strong>Discuss CNNs:</strong>
<ul>
<li>“CNNs, initially designed for images, have been adapted for sequence modeling due to their computational efficiency and parallelizability. Key innovations here involve expanding the receptive field and ensuring causality.”</li>
<li>“Dilated convolutions are crucial for expanding the receptive field without adding parameters. Causal convolutions are essential for sequence generation tasks, ensuring that the model doesn’t ‘look into the future.’”</li>
<li>“TCNs combine these concepts. CNNs also benefit from the incorporation of attention mechanisms.”</li>
<li>“Depthwise seperable convolutions make the CNNs more efficient.”</li>
</ul></li>
<li><strong>Summarize and Compare:</strong>
<ul>
<li>“In summary, each model family has seen innovations to improve contextual understanding. Transformers excel at long-range dependencies but can be computationally expensive. RNNs are well-suited for sequential data but can struggle with very long contexts. CNNs offer computational efficiency but may require careful design to capture long-range dependencies. The best choice depends on the specific task and resource constraints.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to digest the information.</li>
<li><strong>Use Visual Aids (if available):</strong> If a whiteboard is available, jot down key equations or diagrams to illustrate your points.</li>
<li><strong>Gauge the Interviewer’s Interest:</strong> Pay attention to their body language and questions. If they seem particularly interested in one area, delve deeper. If they seem overwhelmed, simplify your explanation.</li>
<li><strong>Focus on “Why” and “Trade-offs”:</strong> Don’t just list the innovations; explain why they are effective and what trade-offs are involved.</li>
<li><strong>Be Prepared to Answer Follow-Up Questions:</strong> The interviewer may ask you to elaborate on specific techniques or compare different approaches.</li>
<li><strong>End with a Summary:</strong> Reinforce the key takeaways and reiterate the importance of choosing the right model for the task.</li>
<li><strong>Be Confident:</strong> Show that you have a strong understanding of the concepts and are capable of applying them to real-world problems.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>