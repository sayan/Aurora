<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>encoder_decoder_structure_in_transformers_6</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-7.-how-does-the-encoder-decoder-structure-assist-in-tasks-like-machine-translation-compared-to-simpler-architectures-what-unique-challenges-does-it-pose-in-training-and-inference" class="level2">
<h2 class="anchored" data-anchor-id="question-7.-how-does-the-encoder-decoder-structure-assist-in-tasks-like-machine-translation-compared-to-simpler-architectures-what-unique-challenges-does-it-pose-in-training-and-inference">Question: 7. How does the encoder-decoder structure assist in tasks like machine translation compared to simpler architectures? What unique challenges does it pose in training and inference?</h2>
<p><strong>Best Answer</strong></p>
<p>The encoder-decoder architecture revolutionized machine translation and sequence-to-sequence tasks, offering significant advantages over simpler architectures like recurrent neural networks (RNNs) used directly for sequence generation. Its strength lies in its ability to decouple the input (source) and output (target) sequences, learning an intermediate representation that captures the essence of the input, independent of its length.</p>
<p><strong>Advantages over Simpler Architectures:</strong></p>
<ol type="1">
<li><p><strong>Handling Variable Length Sequences:</strong> Traditional RNNs struggled with aligning input and output sequences of different lengths. The encoder-decoder architecture elegantly addresses this. The encoder compresses the variable-length input sequence into a fixed-length context vector, and the decoder expands this vector into a variable-length output sequence.</p></li>
<li><p><strong>Learning Complex Mappings:</strong> The encoder-decoder learns a complex mapping between source and target languages. The encoder essentially creates a semantic representation of the input sentence, which can then be used by the decoder to generate the output sentence in the target language. This allows the model to learn complex relationships between words and phrases in the two languages.</p></li>
<li><p><strong>Improved Contextual Understanding:</strong> By encoding the entire input sequence before decoding, the model has access to a global context, which can improve translation accuracy and fluency, especially for longer sentences.</p></li>
</ol>
<p><strong>Architecture Breakdown:</strong></p>
<ul>
<li><p><strong>Encoder:</strong> The encoder processes the input sequence <span class="math inline">\(x = (x_1, x_2, ..., x_T)\)</span> and transforms it into a context vector <span class="math inline">\(c\)</span>. This is often achieved using an RNN (e.g., LSTM or GRU) or a Transformer encoder. The context vector <span class="math inline">\(c\)</span> is typically the final hidden state of the encoder. <span class="math display">\[c = f(x_1, x_2, ..., x_T)\]</span> where <span class="math inline">\(f\)</span> represents the encoding function (e.g., a recurrent network).</p></li>
<li><p><strong>Decoder:</strong> The decoder takes the context vector <span class="math inline">\(c\)</span> as input and generates the output sequence <span class="math inline">\(y = (y_1, y_2, ..., y_{T'})\)</span>. This is also commonly implemented using an RNN or a Transformer decoder. At each time step <span class="math inline">\(t\)</span>, the decoder predicts the next word <span class="math inline">\(y_t\)</span> based on the context vector <span class="math inline">\(c\)</span>, the previously generated words <span class="math inline">\(y_{&lt;t}\)</span>, and its own internal state. <span class="math display">\[p(y_t | y_{&lt;t}, c) = g(y_{t-1}, s_t, c)\]</span> where <span class="math inline">\(s_t\)</span> is the decoder’s hidden state at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(g\)</span> is the decoding function.</p></li>
<li><p><strong>Attention Mechanism:</strong> The introduction of attention mechanisms further enhanced the encoder-decoder architecture. Instead of relying solely on the fixed-length context vector, attention allows the decoder to focus on different parts of the input sequence at each decoding step. This is crucial for handling long sentences and capturing long-range dependencies. The attention mechanism computes a weighted sum of the encoder hidden states, where the weights reflect the relevance of each input word to the current output word. <span class="math display">\[a_{ti} = \frac{exp(score(s_t, h_i))}{\sum_{j=1}^T exp(score(s_t, h_j))}\]</span> where <span class="math inline">\(a_{ti}\)</span> is the attention weight for the <span class="math inline">\(i\)</span>-th input word at time <span class="math inline">\(t\)</span>, <span class="math inline">\(s_t\)</span> is the decoder hidden state at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(h_i\)</span> is the encoder hidden state for the <span class="math inline">\(i\)</span>-th input word. The <span class="math inline">\(score\)</span> function can be a dot product, a bilinear function, or a multi-layer perceptron.</p></li>
</ul>
<p><strong>Challenges in Training and Inference:</strong></p>
<ol type="1">
<li><p><strong>Exposure Bias:</strong> During training, the decoder is fed with the ground truth (correct) words as input, but during inference, it has to rely on its own predictions. This discrepancy, known as exposure bias, can lead to error accumulation and poor performance. The model is never exposed to its own mistakes during training.</p>
<ul>
<li><strong>Mitigation:</strong> Techniques like Scheduled Sampling can mitigate this. Scheduled sampling gradually replaces ground truth inputs with the model’s own predictions during training, forcing the model to learn to handle its own errors. Another approach is Dagger (Dataset Aggregation).</li>
</ul></li>
<li><p><strong>Vanishing/Exploding Gradients (for RNNs):</strong> When using RNNs (LSTMs, GRUs) for very long sequences, the gradients can vanish or explode, making it difficult to train the model effectively. This is less of a problem for Transformers due to the attention mechanism and residual connections.</p>
<ul>
<li><strong>Mitigation:</strong> Gradient clipping helps to prevent exploding gradients by scaling the gradients down when they exceed a certain threshold. LSTMs and GRUs were designed to help with vanishing gradients compared to vanilla RNNs. For very long sequences, Transformers are now generally preferred.</li>
</ul></li>
<li><p><strong>Long-Range Dependencies:</strong> While attention mechanisms help, capturing long-range dependencies can still be challenging, especially for extremely long sequences. The attention mechanism needs to correctly identify and weight relevant parts of the input sequence, which can be difficult when the input is very long and complex.</p>
<ul>
<li><strong>Mitigation:</strong> Using Transformers which have a better capacity to capture long-range dependencies because of the self-attention mechanism. Furthermore, techniques such as relative positional encoding can further assist the model to understand the relationship between words regardless of their distance within the input sequence.</li>
</ul></li>
<li><p><strong>Beam Search and Inference Complexity:</strong> During inference, beam search is commonly used to find the most likely output sequence. Beam search explores multiple candidate sequences in parallel, keeping track of the top <span class="math inline">\(k\)</span> most promising sequences at each step. However, beam search can be computationally expensive, especially for large beam sizes (<span class="math inline">\(k\)</span>) and long sequences.</p>
<ul>
<li><strong>Mitigation:</strong> Techniques like length normalization can improve the quality of beam search results by penalizing shorter sequences. Additionally, pruning techniques can be used to reduce the computational cost of beam search by discarding less promising candidates early on. Approximation techniques like greedy decoding can be used to speed up inference, but at the cost of reduced accuracy.</li>
</ul></li>
<li><p><strong>Balancing Encoding and Decoding:</strong> Achieving the right balance between encoding the source context comprehensively and generating fluent, coherent target sequences is crucial. An overly compressed context vector can lose important information, while an overly detailed context vector can make it difficult for the decoder to focus on the essential information. The model has to learn to compress the essential information without losing nuance.</p>
<ul>
<li><strong>Mitigation:</strong> Experimenting with different encoder and decoder architectures, hidden layer sizes, and regularization techniques can help to find the right balance. Analyzing the attention weights can also provide insights into how the model is using the context vector and identify potential areas for improvement.</li>
</ul></li>
<li><p><strong>Computational Cost:</strong> Transformer-based encoder-decoders are computationally expensive to train, especially for very large models and datasets. Training can require significant computational resources and time.</p>
<ul>
<li><strong>Mitigation:</strong> Techniques like model parallelism and data parallelism can be used to distribute the training workload across multiple GPUs or machines. Additionally, techniques like knowledge distillation can be used to train smaller, more efficient models that approximate the performance of larger models. Quantization and pruning can be used to further reduce the size and computational cost of the models.</li>
</ul></li>
</ol>
<p>In summary, the encoder-decoder architecture, especially when augmented with attention mechanisms, provides a powerful framework for machine translation and other sequence-to-sequence tasks. However, it presents unique challenges in training and inference that require careful consideration and mitigation.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with the Core Advantage:</strong> Begin by stating the primary reason why the encoder-decoder is superior: its ability to handle variable-length input and output sequences, which is crucial for machine translation.</p></li>
<li><p><strong>Explain the Basic Architecture (High-Level):</strong> Briefly describe the two main components: the encoder and the decoder. Emphasize that the encoder compresses the input into a context vector, and the decoder expands it into the output. “Think of the encoder as reading the input sentence and summarizing it into a thought vector, and the decoder as taking that thought vector and writing out the translation.”</p></li>
<li><p><strong>Mention the Limitations of Simpler Models:</strong> Contrast the encoder-decoder with simpler RNN architectures. Highlight the inability of standard RNNs to handle varying sequence lengths effectively and their limitations in capturing long-range dependencies.</p></li>
<li><p><strong>Introduce Equations (Judiciously):</strong> Present the key equations, but do so in a digestible way. For example:</p>
<ul>
<li>“The encoder takes the input sequence <span class="math inline">\(x\)</span> and produces a context vector <span class="math inline">\(c\)</span>. We can represent this as <span class="math inline">\(c = f(x_1, x_2, ..., x_T)\)</span>, where <span class="math inline">\(f\)</span> is the encoding function.”</li>
<li>“Similarly, the decoder generates the output sequence <span class="math inline">\(y\)</span> based on the context vector and previously generated words. We can write this as <span class="math inline">\(p(y_t | y_{&lt;t}, c) = g(y_{t-1}, s_t, c)\)</span>.”</li>
<li>“Don’t dive into every detail; the goal is to show you understand the underlying math without overwhelming the interviewer. Mention that ‘f’ and ‘g’ are typically implemented as RNNs or Transformers.”</li>
</ul></li>
<li><p><strong>Discuss the Attention Mechanism:</strong> Explain the importance of the attention mechanism. “The attention mechanism allows the decoder to focus on relevant parts of the input sequence when generating each output word, which significantly improves performance, especially for long sentences.” Present the formula while explaining each element in plain language.</p></li>
<li><p><strong>Address the Challenges (and Solutions):</strong> Spend a significant portion of the time discussing the challenges:</p>
<ul>
<li><strong>Exposure Bias:</strong> “One major challenge is exposure bias. During training, the decoder sees the correct words, but during inference, it has to rely on its own (potentially incorrect) predictions. This can lead to error accumulation.” Briefly mention solutions like scheduled sampling.</li>
<li><strong>Vanishing/Exploding Gradients:</strong> “For RNN-based encoder-decoders, vanishing and exploding gradients can be a problem, especially for long sequences.” Briefly mention gradient clipping and the advantages of LSTMs/GRUs.</li>
<li><strong>Long-Range Dependencies:</strong> “Even with attention, capturing long-range dependencies can be challenging. Transformer-based models help address this.”</li>
<li><strong>Inference Complexity (Beam Search):</strong> “During inference, we often use beam search to find the best output sequence, but this can be computationally expensive.” Briefly mention length normalization and pruning.</li>
</ul></li>
<li><p><strong>Connect to Real-World Considerations:</strong> Emphasize the practical aspects, such as the computational cost of training large Transformer models and the techniques used to mitigate this (model/data parallelism, knowledge distillation).</p></li>
<li><p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush. Allow the interviewer to ask clarifying questions.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you’re in a virtual interview, consider sharing your screen and sketching a simple diagram of the encoder-decoder architecture.</li>
<li><strong>Check for Understanding:</strong> Periodically ask the interviewer if they have any questions or if they’d like you to elaborate on a particular point.</li>
<li><strong>Stay High-Level When Appropriate:</strong> If the interviewer seems less technical, focus on the conceptual understanding rather than the mathematical details.</li>
<li><strong>Be Confident, But Humble:</strong> Project confidence in your knowledge, but acknowledge that the field is constantly evolving and that there’s always more to learn.</li>
</ul></li>
</ol>
<p>By following this approach, you can effectively demonstrate your expertise in encoder-decoder architectures and their application to machine translation. Remember to tailor your response to the specific interests and background of the interviewer.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>