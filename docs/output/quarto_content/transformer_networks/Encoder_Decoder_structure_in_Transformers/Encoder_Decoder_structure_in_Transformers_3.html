<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>encoder_decoder_structure_in_transformers_3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-explain-the-use-of-residual-connections-skip-connections-and-layer-normalization-within-the-architecture.-are-there-differences-in-how-these-mechanisms-are-applied-in-the-encoder-versus-the-decoder" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-explain-the-use-of-residual-connections-skip-connections-and-layer-normalization-within-the-architecture.-are-there-differences-in-how-these-mechanisms-are-applied-in-the-encoder-versus-the-decoder">Question: 4. Explain the use of residual connections (skip connections) and layer normalization within the architecture. Are there differences in how these mechanisms are applied in the encoder versus the decoder?</h2>
<p><strong>Best Answer</strong></p>
<p>Within the Transformer architecture, residual connections (or skip connections) and layer normalization are crucial components that contribute significantly to the model’s trainability and performance. Both mechanisms are applied throughout the encoder and decoder blocks, though subtle differences exist in their precise application.</p>
<p><strong>1. Residual Connections (Skip Connections)</strong></p>
<ul>
<li><p><strong>Concept:</strong> Residual connections, introduced in ResNet, allow the gradient to flow more easily through the network by adding the input of a layer to its output. In other words, instead of directly learning a mapping <span class="math inline">\(H(x)\)</span>, the layer learns a residual function <span class="math inline">\(F(x) = H(x) - x\)</span>. The overall mapping then becomes <span class="math inline">\(H(x) = F(x) + x\)</span>.</p></li>
<li><p><strong>Mathematical Formulation:</strong> Let <span class="math inline">\(x\)</span> be the input to a sub-layer (e.g., a multi-head attention layer or a feed-forward network). The output of the sub-layer, denoted as <span class="math inline">\(Sublayer(x)\)</span>, is then combined with the original input <span class="math inline">\(x\)</span> via a residual connection:</p>
<p><span class="math display">\[
Output = LayerNorm(x + Sublayer(x))
\]</span></p></li>
<li><p><strong>Importance:</strong></p>
<ul>
<li><p><em>Mitigating Vanishing Gradients:</em> In deep networks, gradients can diminish as they propagate backward through many layers, hindering learning, especially in earlier layers. Residual connections provide a direct path for the gradient, ensuring that it doesn’t vanish completely. This addresses the vanishing gradient problem.</p></li>
<li><p><em>Enabling Deeper Networks:</em> By facilitating gradient flow, residual connections allow us to train much deeper networks, which can capture more complex patterns in the data. Without residual connections, training very deep Transformers would be significantly more difficult.</p></li>
<li><p><em>Improving Training Convergence:</em> Skip connections improve the loss landscape, making it smoother and easier to navigate during optimization. They alleviate the problem of optimization getting stuck in local minima or saddle points.</p></li>
</ul></li>
<li><p><strong>Application in Encoder and Decoder:</strong></p>
<ul>
<li>In both the encoder and decoder, residual connections are applied around each sub-layer (multi-head attention and feed-forward networks). This consistent application helps to maintain good gradient flow throughout the entire Transformer model.</li>
</ul></li>
</ul>
<p><strong>2. Layer Normalization</strong></p>
<ul>
<li><p><strong>Concept:</strong> Layer normalization is a technique for normalizing the activations of a layer across its features. Unlike batch normalization, which normalizes across the batch dimension, layer normalization computes the mean and variance for each training example separately.</p></li>
<li><p><strong>Mathematical Formulation:</strong> Given an input <span class="math inline">\(x\)</span> to a layer with <span class="math inline">\(D\)</span> features, the layer normalization is computed as follows:</p>
<ol type="1">
<li><p>Calculate the mean (<span class="math inline">\(\mu\)</span>) and variance (<span class="math inline">\(\sigma^2\)</span>) across the features: <span class="math display">\[
\mu = \frac{1}{D} \sum_{i=1}^{D} x_i
\]</span> <span class="math display">\[
\sigma^2 = \frac{1}{D} \sum_{i=1}^{D} (x_i - \mu)^2
\]</span></p></li>
<li><p>Normalize the input: <span class="math display">\[
\hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
\]</span> where <span class="math inline">\(\epsilon\)</span> is a small constant added for numerical stability.</p></li>
<li><p>Scale and shift the normalized input: <span class="math display">\[
y_i = \gamma \hat{x}_i + \beta
\]</span> where <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\beta\)</span> are learnable parameters (gain and bias), specific to each feature.</p></li>
</ol></li>
<li><p><strong>Importance:</strong></p>
<ul>
<li><p><em>Stabilizing Training:</em> Layer normalization stabilizes the learning process by reducing internal covariate shift, which is the change in the distribution of network activations due to the changing parameters during training.</p></li>
<li><p><em>Faster Convergence:</em> By stabilizing activations, layer normalization allows for the use of higher learning rates, leading to faster convergence.</p></li>
<li><p><em>Improved Generalization:</em> Layer normalization can improve the generalization performance of the model by making it less sensitive to the initial parameter values and the specific mini-batch used during training.</p></li>
</ul></li>
<li><p><strong>Application in Encoder and Decoder:</strong></p>
<ul>
<li><p><em>Encoder:</em> In the encoder, layer normalization is typically applied <em>after</em> the residual connection and sub-layer computation, as shown in the equation above.</p></li>
<li><p><em>Decoder:</em> In the decoder, layer normalization is also applied after the residual connection for both the masked multi-head attention and the encoder-decoder attention. <em>It’s common to see an additional LayerNorm after the entire attention block including the residual connection.</em></p></li>
</ul></li>
</ul>
<p><strong>Differences in Application between Encoder and Decoder</strong></p>
<p>While the fundamental principles of residual connections and layer normalization are the same in the encoder and decoder, there are a few subtle differences in how they are applied:</p>
<ul>
<li><p><strong>Number of Attention Layers:</strong> The decoder has an <em>additional</em> attention sub-layer (encoder-decoder attention) compared to the encoder. This means that the decoder typically has <em>more</em> residual connections and layer normalization layers overall, which can affect the training dynamics.</p></li>
<li><p><strong>Layer Normalization Placement</strong>: Specifically, in the original Transformer paper, the “pre-normalization” version was used, meaning the layer normalization was applied <em>before</em> the attention and feed-forward layers. Subsequent works explored “post-normalization” (applying LayerNorm <em>after</em>), often with variations like applying it before the residual connection. Variations in the exact placement of LayerNorm layers can have subtle effects on performance and stability.</p></li>
<li><p><strong>Causal Masking:</strong> The masked multi-head attention in the decoder requires careful implementation to ensure that the model cannot “see” future tokens. This masking doesn’t directly impact how residual connections or layer normalization are applied, but it is a crucial aspect of the decoder’s functionality.</p></li>
</ul>
<p>In summary, residual connections and layer normalization are essential for training deep Transformer models. They facilitate gradient flow, stabilize learning, and improve generalization. While the basic principles are consistent across the encoder and decoder, the decoder includes an extra attention layer and there may be slight variations in the specific placement of LayerNorm depending on the architecture variant, influencing the training dynamics and overall performance.</p>
<hr>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with a High-Level Overview:</strong>
<ul>
<li>Begin by stating that residual connections and layer normalization are fundamental components in Transformer architectures, crucial for enabling deep and stable training. Briefly mention that both are used in the encoder and decoder but with some nuances.</li>
</ul></li>
<li><strong>Explain Residual Connections:</strong>
<ul>
<li>Define residual connections as “skip connections” that add the input of a layer to its output.</li>
<li>Explain the mathematical intuition: “Instead of learning a direct mapping, the layer learns a residual function, so the overall mapping becomes the residual function plus the original input.” You can show the equation <span class="math inline">\(H(x) = F(x) + x\)</span> here, stating: “Where <span class="math inline">\(H(x)\)</span> is the desired mapping, <span class="math inline">\(F(x)\)</span> is the residual function, and <span class="math inline">\(x\)</span> is the input.”</li>
<li>Highlight the key benefits: mitigating vanishing gradients (allowing deeper networks), improving training convergence, and enabling the training of deeper architectures.</li>
</ul></li>
<li><strong>Explain Layer Normalization:</strong>
<ul>
<li>Describe layer normalization as a technique that normalizes activations across the features of a layer for each training example separately.</li>
<li>You might want to say: “Unlike Batch Normalization, that normalizes across a batch of examples, Layer Normalization works on a per-example basis.”</li>
<li>Mention the steps involved (calculating mean and variance, normalizing, scaling, and shifting). You don’t need to delve into all the equations unless the interviewer specifically asks.</li>
<li>Emphasize the benefits: stabilizing training by reducing internal covariate shift, enabling the use of higher learning rates for faster convergence, and improving generalization.</li>
</ul></li>
<li><strong>Discuss the Application in Encoder and Decoder:</strong>
<ul>
<li>State that both mechanisms are consistently applied in both encoder and decoder blocks, around each sub-layer (attention and feed-forward networks).</li>
<li>Highlight the subtle differences:
<ul>
<li>The decoder has an extra attention layer (encoder-decoder attention), leading to slightly more residual connections and layer normalization layers.</li>
<li>Mention that there are variants to the architecture where LayerNorm is applied before or after the sublayers.</li>
</ul></li>
</ul></li>
<li><strong>Conclude with a Summary:</strong>
<ul>
<li>Reiterate that residual connections and layer normalization are essential for training deep Transformer models, enabling gradient flow, stabilizing learning, and improving generalization. The additional encoder-decoder attention layer in the decoder results in a different structure, but the core benefits of these techniques remain consistent.</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Speak clearly and deliberately.</li>
<li><strong>Use Visual Aids (if available):</strong> If you have a whiteboard, you can draw a simple diagram of a Transformer block showing the residual connections and layer normalization.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask the interviewer if they have any questions or if they would like you to elaborate on a specific point.</li>
<li><strong>Be Prepared to Go Deeper:</strong> The interviewer might ask follow-up questions about the mathematical details, alternative normalization techniques, or the specific implementation details.</li>
<li><strong>Avoid Jargon:</strong> Use technical terms when necessary, but always explain them clearly.</li>
<li><strong>Be Confident:</strong> You are demonstrating senior-level knowledge, so speak with confidence and authority.</li>
<li><strong>Be Adaptable:</strong> Tailor your response to the interviewer’s level of understanding. If they are less familiar with the concepts, provide a more basic explanation. If they are very knowledgeable, you can delve into more advanced details.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>