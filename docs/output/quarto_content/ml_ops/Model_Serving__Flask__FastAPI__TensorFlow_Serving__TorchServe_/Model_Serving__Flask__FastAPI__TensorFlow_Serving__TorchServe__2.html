<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>model_serving__flask__fastapi__tensorflow_serving__torchserve__2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-3.-imagine-you-need-to-deploy-a-real-time-model-with-high-throughput-requirements-using-tensorflow-serving.-describe-an-overall-deployment-architecture-including-strategies-for-scaling-model-versioning-monitoring-and-failover.-how-would-you-mitigate-potential-bottlenecks" class="level2">
<h2 class="anchored" data-anchor-id="question-3.-imagine-you-need-to-deploy-a-real-time-model-with-high-throughput-requirements-using-tensorflow-serving.-describe-an-overall-deployment-architecture-including-strategies-for-scaling-model-versioning-monitoring-and-failover.-how-would-you-mitigate-potential-bottlenecks">Question: 3. Imagine you need to deploy a real-time model with high throughput requirements using TensorFlow Serving. Describe an overall deployment architecture, including strategies for scaling, model versioning, monitoring, and failover. How would you mitigate potential bottlenecks?</h2>
<p><strong>Best Answer</strong></p>
<p>To deploy a real-time model with high throughput requirements using TensorFlow Serving, a robust and scalable architecture is essential. Here’s a comprehensive deployment architecture addressing scaling, model versioning, monitoring, failover, and bottleneck mitigation:</p>
<p><strong>1. Overall Architecture</strong></p>
<p>The proposed architecture is a multi-tiered system designed for high availability, scalability, and maintainability. It leverages containerization and orchestration for efficient resource management and deployment.</p>
<ul>
<li><strong>Client Layer:</strong> This layer represents the applications or services that consume the model’s predictions. Clients send requests to the load balancer.</li>
<li><strong>Load Balancer:</strong> A load balancer (e.g., Nginx, HAProxy, or a cloud-based load balancer like AWS ALB or Google Cloud Load Balancer) distributes incoming traffic across multiple TensorFlow Serving instances. It provides a single point of entry and ensures high availability.</li>
<li><strong>TensorFlow Serving Cluster:</strong> This is the core of the architecture. It consists of multiple instances of TensorFlow Serving, each running in a separate container. Each instance loads one or more model versions.</li>
<li><strong>Container Orchestration (Kubernetes):</strong> Kubernetes manages the deployment, scaling, and health of the TensorFlow Serving containers. It ensures that the desired number of replicas are running and automatically restarts failed containers.</li>
<li><strong>Model Storage:</strong> Models are stored in a centralized location (e.g., Google Cloud Storage, AWS S3, or a Network File System) accessible by all TensorFlow Serving instances. This allows for easy model updates and versioning.</li>
<li><strong>Monitoring and Logging:</strong> A comprehensive monitoring and logging system collects metrics and logs from all components, including the load balancer, TensorFlow Serving instances, and Kubernetes. This data is used to identify performance bottlenecks, detect errors, and track model performance. Tools such as Prometheus, Grafana, Elasticsearch, and Kibana can be utilized.</li>
</ul>
<p><strong>2. Scaling Strategies</strong></p>
<ul>
<li><p><strong>Horizontal Scaling:</strong> The primary scaling strategy is horizontal scaling. Kubernetes automatically adjusts the number of TensorFlow Serving replicas based on resource utilization (CPU, memory) and request load. The Horizontal Pod Autoscaler (HPA) in Kubernetes enables this. We can define target CPU utilization or custom metrics (e.g., requests per second) to trigger scaling events. The HPA controller adjusts the number of pods to maintain the desired utilization level.</p>
<p>Let <span class="math inline">\(N\)</span> be the number of replicas, <span class="math inline">\(R\)</span> be the request rate, and <span class="math inline">\(C\)</span> be the capacity of a single instance. We aim to maintain:</p>
<p><span class="math display">\[R \le N \cdot C\]</span> The HPA dynamically adjusts <span class="math inline">\(N\)</span> to satisfy this condition.</p></li>
<li><p><strong>Vertical Scaling:</strong> Increasing the resources (CPU, memory) allocated to each TensorFlow Serving instance. This can be useful for handling larger models or more complex computations but has limitations as each machine has an upper limit.</p></li>
<li><p><strong>Model Sharding:</strong> If a single model is too large to fit into the memory of a single instance, model sharding can be used. This involves splitting the model into multiple parts and distributing them across multiple instances. Each instance handles a subset of the input data.</p></li>
<li><p><strong>Geographic Scaling:</strong> Deploying the TensorFlow Serving cluster in multiple geographic regions to reduce latency for users in different locations. A global load balancer (e.g., AWS Route 53 or Google Cloud DNS) can route traffic to the closest region.</p></li>
</ul>
<p><strong>3. Model Versioning</strong></p>
<ul>
<li><p><strong>Versioning Scheme:</strong> Implement a consistent versioning scheme for models (e.g., semantic versioning). This allows for easy tracking of model changes and rollbacks.</p></li>
<li><p><strong>Serving Multiple Versions:</strong> TensorFlow Serving supports serving multiple versions of the same model simultaneously. This allows for A/B testing, canary deployments, and seamless rollouts.</p></li>
<li><p><strong>Deployment Strategies:</strong></p>
<ul>
<li><strong>Canary Deployment:</strong> Route a small percentage of traffic to the new model version while the majority of traffic continues to be served by the old version. Monitor the performance of the new version closely and roll it back if any issues are detected.</li>
<li><strong>Blue-Green Deployment:</strong> Deploy the new model version in a separate environment (the “blue” environment). Test the new version thoroughly and then switch all traffic to the new version (the “green” environment). This minimizes downtime and provides a quick rollback mechanism.</li>
</ul></li>
</ul>
<p><strong>4. Monitoring</strong></p>
<ul>
<li><strong>Resource Monitoring:</strong> Monitor CPU utilization, memory usage, network I/O, and disk I/O for all components. This helps identify resource bottlenecks.</li>
<li><strong>Request Monitoring:</strong> Track the request rate, latency, and error rate. This provides insights into the overall performance of the system.</li>
<li><strong>Model Performance Monitoring:</strong> Monitor the accuracy and other relevant metrics of the model. This helps detect model drift and degradation. Techniques such as shadow deployment or mirroring production traffic can be useful here.</li>
</ul>
<p><strong>Key metrics:</strong></p>
<ul>
<li><strong>Latency (<span class="math inline">\(L\)</span>):</strong> Time taken to process a request. Monitor the average, P50, P90, and P99 latencies.</li>
<li><strong>Throughput (<span class="math inline">\(T\)</span>):</strong> Number of requests processed per second.</li>
<li><strong>Error Rate (<span class="math inline">\(E\)</span>):</strong> Percentage of requests that result in an error.</li>
</ul>
<p><strong>5. Failover</strong></p>
<ul>
<li><strong>Redundancy:</strong> Ensure that all components are deployed with redundancy. This means running multiple instances of each component.</li>
<li><strong>Health Checks:</strong> Implement health checks for all components. Kubernetes uses health checks to automatically restart failed containers.</li>
<li><strong>Automatic Failover:</strong> Configure the load balancer to automatically failover to healthy instances if any instances become unhealthy.</li>
<li><strong>Disaster Recovery:</strong> Implement a disaster recovery plan that includes backing up models and data and replicating the infrastructure in a separate geographic region.</li>
</ul>
<p><strong>6. Mitigating Potential Bottlenecks</strong></p>
<ul>
<li><strong>Network Bottlenecks:</strong>
<ul>
<li><strong>Compression:</strong> Compress requests and responses to reduce network bandwidth usage. Using techniques like gzip or Brotli can significantly reduce the size of the data being transmitted.</li>
<li><strong>Caching:</strong> Cache frequently accessed data to reduce the load on the TensorFlow Serving instances. A caching layer (e.g., Redis or Memcached) can be added in front of the TensorFlow Serving cluster.</li>
<li><strong>Optimize Network Configuration:</strong> Ensure that the network is properly configured to handle the expected traffic load. This includes using appropriate network interfaces and configuring network routing.</li>
</ul></li>
<li><strong>CPU Bottlenecks:</strong>
<ul>
<li><strong>Batching:</strong> Process multiple requests in a single batch to reduce overhead. TensorFlow Serving supports batching.</li>
<li><strong>Model Optimization:</strong> Optimize the model for inference. This includes using techniques such as quantization, pruning, and knowledge distillation.</li>
<li><strong>Hardware Acceleration:</strong> Utilize hardware acceleration, such as GPUs or TPUs, to speed up inference.</li>
</ul></li>
<li><strong>Memory Bottlenecks:</strong>
<ul>
<li><strong>Model Optimization:</strong> Reduce the size of the model by using techniques such as quantization or pruning.</li>
<li><strong>Memory Profiling:</strong> Profile the memory usage of the TensorFlow Serving instances to identify memory leaks or inefficient memory usage.</li>
</ul></li>
<li><strong>I/O Bottlenecks:</strong>
<ul>
<li><strong>Caching:</strong> Cache frequently accessed data to reduce the load on the storage system.</li>
<li><strong>Optimize Storage System:</strong> Use a high-performance storage system, such as SSDs, to reduce I/O latency.</li>
<li><strong>Prefetching:</strong> Prefetch data into memory before it is needed to reduce latency.</li>
</ul></li>
<li><strong>TensorFlow Serving Configuration:</strong>
<ul>
<li><strong>Optimize TensorFlow Serving Configuration:</strong> Tune TensorFlow Serving configuration parameters, such as the number of threads, the batch size, and the model loading strategy, to optimize performance.</li>
</ul></li>
<li><strong>Profiling and Tracing:</strong> Utilize profiling and tracing tools to identify performance bottlenecks in the TensorFlow Serving code. TensorFlow Profiler and tracing tools like Jaeger or Zipkin can be helpful.</li>
</ul>
<p><strong>7. Example Kubernetes Configuration (Illustrative)</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> apps/v1</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> Deployment</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">replicas</span><span class="kw">:</span><span class="at"> </span><span class="dv">3</span><span class="co">  # Start with 3 replicas</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">selector</span><span class="kw">:</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">matchLabels</span><span class="kw">:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">app</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">template</span><span class="kw">:</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">labels</span><span class="kw">:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">app</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">containers</span><span class="kw">:</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">image</span><span class="kw">:</span><span class="at"> tensorflow/serving:latest</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">args</span><span class="kw">:</span><span class="at"> </span><span class="kw">[</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="st">"--port=8500"</span><span class="kw">,</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="st">"--rest_api_port=8501"</span><span class="kw">,</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="st">"--model_name=my_model"</span><span class="kw">,</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="st">"--model_base_path=/models/my_model"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">]</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">ports</span><span class="kw">:</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">containerPort</span><span class="kw">:</span><span class="at"> </span><span class="dv">8500</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">containerPort</span><span class="kw">:</span><span class="at"> </span><span class="dv">8501</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">volumeMounts</span><span class="kw">:</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> model-volume</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="fu">mountPath</span><span class="kw">:</span><span class="at"> /models/my_model</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">volumes</span><span class="kw">:</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="kw">-</span><span class="at"> </span><span class="fu">name</span><span class="kw">:</span><span class="at"> model-volume</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">persistentVolumeClaim</span><span class="kw">:</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="at">          </span><span class="fu">claimName</span><span class="kw">:</span><span class="at"> model-pvc</span><span class="co">  # Persistent Volume Claim to access model storage</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> v1</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> Service</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> tf-serving-service</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">selector</span><span class="kw">:</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">app</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">ports</span><span class="kw">:</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">protocol</span><span class="kw">:</span><span class="at"> TCP</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">port</span><span class="kw">:</span><span class="at"> </span><span class="dv">8500</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">targetPort</span><span class="kw">:</span><span class="at"> </span><span class="dv">8500</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">type</span><span class="kw">:</span><span class="at"> LoadBalancer</span><span class="co">  # Or NodePort if using an external load balancer</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> autoscaling/v2beta2</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="fu">kind</span><span class="kw">:</span><span class="at"> HorizontalPodAutoscaler</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="fu">metadata</span><span class="kw">:</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">name</span><span class="kw">:</span><span class="at"> tf-serving-hpa</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="fu">spec</span><span class="kw">:</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">scaleTargetRef</span><span class="kw">:</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">apiVersion</span><span class="kw">:</span><span class="at"> apps/v1</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">kind</span><span class="kw">:</span><span class="at"> Deployment</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">name</span><span class="kw">:</span><span class="at"> tf-serving</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">minReplicas</span><span class="kw">:</span><span class="at"> </span><span class="dv">3</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">maxReplicas</span><span class="kw">:</span><span class="at"> </span><span class="dv">10</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">metrics</span><span class="kw">:</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">type</span><span class="kw">:</span><span class="at"> Resource</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="at">    </span><span class="fu">resource</span><span class="kw">:</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">name</span><span class="kw">:</span><span class="at"> cpu</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="at">      </span><span class="fu">target</span><span class="kw">:</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">type</span><span class="kw">:</span><span class="at"> Utilization</span></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">averageUtilization</span><span class="kw">:</span><span class="at"> </span><span class="dv">70</span><span class="co">  # Scale when CPU utilization exceeds 70%</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>8. Real-World Considerations and Corner Cases</strong></p>
<ul>
<li><strong>Model Size:</strong> Large models require significant memory and can impact startup time. Techniques like model quantization or sharding may be necessary.</li>
<li><strong>Dynamic Batching:</strong> While batching improves throughput, it can increase latency. The batch size needs to be tuned carefully to balance throughput and latency.</li>
<li><strong>Cold Starts:</strong> The first request after a TensorFlow Serving instance starts can be slow due to model loading. Consider using warm-up requests to pre-load the model into memory.</li>
<li><strong>Model Updates:</strong> Model updates can cause downtime. Using techniques like blue-green deployments or canary deployments can minimize downtime.</li>
<li><strong>Security:</strong> Secure the TensorFlow Serving cluster by using authentication and authorization mechanisms. Consider using TLS encryption for all communication.</li>
<li><strong>Data Preprocessing:</strong> Preprocessing data before sending it to the model can improve performance. However, it can also add latency. Consider performing preprocessing on the client side or using a separate preprocessing service.</li>
<li><strong>Explainability:</strong> Consider incorporating explainability techniques to understand why the model is making certain predictions. This can be useful for debugging and improving the model.</li>
<li><strong>Bias Detection:</strong> Implement bias detection techniques to identify and mitigate bias in the model. This is important for ensuring that the model is fair and equitable.</li>
</ul>
<p>This comprehensive architecture provides a foundation for deploying a real-time model with high throughput requirements using TensorFlow Serving. By carefully considering the scaling, model versioning, monitoring, failover, and bottleneck mitigation strategies, you can build a robust and scalable system that meets the needs of your application.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested approach for explaining this architecture in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Big Picture (30 seconds):</strong></p>
<ul>
<li>“To deploy a real-time model with high throughput using TensorFlow Serving, I would propose a multi-tiered architecture focused on scalability, availability, and maintainability.”</li>
<li>“This architecture leverages containerization (Docker) and orchestration (Kubernetes) to manage and scale the deployment effectively.”</li>
<li>“The goal is to design a system that can handle a high volume of requests with low latency while being resilient to failures.”</li>
</ul></li>
<li><p><strong>Explain the Architecture Layers (2 minutes):</strong></p>
<ul>
<li>“The architecture consists of several key layers. Starting from the outside…”</li>
<li>“First, we have the <em>Client Layer</em>, representing the applications that consume the model’s predictions. These clients send requests to a <em>Load Balancer</em>.”</li>
<li>“The <em>Load Balancer</em> (like Nginx or a cloud-based load balancer) distributes traffic across multiple <em>TensorFlow Serving instances</em>, ensuring high availability and preventing any single instance from being overwhelmed.”</li>
<li>“The <em>TensorFlow Serving Cluster</em> is the core, with each instance running in a Docker container managed by <em>Kubernetes</em>.”</li>
<li>“Kubernetes handles the deployment, scaling, and health of the containers. It ensures the desired number of replicas are running.”</li>
<li>“All model files reside in <em>Model Storage</em> (like Google Cloud Storage or S3). This centralized location allows for easy versioning and updates.”</li>
<li>“Finally, <em>Monitoring and Logging</em> is crucial. We collect metrics and logs from all components for performance analysis and troubleshooting, using tools like Prometheus, Grafana, and Elasticsearch.”</li>
</ul></li>
<li><p><strong>Dive into Scaling (2 minutes):</strong></p>
<ul>
<li>“The primary scaling strategy is <em>horizontal scaling</em>. Kubernetes automatically adjusts the number of TensorFlow Serving replicas using the Horizontal Pod Autoscaler (HPA).”</li>
<li>“The HPA monitors resource utilization (CPU, memory) and request load. We can define target CPU utilization or custom metrics like requests per second to trigger scaling.”</li>
<li>“Mathematically, we aim to maintain <span class="math inline">\(R \le N \cdot C\)</span>, where <span class="math inline">\(R\)</span> is the request rate, <span class="math inline">\(N\)</span> is the number of replicas, and <span class="math inline">\(C\)</span> is the capacity of a single instance. The HPA dynamically adjusts <span class="math inline">\(N\)</span>.”</li>
<li>“While less frequent, we could also consider <em>vertical scaling</em> - increasing resources per instance. Model sharding can be used if a model is too large for a single instance.”</li>
</ul></li>
<li><p><strong>Discuss Model Versioning (1.5 minutes):</strong></p>
<ul>
<li>“We need a consistent <em>versioning scheme</em> for our models to track changes and allow rollbacks. Something like semantic versioning would be ideal.”</li>
<li>“TensorFlow Serving allows us to serve <em>multiple versions</em> simultaneously, enabling A/B testing and canary deployments.”</li>
<li>“For deployments, I’d recommend <em>canary deployments</em> or <em>blue-green deployments</em>. Canary deployments route a small percentage of traffic to the new version, while blue-green deployments switch all traffic after thorough testing.”</li>
</ul></li>
<li><p><strong>Highlight Monitoring and Failover (1.5 minutes):</strong></p>
<ul>
<li>“Comprehensive <em>monitoring</em> is critical. We need to track resource utilization, request performance (rate, latency, error rate), and model performance (accuracy, drift).”</li>
<li>“Key metrics include latency (<span class="math inline">\(L\)</span>), throughput (<span class="math inline">\(T\)</span>), and error rate (<span class="math inline">\(E\)</span>).”</li>
<li>“For <em>failover</em>, we ensure redundancy by running multiple instances of each component. Kubernetes health checks automatically restart failed containers, and the load balancer automatically fails over to healthy instances.”</li>
</ul></li>
<li><p><strong>Address Bottlenecks (2 minutes):</strong></p>
<ul>
<li>“Potential bottlenecks can occur in the network, CPU, memory, or I/O.”</li>
<li>“To mitigate <em>network bottlenecks</em>, we can use compression (gzip, Brotli) and caching.”</li>
<li>“For <em>CPU bottlenecks</em>, we can use batching, model optimization (quantization, pruning), and hardware acceleration (GPUs, TPUs).”</li>
<li>“To address <em>memory bottlenecks</em>, we can reduce the model size or use memory profiling to find inefficiencies.”</li>
<li>“For <em>I/O bottlenecks</em>, caching and using high-performance storage are essential.”</li>
<li>“TensorFlow Serving provides its own configuration parameters that also help.”</li>
<li>“Profiling and tracing tools can help to identify hotspots in the application.”</li>
</ul></li>
<li><p><strong>Discuss Real-World Considerations (1 minute):</strong></p>
<ul>
<li>“Finally, some real-world considerations include large model sizes impacting startup time, dynamic batching impacting latency, cold starts, model updates causing downtime, and ensuring security through authentication and encryption.”</li>
</ul></li>
<li><p><strong>Interact with the interviewer:</strong></p>
<ul>
<li>“Does this architecture make sense? Are there any specific areas you would like me to elaborate on?”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation.</li>
<li><strong>Use visuals if possible:</strong> If you are in a virtual interview, consider sharing a diagram of the architecture. If in-person, ask if you can sketch a simple diagram.</li>
<li><strong>Check for understanding:</strong> Pause periodically to ask if the interviewer has any questions.</li>
<li><strong>Focus on the key concepts:</strong> Don’t get bogged down in the details. Focus on the overall architecture and the key strategies for scaling, model versioning, monitoring, and failover.</li>
<li><strong>Be prepared to answer follow-up questions:</strong> The interviewer may ask you to elaborate on specific aspects of the architecture.</li>
<li><strong>Be confident:</strong> You have a solid understanding of the architecture. Project confidence in your answer.</li>
<li><strong>Mathematical notations:</strong> When presenting equations like <span class="math inline">\(R \le N \cdot C\)</span>, briefly explain the variables and their relevance to the concept. Avoid overwhelming the interviewer with complex derivations unless specifically asked.</li>
<li><strong>Tailor the depth:</strong> Adjust the level of detail based on the interviewer’s expertise and the flow of the conversation. If they seem particularly interested in one area, spend more time on it.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>