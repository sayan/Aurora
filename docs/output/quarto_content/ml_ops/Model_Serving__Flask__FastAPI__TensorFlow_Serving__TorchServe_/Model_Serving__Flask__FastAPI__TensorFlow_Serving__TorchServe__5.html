<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>model_serving__flask__fastapi__tensorflow_serving__torchserve__5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-6.-torchserve-allows-for-customization-in-model-serving-workflows.-explain-the-process-of-deploying-a-pytorch-model-with-torchserve-detailing-how-you-would-integrate-custom-pre-processing-and-post-processing-logic-within-the-serving-pipeline." class="level2">
<h2 class="anchored" data-anchor-id="question-6.-torchserve-allows-for-customization-in-model-serving-workflows.-explain-the-process-of-deploying-a-pytorch-model-with-torchserve-detailing-how-you-would-integrate-custom-pre-processing-and-post-processing-logic-within-the-serving-pipeline.">Question: 6. TorchServe allows for customization in model serving workflows. Explain the process of deploying a PyTorch model with TorchServe, detailing how you would integrate custom pre-processing and post-processing logic within the serving pipeline.</h2>
<p><strong>Best Answer</strong></p>
<p>TorchServe is a flexible and scalable model serving framework for PyTorch. Deploying a PyTorch model with custom pre-processing and post-processing logic involves several steps: creating a model archive (MAR) file, defining a custom handler, and configuring the serving pipeline.</p>
<p><strong>1. Understanding the Model Archive (MAR) File</strong></p>
<p>The MAR file is a ZIP archive that contains all the necessary components for serving a model:</p>
<ul>
<li><strong>Model Definition:</strong> The PyTorch model’s <code>.pth</code> or <code>.pt</code> file containing the serialized model.</li>
<li><strong>Handler:</strong> A Python file (<code>.py</code>) that defines the pre-processing, inference, and post-processing logic. This is <em>the</em> key component for customization.</li>
<li><strong>Extra Files (Optional):</strong> Any additional files required by the handler, such as vocabulary files, configuration files, or serialized data transforms.</li>
<li><strong><code>model-config.yaml</code>:</strong> A configuration file that specifies the model name, handler script, batching parameters, and other serving-related configurations.</li>
</ul>
<p><strong>2. Implementing a Custom Handler</strong></p>
<p>The custom handler is the heart of the customization. It’s a Python class that inherits from <code>torchserve.handler.ModelHandler</code> (or <code>torchserve.handler.BaseHandler</code>) and overrides specific methods to implement the desired pre-processing, inference, and post-processing steps. A basic handler structure looks like this:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ts.torch_handler.base_handler <span class="im">import</span> BaseHandler</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomHandler(BaseHandler):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initialized <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> initialize(<span class="va">self</span>, context):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Load model and other artifacts.</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.manifest <span class="op">=</span> context.manifest</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        properties <span class="op">=</span> context.system_properties</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        model_dir <span class="op">=</span> properties.get(<span class="st">"model_dir"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> torch.device(<span class="st">"cuda:"</span> <span class="op">+</span> <span class="bu">str</span>(properties.get(<span class="st">"gpu_id"</span>)) <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Read model serialize/pt file directly</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> torch.jit.load(os.path.join(model_dir, <span class="st">"your_model.pt"</span>)) <span class="co"># Or torch.load for eager mode models</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.to(<span class="va">self</span>.device)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.<span class="bu">eval</span>()</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initialized <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> preprocess(<span class="va">self</span>, data):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Transform raw input to tensor.</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract data from request</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> data[<span class="dv">0</span>].get(<span class="st">"data"</span>) <span class="kw">or</span> data[<span class="dv">0</span>].get(<span class="st">"body"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Preprocessing logic (e.g., image decoding, resizing, normalization)</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(image))</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> <span class="va">self</span>.transform(img)  <span class="co"># Assuming self.transform is a torchvision.transform</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> img.unsqueeze(<span class="dv">0</span>).to(<span class="va">self</span>.device)  <span class="co"># Add batch dimension and move to device</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> inference(<span class="va">self</span>, data, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co">        Predict the class of the image.</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inference logic</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> <span class="va">self</span>.model(data)  <span class="co"># data is the preprocessed input</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> postprocess(<span class="va">self</span>, output):</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">        Transform the model output to a response.</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Post-processing logic (e.g., softmax, class label mapping)</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> torch.nn.functional.softmax(output[<span class="dv">0</span>], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        predicted_idx <span class="op">=</span> torch.argmax(probabilities).item()</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [ {<span class="st">"class_name"</span>: <span class="va">self</span>.labels[predicted_idx], <span class="st">"probability"</span>: probabilities[predicted_idx].item()} ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><strong><code>initialize(self, context)</code>:</strong> This method is called when the model is loaded. It’s used to load the model, vocabulary files, or any other necessary artifacts. The <code>context</code> object provides access to system properties (e.g., model directory, GPU ID) and the model manifest.</li>
<li><strong><code>preprocess(self, data)</code>:</strong> This method takes the raw input data (usually a list of dictionaries) from the client request and transforms it into a format suitable for the model. This might involve image decoding, resizing, normalization, tokenization, or any other data preparation steps.</li>
<li><strong><code>inference(self, data)</code>:</strong> This method performs the actual inference using the loaded model. It receives the pre-processed data as input and returns the model’s output.</li>
<li><strong><code>postprocess(self, output)</code>:</strong> This method takes the model’s output and transforms it into a format suitable for the client. This might involve applying a softmax function, mapping predicted indices to class labels, or generating a JSON response.</li>
</ul>
<p><strong>3. Configuring <code>model-config.yaml</code></strong></p>
<p>The <code>model-config.yaml</code> file tells TorchServe how to load and serve the model. A minimal example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modelName</span><span class="kw">:</span><span class="at"> my_model</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">modelVersion</span><span class="kw">:</span><span class="at"> </span><span class="st">"1.0"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">handler</span><span class="kw">:</span><span class="at"> my_handler:MyCustomHandler</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">description</span><span class="kw">:</span><span class="at"> </span><span class="st">"My custom model serving example"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">engine</span><span class="kw">:</span><span class="at"> PyTorch</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="fu">gpu</span><span class="kw">:</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">memory_utilization</span><span class="kw">:</span><span class="at"> </span><span class="fl">0.8</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">batching</span><span class="kw">:</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">maxBatchDelay</span><span class="kw">:</span><span class="at"> </span><span class="dv">100</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="fu">maxBatchSize</span><span class="kw">:</span><span class="at"> </span><span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Key configuration parameters:</p>
<ul>
<li><strong><code>modelName</code>:</strong> A unique name for the model.</li>
<li><strong><code>modelVersion</code>:</strong> The model’s version.</li>
<li><strong><code>handler</code>:</strong> Specifies the handler to use. The format is <code>module_name:ClassName</code>. Crucially, this is where you point to your custom handler.</li>
<li><strong><code>engine</code>:</strong> Specifies the inference engine. Commonly <code>PyTorch</code> but other options exist.</li>
<li><strong><code>gpu</code>:</strong> Specifies GPU related configurations.</li>
<li><strong><code>batching</code>:</strong> Configures batch inference settings.</li>
</ul>
<p><strong>4. Creating the MAR File</strong></p>
<p>Once you have the model, handler, and configuration file, you can create the MAR file using the <code>torch-model-archiver</code> tool:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torch-model-archiver</span> <span class="at">--model-name</span> my_model <span class="at">--version</span> 1.0 <span class="at">--model-file</span> model.pt <span class="at">--handler</span> custom_handler.py <span class="at">--config-file</span> model-config.yaml <span class="at">--export-path</span> . <span class="at">--force</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>--model-name</code>: The name of the model.</li>
<li><code>--version</code>: The model’s version.</li>
<li><code>--model-file</code>: Path to the serialized model file (.pt or .pth).</li>
<li><code>--handler</code>: Path to the custom handler script.</li>
<li><code>--config-file</code>: Path to the <code>model-config.yaml</code> file.</li>
<li><code>--export-path</code>: The directory where the MAR file will be created.</li>
<li><code>--force</code>: Overwrite existing MAR files.</li>
</ul>
<p><strong>5. Starting TorchServe</strong></p>
<p>Finally, start TorchServe using the <code>torchserve</code> command:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">torchserve</span> <span class="at">--start</span> <span class="at">--model-store</span> . <span class="at">--models</span> my_model=my_model.mar <span class="at">--ncs</span> <span class="at">--ts-config</span> ./config.properties</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>--start</code>: Start the TorchServe server.</li>
<li><code>--model-store</code>: The directory containing the MAR files.</li>
<li><code>--models</code>: Specifies which models to load. The format is <code>model_name=mar_file_name</code>.</li>
<li><code>--ncs</code>: Disable metrics reporting.</li>
<li><code>--ts-config</code>: Configuration for the TorchServe cluster (e.g., number of workers)</li>
</ul>
<p><strong>6. Performance Considerations and Error Handling</strong></p>
<ul>
<li><strong>Batching:</strong> Implement batch processing in the <code>preprocess</code>, <code>inference</code>, and <code>postprocess</code> methods to improve throughput.</li>
<li><strong>Asynchronous Operations:</strong> Use asynchronous operations (e.g., <code>asyncio</code>) for I/O-bound tasks in the handler.</li>
<li><strong>GPU Utilization:</strong> Optimize GPU memory usage by moving data to the GPU only when necessary and releasing memory after use.</li>
<li><strong>Logging:</strong> Use the <code>logging</code> module to log errors and debugging information.</li>
<li><strong>Exception Handling:</strong> Implement robust exception handling in the handler to prevent crashes and provide informative error messages to clients. Handle exceptions gracefully in the <code>preprocess</code>, <code>inference</code>, and <code>postprocess</code> functions.</li>
<li><strong>Input Validation:</strong> Validate the input data in the <code>preprocess</code> method to ensure it conforms to the expected format and range.</li>
<li><strong>Model Monitoring:</strong> Implement model monitoring to track performance metrics such as latency, throughput, and error rate.</li>
</ul>
<p><strong>7. Advanced Customization</strong></p>
<ul>
<li><strong>Custom Metrics:</strong> Define custom metrics to track specific aspects of the model’s performance.</li>
<li><strong>Model Versioning:</strong> Use model versioning to manage different versions of the model and handler.</li>
<li><strong>Dynamic Batching:</strong> Implement dynamic batching to adjust the batch size based on the workload.</li>
<li><strong>Ensemble Models:</strong> Serve ensemble models by combining multiple models in the handler.</li>
</ul>
<p>By following these steps, you can deploy PyTorch models with custom pre-processing and post-processing logic using TorchServe, ensuring a flexible and scalable serving pipeline.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to deliver this answer in an interview, keeping it clear and engaging:</p>
<ol type="1">
<li><p><strong>Start with a high-level overview:</strong> “TorchServe provides a powerful and customizable way to serve PyTorch models. The key to integrating custom logic lies in crafting a custom handler that manages pre-processing, inference, and post-processing.”</p></li>
<li><p><strong>Explain the MAR file:</strong> “The first crucial concept is the Model Archive, or MAR, file. This is essentially a ZIP file that packages your model, your custom handler script, any necessary configuration files, and other assets into a single deployable unit.”</p></li>
<li><p><strong>Focus on the Custom Handler:</strong> “The heart of customization is the custom handler. This is a Python class where you define the <code>preprocess</code>, <code>inference</code>, and <code>postprocess</code> methods. The <code>initialize</code> method handles model loading.” Then, walk through each of these methods, and can offer code snippets for each of these methods.</p></li>
<li><p><strong>Configuration with <code>model-config.yaml</code>:</strong> “The <code>model-config.yaml</code> file tells TorchServe <em>how</em> to use your model. You specify the model name, version, and, importantly, the handler you’ve created. The <code>handler</code> entry points to your custom handler script and class.” Explain the other parameters briefly, focusing on their role.</p></li>
<li><p><strong>MAR File Creation:</strong> “The <code>torch-model-archiver</code> tool bundles everything into the MAR file. You provide the model file, handler script, and configuration, and it creates the archive.” Show example command line usage and briefly explain the parameters.</p></li>
<li><p><strong>Starting TorchServe:</strong> “Finally, you start TorchServe, pointing it to your model store and specifying the model to load from the MAR file.” Include the command-line example.</p></li>
<li><p><strong>Performance and Error Handling:</strong> “Performance is critical. I’d implement batching, consider asynchronous operations for I/O, and optimize GPU utilization. Robust error handling is also essential for production deployments.”</p></li>
<li><p><strong>Advanced Customization (If time allows):</strong> “For more complex scenarios, TorchServe supports custom metrics, model versioning, dynamic batching, and even serving ensemble models.” Briefly mention these to showcase advanced knowledge.</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Give the interviewer time to absorb the information.</li>
<li><strong>Use visuals (if possible):</strong> If you are in a virtual interview and are able to share your screen, consider showing a simple diagram of the serving pipeline or a code snippet of the handler.</li>
<li><strong>Check for understanding:</strong> Ask the interviewer if they have any questions at each step.</li>
<li><strong>Focus on the “why”:</strong> Explain <em>why</em> each step is necessary and how it contributes to the overall goal of deploying a custom model serving pipeline.</li>
<li><strong>Tailor to the audience:</strong> If the interviewer is less technical, focus on the high-level concepts and avoid getting bogged down in the details. If they are more technical, you can delve deeper into the implementation aspects.</li>
<li><strong>Don’t be afraid to say “I don’t know”:</strong> If you are asked a question you don’t know the answer to, it’s better to be honest than to try to fake it. You can say something like, “That’s a good question. I’m not sure of the answer, but I would research it by…” (and then describe your research process).</li>
<li><strong>Mathematical Sections:</strong> When explaining equations, say, “This equation describes…”, then walk through the components. Keep it conceptual unless asked for detail. For longer equations, break them into logical parts. For example “The left side represents X, and the right side can be split into two terms: A and B.”</li>
</ul>
<p>By following these guidelines, you can effectively demonstrate your expertise in deploying PyTorch models with custom logic using TorchServe.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>