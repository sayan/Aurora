<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ml_pipelines__airflow__kubeflow__0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-1.-what-is-the-role-of-ml-pipelines-in-production-machine-learning-systems-and-why-are-tools-like-airflow-and-kubeflow-critical-for-managing-these-pipelines" class="level2">
<h2 class="anchored" data-anchor-id="question-1.-what-is-the-role-of-ml-pipelines-in-production-machine-learning-systems-and-why-are-tools-like-airflow-and-kubeflow-critical-for-managing-these-pipelines">Question: 1. What is the role of ML pipelines in production machine learning systems, and why are tools like Airflow and Kubeflow critical for managing these pipelines?</h2>
<p><strong>Best Answer</strong></p>
<p>Machine Learning (ML) pipelines are the backbone of production ML systems. They represent a structured and automated workflow that streamlines the entire ML lifecycle, from data ingestion to model deployment and monitoring. The core function is to transform a raw dataset into a valuable, deployable model, ready to serve predictions or insights.</p>
<p>Here’s a breakdown of their role and the importance of tools like Airflow and Kubeflow:</p>
<p><strong>1. Defining ML Pipelines:</strong></p>
<p>An ML pipeline is a sequence of interconnected components, each performing a specific task. These components typically include:</p>
<ul>
<li><p><strong>Data Ingestion:</strong> Extracting data from various sources (databases, cloud storage, APIs, etc.).</p></li>
<li><p><strong>Data Validation:</strong> Ensuring data quality and consistency through schema validation, anomaly detection, and data type checks. This is crucial to prevent issues downstream.</p></li>
<li><p><strong>Data Preprocessing:</strong> Cleaning, transforming, and preparing the data for model training. This may involve handling missing values, feature scaling (e.g., standardization, min-max scaling), feature engineering, and encoding categorical variables. Common techniques include:</p>
<ul>
<li><strong>Standardization:</strong> Scaling features to have zero mean and unit variance. <span class="math display">\[
x_{scaled} = \frac{x - \mu}{\sigma}
\]</span> where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
<li><strong>Min-Max Scaling:</strong> Scaling features to a specific range (e.g., [0, 1]). <span class="math display">\[
x_{scaled} = \frac{x - x_{min}}{x_{max} - x_{min}}
\]</span></li>
<li><strong>Handling Categorical Variables:</strong> One-Hot Encoding or Embedding Layers</li>
</ul></li>
<li><p><strong>Feature Selection/Extraction:</strong> Selecting the most relevant features or creating new features from existing ones to improve model performance and reduce dimensionality.</p></li>
<li><p><strong>Model Training:</strong> Training ML models using the preprocessed data. This often involves hyperparameter tuning using techniques like Grid Search, Random Search, or Bayesian Optimization. For example, optimization algorithms use gradient descent:</p>
<pre><code>$$
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t)
$$

where $\theta$ represents the model parameters, $\eta$ is the learning rate, and $\nabla J(\theta_t)$ is the gradient of the loss function $J$ with respect to the parameters.</code></pre></li>
<li><p><strong>Model Evaluation:</strong> Evaluating the trained model’s performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score, AUC) on a held-out dataset.</p></li>
<li><p><strong>Model Validation:</strong> Assess if model is ready for production or needs further tuning.</p></li>
<li><p><strong>Model Deployment:</strong> Deploying the trained model to a production environment (e.g., web server, cloud platform) where it can serve predictions.</p></li>
<li><p><strong>Model Monitoring:</strong> Continuously monitoring the model’s performance and data quality in production to detect and address issues like model drift.</p></li>
</ul>
<p><strong>2. Why ML Pipelines are Critical:</strong></p>
<ul>
<li><strong>Automation:</strong> Pipelines automate the entire ML workflow, reducing manual intervention and the risk of errors.</li>
<li><strong>Reproducibility:</strong> Pipelines ensure that the same data and code will always produce the same model, enabling reproducibility and facilitating debugging. By versioning each step, a pipeline offers complete traceability of how a model was built.</li>
<li><strong>Scalability:</strong> Pipelines can be scaled to handle large datasets and complex models, enabling efficient training and deployment.</li>
<li><strong>Maintainability:</strong> Pipelines provide a modular and well-defined structure, making it easier to maintain, update, and debug ML systems.</li>
<li><strong>Collaboration:</strong> Pipelines facilitate collaboration among data scientists, engineers, and other stakeholders by providing a shared understanding of the ML workflow.</li>
<li><strong>Efficiency:</strong> By automating processes and optimizing resource utilization, pipelines improve the overall efficiency of ML projects.</li>
</ul>
<p><strong>3. Role of Airflow and Kubeflow:</strong></p>
<p>Airflow and Kubeflow are workflow management platforms that are specifically designed to address the challenges of building and managing ML pipelines at scale.</p>
<ul>
<li><p><strong>Apache Airflow:</strong> Airflow is a platform for programmatically authoring, scheduling, and monitoring workflows. It uses Directed Acyclic Graphs (DAGs) to represent pipelines, where each node in the graph represents a task and each edge represents a dependency between tasks.</p>
<ul>
<li><strong>Orchestration:</strong> Airflow provides a centralized platform for orchestrating the execution of tasks in a pipeline, ensuring that they are executed in the correct order and with the appropriate resources.</li>
<li><strong>Scheduling:</strong> Airflow allows you to schedule pipelines to run automatically at specific intervals or in response to events.</li>
<li><strong>Monitoring:</strong> Airflow provides a web interface for monitoring the status of pipelines and tasks, making it easy to identify and resolve issues.</li>
<li><strong>Extensibility:</strong> Airflow supports a wide range of operators for interacting with different systems and services, making it easy to integrate into existing ML infrastructure.</li>
</ul></li>
<li><p><strong>Kubeflow:</strong> Kubeflow is a platform for running ML workloads on Kubernetes. It provides a set of tools and components for building, deploying, and managing ML pipelines in a containerized environment.</p>
<ul>
<li><strong>Containerization:</strong> Kubeflow leverages Kubernetes to containerize ML components, making them portable and scalable.</li>
<li><strong>Pipeline Orchestration:</strong> Kubeflow Pipelines provides a domain-specific language (DSL) for defining ML pipelines as code, making them easy to reproduce and share.</li>
<li><strong>Experiment Tracking:</strong> Kubeflow integrates with experiment tracking tools like MLflow to track the performance of different models and experiments.</li>
<li><strong>Model Serving:</strong> Kubeflow provides tools for deploying and serving ML models in a scalable and reliable manner.</li>
<li><strong>Scalability:</strong> Kubeflow is designed to scale ML workloads to handle large datasets and complex models.</li>
</ul></li>
</ul>
<p><strong>4. Key Differences and When to Use Each:</strong></p>
<ul>
<li><strong>Airflow:</strong> Excels at general-purpose workflow orchestration. Use it when you need to integrate ML tasks with other business processes or when you have complex dependencies between tasks. Airflow is language agnostic, meaning it can orchestrate any task.</li>
<li><strong>Kubeflow:</strong> Is purpose-built for ML on Kubernetes. Use it when you want to leverage the scalability and resource management capabilities of Kubernetes, and when you need a complete ML platform that includes pipeline orchestration, experiment tracking, and model serving. Kubeflow’s focus is tighter on the ML lifecycle.</li>
</ul>
<p><strong>5. Challenges in Production ML Pipeline Management:</strong></p>
<ul>
<li><strong>Dependency Management:</strong> Managing dependencies between different components of a pipeline can be challenging, especially in complex ML systems. Containerization helps, but versioning dependencies within those containers is also crucial.</li>
<li><strong>Version Control:</strong> Tracking changes to data, code, and models is essential for reproducibility and debugging. Tools like Git for code, DVC for data, and MLflow for model versioning are important.</li>
<li><strong>Data Drift:</strong> Monitoring data distributions in production and detecting drift is crucial for maintaining model accuracy. This requires setting up statistical tests and alerts.</li>
<li><strong>Model Drift:</strong> Models’ performance degrades over time as the data they are trained on becomes stale. Retraining pipelines and A/B testing new models are necessary to combat this.</li>
<li><strong>Resource Management:</strong> Efficiently allocating resources to different components of a pipeline is crucial for optimizing performance and cost.</li>
<li><strong>Monitoring and Alerting:</strong> Setting up comprehensive monitoring and alerting systems to detect and respond to issues in production is essential for ensuring the reliability of ML systems. This includes monitoring data quality, model performance, and system health.</li>
</ul>
<p>In summary, ML pipelines are essential for building and deploying reliable and scalable ML systems. Airflow and Kubeflow are powerful tools for managing these pipelines, but they require careful planning and implementation to address the challenges of production environments. Addressing these challenges requires a combination of robust infrastructure, well-defined processes, and skilled personnel.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this in an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Definition:</strong> “ML pipelines are automated workflows that streamline the entire machine learning lifecycle, from data ingestion to model deployment and monitoring.” Emphasize the <em>purpose</em> of pipelines – to make ML scalable, reproducible, and maintainable.</p></li>
<li><p><strong>Describe the Components (Focus on Key Stages):</strong> “A typical ML pipeline consists of stages like data ingestion, preprocessing, feature engineering, model training, evaluation, and deployment. Each stage transforms the data or the model in some way.” Don’t list <em>every</em> possible component; focus on the most common and important. Give examples of techniques used within each stage (e.g., standardization, one-hot encoding).</p></li>
<li><p><strong>Explain Why Pipelines are Critical:</strong> “Pipelines address several critical needs in production ML. They automate repetitive tasks, ensure reproducibility by versioning data and code, scale to handle large datasets, and improve collaboration between team members.” Highlight the <em>benefits</em> – automation, reproducibility, scalability, and maintainability.</p></li>
<li><p><strong>Introduce Airflow and Kubeflow:</strong> “Tools like Airflow and Kubeflow are workflow management platforms specifically designed to orchestrate and manage these ML pipelines at scale.” Clearly state their primary purpose.</p></li>
<li><p><strong>Explain Airflow’s Role:</strong> “Airflow uses DAGs to define workflows, allowing you to schedule and monitor tasks. It’s excellent for integrating ML with other business processes and is language agnostic.” Emphasize its scheduling and monitoring capabilities and its broad applicability.</p></li>
<li><p><strong>Explain Kubeflow’s Role:</strong> “Kubeflow, on the other hand, is built for Kubernetes and is focused on running ML workloads in containers. It provides tools for pipeline orchestration, experiment tracking, and model serving.” Highlight its containerization and ML-specific features.</p></li>
<li><p><strong>Discuss the Key Differences and Use Cases:</strong> “Airflow is a more general-purpose workflow engine, suitable when you need to integrate ML tasks with other systems. Kubeflow is purpose-built for ML on Kubernetes, providing a more complete ML platform.” Provide a clear comparison and guidance on choosing the right tool.</p></li>
<li><p><strong>Address the Challenges:</strong> “Managing ML pipelines in production presents several challenges, including dependency management, version control, data and model drift, and resource management. Addressing these requires robust infrastructure, well-defined processes, and skilled personnel.” Conclude by acknowledging the complexities and highlighting the need for a holistic approach.</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you are in a virtual interview, consider sharing your screen and showing a simple diagram of an ML pipeline.</li>
<li><strong>Check for Understanding:</strong> Periodically ask the interviewer if they have any questions or if you should elaborate on a particular point.</li>
<li><strong>Avoid Jargon:</strong> Use clear and concise language, and avoid using technical jargon that the interviewer may not understand.</li>
<li><strong>Be Enthusiastic:</strong> Show your passion for the topic and your genuine interest in the role.</li>
</ul>
<p><strong>How to Handle Mathematical Sections:</strong></p>
<ul>
<li><strong>Don’t Overwhelm:</strong> Avoid presenting too much math at once. Focus on the key formulas and concepts.</li>
<li><strong>Explain the Intuition:</strong> For each formula, explain the underlying intuition in plain English.</li>
<li><strong>Give Examples:</strong> Provide concrete examples of how the formula is used in practice.</li>
<li><strong>Offer Simplifications:</strong> If the formula is complex, offer a simplified version or a high-level explanation.</li>
<li><strong>Be Prepared to Go Deeper:</strong> If the interviewer asks for more detail, be prepared to provide it.</li>
</ul>
<p>For example, when discussing the gradient descent equation, you could say:</p>
<p>“Gradient descent is an optimization algorithm used to find the minimum of a function. The equation is: <span class="math inline">\(\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t)\)</span>. In simpler terms, we’re updating the model’s parameters (<span class="math inline">\(\theta\)</span>) by taking a step in the opposite direction of the gradient (<span class="math inline">\(\nabla J(\theta_t)\)</span>), which tells us the direction of steepest ascent. The learning rate (<span class="math inline">\(\eta\)</span>) controls the size of that step. We repeat this process iteratively until we reach a minimum.”</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>