<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>explainability___interpretability_in_production_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-6.-explain-a-situation-where-a-models-explanation-may-be-misleading-or-misinterpreted.-what-pitfalls-should-practitioners-be-aware-of-to-ensure-that-explanations-are-both-valid-and-actionable" class="level2">
<h2 class="anchored" data-anchor-id="question-6.-explain-a-situation-where-a-models-explanation-may-be-misleading-or-misinterpreted.-what-pitfalls-should-practitioners-be-aware-of-to-ensure-that-explanations-are-both-valid-and-actionable">Question: 6. Explain a situation where a model’s explanation may be misleading or misinterpreted. What pitfalls should practitioners be aware of to ensure that explanations are both valid and actionable?</h2>
<p><strong>Best Answer</strong></p>
<p>Model explanations, while immensely valuable, are susceptible to being misleading or misinterpreted, especially in complex systems. These issues arise from several factors, including the inherent limitations of explanation techniques, the nature of the data, and the potential for cognitive biases in interpretation.</p>
<p>Here are situations where a model’s explanation may be misleading:</p>
<ul>
<li><p><strong>Correlation vs.&nbsp;Causation:</strong> Explanation methods often highlight features strongly correlated with the model’s output. However, correlation doesn’t imply causation. For instance, in a model predicting ice cream sales, a high temperature might be highlighted as a crucial factor. While there’s a correlation, it’s not necessarily causal; other factors like a summer holiday or a local event could also be significant drivers. Misinterpreting this correlation as a direct causal link could lead to ineffective interventions (e.g., trying to raise ice cream sales by artificially increasing the temperature).</p></li>
<li><p><strong>Simpson’s Paradox:</strong> This statistical phenomenon can lead to misleading explanations when aggregated data hides underlying relationships. Suppose we are evaluating a medical treatment across two hospitals. In each hospital, the treatment appears less effective than the alternative. However, when we combine the data, the treatment seems more effective. A model trained on the combined data might highlight features that seem beneficial overall but mask the fact that the treatment is harmful in specific subgroups.</p></li>
<li><p><strong>Feature Interactions:</strong> Many explanation methods focus on the individual contribution of features, neglecting complex interactions between them. A feature might appear unimportant when considered in isolation, but its effect could be significant when combined with another feature. For example, consider a model predicting loan defaults. Neither “income” nor “debt” alone might be strong predictors, but the “debt-to-income ratio” (an interaction term) could be highly significant. Explanation methods that ignore such interactions provide incomplete, and potentially misleading, insights.</p></li>
<li><p><strong>Proxy Features:</strong> Sometimes, a model might rely on a proxy feature—one that is correlated with the actual causal factor but isn’t the direct cause. For example, zip code might be a strong predictor in a model predicting health outcomes. However, zip code isn’t the <em>cause</em> of health issues; it’s a proxy for socioeconomic status, access to healthcare, environmental factors, etc. Intervening on the zip code directly (e.g., by offering services only to certain zip codes) would be misguided and potentially discriminatory.</p></li>
<li><p><strong>Model Instability:</strong> Certain explanation methods, especially those that rely on perturbing the input data (e.g., LIME), can be sensitive to the specific perturbation strategy used. Small changes in the perturbation process can lead to significantly different explanations. This instability makes the explanations unreliable and hard to trust.</p></li>
<li><p><strong>Adversarial Examples:</strong> Adversarial examples are inputs crafted to fool a model, often with minimal changes that are imperceptible to humans. Explanations for adversarial examples can be completely nonsensical, as they reflect the model’s distorted perception of the input rather than the underlying reality.</p></li>
<li><p><strong>Feedback Loops:</strong> In deployed systems, model predictions can influence the real world, creating feedback loops that distort the relationship between features and outcomes. For instance, a model that predicts crime hotspots might lead to increased police presence in those areas, which in turn leads to more arrests and confirms the model’s predictions, even if the initial predictions were based on biased data.</p></li>
</ul>
<p>To ensure explanations are both valid and actionable, practitioners should be aware of the following pitfalls:</p>
<ul>
<li><p><strong>Lack of Domain Expertise:</strong> Explanations should always be interpreted in the context of domain knowledge. Without understanding the underlying processes, it’s easy to draw incorrect conclusions from the highlighted features.</p></li>
<li><p><strong>Over-Reliance on Automated Explanations:</strong> Explanation methods should be viewed as tools for exploration and hypothesis generation, not as definitive answers. Don’t take automated explanation outputs at face value without further analysis.</p></li>
<li><p><strong>Insufficient Validation:</strong> Explanation methods should be validated rigorously. This can involve comparing explanations across different models, checking for consistency with known causal relationships, and conducting experiments to test the effect of interventions based on the explanations.</p></li>
<li><p><strong>Ignoring Counterfactual Explanations:</strong> Focusing solely on what <em>did</em> influence the model’s prediction can be misleading. Considering counterfactual explanations—what <em>would have</em> changed the prediction—can provide more actionable insights. For example, instead of just knowing that “income” was important for a loan approval, knowing how much the income would have to increase for the loan to be approved is more actionable.</p></li>
<li><p><strong>Misapplication of Explanation Methods:</strong> Different explanation methods have different assumptions and limitations. Applying a method inappropriately can lead to misleading results. For example, applying LIME to a highly non-linear model might produce unstable and unreliable explanations.</p></li>
<li><p><strong>Bias in Data and Models:</strong> Explanations can reflect and amplify biases present in the training data or the model itself. It’s crucial to be aware of potential biases and to evaluate explanations for fairness and equity.</p></li>
<li><p><strong>Oversimplification:</strong> Explanation methods often provide simplified views of complex model behavior. It’s important to recognize these limitations and to avoid over-interpreting the explanations.</p></li>
<li><p><strong>Ignoring Uncertainty:</strong> Many explanation methods provide point estimates of feature importance without quantifying the uncertainty associated with these estimates. Incorporating uncertainty estimates can help avoid overconfidence in the explanations.</p></li>
<li><p><strong>Choosing the Wrong Granularity:</strong> Explanations can be provided at different levels of granularity (e.g., global vs.&nbsp;local, feature-level vs.&nbsp;instance-level). Choosing the appropriate level of granularity depends on the specific application and the needs of the user.</p></li>
</ul>
<p>By being aware of these pitfalls and adopting a critical and rigorous approach to interpreting model explanations, practitioners can ensure that the explanations are both valid and actionable, leading to better decision-making and more trustworthy AI systems.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to deliver this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview:</strong></p>
<ul>
<li>“Model explanations are very useful, but they can also be misleading if we’re not careful.”</li>
<li>“The core issue is that explanations are often simplifications of complex processes, and can be affected by things like data quality or the specific explanation method used.”</li>
</ul></li>
<li><p><strong>Discuss Examples of Misleading Explanations:</strong></p>
<ul>
<li>“One common problem is confusing correlation with causation. For example, a model might say that high temperature leads to ice cream sales, but it’s probably just that both are common in summer.”</li>
<li>“Simpson’s Paradox can also cause issues. The overall trend might hide what is really happening within smaller groups of data.”</li>
<li>“Another thing is that models can pick up on features that are correlated with the <em>real</em> cause, but aren’t the cause themselves. For instance, a zip code could be a stand-in for socioeconomic status, but it’s the poverty or lack of opportunity, not the location itself, that affects the outcome.”</li>
<li>“Feature interactions are often ignored as well. A feature on its own might seem unimportant, but combined with another, its suddenly crucial.”</li>
</ul></li>
<li><p><strong>Explain Pitfalls to be Aware Of</strong></p>
<ul>
<li>“Practitioners should be aware of several pitfalls to ensure that explanations are both valid and actionable. The first is the lack of domain expertise, explanations should always be interpreted in the context of domain knowledge.”</li>
<li>“Another is over-reliance on automated explanations. Explanation methods should be viewed as tools for exploration and hypothesis generation, not as definitive answers.”</li>
<li>“Lastly is insufficient validation. Explanation methods should be validated rigorously such as compare explanations across different models”</li>
</ul></li>
<li><p><strong>Mathematical Sections (If Applicable):</strong></p>
<ul>
<li>If you mention Simpson’s Paradox, you could briefly describe it with a simple example: “Simpson’s Paradox is when a trend appears in several different groups of data but disappears or reverses when these groups are combined. For example, consider a medical treatment which is less effective than the alternative in each of two hospitals. However, when the data is combined, the treatment seems more effective.”</li>
<li>Avoid getting bogged down in details. If the interviewer asks for more details, provide them, but keep the initial explanation concise.</li>
</ul></li>
<li><p><strong>Use Analogies:</strong></p>
<ul>
<li>When explaining proxy features, use the zip code example, which is easily understandable.</li>
</ul></li>
<li><p><strong>Summarize and Emphasize Actionable Steps:</strong></p>
<ul>
<li>“So, to make sure our explanations are valid and actionable, we need to use domain knowledge, validate our explanations, and be wary of taking automated outputs at face value. We should also choose explanation methods that are appropriate for the model and data, and consider counterfactuals – what <em>would have</em> changed the prediction.”</li>
</ul></li>
<li><p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Speak Clearly and Slowly:</strong> Especially when discussing complex concepts.</li>
<li><strong>Use “We” Instead of “I”:</strong> This conveys a collaborative approach and that you’re thinking about the entire team and problem, not just your individual efforts.</li>
<li><strong>Pause for Questions:</strong> Give the interviewer a chance to jump in and ask for clarification.</li>
<li><strong>Read the Interviewer’s Body Language:</strong> If they seem confused or overwhelmed, simplify your explanation.</li>
</ul></li>
</ol>
<p>By following these steps, you can confidently explain the potential pitfalls of model explanations and demonstrate your expertise in ensuring their validity and usefulness.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>