<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>cyclegan__stylegan__etc__4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-stylegans-architecture-leverages-style-mixing-and-adaptive-instance-normalization-to-control-image-attributes.-what-are-the-trade-offs-of-using-such-a-style-based-architecture-regarding-resolution-fine-grained-control-computational-demands-and-diversity-of-generated-images" class="level2">
<h2 class="anchored" data-anchor-id="question-5.-stylegans-architecture-leverages-style-mixing-and-adaptive-instance-normalization-to-control-image-attributes.-what-are-the-trade-offs-of-using-such-a-style-based-architecture-regarding-resolution-fine-grained-control-computational-demands-and-diversity-of-generated-images">Question: 5. StyleGAN’s architecture leverages style mixing and adaptive instance normalization to control image attributes. What are the trade-offs of using such a style-based architecture regarding resolution, fine-grained control, computational demands, and diversity of generated images?</h2>
<p><strong>Best Answer</strong></p>
<p>StyleGAN represents a significant advancement in generative adversarial networks (GANs), particularly for high-resolution image synthesis. Its architecture introduces several key innovations, including a style-based generator network and adaptive instance normalization (AdaIN), which offer improved control over image attributes. However, these advancements come with their own set of trade-offs.</p>
<p>Here’s a breakdown of the trade-offs concerning resolution, fine-grained control, computational demands, and diversity of generated images:</p>
<p><strong>1. Resolution:</strong></p>
<ul>
<li><strong>Benefit:</strong> StyleGAN excels at generating high-resolution images (e.g., 1024x1024 or higher) with impressive detail and realism. The style-based generator progressively increases the resolution of the generated image, starting from a low-resolution latent representation and gradually adding finer details. This allows the network to learn hierarchical representations of image features at different scales.</li>
<li><strong>Mechanism:</strong> The generator architecture can be described as a mapping network <span class="math inline">\(f: z \in \mathcal{Z} \rightarrow w \in \mathcal{W}\)</span>, where <span class="math inline">\(\mathcal{Z}\)</span> is the latent space (usually Gaussian) and <span class="math inline">\(\mathcal{W}\)</span> is an intermediate latent space. Then, an synthesis network <span class="math inline">\(g: w \in \mathcal{W} \rightarrow x\)</span> transforms <span class="math inline">\(w\)</span> into the final image. <span class="math inline">\(x\)</span>. AdaIN layers are applied at each resolution level in the synthesis network, modulating the activations based on the style code <span class="math inline">\(w\)</span>.</li>
</ul>
<p><span class="math display">\[
AdaIN(x_i, y) = \sigma(y) \frac{x_i - \mu(x_i)}{\sigma(x_i)} + \mu(y)
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is the activation map, <span class="math inline">\(y\)</span> is the style code derived from <span class="math inline">\(w\)</span>, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are the mean and standard deviation respectively.</p>
<ul>
<li><strong>Trade-off:</strong> The progressive growing approach and the increased complexity of the generator contribute to higher computational demands during both training and inference, especially when generating very high-resolution images. Memory consumption also increases significantly.</li>
</ul>
<p><strong>2. Fine-Grained Control:</strong></p>
<ul>
<li><strong>Benefit:</strong> StyleGAN provides excellent fine-grained control over various image attributes, such as hair style, skin tone, age, pose, and facial expression. The style mixing technique allows you to selectively transfer attributes from one image to another by swapping style codes at different resolution levels.</li>
<li><strong>Mechanism:</strong> Style mixing involves using different style vectors <span class="math inline">\(w_1, w_2\)</span> at different layers of the generator. For instance, the first few layers might use style vector <span class="math inline">\(w_1\)</span> while the later layers use <span class="math inline">\(w_2\)</span>. This allows for disentangled control over coarse and fine details.</li>
<li><strong>Trade-off:</strong> Disentanglement relies on the intermediate latent space <span class="math inline">\(\mathcal{W}\)</span>. The level of disentanglement achieved can be sensitive to hyperparameters and dataset characteristics. Furthermore, while individual style parameters <em>tend</em> to control specific features, perfect independence is rarely achieved in practice. Some degree of feature entanglement remains, meaning changes to one style parameter can sometimes affect other attributes. Also, manually exploring and understanding the latent space to find meaningful style manipulations can be time-consuming.</li>
</ul>
<p><strong>3. Computational Demands:</strong></p>
<ul>
<li><strong>Cost:</strong> StyleGAN is computationally more expensive than traditional GAN architectures, like DCGAN or even earlier progressive GANs. The increased complexity comes from:
<ul>
<li>The mapping network <span class="math inline">\(f\)</span>.</li>
<li>The style modulation using AdaIN.</li>
<li>The progressive growing architecture.</li>
<li>The increased number of parameters overall.</li>
</ul></li>
<li><strong>Impact:</strong> This increased computational cost manifests in:
<ul>
<li>Longer training times, requiring more powerful GPUs or TPUs and more memory.</li>
<li>Higher inference costs, making real-time generation challenging, especially for high-resolution images on less powerful hardware.</li>
<li>Larger model size, requiring more storage space and bandwidth for deployment.</li>
</ul></li>
<li><strong>Mitigation:</strong> Techniques like knowledge distillation or model compression can be applied after training to reduce the model size and inference cost.</li>
</ul>
<p><strong>4. Diversity of Generated Images:</strong></p>
<ul>
<li><strong>Potential Benefit:</strong> The style-based architecture, particularly the mapping network and the intermediate latent space, <em>can</em> enhance the diversity of generated images by providing a more disentangled and well-behaved latent space compared to directly feeding the latent code into the generator, as in traditional GANs.</li>
<li><strong>Challenge and Trade-off:</strong> StyleGANs, like all GANs, are susceptible to mode collapse, where the generator produces only a limited set of images and fails to cover the full diversity of the real data distribution. While the style-based architecture <em>can</em> improve diversity, it does not eliminate the risk of mode collapse entirely. Careful regularization of the latent space, the use of appropriate training techniques (e.g., minibatch discrimination), and a well-chosen dataset are still crucial to ensure diversity. Furthermore, the improved image quality can sometimes overshadow a lack of <em>semantic</em> diversity, meaning the images look realistic but represent a limited range of content. The choice of loss function, such as non-saturating loss or hinge loss, can also impact diversity.</li>
</ul>
<p><strong>Comparison with Traditional Convolution-Based GANs:</strong></p>
<p>Compared to traditional convolution-based GANs (e.g., DCGAN), StyleGAN offers:</p>
<ul>
<li><strong>Superior image quality and resolution:</strong> Convolution-based GANs typically struggle to generate high-resolution images with the same level of detail and realism as StyleGAN.</li>
<li><strong>Finer-grained control over image attributes:</strong> StyleGAN’s style mixing and AdaIN layers provide much more precise control over image features than the global conditioning methods used in traditional GANs.</li>
<li><strong>Increased computational cost:</strong> StyleGAN is significantly more computationally expensive than DCGAN, requiring more resources for training and inference.</li>
<li><strong>Potentially improved diversity (but not guaranteed):</strong> While StyleGAN <em>can</em> improve diversity, careful training and regularization are still necessary to avoid mode collapse, which can also plague simpler GAN architectures.</li>
</ul>
<p>In summary, StyleGAN achieves state-of-the-art image synthesis quality and control at the cost of increased computational complexity. The trade-offs between resolution, control, computational demands, and diversity need to be carefully considered when choosing StyleGAN for a specific application.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to deliver this answer verbally in an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview (30 seconds):</strong></p>
<ul>
<li>“StyleGAN is a significant advancement in GANs, especially for high-resolution image synthesis. It offers improved control over image attributes but introduces some trade-offs.”</li>
<li>“I can discuss the trade-offs regarding resolution, fine-grained control, computational demands, and the diversity of generated images, comparing it briefly to more traditional GANs.”</li>
</ul></li>
<li><p><strong>Discuss Resolution (1 minute):</strong></p>
<ul>
<li>“StyleGAN excels at generating high-resolution images due to its progressive growing approach. The generator starts with a low-resolution representation and gradually adds details.”</li>
<li>“However, this comes at the cost of higher computational demands, particularly when generating very high-resolution images. It consumes more memory and requires more processing power.”</li>
</ul></li>
<li><p><strong>Explain Fine-Grained Control (1.5 minutes):</strong></p>
<ul>
<li>“One of the key advantages of StyleGAN is its fine-grained control over image attributes like hair style or facial expressions. This is achieved through style mixing and AdaIN layers.”</li>
<li>“I can explain the AdaIN with the equation (write or approximate it on a whiteboard if available): <span class="math inline">\(AdaIN(x_i, y) = \sigma(y) \frac{x_i - \mu(x_i)}{\sigma(x_i)} + \mu(y)\)</span> which modulates the activation maps based on style codes”</li>
<li>“Style mixing involves swapping style codes at different layers to transfer attributes. However, complete disentanglement is difficult to achieve, and exploring the latent space can be time-consuming.”</li>
</ul></li>
<li><p><strong>Address Computational Demands (1 minute):</strong></p>
<ul>
<li>“StyleGAN is computationally more expensive than traditional GANs due to the mapping network, style modulation, and progressive growing. This translates to longer training times and higher inference costs.”</li>
<li>“Techniques like knowledge distillation can be used to mitigate these costs after training.”</li>
</ul></li>
<li><p><strong>Discuss Diversity (1 minute):</strong></p>
<ul>
<li>“The style-based architecture <em>can</em> enhance the diversity of generated images by providing a more disentangled latent space. But StyleGANs, like all GANs, are still susceptible to mode collapse.”</li>
<li>“Careful regularization and training techniques are crucial to ensure diversity. The choice of loss function also has impact on the diversity.”</li>
</ul></li>
<li><p><strong>Compare to Traditional GANs (30 seconds):</strong></p>
<ul>
<li>“Compared to traditional convolution-based GANs, StyleGAN offers superior image quality and control but at a higher computational cost. While it <em>can</em> improve diversity, this is not guaranteed.”</li>
</ul></li>
<li><p><strong>Concluding Remarks (15 seconds):</strong></p>
<ul>
<li>“In summary, StyleGAN achieves state-of-the-art image synthesis quality and control, but it’s essential to consider the trade-offs when choosing it for a specific application.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Use visuals if possible:</strong> If you have access to a whiteboard, use it to draw diagrams or write down key equations.</li>
<li><strong>Check for understanding:</strong> Ask the interviewer if they have any questions or if they would like you to elaborate on any specific point.</li>
<li><strong>Be honest about limitations:</strong> Acknowledge the limitations of StyleGAN, such as the difficulty of achieving perfect disentanglement or the risk of mode collapse.</li>
<li><strong>Connect to real-world applications:</strong> If you have experience using StyleGAN in a real-world project, briefly mention it to demonstrate practical knowledge.</li>
</ul>
<p>By following these guidelines, you can effectively communicate your understanding of StyleGAN and its trade-offs, demonstrating your expertise as a senior-level candidate.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>