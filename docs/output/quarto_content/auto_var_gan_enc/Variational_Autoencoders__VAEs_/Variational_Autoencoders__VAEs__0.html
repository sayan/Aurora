<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>variational_autoencoders__vaes__0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-1.-what-is-a-variational-autoencoder-vae-and-how-does-it-differ-from-a-traditional-autoencoder-please-describe-the-core-components-of-a-vae." class="level2">
<h2 class="anchored" data-anchor-id="question-1.-what-is-a-variational-autoencoder-vae-and-how-does-it-differ-from-a-traditional-autoencoder-please-describe-the-core-components-of-a-vae.">Question: 1. What is a Variational Autoencoder (VAE), and how does it differ from a traditional Autoencoder? Please describe the core components of a VAE.</h2>
<p><strong>Best Answer</strong></p>
<p>A Variational Autoencoder (VAE) is a type of generative model that learns a latent representation of the input data and can generate new samples similar to the training data. Unlike traditional autoencoders, which learn a deterministic mapping from the input to a lower-dimensional latent space, VAEs learn a <em>probabilistic</em> mapping. This means that instead of encoding an input into a fixed vector in the latent space, the VAE encodes it into parameters of a probability distribution, typically a Gaussian distribution.</p>
<p>Here’s a breakdown of the key differences and components:</p>
<p><strong>1. Differences from Traditional Autoencoders:</strong></p>
<ul>
<li><p><strong>Deterministic vs.&nbsp;Probabilistic Latent Space:</strong> Traditional autoencoders map inputs to a fixed point in the latent space. VAEs, on the other hand, map inputs to a probability distribution (usually Gaussian) in the latent space.</p></li>
<li><p><strong>Generative Capability:</strong> Traditional autoencoders are primarily used for dimensionality reduction or feature learning. While they can decode latent vectors, they don’t inherently provide a mechanism for generating <em>new</em> samples effectively. Because of the probabilistic nature of the latent space, VAEs are explicitly designed for generation. By sampling from the learned latent distributions and decoding, we can create new data instances.</p></li>
<li><p><strong>Latent Space Structure:</strong> In a traditional autoencoder, the latent space can be highly irregular and discontinuous. This can lead to poor results if you try to generate new data by sampling from arbitrary points in this space. VAEs enforce a smoother and more continuous latent space through the use of a regularization term (the Kullback-Leibler divergence), making sampling and generation more reliable.</p></li>
</ul>
<p><strong>2. Core Components of a VAE:</strong></p>
<p>A VAE consists of two main neural networks: an encoder and a decoder, along with a crucial sampling step:</p>
<ul>
<li><p><strong>Encoder (Inference Network):</strong> The encoder takes an input data point <span class="math inline">\(x\)</span> and maps it to the parameters of a probability distribution in the latent space, typically a Gaussian distribution. Specifically, the encoder outputs the mean vector <span class="math inline">\(\mu(x)\)</span> and the standard deviation <span class="math inline">\(\sigma(x)\)</span> (or log-variance <span class="math inline">\(log(\sigma^2(x))\)</span> for numerical stability) of this Gaussian.</p>
<p>Mathematically, given an input <span class="math inline">\(x\)</span>, the encoder approximates the posterior distribution <span class="math inline">\(q_{\phi}(z|x) \approx P(z|x)\)</span>, where <span class="math inline">\(z\)</span> is the latent variable, <span class="math inline">\(\phi\)</span> represents the encoder’s parameters, and we usually assume <span class="math inline">\(q_{\phi}(z|x)\)</span> follows a Gaussian distribution:</p>
<p><span class="math display">\[q_{\phi}(z|x) = \mathcal{N}(z; \mu(x), \sigma^2(x)I)\]</span></p>
<p>where <span class="math inline">\(\mu(x)\)</span> and <span class="math inline">\(\sigma(x)\)</span> are the mean and standard deviation vectors produced by the encoder network, and <span class="math inline">\(I\)</span> is the identity matrix.</p></li>
<li><p><strong>Sampling:</strong> A latent vector <span class="math inline">\(z\)</span> is sampled from the distribution <span class="math inline">\(q_{\phi}(z|x)\)</span>. This is a crucial stochastic step that introduces the probabilistic nature of the VAE. The sampling is usually done using the “reparameterization trick.” Instead of directly sampling <span class="math inline">\(z\)</span> from <span class="math inline">\(\mathcal{N}(\mu(x), \sigma^2(x)I)\)</span>, we sample from a standard normal distribution <span class="math inline">\(\epsilon \sim \mathcal{N}(0, I)\)</span> and then compute <span class="math inline">\(z\)</span> as:</p>
<p><span class="math display">\[z = \mu(x) + \sigma(x) \odot \epsilon\]</span></p>
<p>where <span class="math inline">\(\odot\)</span> denotes element-wise multiplication (Hadamard product). The reparameterization trick is essential because it allows us to backpropagate gradients through the sampling process, which is necessary for training the encoder and decoder networks.</p></li>
<li><p><strong>Decoder (Generative Network):</strong> The decoder takes the sampled latent vector <span class="math inline">\(z\)</span> and maps it back to the original data space, attempting to reconstruct the input <span class="math inline">\(x\)</span>. The decoder outputs the parameters of a distribution <span class="math inline">\(p_{\theta}(x|z)\)</span>, where <span class="math inline">\(\theta\)</span> represents the decoder’s parameters. Depending on the data type, <span class="math inline">\(p_{\theta}(x|z)\)</span> can be a Gaussian (for continuous data) or a Bernoulli distribution (for binary data). The decoder aims to maximize the likelihood of generating <span class="math inline">\(x\)</span> given <span class="math inline">\(z\)</span>.</p>
<p>For example, if <span class="math inline">\(x\)</span> is continuous, the decoder might output the mean of a Gaussian distribution:</p>
<p><span class="math display">\[p_{\theta}(x|z) = \mathcal{N}(x; \mu(z), \sigma^2)\]</span></p>
<p>where <span class="math inline">\(\mu(z)\)</span> is the mean vector produced by the decoder network and <span class="math inline">\(\sigma^2\)</span> is a fixed variance.</p></li>
<li><p><strong>Loss Function:</strong> The VAE’s loss function consists of two terms: a reconstruction loss and a regularization term.</p>
<ul>
<li><p><strong>Reconstruction Loss:</strong> This term measures how well the decoder can reconstruct the original input <span class="math inline">\(x\)</span> from the latent vector <span class="math inline">\(z\)</span>. It’s typically a negative log-likelihood of the data given the latent code, such as the mean squared error (MSE) for Gaussian output or binary cross-entropy for Bernoulli output. For example, with Gaussian decoder, reconstruction loss is proportional to:</p>
<p><span class="math display">\[L_{reconstruction} = ||x - \mu(z)||^2\]</span></p>
<p>where <span class="math inline">\(\mu(z)\)</span> is the mean output by the decoder.</p></li>
<li><p><strong>Regularization Term (KL Divergence):</strong> This term encourages the learned latent distribution <span class="math inline">\(q_{\phi}(z|x)\)</span> to be close to a prior distribution <span class="math inline">\(p(z)\)</span>, usually a standard normal distribution <span class="math inline">\(\mathcal{N}(0, I)\)</span>. The Kullback-Leibler (KL) divergence measures the difference between two probability distributions.</p>
<p><span class="math display">\[L_{KL} = D_{KL}(q_{\phi}(z|x) || p(z)) = D_{KL}(\mathcal{N}(\mu(x), \sigma^2(x)I) || \mathcal{N}(0, I))\]</span></p>
<p>For Gaussian distributions, the KL divergence has a closed-form solution:</p>
<p><span class="math display">\[L_{KL} = \frac{1}{2} \sum_{i=1}^{d} ( \mu_i^2 + \sigma_i^2 - log(\sigma_i^2) - 1 )\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the dimensionality of the latent space, and <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\sigma_i\)</span> are the <span class="math inline">\(i\)</span>-th elements of the mean and standard deviation vectors, respectively.</p></li>
</ul>
<p>The total loss function is then:</p>
<p><span class="math display">\[L = L_{reconstruction} + \beta * L_{KL}\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is a hyperparameter that controls the strength of the regularization. Setting <span class="math inline">\(\beta\)</span> to 0 would effectively turn the VAE into a regular autoencoder, and higher values would make the prior distribution stronger.</p></li>
</ul>
<p>In summary, VAEs learn a probabilistic latent representation that allows for generating new samples by sampling from the latent space and decoding. The key components are the encoder, the decoder, the sampling step with the reparameterization trick, and the loss function containing a reconstruction loss and a KL divergence regularization term.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s how you can articulate this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the basics:</strong></p>
<ul>
<li>“A Variational Autoencoder, or VAE, is a generative model used for learning latent representations of data, similar to autoencoders, but with a crucial difference: instead of learning a deterministic mapping to the latent space, it learns a <em>probabilistic</em> mapping.”</li>
</ul></li>
<li><p><strong>Highlight the core difference between VAEs and Autoencoders:</strong></p>
<ul>
<li>“Unlike traditional autoencoders that encode inputs into a fixed vector, VAEs encode inputs into the parameters of a probability distribution, typically a Gaussian. This is the core difference that enables VAEs to generate new samples effectively.”</li>
<li>“This probabilistic nature results in a more structured and continuous latent space in VAEs, which is a contrast to the potentially irregular latent space learned by a standard autoencoder.”</li>
</ul></li>
<li><p><strong>Explain the three key components:</strong></p>
<ul>
<li>“A VAE consists of an encoder, a decoder, and a sampling step, all tied together by a specific loss function.”</li>
</ul></li>
<li><p><strong>Walk through the Encoder:</strong></p>
<ul>
<li>“The <em>encoder</em> takes an input, <span class="math inline">\(x\)</span>, and outputs the parameters of a Gaussian distribution, specifically the mean, <span class="math inline">\(\mu(x)\)</span>, and the standard deviation, <span class="math inline">\(\sigma(x)\)</span>. Think of it as mapping the input to a region in the latent space rather than a single point.”</li>
<li><em>(Optional: If the interviewer seems interested in more detail, you can mention that the encoder approximates the posterior distribution <span class="math inline">\(q_{\phi}(z|x) \approx P(z|x)\)</span>.)</em></li>
</ul></li>
<li><p><strong>Explain the Sampling step with the Re-parameterization Trick:</strong></p>
<ul>
<li>“We then <em>sample</em> a latent vector, <span class="math inline">\(z\)</span>, from this Gaussian distribution. This is where the reparameterization trick comes in. Instead of directly sampling from the distribution defined by <span class="math inline">\(\mu(x)\)</span> and <span class="math inline">\(\sigma(x)\)</span>, we sample from a standard normal distribution, <span class="math inline">\(\epsilon\)</span>, and then calculate <span class="math inline">\(z\)</span> as <span class="math inline">\(z = \mu(x) + \sigma(x) \odot \epsilon\)</span>. This allows us to backpropagate gradients through the sampling process.”</li>
<li>Emphasize that this reparameterization is important for training.</li>
</ul></li>
<li><p><strong>Explain the Decoder:</strong></p>
<ul>
<li>“The <em>decoder</em> takes the sampled latent vector, <span class="math inline">\(z\)</span>, and attempts to reconstruct the original input, <span class="math inline">\(x\)</span>. It outputs the parameters of a distribution, <span class="math inline">\(p_{\theta}(x|z)\)</span>, such as the mean of a Gaussian if the data is continuous.”</li>
</ul></li>
<li><p><strong>Explain the Loss Function:</strong></p>
<ul>
<li>“The <em>loss function</em> has two components: a reconstruction loss and a KL divergence term.”</li>
<li>“The reconstruction loss measures how well the decoder can reconstruct the input. It could be Mean Squared Error or binary cross-entropy depending on the data. For example, <span class="math inline">\(L_{reconstruction} = ||x - \mu(z)||^2\)</span>, where <span class="math inline">\(\mu(z)\)</span> is the decoder output.”</li>
<li>“The KL divergence term regularizes the latent space by encouraging the learned distribution to be close to a standard normal distribution. The formula for KL divergence between two Gaussians is <span class="math inline">\(L_{KL} = \frac{1}{2} \sum_{i=1}^{d} ( \mu_i^2 + \sigma_i^2 - log(\sigma_i^2) - 1 )\)</span>. This ensures the latent space is well-behaved and continuous.”</li>
<li>“The total loss is a weighted sum of these two terms: <span class="math inline">\(L = L_{reconstruction} + \beta * L_{KL}\)</span>, where <span class="math inline">\(\beta\)</span> controls the strength of the regularization.”</li>
</ul></li>
<li><p><strong>Conclude with the overall goal:</strong></p>
<ul>
<li>“In essence, VAEs aim to learn a probabilistic latent representation that allows us to generate new samples by sampling from this latent space and decoding. The KL divergence forces the latent space to be continuous and complete, which enables meaningful sampling.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush. Give the interviewer time to process the information.</li>
<li><strong>Use simple language:</strong> Avoid overly technical jargon unless you are sure the interviewer is familiar with it. Explain concepts in a clear and concise manner.</li>
<li><strong>Check for understanding:</strong> Pause periodically and ask if they have any questions.</li>
<li><strong>Focus on the “why”</strong>: Explain the motivation behind VAEs and the benefits of using them over traditional autoencoders.</li>
<li><strong>Don’t overwhelm with math:</strong> The formulas are good to have but don’t just recite them. Explain what each term represents and why it’s important. Only delve into the math if the interviewer indicates they want to see it.</li>
<li><strong>Be enthusiastic:</strong> Show that you are passionate about the topic and that you understand it deeply.</li>
<li><strong>Consider having a visual aid:</strong> If it’s a virtual interview, ask if it’s okay to share your screen and show a simple diagram of a VAE.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>