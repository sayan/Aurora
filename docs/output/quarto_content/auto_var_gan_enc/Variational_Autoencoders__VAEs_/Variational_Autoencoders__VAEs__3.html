<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>variational_autoencoders__vaes__3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-vaes-often-struggle-with-scaling-to-high-dimensional-data-such-as-images.-what-are-the-potential-challenges-in-these-scenarios-and-what-techniques-can-be-employed-to-handle-these-issues-effectively" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-vaes-often-struggle-with-scaling-to-high-dimensional-data-such-as-images.-what-are-the-potential-challenges-in-these-scenarios-and-what-techniques-can-be-employed-to-handle-these-issues-effectively">Question: 4. VAEs often struggle with scaling to high-dimensional data such as images. What are the potential challenges in these scenarios, and what techniques can be employed to handle these issues effectively?</h2>
<p><strong>Best Answer</strong></p>
<p>Variational Autoencoders (VAEs) are powerful generative models, but they do face several challenges when scaling to high-dimensional data like images. These challenges stem from both computational limitations and difficulties in learning a meaningful latent representation. Here’s a breakdown of the key issues and some effective techniques to address them:</p>
<p><strong>1. Challenges in High-Dimensional Data with VAEs:</strong></p>
<ul>
<li><p><strong>Increased Computational Cost:</strong> The computational complexity of VAEs grows significantly with the dimensionality of the input data. Encoding and decoding high-resolution images requires substantially more memory and processing power. The encoder and decoder networks, often implemented as deep neural networks, have a large number of parameters that need to be optimized. The forward and backward passes become very expensive.</p></li>
<li><p><strong>Difficulty in Learning Useful Latent Representations:</strong> VAEs aim to learn a low-dimensional latent representation <span class="math inline">\(z\)</span> that captures the essential features of the data. However, in high-dimensional spaces, the latent space can become disentangled or fail to capture the relevant structure. The encoder struggles to map complex, high-dimensional data distributions to a simpler latent distribution (typically a Gaussian). This results in a latent space that doesn’t effectively represent the underlying data manifold.</p></li>
<li><p><strong>Posterior Collapse:</strong> This is a common and critical issue. In posterior collapse, the decoder effectively ignores the latent variable <span class="math inline">\(z\)</span> and relies solely on the decoder’s capacity to reconstruct the input. This happens when the decoder is sufficiently powerful to generate the data without the help of the latent code. The encoder then learns to simply output a standard Gaussian, rendering the latent space useless. Mathematically, the KL divergence term in the VAE loss function, which encourages the latent distribution <span class="math inline">\(q(z|x)\)</span> to be close to the prior <span class="math inline">\(p(z)\)</span>, goes to zero. The VAE loss function is given by:</p>
<p><span class="math display">\[
\mathcal{L}(\theta, \phi) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - D_{KL}(q_{\phi}(z|x) || p(z))
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x\)</span> is the input data,</li>
<li><span class="math inline">\(z\)</span> is the latent variable,</li>
<li><span class="math inline">\(q_{\phi}(z|x)\)</span> is the encoder’s approximate posterior distribution, parameterized by <span class="math inline">\(\phi\)</span>,</li>
<li><span class="math inline">\(p_{\theta}(x|z)\)</span> is the decoder’s likelihood, parameterized by <span class="math inline">\(\theta\)</span>,</li>
<li><span class="math inline">\(p(z)\)</span> is the prior distribution over the latent variable (typically a standard Gaussian), and</li>
<li><span class="math inline">\(D_{KL}\)</span> is the Kullback-Leibler divergence.</li>
</ul>
<p>In posterior collapse, <span class="math inline">\(D_{KL}(q_{\phi}(z|x) || p(z)) \rightarrow 0\)</span>, meaning <span class="math inline">\(q_{\phi}(z|x)\)</span> becomes almost identical to <span class="math inline">\(p(z)\)</span>, regardless of the input <span class="math inline">\(x\)</span>. The model effectively stops using the latent space.</p></li>
<li><p><strong>Vanishing Gradients:</strong> Deep networks used in VAEs can suffer from vanishing gradients, making training difficult, especially in the earlier layers of the network. This issue can hinder the learning of meaningful representations, particularly when dealing with high-dimensional inputs.</p></li>
</ul>
<p><strong>2. Techniques to Handle These Issues:</strong></p>
<ul>
<li><p><strong>Convolutional Architectures (CNNs):</strong> Using Convolutional Neural Networks (CNNs) for both the encoder and decoder is crucial. CNNs are specifically designed to handle high-dimensional data like images by exploiting local correlations and spatial hierarchies. They reduce the number of parameters compared to fully connected networks, alleviating the computational burden.</p>
<ul>
<li><strong>Encoder:</strong> The encoder employs convolutional layers followed by pooling layers to progressively downsample the input image and extract features. The final layers map these features to the parameters (mean and variance) of the latent distribution.</li>
<li><strong>Decoder:</strong> The decoder uses transposed convolutional layers (deconvolution or fractionally-strided convolution) to upsample the latent representation back to the original image dimensions.</li>
</ul></li>
<li><p><strong>More Expressive Encoder/Decoder Architectures:</strong> Beyond basic CNNs, employing more sophisticated architectures can improve performance. Examples include:</p>
<ul>
<li><strong>Residual Networks (ResNets):</strong> ResNets use skip connections to alleviate the vanishing gradient problem and allow for training deeper networks.</li>
<li><strong>Densely Connected Networks (DenseNets):</strong> DenseNets connect each layer to every other layer in a feed-forward fashion, promoting feature reuse and improving gradient flow.</li>
<li><strong>Attention Mechanisms:</strong> Incorporating attention mechanisms allows the model to focus on the most relevant parts of the input image during encoding and decoding. Self-attention can be especially useful.</li>
</ul></li>
<li><p><strong>Advanced Inference Techniques:</strong> The standard VAE uses a simple Gaussian approximate posterior. More sophisticated inference techniques can improve the quality of the learned latent space.</p>
<ul>
<li><strong>Amortized Inference with Normalizing Flows:</strong> Normalizing flows transform a simple distribution (e.g., Gaussian) into a more complex one by applying a sequence of invertible transformations. This allows the encoder to learn a more flexible and accurate approximation of the true posterior. The encoder outputs the parameters of the normalizing flow, which is then used to sample from the approximate posterior.</li>
<li><strong>Auxiliary Deep Generative Models (ADGM):</strong> ADGMs introduce auxiliary variables and networks to improve the inference process and prevent posterior collapse.</li>
</ul></li>
<li><p><strong>Hierarchical Latent Variable Models:</strong> Using a hierarchical latent space can help capture complex dependencies in the data. Instead of a single latent variable <span class="math inline">\(z\)</span>, a hierarchy of latent variables <span class="math inline">\(z_1, z_2, ..., z_L\)</span> is used, where each level captures different levels of abstraction.</p>
<ul>
<li><strong>Variational Hierarchy:</strong> Each latent variable <span class="math inline">\(z_i\)</span> depends on the previous one <span class="math inline">\(z_{i-1}\)</span>, forming a hierarchical generative process. This allows the model to learn more disentangled and interpretable representations.</li>
</ul></li>
<li><p><strong>KL Annealing:</strong> KL annealing is a technique to address posterior collapse by gradually increasing the weight of the KL divergence term in the VAE loss function during training.</p>
<ul>
<li><strong>Warm-up Period:</strong> In the initial stages of training, the KL divergence term is scaled by a small factor (e.g., 0). This allows the decoder to learn to reconstruct the input without being heavily constrained by the prior.</li>
<li><strong>Gradual Increase:</strong> The scaling factor is gradually increased over time until it reaches 1. This encourages the encoder to learn a latent distribution that is close to the prior, preventing posterior collapse.</li>
</ul>
<p>The modified loss function with KL annealing becomes:</p>
<p><span class="math display">\[
\mathcal{L}(\theta, \phi) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - \beta D_{KL}(q_{\phi}(z|x) || p(z))
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is the annealing factor, which starts at 0 and gradually increases to 1.</p></li>
<li><p><strong>Beta-VAE:</strong> Beta-VAE extends the idea of KL annealing by introducing a hyperparameter <span class="math inline">\(\beta\)</span> that controls the strength of the KL divergence term. Unlike KL annealing, <span class="math inline">\(\beta\)</span> remains constant throughout training. A higher <span class="math inline">\(\beta\)</span> encourages more disentangled latent representations, but it can also lead to posterior collapse if set too high. The loss function for Beta-VAE is:</p>
<p><span class="math display">\[
\mathcal{L}(\theta, \phi) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - \beta D_{KL}(q_{\phi}(z|x) || p(z))
\]</span></p></li>
<li><p><strong>Regularization Techniques:</strong> Adding regularization terms to the loss function can help prevent overfitting and improve the generalization ability of the VAE.</p>
<ul>
<li><strong>Weight Decay (L2 Regularization):</strong> Penalizes large weights in the network, preventing overfitting.</li>
<li><strong>Dropout:</strong> Randomly drops out neurons during training, forcing the network to learn more robust representations.</li>
</ul></li>
<li><p><strong>Improved Training Stability:</strong> Techniques to improve the training stability of deep neural networks, such as batch normalization and gradient clipping, can also be helpful in training VAEs with high-dimensional data.</p></li>
</ul>
<p>By combining these techniques, VAEs can be effectively scaled to handle high-dimensional data like images, leading to improved generative performance and more meaningful latent representations.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview, along with communication tips:</p>
<ol type="1">
<li><strong>Start with a concise summary:</strong>
<ul>
<li>“VAEs do face challenges when scaling to high-dimensional data, primarily due to increased computational demands and difficulties in learning useful latent representations. This can lead to issues like posterior collapse.”</li>
</ul></li>
<li><strong>Explain the key challenges in detail:</strong>
<ul>
<li>“Firstly, the computational cost increases significantly with the dimensionality. Encoding and decoding high-resolution images require more resources. The encoder and decoder networks grow in complexity.”</li>
<li>“Secondly, learning a good latent representation becomes harder. The latent space may fail to capture the relevant structure in the data, leading to a disentangled or uninformative latent space.”</li>
<li>“Most importantly, posterior collapse is a major concern. This is where the decoder ignores the latent variable and reconstructs the input directly, rendering the latent space useless. To understand it better, recall the VAE loss function…”</li>
<li><em>Optional: Write the equation for VAE loss on a whiteboard if available.</em>
<ul>
<li>“<span class="math inline">\(\mathcal{L}(\theta, \phi) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - D_{KL}(q_{\phi}(z|x) || p(z))\)</span>”</li>
<li>“In posterior collapse, the KL divergence term goes to zero, meaning the approximate posterior becomes identical to the prior.”</li>
</ul></li>
<li>“Finally, the use of deep networks can lead to vanishing gradients.”</li>
</ul></li>
<li><strong>Introduce the techniques to address these issues:</strong>
<ul>
<li>“Fortunately, there are several techniques that can effectively address these challenges and allow VAEs to scale to high-dimensional data.”</li>
</ul></li>
<li><strong>Explain each technique with relevant details:</strong>
<ul>
<li><strong>Convolutional Architectures:</strong> “Using CNNs for both the encoder and decoder is critical. CNNs exploit local correlations and spatial hierarchies, reducing the number of parameters.”</li>
<li><strong>More Expressive Architectures:</strong> “Employing more sophisticated architectures like ResNets, DenseNets, and Attention Mechanisms can further improve performance.” Briefly explain how each helps.</li>
<li><strong>Advanced Inference:</strong> “Techniques like normalizing flows can help the encoder learn a more flexible and accurate approximation of the true posterior.”</li>
<li><strong>Hierarchical Models:</strong> “Hierarchical latent variable models can capture more complex dependencies in the data by using a hierarchy of latent variables.”</li>
<li><strong>KL Annealing:</strong> “KL annealing is a technique to prevent posterior collapse by gradually increasing the weight of the KL divergence term during training.” Explain the warm-up period and gradual increase.
<ul>
<li><em>Optional: Write the equation for KL Annealing on a whiteboard if available.</em>
<ul>
<li>“<span class="math inline">\(\mathcal{L}(\theta, \phi) = \mathbb{E}_{q_{\phi}(z|x)}[\log p_{\theta}(x|z)] - \beta D_{KL}(q_{\phi}(z|x) || p(z))\)</span>”</li>
<li>“Where <span class="math inline">\(\beta\)</span> gradually goes from 0 to 1”</li>
</ul></li>
</ul></li>
<li><strong>Beta-VAE:</strong> “Beta-VAE uses a hyperparameter to weight the KL Divergence, but it remains constant during training.”</li>
<li><strong>Regularization:</strong> “Regularization techniques like weight decay and dropout help prevent overfitting.”</li>
<li><strong>Training Stability:</strong> “Techniques like batch normalization and gradient clipping can improve training stability.”</li>
</ul></li>
<li><strong>Summarize and Conclude:</strong>
<ul>
<li>“By combining these techniques, VAEs can be effectively scaled to handle high-dimensional data, leading to better generative performance and more meaningful latent representations.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Give the interviewer time to digest the information.</li>
<li><strong>Check for understanding:</strong> Periodically ask if the interviewer has any questions or needs clarification.</li>
<li><strong>Use visuals:</strong> If a whiteboard is available, use it to draw diagrams or write down equations.</li>
<li><strong>Focus on key concepts:</strong> Don’t get bogged down in unnecessary details. Focus on the core ideas and their implications.</li>
<li><strong>Be confident:</strong> Project confidence in your knowledge and ability to explain complex concepts.</li>
<li><strong>Relate to real-world applications:</strong> If possible, give examples of how these techniques are used in real-world applications. For example, mention using convolutional VAEs for image generation or anomaly detection.</li>
<li><strong>Be prepared to elaborate:</strong> The interviewer may ask follow-up questions about specific techniques. Be prepared to provide more detailed explanations and discuss their advantages and disadvantages.</li>
<li><strong>Maintain eye contact and engage:</strong> Try to make eye contact with the interviewer to show that you are engaged in the conversation.</li>
</ul>
<p>By following these guidelines, you can effectively demonstrate your expertise and communicate your understanding of VAEs and their challenges when scaling to high-dimensional data.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>