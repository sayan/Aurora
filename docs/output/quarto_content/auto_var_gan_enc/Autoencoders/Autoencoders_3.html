<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>autoencoders_3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-can-you-differentiate-between-a-standard-autoencoder-and-a-variational-autoencoder-vae-what-mathematical-concepts-underpin-vaes-and-what-are-the-challenges-associated-with-training-them" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-can-you-differentiate-between-a-standard-autoencoder-and-a-variational-autoencoder-vae-what-mathematical-concepts-underpin-vaes-and-what-are-the-challenges-associated-with-training-them">Question: 4. Can you differentiate between a standard autoencoder and a variational autoencoder (VAE)? What mathematical concepts underpin VAEs and what are the challenges associated with training them?</h2>
<p><strong>Best Answer</strong></p>
<p>Let’s dive into the differences between standard autoencoders (AEs) and variational autoencoders (VAEs), the mathematical underpinnings of VAEs, and the challenges associated with training them.</p>
<p><strong>1. Standard Autoencoders vs.&nbsp;Variational Autoencoders: A Fundamental Difference</strong></p>
<ul>
<li><p><strong>Standard Autoencoders (AEs):</strong> AEs learn a deterministic mapping from an input to a lower-dimensional latent space and then reconstruct the input from that latent representation. Essentially, they try to learn a compressed representation of the data. However, they don’t impose any specific structure on the latent space. This can lead to a latent space that is not continuous or well-organized, making it difficult to generate new, meaningful data points by sampling from the latent space. In essence, the encoder learns a function <span class="math inline">\(z = f(x)\)</span>, and the decoder learns a function <span class="math inline">\(\hat{x} = g(z)\)</span>, where <span class="math inline">\(x\)</span> is the input and <span class="math inline">\(\hat{x}\)</span> is the reconstruction. The loss function typically minimizes the reconstruction error:</p>
<p><span class="math display">\[
L = ||x - \hat{x}||^2
\]</span></p></li>
<li><p><strong>Variational Autoencoders (VAEs):</strong> VAEs, on the other hand, take a probabilistic approach. Instead of learning a deterministic latent vector, they learn the parameters of a probability distribution (typically a Gaussian) in the latent space. This means the encoder outputs the mean (<span class="math inline">\(\mu\)</span>) and variance (<span class="math inline">\(\sigma^2\)</span>) of the latent distribution for each input data point. This probabilistic framework encourages a more structured and continuous latent space, making it possible to generate new data points by sampling from this space. The encoder learns <span class="math inline">\(q(z|x)\)</span>, an approximation to the true posterior <span class="math inline">\(p(z|x)\)</span>. The decoder then learns <span class="math inline">\(p(x|z)\)</span>, the probability of reconstructing the input given a latent sample.</p></li>
</ul>
<p><strong>2. Mathematical Concepts Underpinning VAEs</strong></p>
<p>VAEs are rooted in several key mathematical concepts:</p>
<ul>
<li><p><strong>Bayesian Inference:</strong> VAEs attempt to perform Bayesian inference, aiming to approximate the intractable posterior distribution <span class="math inline">\(p(z|x)\)</span>. Because directly calculating <span class="math inline">\(p(z|x)\)</span> is often impossible, VAEs use an inference network (the encoder) to approximate it with <span class="math inline">\(q(z|x)\)</span>.</p></li>
<li><p><strong>Variational Inference:</strong> VAEs employ variational inference to find the best approximation <span class="math inline">\(q(z|x)\)</span> to the true posterior <span class="math inline">\(p(z|x)\)</span>. This involves minimizing the Kullback-Leibler (KL) divergence between <span class="math inline">\(q(z|x)\)</span> and <span class="math inline">\(p(z|x)\)</span>. The goal is to find a tractable distribution <span class="math inline">\(q(z|x)\)</span> that is “close” to the true posterior.</p></li>
<li><p><strong>Kullback-Leibler (KL) Divergence:</strong> The KL divergence measures the difference between two probability distributions. In the context of VAEs, it quantifies how well the approximate posterior <span class="math inline">\(q(z|x)\)</span> matches a prior distribution <span class="math inline">\(p(z)\)</span>, which is typically a standard normal distribution <span class="math inline">\(\mathcal{N}(0, I)\)</span>. The KL divergence ensures that the learned latent distribution resembles a known, well-behaved distribution. The KL divergence is defined as:</p>
<p><span class="math display">\[
D_{KL}(q(z|x) || p(z)) = \int q(z|x) \log \frac{q(z|x)}{p(z)} dz
\]</span></p>
<p>For Gaussian distributions, the KL divergence has a closed-form solution:</p>
<p><span class="math display">\[
D_{KL}(\mathcal{N}(\mu, \sigma^2) || \mathcal{N}(0, 1)) = \frac{1}{2} \sum_{i=1}^{d} (\mu_i^2 + \sigma_i^2 - \log(\sigma_i^2) - 1)
\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the dimensionality of the latent space.</p></li>
<li><p><strong>Reparameterization Trick:</strong> This is a crucial technique that enables backpropagation through the sampling process. Directly sampling from the latent distribution <span class="math inline">\(q(z|x)\)</span> is a non-differentiable operation, preventing gradients from flowing back through the encoder. The reparameterization trick expresses the latent variable <span class="math inline">\(z\)</span> as a deterministic function of the encoder’s output and a random noise variable <span class="math inline">\(\epsilon\)</span> drawn from a fixed distribution (e.g., <span class="math inline">\(\mathcal{N}(0, I)\)</span>). Specifically:</p>
<p><span class="math display">\[
z = \mu + \sigma \odot \epsilon
\]</span></p>
<p>where <span class="math inline">\(\epsilon \sim \mathcal{N}(0, I)\)</span> and <span class="math inline">\(\odot\)</span> denotes element-wise multiplication. Now, the gradients can flow through <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> during backpropagation, allowing the encoder to be trained effectively.</p></li>
<li><p><strong>Evidence Lower Bound (ELBO):</strong> VAEs maximize the Evidence Lower Bound (ELBO) instead of directly maximizing the marginal likelihood <span class="math inline">\(p(x)\)</span>. The ELBO is a lower bound on the log-likelihood of the data and is defined as:</p>
<p><span class="math display">\[
\log p(x) \geq \mathbb{E}_{q(z|x)}[\log p(x|z)] - D_{KL}(q(z|x) || p(z))
\]</span></p>
<p>The ELBO consists of two terms: a reconstruction term (<span class="math inline">\(\mathbb{E}_{q(z|x)}[\log p(x|z)]\)</span>) that encourages the decoder to accurately reconstruct the input, and a regularization term (<span class="math inline">\(D_{KL}(q(z|x) || p(z))\)</span>) that encourages the latent distribution to be similar to the prior. The loss function to be minimized is the negative ELBO:</p>
<p><span class="math display">\[
L = - \mathbb{E}_{q(z|x)}[\log p(x|z)] + D_{KL}(q(z|x) || p(z))
\]</span></p></li>
</ul>
<p><strong>3. Challenges Associated with Training VAEs</strong></p>
<p>Training VAEs can be challenging due to several factors:</p>
<ul>
<li><p><strong>Balancing Reconstruction Quality and Latent Space Regularization:</strong> The ELBO loss function contains two competing terms: reconstruction loss and KL divergence. If the KL divergence term is too strong, the latent space will be well-regularized, but the reconstruction quality may suffer. Conversely, if the reconstruction loss is too strong, the VAE might ignore the regularization term and learn a poorly structured latent space, effectively behaving like a standard autoencoder.</p></li>
<li><p><strong>Posterior Collapse:</strong> A common problem in VAE training is posterior collapse, where the decoder ignores the latent variable <span class="math inline">\(z\)</span>, and the encoder learns to map all inputs to the same (or very similar) latent distribution, often close to the prior. This results in the KL divergence term going to zero, and the model only focuses on minimizing the reconstruction error, rendering the latent space useless for generative purposes.</p></li>
<li><p><strong>Choosing the Right Prior:</strong> The choice of prior distribution <span class="math inline">\(p(z)\)</span> can significantly impact the performance of the VAE. While a standard normal distribution is commonly used, it may not be suitable for all datasets. Selecting a more appropriate prior, or even learning the prior from the data, can improve the quality of the learned latent space and generated samples.</p></li>
<li><p><strong>Hyperparameter Tuning:</strong> VAEs have several hyperparameters that need to be tuned, including the learning rate, the dimensionality of the latent space, and the weights associated with the reconstruction loss and KL divergence. Finding the optimal hyperparameter settings can be time-consuming and computationally expensive. Techniques like grid search, random search, and Bayesian optimization can be used to automate this process.</p></li>
<li><p><strong>Evaluating Generative Models:</strong> Evaluating the quality of generated samples from a VAE can be challenging. Metrics like Inception Score (IS) and Fréchet Inception Distance (FID) are often used, but they have limitations. Visual inspection of the generated samples is also important, but it can be subjective.</p></li>
</ul>
<p>In summary, VAEs offer a powerful probabilistic framework for learning latent representations and generating new data. However, training them effectively requires careful consideration of the underlying mathematical concepts and addressing the challenges associated with balancing reconstruction quality, latent space regularization, and avoiding posterior collapse.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide to deliver this answer effectively in an interview:</p>
<ol type="1">
<li><p><strong>Start with a high-level overview:</strong></p>
<ul>
<li>“The main difference between standard autoencoders and variational autoencoders lies in how they treat the latent space. Standard AEs learn a deterministic mapping, while VAEs learn the parameters of a probability distribution.”</li>
<li>“This probabilistic approach in VAEs is key because it encourages a structured latent space that can be sampled from to generate new data.”</li>
</ul></li>
<li><p><strong>Explain Standard Autoencoders (AEs):</strong></p>
<ul>
<li>“Standard autoencoders, at their core, aim to learn a compressed representation of the input data. The encoder maps the input to a latent vector, and the decoder attempts to reconstruct the original input from this latent vector.”</li>
<li>Mention: “The loss function typically minimizes the difference between the input and the reconstructed output, as shown by the equation: <span class="math inline">\(L = ||x - \hat{x}||^2\)</span>.”</li>
</ul></li>
<li><p><strong>Introduce Variational Autoencoders (VAEs):</strong></p>
<ul>
<li>“Variational Autoencoders, on the other hand, introduce a probabilistic twist. Instead of a single latent vector, the encoder predicts the parameters of a distribution – usually the mean and variance of a Gaussian – for each data point.”</li>
<li>“This forces the latent space to be continuous and well-organized, which is beneficial for generating new data.”</li>
</ul></li>
<li><p><strong>Discuss Mathematical Underpinnings (Key Concepts):</strong></p>
<ul>
<li><strong>Variational Inference and KL Divergence:</strong> “VAEs use variational inference to approximate the true posterior distribution of the latent variables, which is often intractable. A key component here is minimizing the Kullback-Leibler divergence between the approximate posterior and a prior distribution, usually a standard normal. This ensures the latent space is well-behaved.”</li>
<li>Mention: “The KL divergence is mathematically expressed as: <span class="math inline">\(D_{KL}(q(z|x) || p(z)) = \int q(z|x) \log \frac{q(z|x)}{p(z)} dz\)</span>. For Gaussians, there’s a closed-form solution, which simplifies computation.” (Don’t go into heavy detail <em>unless</em> asked).</li>
<li><strong>Reparameterization Trick:</strong> “A crucial element for training VAEs is the reparameterization trick. Since we need to sample from the latent distribution, which is a non-differentiable operation, this trick allows us to backpropagate through the sampling process by expressing the latent variable as a function of the mean, standard deviation, and a random noise variable. We use <span class="math inline">\(z = \mu + \sigma \odot \epsilon\)</span>, where epsilon is noise. This is vital to learn meaningful <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.”</li>
<li><strong>ELBO (Evidence Lower Bound):</strong> “The ELBO is the objective function we actually optimize. It’s a lower bound on the log-likelihood of the data and consists of two parts: a reconstruction term and a KL divergence term. The reconstruction term ensures that the decoder can accurately reconstruct the input, while the KL divergence term encourages the latent distribution to be similar to the prior.” The loss we minimize is: <span class="math inline">\(L = - \mathbb{E}_{q(z|x)}[\log p(x|z)] + D_{KL}(q(z|x) || p(z))\)</span></li>
</ul></li>
<li><p><strong>Address Training Challenges:</strong></p>
<ul>
<li>“Training VAEs presents a few challenges, notably balancing the reconstruction quality and the latent space regularization. If we prioritize reconstruction too much, we risk ending up with a poorly structured latent space, similar to a standard autoencoder.”</li>
<li>“Posterior collapse is another common issue, where the decoder ignores the latent variable, and the encoder maps all inputs to the same distribution. This makes the latent space useless. Proper hyperparameter tuning and architectural choices are key to prevent this.”</li>
<li>Briefly mention hyperparameter tuning and evaluation metrics (IS, FID).</li>
</ul></li>
<li><p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Give the interviewer time to absorb the information.</li>
<li><strong>Use visuals:</strong> If possible (e.g., in a virtual interview with screen sharing), show a diagram of a VAE architecture to illustrate the flow of information.</li>
<li><strong>Check for understanding:</strong> After explaining a complex concept like the reparameterization trick, ask if the interviewer has any questions before moving on.</li>
<li><strong>Relate to practical applications:</strong> If possible, mention how VAEs are used in practice, such as for image generation, anomaly detection, or representation learning.</li>
<li><strong>Gauge Interest:</strong> Adjust the level of mathematical detail based on the interviewer’s background and apparent level of interest. If they seem comfortable with equations, go into more depth. If they prefer a high-level overview, focus on the conceptual understanding.</li>
</ul></li>
</ol>
<p>By following this guide, you can clearly and concisely explain the differences between standard AEs and VAEs, highlight the key mathematical concepts underpinning VAEs, and discuss the challenges associated with training them, demonstrating your senior-level expertise.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>