<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>autoencoders_4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-discuss-potential-methods-or-regularization-techniques-to-prevent-issues-such-as-overfitting-or-latent-space-collapse-in-autoencoders-particularly-in-variational-settings." class="level2">
<h2 class="anchored" data-anchor-id="question-5.-discuss-potential-methods-or-regularization-techniques-to-prevent-issues-such-as-overfitting-or-latent-space-collapse-in-autoencoders-particularly-in-variational-settings.">Question: 5. Discuss potential methods or regularization techniques to prevent issues such as overfitting or latent space collapse in autoencoders, particularly in variational settings.</h2>
<p><strong>Best Answer</strong></p>
<p>Autoencoders, particularly Variational Autoencoders (VAEs), are prone to overfitting and latent space collapse. Overfitting occurs when the autoencoder memorizes the training data, leading to poor generalization to unseen data. Latent space collapse, specific to VAEs, happens when the encoder ignores the input and maps all inputs to a single point or a very small region in the latent space, rendering the decoder ineffective.</p>
<p>Here’s a breakdown of regularization techniques to address these issues:</p>
<p><strong>1. Regularization to Prevent Overfitting:</strong></p>
<ul>
<li><p><strong>L1 and L2 Regularization:</strong> These methods add a penalty term to the loss function based on the weights of the network.</p>
<ul>
<li><p><strong>L1 Regularization (Lasso):</strong> Adds the sum of the absolute values of the weights to the loss function: <span class="math display">\[Loss_{regularized} = Loss_{original} + \lambda \sum_{i} |w_i|\]</span> L1 regularization encourages sparsity in the weights, effectively performing feature selection.</p></li>
<li><p><strong>L2 Regularization (Ridge):</strong> Adds the sum of the squared values of the weights to the loss function: <span class="math display">\[Loss_{regularized} = Loss_{original} + \lambda \sum_{i} w_i^2\]</span> L2 regularization penalizes large weights, leading to a more distributed weight configuration. <span class="math inline">\(\lambda\)</span> is the regularization strength, a hyperparameter that needs tuning.</p></li>
</ul></li>
<li><p><strong>Dropout:</strong> Randomly “drops out” (sets to zero) a proportion of neurons during training. This prevents neurons from co-adapting and forces the network to learn more robust features. It can be applied in both the encoder and decoder.</p></li>
<li><p><strong>Data Augmentation:</strong> Increasing the size and diversity of the training data by applying transformations (e.g., rotations, translations, noise addition) helps the autoencoder generalize better.</p></li>
<li><p><strong>Early Stopping:</strong> Monitoring the validation loss and stopping the training process when the validation loss starts to increase. This prevents the model from continuing to learn noise in the training data.</p></li>
</ul>
<p><strong>2. Regularization to Prevent Latent Space Collapse in VAEs:</strong></p>
<ul>
<li><p><strong>KL Divergence Annealing:</strong> Gradually increasing the weight of the KL divergence term in the VAE loss function during training. The VAE loss function is composed of a reconstruction loss and a KL divergence term:</p>
<p><span class="math display">\[Loss_{VAE} = E_{z \sim q_{\phi}(z|x)}[log \, p_{\theta}(x|z)] - D_{KL}(q_{\phi}(z|x) || p(z))\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(x\)</span> is the input data.</li>
<li><span class="math inline">\(z\)</span> is the latent variable.</li>
<li><span class="math inline">\(q_{\phi}(z|x)\)</span> is the encoder’s approximate posterior distribution.</li>
<li><span class="math inline">\(p_{\theta}(x|z)\)</span> is the decoder’s likelihood of reconstructing <span class="math inline">\(x\)</span> given <span class="math inline">\(z\)</span>.</li>
<li><span class="math inline">\(p(z)\)</span> is the prior distribution over the latent space (typically a standard Gaussian).</li>
<li><span class="math inline">\(D_{KL}\)</span> is the Kullback-Leibler divergence, measuring the difference between <span class="math inline">\(q_{\phi}(z|x)\)</span> and <span class="math inline">\(p(z)\)</span>.</li>
</ul>
<p>Annealing involves a scaling factor <span class="math inline">\(\beta(t)\)</span> on the KL divergence:</p>
<p><span class="math display">\[Loss_{VAE, annealed} = E_{z \sim q_{\phi}(z|x)}[log \, p_{\theta}(x|z)] - \beta(t) * D_{KL}(q_{\phi}(z|x) || p(z))\]</span></p>
<p>Where <span class="math inline">\(\beta(t)\)</span> increases from 0 to 1 over time (<span class="math inline">\(t\)</span>). This allows the autoencoder to first focus on learning a good reconstruction before enforcing the prior distribution, which helps prevent premature collapse. Common annealing schedules include linear, sigmoid, and cyclical functions.</p></li>
<li><p><strong><span class="math inline">\(\beta\)</span>-VAE:</strong> Introduces a hyperparameter <span class="math inline">\(\beta\)</span> to control the strength of the KL divergence term:</p>
<p><span class="math display">\[Loss_{\beta-VAE} = E_{z \sim q_{\phi}(z|x)}[log \, p_{\theta}(x|z)] - \beta * D_{KL}(q_{\phi}(z|x) || p(z))\]</span></p>
<p>A <span class="math inline">\(\beta &gt; 1\)</span> encourages more disentangled latent representations by forcing the approximate posterior closer to the prior. This comes at the cost of potentially lower reconstruction quality. Finding the right <span class="math inline">\(\beta\)</span> value requires experimentation.</p></li>
<li><p><strong>Capacity Constraints:</strong> Impose limits on the information capacity of the latent space. This can be achieved by limiting the number of latent dimensions or by using techniques like Information Bottleneck.</p></li>
<li><p><strong>Adversarial Regularization:</strong> Using a discriminator network to ensure that the latent distribution matches the prior distribution. This forces the encoder to produce latent codes that are indistinguishable from the prior, preventing collapse.</p></li>
<li><p><strong>Wasserstein Autoencoders (WAEs):</strong> Instead of using KL divergence, WAEs use the Wasserstein distance (Earth Mover’s Distance) to regularize the latent space. The Wasserstein distance is more robust to non-overlapping distributions and can lead to better-behaved latent spaces. WAEs optimize the following objective:</p>
<p><span class="math display">\[Loss_{WAE} = E_{p(x)}[E_{q_{\phi}(z|x)}[log \, p_{\theta}(x|z)]] + \lambda * W(q_{\phi}(z), p(z))\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(W(q_{\phi}(z), p(z))\)</span> is the Wasserstein distance between the aggregated posterior <span class="math inline">\(q_{\phi}(z) = E_{p(x)}[q_{\phi}(z|x)]\)</span> and the prior <span class="math inline">\(p(z)\)</span>.</li>
<li><span class="math inline">\(\lambda\)</span> is a hyperparameter controlling the regularization strength.</li>
</ul></li>
<li><p><strong>Normalization Techniques:</strong> Using batch normalization or layer normalization within the encoder and decoder can stabilize training and prevent extreme values in the latent space, thus reducing the risk of collapse.</p></li>
<li><p><strong>Variational Information Bottleneck (VIB):</strong> VIB is a technique that encourages the latent space to be both informative about the input and compact. It explicitly minimizes the mutual information between the latent code and the input, subject to the constraint that the latent code should still be able to reconstruct the input.</p></li>
</ul>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Hyperparameter Tuning:</strong> The regularization strength (e.g., <span class="math inline">\(\lambda\)</span> in L1/L2 regularization, <span class="math inline">\(\beta\)</span> in <span class="math inline">\(\beta\)</span>-VAE) needs to be carefully tuned using a validation set.</li>
<li><strong>Computational Cost:</strong> Some regularization techniques (e.g., adversarial regularization, WAEs) can significantly increase the computational cost of training.</li>
<li><strong>Interpretability:</strong> Disentangled latent representations (achieved through <span class="math inline">\(\beta\)</span>-VAE) can improve the interpretability of the latent space.</li>
<li><strong>Dataset Dependence:</strong> The best regularization technique depends on the specific dataset and the architecture of the autoencoder.</li>
</ul>
<p><strong>3. Mathematical Background for KL-Divergence:</strong></p>
<p>The Kullback-Leibler (KL) divergence is a measure of how one probability distribution differs from a second, reference probability distribution. In the context of VAEs, it quantifies the difference between the encoder’s approximate posterior distribution <span class="math inline">\(q_{\phi}(z|x)\)</span> and the prior distribution <span class="math inline">\(p(z)\)</span>.</p>
<p>For continuous distributions, the KL divergence is defined as:</p>
<p><span class="math display">\[D_{KL}(q || p) = \int q(z) \, log\left(\frac{q(z)}{p(z)}\right) dz\]</span></p>
<p>In VAEs, we typically assume that both <span class="math inline">\(q_{\phi}(z|x)\)</span> and <span class="math inline">\(p(z)\)</span> are Gaussian distributions. Specifically, <span class="math inline">\(p(z)\)</span> is a standard normal distribution <span class="math inline">\(N(0, I)\)</span>, and <span class="math inline">\(q_{\phi}(z|x)\)</span> is a Gaussian distribution with mean <span class="math inline">\(\mu_{\phi}(x)\)</span> and variance <span class="math inline">\(\sigma_{\phi}^2(x)\)</span>, where <span class="math inline">\(\mu_{\phi}(x)\)</span> and <span class="math inline">\(\sigma_{\phi}(x)\)</span> are outputs of the encoder.</p>
<p>In this case, the KL divergence has a closed-form solution:</p>
<p><span class="math display">\[D_{KL}(q_{\phi}(z|x) || p(z)) = \frac{1}{2} \sum_{i=1}^{d} \left( \sigma_i^2 + \mu_i^2 - log(\sigma_i^2) - 1 \right)\]</span></p>
<p>Where: * <span class="math inline">\(d\)</span> is the dimensionality of the latent space. * <span class="math inline">\(\mu_i\)</span> is the <span class="math inline">\(i\)</span>-th component of the mean vector <span class="math inline">\(\mu_{\phi}(x)\)</span>. * <span class="math inline">\(\sigma_i^2\)</span> is the <span class="math inline">\(i\)</span>-th component of the variance vector <span class="math inline">\(\sigma_{\phi}^2(x)\)</span>.</p>
<p>This closed-form solution allows for efficient computation of the KL divergence during training. By minimizing this term, the VAE encourages the encoder’s approximate posterior to be similar to the prior distribution, preventing the latent space from deviating too far from the assumed structure.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with the Problem Statement:</strong>
<ul>
<li>“Autoencoders, especially VAEs, are susceptible to overfitting and latent space collapse. Overfitting leads to poor generalization, while latent space collapse renders the latent space meaningless.”</li>
</ul></li>
<li><strong>Discuss Regularization for Overfitting:</strong>
<ul>
<li>“To combat overfitting, we can use standard regularization techniques like L1 and L2 regularization. L1 adds a penalty to the loss proportional to the absolute values of the weights, encouraging sparsity. L2 adds a penalty proportional to the squared values, preventing large weights.”</li>
<li>Show the L1 and L2 equations.</li>
<li>“Dropout is another effective technique where we randomly drop out neurons during training. This prevents co-adaptation and forces the network to learn more robust features. Data augmentation can also help by increasing the size and diversity of the training data.”</li>
<li>“Finally, Early stopping, based on monitoring validation set performance, is useful.”</li>
</ul></li>
<li><strong>Dive into Latent Space Collapse in VAEs:</strong>
<ul>
<li>“Latent space collapse is a more specific problem in VAEs where the encoder ignores the input and maps everything to a small region in the latent space. The decoder then becomes useless.”</li>
</ul></li>
<li><strong>Explain KL Divergence Annealing:</strong>
<ul>
<li>“One approach to prevent collapse is KL divergence annealing. The VAE loss function has a reconstruction loss and a KL divergence term. We gradually increase the weight of the KL divergence during training. Initially reconstruction is emphasized, and later, the KL divergence is enforced.”</li>
<li>Explain VAE Loss equation, and KL Annealing.</li>
<li>“This allows the autoencoder to learn meaningful features before enforcing the prior distribution, preventing premature collapse.”</li>
</ul></li>
<li><strong>Discuss <span class="math inline">\(\beta\)</span>-VAE:</strong>
<ul>
<li>“Another technique is <span class="math inline">\(\beta\)</span>-VAE, where we introduce a hyperparameter <span class="math inline">\(\beta\)</span> to control the strength of the KL divergence. A <span class="math inline">\(\beta\)</span> greater than 1 encourages more disentangled latent representations but may reduce reconstruction quality. Finding the right <span class="math inline">\(\beta\)</span> value is key.”</li>
</ul></li>
<li><strong>Mention other techniques:</strong>
<ul>
<li>“Other methods include capacity constraints, adversarial regularization, and using Wasserstein Autoencoders (WAEs).”</li>
</ul></li>
<li><strong>Explain KL-Divergence Math:</strong>
<ul>
<li>Only if the interviewer is interested in the mathematical underpinnings, then show the equations and explain the components.</li>
<li>“The KL Divergence measures how much one distribution differs from another distribution.”</li>
</ul></li>
<li><strong>Address Real-World Considerations:</strong>
<ul>
<li>“It’s important to remember that hyperparameter tuning is crucial, and the best regularization technique depends on the specific dataset and autoencoder architecture. Some techniques, like adversarial regularization, can be computationally expensive.”</li>
<li>“Disentangled latent representations can improve interpretability, which is valuable in many applications.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask if they have any questions.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you are in a virtual interview, consider sharing your screen and sketching out the loss functions or network architectures. If in person, ask for a whiteboard if needed.</li>
<li><strong>Tailor the Depth:</strong> Adjust the level of detail based on the interviewer’s background. If they seem less familiar with the concepts, focus on the high-level overview. If they are more experienced, you can delve into the mathematical details.</li>
<li><strong>Show Enthusiasm:</strong> Express your genuine interest in the topic.</li>
</ul>
<p>By following this structure and keeping the communication tips in mind, you can effectively demonstrate your expertise in regularization techniques for autoencoders during the interview.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>