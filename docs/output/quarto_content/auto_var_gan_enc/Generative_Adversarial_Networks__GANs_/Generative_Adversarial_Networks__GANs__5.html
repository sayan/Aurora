<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>generative_adversarial_networks__gans__5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-6.-discuss-the-theoretical-underpinnings-and-limitations-of-gans.-are-there-any-formal-convergence-guarantees-and-under-what-conditions-might-these-theoretical-properties-break-down" class="level2">
<h2 class="anchored" data-anchor-id="question-6.-discuss-the-theoretical-underpinnings-and-limitations-of-gans.-are-there-any-formal-convergence-guarantees-and-under-what-conditions-might-these-theoretical-properties-break-down">Question: 6. Discuss the theoretical underpinnings and limitations of GANs. Are there any formal convergence guarantees, and under what conditions might these theoretical properties break down?</h2>
<p><strong>Best Answer</strong></p>
<p>Generative Adversarial Networks (GANs) are a powerful class of generative models introduced by Ian Goodfellow et al.&nbsp;in 2014. They are based on a game-theoretic framework where two neural networks, a generator (<span class="math inline">\(G\)</span>) and a discriminator (<span class="math inline">\(D\)</span>), compete against each other. The generator tries to produce synthetic data that resembles the real data distribution, while the discriminator tries to distinguish between real and generated samples.</p>
<section id="theoretical-underpinnings-game-theory-and-nash-equilibrium" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-underpinnings-game-theory-and-nash-equilibrium">Theoretical Underpinnings: Game Theory and Nash Equilibrium</h3>
<p>GANs are formulated as a minimax game with a value function <span class="math inline">\(V(G, D)\)</span>:</p>
<p><span class="math display">\[
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
\]</span></p>
<p>where: - <span class="math inline">\(x\)</span> represents real data sampled from the real data distribution <span class="math inline">\(p_{data}(x)\)</span>. - <span class="math inline">\(z\)</span> represents a random noise vector sampled from a prior distribution <span class="math inline">\(p_z(z)\)</span> (e.g., Gaussian). - <span class="math inline">\(G(z)\)</span> is the generator’s output, i.e., the generated data. - <span class="math inline">\(D(x)\)</span> is the discriminator’s probability estimate that <span class="math inline">\(x\)</span> is real. - <span class="math inline">\(\mathbb{E}\)</span> denotes the expected value.</p>
<p>The discriminator <span class="math inline">\(D\)</span> tries to maximize <span class="math inline">\(V(D, G)\)</span>, learning to accurately classify real and generated samples. The generator <span class="math inline">\(G\)</span> tries to minimize <span class="math inline">\(V(D, G)\)</span>, learning to generate samples that fool the discriminator.</p>
<p>The optimal discriminator <span class="math inline">\(D^*\)</span> for a given generator <span class="math inline">\(G\)</span> can be found analytically:</p>
<p><span class="math display">\[
D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}
\]</span></p>
<p>where <span class="math inline">\(p_g(x)\)</span> is the distribution of the generated data, <span class="math inline">\(G(z)\)</span>.</p>
<p>Plugging <span class="math inline">\(D^*(x)\)</span> back into the value function, we get:</p>
<p><span class="math display">\[
C(G) = \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}}[\log D^*(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D^*(G(z)))] \\
       = \mathbb{E}_{x \sim p_{data}}\left[\log \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\right] + \mathbb{E}_{x \sim p_g}\left[\log \frac{p_g(x)}{p_{data}(x) + p_g(x)}\right]
\]</span></p>
<p>The global optimum is achieved when <span class="math inline">\(p_g(x) = p_{data}(x)\)</span>, i.e., when the generator perfectly replicates the real data distribution. At this point, <span class="math inline">\(D^*(x) = \frac{1}{2}\)</span>, and <span class="math inline">\(C(G) = -\log 4\)</span>.</p>
<p>The original paper showed that minimizing <span class="math inline">\(C(G)\)</span> is equivalent to minimizing the Jensen-Shannon Divergence (JSD) between <span class="math inline">\(p_{data}\)</span> and <span class="math inline">\(p_g\)</span>:</p>
<p><span class="math display">\[
JSD(p_{data} || p_g) = \frac{1}{2}\mathbb{E}_{x \sim p_{data}}\left[\log \frac{p_{data}(x)}{(p_{data}(x) + p_g(x))/2}\right] + \frac{1}{2}\mathbb{E}_{x \sim p_g}\left[\log \frac{p_g(x)}{(p_{data}(x) + p_g(x))/2}\right]
\]</span></p>
<p>Specifically, <span class="math inline">\(C(G) = -\log 4 + 2 \cdot JSD(p_{data} || p_g)\)</span>. Minimizing <span class="math inline">\(C(G)\)</span> is equivalent to minimizing <span class="math inline">\(JSD(p_{data} || p_g)\)</span>.</p>
<p>The training process aims to find a Nash equilibrium, where neither the generator nor the discriminator can improve their performance by unilaterally changing their strategy.</p>
</section>
<section id="limitations-and-challenges" class="level3">
<h3 class="anchored" data-anchor-id="limitations-and-challenges">Limitations and Challenges</h3>
<p>Despite their theoretical elegance, GANs face several limitations in practice:</p>
<ol type="1">
<li><p><strong>Non-Convergence:</strong> GAN training is notoriously unstable. Unlike typical optimization problems, GANs involve a dynamic interplay between two networks, making convergence difficult to guarantee. The alternating optimization procedure can lead to oscillations and mode collapse.</p></li>
<li><p><strong>Mode Collapse:</strong> The generator may learn to produce only a limited variety of samples, failing to capture the full diversity of the real data distribution. This happens when the generator finds a subset of the data distribution that easily fools the discriminator, and it gets stuck in this mode. Mathematically, <span class="math inline">\(p_g(x)\)</span> becomes highly peaked, rather than approximating <span class="math inline">\(p_{data}(x)\)</span> across its entire support.</p></li>
<li><p><strong>Vanishing Gradients:</strong> The discriminator can become too good at distinguishing real and generated samples, leading to near-zero gradients for the generator. This prevents the generator from learning effectively because its loss signal is too weak. This occurs because when the discriminator easily distinguishes real from generated data, <span class="math inline">\(D(x) \approx 1\)</span> and <span class="math inline">\(D(G(z)) \approx 0\)</span>. This leads to <span class="math inline">\(\log(1 - D(G(z))) \approx -\infty\)</span>, but the gradients saturate and become close to zero.</p></li>
<li><p><strong>Choice of Divergence:</strong> Minimizing the JSD can be problematic, especially when the real and generated distributions have disjoint support, which is often the case in high-dimensional spaces. In this case, the JSD is constant (<span class="math inline">\(\log 2\)</span>), providing no useful gradient information for the generator.</p></li>
<li><p><strong>Lack of Evaluation Metrics:</strong> Quantifying the quality and diversity of generated samples is challenging. Metrics like Inception Score (IS) and Fréchet Inception Distance (FID) are widely used but have their own limitations and may not always correlate well with human perception.</p></li>
<li><p><strong>Sensitivity to Hyperparameters:</strong> GAN performance is highly sensitive to hyperparameters such as learning rates, batch sizes, and network architectures. Careful tuning is often required to achieve good results.</p></li>
</ol>
</section>
<section id="formal-convergence-guarantees" class="level3">
<h3 class="anchored" data-anchor-id="formal-convergence-guarantees">Formal Convergence Guarantees</h3>
<p>The original GAN paper provides theoretical results suggesting convergence under certain conditions:</p>
<ul>
<li><p><strong>Assumptions:</strong> The generator and discriminator have sufficient capacity (e.g., they are represented by deep neural networks) to approximate the true data distribution and the optimal discriminator function. The optimization process converges to a Nash equilibrium. The objective function is convex.</p></li>
<li><p><strong>Guarantees:</strong> Under these idealized assumptions, the training process should converge to a point where the generated distribution matches the real data distribution (<span class="math inline">\(p_g(x) = p_{data}(x)\)</span>).</p></li>
</ul>
<p>However, these theoretical guarantees often break down in practice because:</p>
<ul>
<li><p><strong>Network Capacity:</strong> Real-world neural networks have limited capacity and may not be able to perfectly represent complex data distributions.</p></li>
<li><p><strong>Non-Convexity:</strong> The objective function is highly non-convex, making it difficult for optimization algorithms to find the global optimum (Nash equilibrium). Gradient-based optimization methods can get stuck in local minima or saddle points.</p></li>
<li><p><strong>Finite Data:</strong> Training data is always finite, leading to generalization errors. The discriminator may overfit to the training data, causing the generator to learn a suboptimal distribution.</p></li>
<li><p><strong>Computational Constraints:</strong> Training GANs requires significant computational resources. Limited computational power may prevent the optimization process from converging to a satisfactory solution.</p></li>
<li><p><strong>Optimization Algorithm:</strong> The alternating gradient descent used to train GANs is not guaranteed to converge to a Nash equilibrium, even in simpler game settings. Simultaneous gradient descent can lead to oscillations.</p></li>
</ul>
</section>
<section id="research-directions" class="level3">
<h3 class="anchored" data-anchor-id="research-directions">Research Directions</h3>
<p>Several research directions aim to address the limitations of GANs:</p>
<ul>
<li><p><strong>Alternative Divergences:</strong> Explore alternative divergence measures that are less prone to vanishing gradients or mode collapse. Examples include Wasserstein GANs (WGANs) that minimize the Earth Mover’s Distance (Wasserstein distance) and rely on the Kantorovich-Rubinstein duality. Wasserstein distance provides a smoother gradient signal even when the distributions have disjoint support. Other approaches use f-divergences or integral probability metrics (IPMs).</p></li>
<li><p><strong>Regularization Techniques:</strong> Apply regularization techniques to stabilize training and prevent overfitting. Examples include gradient penalties, spectral normalization, and batch normalization. Gradient penalty helps to enforce the Lipschitz constraint on the discriminator, which is required for the Wasserstein distance to be well-defined.</p></li>
<li><p><strong>Improved Architectures:</strong> Develop more robust network architectures that are less prone to mode collapse and vanishing gradients. Examples include deep convolutional GANs (DCGANs), progressive GANs (ProGANs), and style-based GANs (StyleGANs).</p></li>
<li><p><strong>Training Strategies:</strong> Explore alternative training strategies that are more stable and efficient. Examples include two-time-scale update rule (TTUR) and using ensembles of discriminators.</p></li>
<li><p><strong>Evaluation Metrics:</strong> Develop more reliable and informative evaluation metrics that better reflect the quality and diversity of generated samples.</p></li>
</ul>
<p>In summary, while GANs have a solid game-theoretic foundation and theoretical convergence guarantees under idealized conditions, their practical limitations arise from network capacity, non-convexity, finite data, computational constraints, and the choice of divergence measures. Ongoing research efforts focus on addressing these limitations and improving the stability, efficiency, and quality of GAN training.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to articulate this answer effectively in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Basics (30 seconds):</strong></p>
<ul>
<li>“GANs are generative models based on a game between two neural networks: the generator, which creates data, and the discriminator, which distinguishes between real and generated data.”</li>
<li>“They are trained using a minimax game objective, aiming to find a Nash equilibrium.”</li>
</ul></li>
<li><p><strong>Explain the Theoretical Foundation (1 minute):</strong></p>
<ul>
<li>“The core idea is to minimize the Jensen-Shannon Divergence between the generated and real data distributions.”</li>
<li>“The objective function can be expressed as <span class="math inline">\(\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]\)</span>. This formulation helps the generator learn to produce samples that the discriminator cannot distinguish from real data.”</li>
<li>“The optimal discriminator <span class="math inline">\(D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_g(x)}\)</span>. Then the problem can be reduced to minimize the Jensen-Shannon Divergence (JSD) between <span class="math inline">\(p_{data}\)</span> and <span class="math inline">\(p_g\)</span>”</li>
</ul>
<p><em>Communication Tip:</em> When showing the equation, briefly explain each term and its role. Do not rush. Pause slightly between each part.</p></li>
<li><p><strong>Acknowledge Idealized Convergence (30 seconds):</strong></p>
<ul>
<li>“Theoretically, under ideal conditions like infinite capacity networks and a convex objective, GAN training should converge to a point where the generated distribution perfectly matches the real distribution.”</li>
</ul></li>
<li><p><strong>Discuss Limitations (2 minutes):</strong></p>
<ul>
<li>“However, in practice, GANs suffer from several challenges: non-convergence, mode collapse, vanishing gradients, and sensitivity to hyperparameters.”</li>
<li>“Mode collapse happens when the generator only produces a limited variety of samples. Vanishing gradients occur when the discriminator becomes too good, hindering the generator’s learning.”</li>
<li>“The choice of divergence (e.g., JSD) can also be problematic, especially when the real and generated distributions have disjoint support, which is common in high-dimensional spaces.”</li>
</ul>
<p><em>Communication Tip:</em> Choose 2-3 key limitations to focus on. Explain <em>why</em> these problems arise, using intuitive examples if possible.</p></li>
<li><p><strong>Explain Why Theory Breaks Down (1 minute):</strong></p>
<ul>
<li>“The theoretical guarantees rely on assumptions that don’t hold in the real world. Networks have limited capacity, objective functions are non-convex, and we only have finite data.”</li>
<li>“Optimization algorithms like alternating gradient descent are not guaranteed to find a Nash equilibrium in non-convex games.”</li>
</ul></li>
<li><p><strong>Mention Research Directions (1 minute):</strong></p>
<ul>
<li>“Ongoing research focuses on addressing these limitations by exploring alternative divergences like the Wasserstein distance (WGANs), using regularization techniques like gradient penalties, and developing improved architectures like StyleGANs.”</li>
<li>“Researchers are also working on better evaluation metrics to assess the quality and diversity of generated samples.”</li>
</ul>
<p><em>Communication Tip:</em> Briefly highlight a few research directions you find particularly interesting or relevant.</p></li>
<li><p><strong>Conclude Briefly (15 seconds):</strong></p>
<ul>
<li>“In conclusion, while GANs are theoretically sound, practical challenges require ongoing research to improve their stability, efficiency, and performance.”</li>
</ul></li>
</ol>
<p><em>Overall Communication Tips:</em></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush. It’s better to cover fewer points in detail than to quickly gloss over everything.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask, “Does that make sense?” or “Would you like me to elaborate on any of these points?”</li>
<li><strong>Tailor to the Interviewer:</strong> Adjust the level of detail based on the interviewer’s background and the flow of the conversation. If they seem particularly interested in one aspect, delve deeper into that area.</li>
<li><strong>Show Enthusiasm:</strong> Let your passion for the subject shine through!</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>