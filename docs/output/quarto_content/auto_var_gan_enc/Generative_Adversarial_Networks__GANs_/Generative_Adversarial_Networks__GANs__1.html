<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>generative_adversarial_networks__gans__1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-2.-what-are-the-common-challenges-encountered-when-training-gans-please-discuss-issues-such-as-mode-collapse-training-instability-and-non-convergence-and-suggest-strategies-to-mitigate-these-problems." class="level2">
<h2 class="anchored" data-anchor-id="question-2.-what-are-the-common-challenges-encountered-when-training-gans-please-discuss-issues-such-as-mode-collapse-training-instability-and-non-convergence-and-suggest-strategies-to-mitigate-these-problems.">Question: 2. What are the common challenges encountered when training GANs? Please discuss issues such as mode collapse, training instability, and non-convergence, and suggest strategies to mitigate these problems.</h2>
<p><strong>Best Answer</strong></p>
<p>Generative Adversarial Networks (GANs), while powerful, are notoriously difficult to train. The training process is essentially a min-max game between two neural networks: the Generator (<span class="math inline">\(G\)</span>) and the Discriminator (<span class="math inline">\(D\)</span>). This adversarial setup can lead to several challenges:</p>
<ul>
<li><p><strong>Mode Collapse:</strong></p>
<ul>
<li><strong>Definition:</strong> Mode collapse occurs when the generator learns to produce only a limited variety of outputs, effectively “collapsing” to a few modes of the target distribution. Instead of generating diverse samples, the generator might repeatedly produce the same or very similar outputs that fool the discriminator.</li>
<li><strong>Why it happens:</strong> This often happens because the generator finds a specific set of outputs that the discriminator consistently classifies as real. The generator then focuses solely on producing these outputs, ignoring other parts of the data distribution. This is exacerbated when the discriminator isn’t providing a diverse enough signal.</li>
<li><strong>Mitigation Strategies:</strong>
<ul>
<li><strong>Mini-batch Discrimination:</strong>
<ul>
<li>The discriminator examines entire mini-batches of generated samples instead of individual samples. It learns to recognize statistical differences between real and generated mini-batches, thus encouraging the generator to produce more diverse outputs.</li>
<li>This can be mathematically represented by creating a matrix <span class="math inline">\(T = f(x)W \in R^{A \times B}\)</span>, where <span class="math inline">\(f(x)\)</span> represents the output of an intermediate layer of the discriminator for input <span class="math inline">\(x\)</span>, and <span class="math inline">\(W\)</span> is a trainable weight matrix. Then, a similarity metric <span class="math inline">\(o(x_i, x_j) = exp(-||T_{x_i} - T_{x_j}||_1)\)</span> is computed between all pairs of samples within the mini-batch. The mini-batch discrimination feature is then the sum of these similarities for each sample: <span class="math inline">\(M_i = \sum_{j=1}^n o(x_i, x_j)\)</span>. This <span class="math inline">\(M_i\)</span> is then concatenated with the original features and fed into the next layer of the discriminator.</li>
</ul></li>
<li><strong>Unrolled GANs:</strong>
<ul>
<li>The generator is trained to fool not just the current discriminator, but also future versions of the discriminator after it has been updated. This forces the generator to be more robust and less likely to exploit weaknesses in a specific discriminator.</li>
<li>The unrolled optimization can be represented as updating the generator based on <span class="math inline">\(k\)</span> steps of discriminator training: <span class="math display">\[G^* = \arg \min_G L_G(G, D^{(k)})\]</span> where <span class="math inline">\(D^{(k)}\)</span> represents the discriminator after <span class="math inline">\(k\)</span> updates, given a fixed generator <span class="math inline">\(G\)</span>.</li>
</ul></li>
<li><strong>Increasing Generator’s Capacity:</strong> A more complex generator may be able to represent a wider range of data distribution and avoid converging to limited modes.</li>
</ul></li>
</ul></li>
<li><p><strong>Training Instability:</strong></p>
<ul>
<li><strong>Definition:</strong> GAN training is often unstable due to the adversarial nature of the learning process. Small changes in either the generator or discriminator can lead to significant changes in the other’s behavior, causing oscillations and making it difficult to reach a stable equilibrium. This instability manifests as fluctuating loss values and generated samples of varying quality throughout training.</li>
<li><strong>Why it happens:</strong> The simultaneous training of two competing networks makes it difficult to find a stable Nash equilibrium. The generator is trying to minimize its loss while the discriminator is trying to maximize its own, resulting in a dynamic system that can easily become unstable. Vanishing gradients in the discriminator or exploding gradients in the generator can also contribute.</li>
<li><strong>Mitigation Strategies:</strong>
<ul>
<li><strong>Gradient Clipping:</strong>
<ul>
<li>Limits the magnitude of gradients during backpropagation to prevent exploding gradients. This helps to stabilize the training process by preventing large updates that can disrupt the equilibrium.</li>
<li>Mathematically, if <span class="math inline">\(||\nabla_\theta L|| &gt; c\)</span>, then <span class="math inline">\(\nabla_\theta L = c \frac{\nabla_\theta L}{||\nabla_\theta L||}\)</span>, where <span class="math inline">\(L\)</span> is the loss function, <span class="math inline">\(\theta\)</span> represents the parameters, and <span class="math inline">\(c\)</span> is the clipping threshold.</li>
</ul></li>
<li><strong>Weight Clipping (original GAN):</strong>
<ul>
<li>A crude way to enforce a Lipschitz constraint on the discriminator, as proposed in the original GAN paper, although this approach is generally disfavored now. Weights are clipped to a specific range after each update.</li>
<li>If <span class="math inline">\(w_i &gt; c\)</span> then <span class="math inline">\(w_i = c\)</span>, and if <span class="math inline">\(w_i &lt; -c\)</span> then <span class="math inline">\(w_i = -c\)</span>, where <span class="math inline">\(w_i\)</span> is the <span class="math inline">\(i\)</span>-th weight and <span class="math inline">\(c\)</span> is the clipping constant.</li>
</ul></li>
<li><strong>Using a Wasserstein GAN (WGAN) or WGAN-GP:</strong>
<ul>
<li>WGANs use the Earth Mover’s distance (Wasserstein distance) instead of the Jensen-Shannon divergence, which provides a smoother loss landscape and more stable gradients. WGAN-GP adds a gradient penalty to enforce a Lipschitz constraint on the discriminator without weight clipping, leading to more stable training.</li>
<li>The WGAN loss function is: <span class="math inline">\(L = \mathbb{E}_{x \sim P_r}[D(x)] - \mathbb{E}_{x \sim P_g}[D(x)]\)</span>, where <span class="math inline">\(P_r\)</span> is the real data distribution and <span class="math inline">\(P_g\)</span> is the generated data distribution. The discriminator <span class="math inline">\(D\)</span> no longer classifies real vs.&nbsp;fake, but instead tries to estimate the Wasserstein distance.</li>
<li>The WGAN-GP adds a gradient penalty term to the WGAN loss: <span class="math inline">\(L_{GP} = \mathbb{E}_{\hat{x} \sim P_{\hat{x}}}[(||\nabla_{\hat{x}}D(\hat{x})||_2 - 1)^2]\)</span>, where <span class="math inline">\(\hat{x}\)</span> is sampled along straight lines between points in <span class="math inline">\(P_r\)</span> and <span class="math inline">\(P_g\)</span>. The total loss becomes <span class="math inline">\(L + \lambda L_{GP}\)</span>, with <span class="math inline">\(\lambda\)</span> as a hyperparameter.</li>
</ul></li>
<li><strong>Using Spectral Normalization:</strong>
<ul>
<li>Normalizes the weights of the discriminator layers by dividing by their spectral norm. This helps to control the Lipschitz constant of the discriminator, leading to more stable training and better gradient flow.</li>
<li><span class="math inline">\(W_{SN} = \frac{W}{\sigma(W)}\)</span>, where <span class="math inline">\(\sigma(W)\)</span> is the spectral norm (largest singular value) of the weight matrix <span class="math inline">\(W\)</span>. This normalization is applied before each forward pass.</li>
</ul></li>
<li><strong>Balancing the Discriminator and Generator:</strong>
<ul>
<li>If one network is much stronger than the other, it can lead to instability. Adjusting the learning rates or architectures of the generator and discriminator to keep them balanced is crucial.</li>
</ul></li>
</ul></li>
</ul></li>
<li><p><strong>Non-Convergence:</strong></p>
<ul>
<li><strong>Definition:</strong> GANs may fail to converge to a stable equilibrium, meaning that the generator and discriminator continue to fluctuate without improving significantly over time. This is often related to the training instability issues discussed above.</li>
<li><strong>Why it happens:</strong> The non-convex nature of the GAN objective function and the adversarial training dynamics can lead to situations where the networks oscillate or get stuck in local optima. The lack of a well-defined convergence metric makes it difficult to determine when training should stop.</li>
<li><strong>Mitigation Strategies:</strong>
<ul>
<li><strong>Feature Matching:</strong>
<ul>
<li>Instead of directly maximizing the discriminator’s output, the generator is trained to match the feature statistics of the real data in an intermediate layer of the discriminator. This provides a more stable training signal.</li>
<li>The generator loss can be defined as: <span class="math inline">\(L_G = ||\mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{z \sim p(z)}[f(G(z))]||_2\)</span>, where <span class="math inline">\(f(x)\)</span> represents the activations of an intermediate layer of the discriminator for real data <span class="math inline">\(x\)</span>, and <span class="math inline">\(f(G(z))\)</span> represents the activations for generated data <span class="math inline">\(G(z)\)</span>.</li>
</ul></li>
<li><strong>Historical Averaging:</strong>
<ul>
<li>Maintains a running average of the generator and discriminator weights. The current weights are then penalized for deviating too far from the historical average. This encourages stability and prevents the networks from oscillating wildly.</li>
<li>The penalty term added to the loss function is typically of the form: <span class="math inline">\(\lambda ||\theta - \bar{\theta}||^2\)</span>, where <span class="math inline">\(\theta\)</span> represents the current weights, <span class="math inline">\(\bar{\theta}\)</span> represents the historical average of the weights, and <span class="math inline">\(\lambda\)</span> is a hyperparameter.</li>
</ul></li>
<li><strong>Careful Hyperparameter Tuning:</strong>
<ul>
<li>GAN training is highly sensitive to hyperparameters such as learning rates, batch sizes, and optimization algorithms. A thorough hyperparameter search is often necessary to find a configuration that promotes convergence.</li>
</ul></li>
<li><strong>Early Stopping with Evaluation Metric:</strong>
<ul>
<li>Since GANs lack a clear convergence metric, monitor generated sample quality visually or using quantitative metrics (e.g., Inception Score, FID) and stop training when performance plateaus or degrades.</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>In summary, training GANs requires careful attention to several challenges, including mode collapse, training instability, and non-convergence. By employing the mitigation strategies described above, it’s possible to improve the stability and performance of GAN training and generate high-quality samples.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with a High-Level Overview:</strong>
<ul>
<li>“GANs are powerful generative models, but training them can be challenging due to their adversarial nature. The process involves a min-max game between the Generator and Discriminator, which can lead to several issues.”</li>
</ul></li>
<li><strong>Discuss Mode Collapse:</strong>
<ul>
<li>“One of the major challenges is mode collapse, where the Generator produces a limited variety of outputs instead of covering the full data distribution. This happens when the Generator finds a small set of samples that consistently fool the Discriminator.”</li>
<li>“To mitigate mode collapse, we can use techniques like mini-batch discrimination, where the Discriminator looks at entire mini-batches to encourage diversity. <em>[Optional: Briefly mention the matrix T and similarity calculation if the interviewer seems interested in more details.]</em>”</li>
<li>“Another approach is Unrolled GANs, which train the Generator to fool future versions of the Discriminator, making it more robust. We are basically trying to optimize the generator <span class="math inline">\(G\)</span> by minimizing the loss function <span class="math inline">\(L_G\)</span> with respect to the discriminator <span class="math inline">\(D\)</span> after <span class="math inline">\(k\)</span> training steps, <span class="math inline">\(D^{(k)}\)</span>. <em>[If asked about this, give the equation mentioned above.]</em>”</li>
</ul></li>
<li><strong>Address Training Instability:</strong>
<ul>
<li>“Training instability is another significant issue. The adversarial training process can cause oscillations and fluctuating loss values, making it difficult to reach a stable equilibrium.”</li>
<li>“We can use gradient clipping to limit the magnitude of gradients and prevent them from exploding. The idea is to enforce that if the norm of the gradient exceeds a certain value <span class="math inline">\(c\)</span>, we scale it down accordingly. <em>[Mention the equation for gradient clipping only if prompted.]</em>”</li>
<li>“Wasserstein GANs (WGANs) offer a more stable alternative by using the Earth Mover’s distance. WGAN-GP further improves stability by adding a gradient penalty to enforce a Lipschitz constraint. In this case, the discriminator learns to estimate the Wasserstein distance between the real and generated distributions.”</li>
<li>“Spectral normalization is also helpful, where we normalize the weights of the discriminator layers by dividing by their spectral norm.”</li>
</ul></li>
<li><strong>Explain Non-Convergence:</strong>
<ul>
<li>“GANs may also fail to converge, meaning that the Generator and Discriminator continue to fluctuate without significant improvement. This is often related to the training instability issues.”</li>
<li>“To address this, we can use feature matching, where the Generator is trained to match the feature statistics of the real data in an intermediate layer of the Discriminator. Therefore, the Generator loss <span class="math inline">\(L_G\)</span> is the difference between expected real feature values and expected generated feature values.”</li>
<li>“Historical averaging, where we maintain a running average of the weights, can also promote stability.”</li>
<li>“Careful hyperparameter tuning is crucial, and we can use early stopping based on visual inspection or quantitative metrics like Inception Score or FID.”</li>
</ul></li>
<li><strong>Summarize and Conclude:</strong>
<ul>
<li>“In summary, training GANs requires careful attention to mode collapse, training instability, and non-convergence. By using techniques like mini-batch discrimination, gradient clipping, WGANs, feature matching, and hyperparameter tuning, we can improve the stability and performance of GAN training.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to absorb the information.</li>
<li><strong>Use Visual Cues:</strong> If possible, use hand gestures to illustrate the concepts.</li>
<li><strong>Check for Understanding:</strong> Periodically ask the interviewer if they have any questions.</li>
<li><strong>Focus on Key Concepts:</strong> While the details are important, emphasize the underlying principles and intuitions.</li>
<li><strong>Adapt to the Interviewer:</strong> Adjust the level of detail based on the interviewer’s background and interest. If they seem particularly interested in a specific technique, elaborate further. If they seem less engaged, keep the explanation more concise.</li>
<li><strong>Be Confident:</strong> Even if you don’t know all the answers, present your knowledge confidently and show that you are willing to learn.</li>
<li><strong>Be Prepared to Elaborate:</strong> The interviewer may ask follow-up questions about specific techniques. Be prepared to provide more details or examples.</li>
<li><strong>Be Honest About Limitations:</strong> If you are unsure about something, don’t pretend to know the answer. It’s better to admit that you don’t know and offer to look it up later.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>