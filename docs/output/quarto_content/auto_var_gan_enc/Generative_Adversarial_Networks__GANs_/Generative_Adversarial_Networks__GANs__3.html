<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>generative_adversarial_networks__gans__3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-in-real-world-applications-data-can-be-noisy-and-high-dimensional.-how-would-you-modify-a-gan-to-effectively-learn-from-such-messy-data-and-ensure-scalability-please-detail-changes-in-data-preprocessing-model-architecture-and-training-strategies." class="level2">
<h2 class="anchored" data-anchor-id="question-4.-in-real-world-applications-data-can-be-noisy-and-high-dimensional.-how-would-you-modify-a-gan-to-effectively-learn-from-such-messy-data-and-ensure-scalability-please-detail-changes-in-data-preprocessing-model-architecture-and-training-strategies.">Question: 4. In real-world applications, data can be noisy and high-dimensional. How would you modify a GAN to effectively learn from such messy data and ensure scalability? Please detail changes in data preprocessing, model architecture, and training strategies.</h2>
<p><strong>Best Answer</strong></p>
<p>Dealing with noisy, high-dimensional data in GANs requires a multi-pronged approach encompassing data preprocessing, architectural modifications, and refined training strategies. The goal is to improve both the robustness and scalability of the GAN.</p>
<section id="data-preprocessing-techniques" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-techniques">1. Data Preprocessing Techniques</h3>
<p>The adage “garbage in, garbage out” is especially true for GANs. Careful preprocessing is crucial.</p>
<ul>
<li><p><strong>Normalization/Standardization:</strong> Scaling features to a similar range prevents certain features from dominating the learning process. Common techniques include:</p>
<ul>
<li><p><strong>Min-Max Scaling:</strong> Scales data to the range [0, 1]:</p>
<p><span class="math display">\[x' = \frac{x - x_{min}}{x_{max} - x_{min}}\]</span></p></li>
<li><p><strong>Z-score Standardization:</strong> Centers data around zero with unit variance:</p>
<p><span class="math display">\[x' = \frac{x - \mu}{\sigma}\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation of the feature. This is especially helpful when the features have Gaussian-like distributions.</p></li>
<li><p><strong>RobustScaler:</strong> Similar to Z-score, but uses median and interquartile range to be robust to outliers.</p></li>
</ul></li>
<li><p><strong>Outlier Removal/Handling:</strong> Noisy data often contains outliers that can destabilize training. Techniques include:</p>
<ul>
<li><strong>Winsorizing:</strong> Limits extreme values to a specified percentile (e.g., capping values above the 99th percentile).</li>
<li><strong>Trimming:</strong> Removing data points beyond a certain percentile range. More aggressive than Winsorizing.</li>
<li><strong>Using Robust Loss Functions (discussed later).</strong></li>
</ul></li>
<li><p><strong>Dimensionality Reduction:</strong> High-dimensional data increases computational cost and can lead to the “curse of dimensionality.”</p>
<ul>
<li><p><strong>Principal Component Analysis (PCA):</strong> Projects data onto a lower-dimensional space while preserving variance. Finds orthogonal principal components that capture the most variance.</p>
<ul>
<li>Let <span class="math inline">\(X\)</span> be the data matrix. Compute the covariance matrix <span class="math inline">\(C = \frac{1}{n-1}X^TX\)</span>.</li>
<li>Find the eigenvectors <span class="math inline">\(v_i\)</span> and eigenvalues <span class="math inline">\(\lambda_i\)</span> of <span class="math inline">\(C\)</span>.</li>
<li>Select the top <span class="math inline">\(k\)</span> eigenvectors corresponding to the largest eigenvalues to form a projection matrix <span class="math inline">\(W\)</span>.</li>
<li>Project the data: <span class="math inline">\(X_{reduced} = XW\)</span>.</li>
</ul></li>
<li><p><strong>t-distributed Stochastic Neighbor Embedding (t-SNE):</strong> Focuses on preserving local structure, useful for visualization and non-linear dimensionality reduction, but less suitable for direct input to a GAN due to information loss.</p></li>
<li><p><strong>Autoencoders:</strong> Train a neural network to reconstruct the input. The bottleneck layer learns a compressed representation. This compressed representation can be fed into the GAN. The loss function would be:</p>
<p><span class="math display">\[L = L_{reconstruction} + L_{GAN}\]</span></p>
<p>where <span class="math inline">\(L_{reconstruction}\)</span> measures how well the autoencoder reconstructs the original input, and <span class="math inline">\(L_{GAN}\)</span> is the standard GAN loss applied to the generator’s output.</p></li>
</ul></li>
<li><p><strong>Data Augmentation:</strong> Artificially increase the dataset size and introduce robustness to variations. Common for image data (rotations, flips, zooms) and can be adapted to other data types. This can help the GAN learn to ignore certain types of noise.</p></li>
<li><p><strong>Denoising Autoencoders:</strong> An autoencoder is trained to reconstruct a clean input from a noisy input. This helps the model learn to extract meaningful features even in the presence of noise. The corrupted input is <span class="math inline">\(x' = x + \eta\)</span>, where <span class="math inline">\(\eta\)</span> is noise. The autoencoder is trained to minimize:</p>
<p><span class="math display">\[L = ||x - D(E(x'))||^2\]</span></p>
<p>where <span class="math inline">\(E\)</span> is the encoder, <span class="math inline">\(D\)</span> is the decoder, and <span class="math inline">\(x\)</span> is the original clean input.</p></li>
</ul>
</section>
<section id="model-architecture-modifications" class="level3">
<h3 class="anchored" data-anchor-id="model-architecture-modifications">2. Model Architecture Modifications</h3>
<p>GAN architectures need to be adapted to handle high-dimensional and noisy data effectively.</p>
<ul>
<li><p><strong>Convolutional Architectures (DCGANs):</strong> For image data, Deep Convolutional GANs (DCGANs) are standard. Convolutional layers effectively learn spatial hierarchies and are relatively robust to local noise. Using strided convolutions instead of pooling helps the generator learn upsampling.</p></li>
<li><p><strong>Attention Mechanisms:</strong> Allow the model to focus on the most relevant parts of the input, filtering out irrelevant noise. Self-attention in particular can be useful for capturing long-range dependencies.</p>
<ul>
<li><p>The attention mechanism typically computes attention weights based on queries, keys, and values:</p>
<p><span class="math display">\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span></p>
<p>where <span class="math inline">\(Q\)</span> is the query, <span class="math inline">\(K\)</span> is the key, <span class="math inline">\(V\)</span> is the value, and <span class="math inline">\(d_k\)</span> is the dimension of the key. These can be integrated into both the generator and discriminator.</p></li>
</ul></li>
<li><p><strong>Progressive Growing GANs (ProGANs):</strong> Start with a low-resolution image and progressively increase the resolution during training. This helps stabilize training and generate high-resolution images. Particularly useful for high-dimensional image data.</p></li>
<li><p><strong>Spectral Normalization:</strong> Stabilizes GAN training by constraining the Lipschitz constant of the discriminator. This prevents the discriminator from becoming too confident and provides more stable gradients to the generator. The weight matrix <span class="math inline">\(W\)</span> is normalized as:</p>
<p><span class="math display">\[W_{SN} = \frac{W}{\sigma(W)}\]</span></p>
<p>where <span class="math inline">\(\sigma(W)\)</span> is the largest singular value of <span class="math inline">\(W\)</span>.</p></li>
<li><p><strong>Residual Connections:</strong> Help with gradient flow, especially in deep networks. Allow the network to learn identity mappings, which can be helpful in noisy environments.</p></li>
<li><p><strong>Conditional GANs (cGANs):</strong> Incorporate conditional information (e.g., class labels) into both the generator and discriminator. This allows for more controlled generation and can improve performance when the noise is related to specific classes.</p></li>
</ul>
</section>
<section id="training-strategies" class="level3">
<h3 class="anchored" data-anchor-id="training-strategies">3. Training Strategies</h3>
<p>Training GANs with noisy, high-dimensional data requires careful attention to training strategies.</p>
<ul>
<li><p><strong>Robust Loss Functions:</strong></p>
<ul>
<li><p><strong>Wasserstein Loss (WGAN):</strong> More stable than the original GAN loss, especially when the generator and discriminator are very different. Minimizes the Earth Mover’s distance between the generated and real distributions.</p></li>
<li><p><strong>Hinge Loss:</strong> Another robust loss function that can improve training stability. <span class="math display">\[L_D = -E_{x\sim P_{data}}[min(0, -1 + D(x))] - E_{z\sim P_z}[min(0, -1 - D(G(z)))]\]</span></p>
<p><span class="math display">\[L_G = -E_{z\sim P_z}[D(G(z))]\]</span></p></li>
<li><p><strong>Least Squares GAN (LSGAN):</strong> Uses a least squares loss function, which can generate higher quality images and stabilize training.</p></li>
</ul></li>
<li><p><strong>Careful Hyperparameter Tuning:</strong> The learning rates, batch sizes, and other hyperparameters need to be carefully tuned for the specific dataset. Techniques like grid search or Bayesian optimization can be used.</p></li>
<li><p><strong>Regularization Techniques:</strong></p>
<ul>
<li><strong>Weight Decay (L2 Regularization):</strong> Penalizes large weights, preventing overfitting.</li>
<li><strong>Dropout:</strong> Randomly drops out neurons during training, forcing the network to learn more robust features.</li>
<li><strong>Gradient Penalty:</strong> Used in WGAN-GP to enforce a Lipschitz constraint on the discriminator.</li>
</ul></li>
<li><p><strong>Early Stopping:</strong> Monitor the performance of the GAN on a validation set and stop training when the performance starts to degrade. This helps prevent overfitting to the noisy data.</p></li>
<li><p><strong>Distributed Training:</strong> For large datasets and complex models, distributed training is essential. Frameworks like TensorFlow, PyTorch, and Horovod can be used to train the GAN on multiple GPUs or machines. Strategies like data parallelism and model parallelism can be employed.</p></li>
<li><p><strong>Ensemble Methods:</strong> Train multiple GANs and combine their outputs. This can improve the robustness and stability of the generation process.</p></li>
<li><p><strong>Curriculum Learning:</strong> Start training with simpler examples and gradually increase the complexity. This can help the GAN learn more effectively from noisy data.</p></li>
<li><p><strong>Feature Matching:</strong> Encourage the generator to match the feature statistics of the real data. The loss is:</p>
<p><span class="math display">\[L = ||E_{x\sim P_{data}}f(x) - E_{z\sim P_z}f(G(z))||^2\]</span></p>
<p>where <span class="math inline">\(f(x)\)</span> is some intermediate layer activation in the discriminator.</p></li>
</ul>
</section>
<section id="summary-table" class="level3">
<h3 class="anchored" data-anchor-id="summary-table">Summary Table</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 23%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="header">
<th>Category</th>
<th>Technique</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Data Preprocessing</td>
<td>Normalization/Standardization</td>
<td>Scaling features to a similar range (Min-Max, Z-score, RobustScaler)</td>
</tr>
<tr class="even">
<td></td>
<td>Outlier Removal/Handling</td>
<td>Winsorizing, Trimming, Robust Loss Functions</td>
</tr>
<tr class="odd">
<td></td>
<td>Dimensionality Reduction</td>
<td>PCA, t-SNE, Autoencoders</td>
</tr>
<tr class="even">
<td></td>
<td>Data Augmentation</td>
<td>Artificially increasing dataset size with transformations</td>
</tr>
<tr class="odd">
<td></td>
<td>Denoising Autoencoders</td>
<td>Training an autoencoder to reconstruct clean input from noisy input</td>
</tr>
<tr class="even">
<td>Model Architecture</td>
<td>Convolutional Architectures (DCGANs)</td>
<td>Using convolutional layers for image data</td>
</tr>
<tr class="odd">
<td></td>
<td>Attention Mechanisms</td>
<td>Allowing the model to focus on relevant parts of the input</td>
</tr>
<tr class="even">
<td></td>
<td>Progressive Growing GANs (ProGANs)</td>
<td>Gradually increasing resolution during training</td>
</tr>
<tr class="odd">
<td></td>
<td>Spectral Normalization</td>
<td>Constraining the Lipschitz constant of the discriminator</td>
</tr>
<tr class="even">
<td></td>
<td>Residual Connections</td>
<td>Improving gradient flow in deep networks</td>
</tr>
<tr class="odd">
<td></td>
<td>Conditional GANs (cGANs)</td>
<td>Incorporating conditional information</td>
</tr>
<tr class="even">
<td>Training Strategies</td>
<td>Robust Loss Functions</td>
<td>Wasserstein Loss (WGAN), Hinge Loss, Least Squares GAN (LSGAN)</td>
</tr>
<tr class="odd">
<td></td>
<td>Careful Hyperparameter Tuning</td>
<td>Using grid search or Bayesian optimization</td>
</tr>
<tr class="even">
<td></td>
<td>Regularization Techniques</td>
<td>Weight Decay, Dropout, Gradient Penalty</td>
</tr>
<tr class="odd">
<td></td>
<td>Early Stopping</td>
<td>Monitoring validation performance to prevent overfitting</td>
</tr>
<tr class="even">
<td></td>
<td>Distributed Training</td>
<td>Training on multiple GPUs or machines</td>
</tr>
<tr class="odd">
<td></td>
<td>Ensemble Methods</td>
<td>Combining outputs from multiple GANs</td>
</tr>
<tr class="even">
<td></td>
<td>Curriculum Learning</td>
<td>Training with simpler examples first</td>
</tr>
<tr class="odd">
<td></td>
<td>Feature Matching</td>
<td>Encourage the generator to match the feature statistics of the real data</td>
</tr>
</tbody>
</table>
<p><strong>How to Narrate</strong></p>
<p>Here’s how I would present this in an interview:</p>
<ol type="1">
<li><p><strong>Start with acknowledging the challenge:</strong> “Dealing with noisy and high-dimensional data in GANs is a common and important problem in real-world applications. The key is to address it from multiple angles: data preprocessing, architectural modifications, and training strategies.”</p></li>
<li><p><strong>Data Preprocessing:</strong> “First, data preprocessing is critical. I’d discuss normalization techniques like min-max scaling and Z-score standardization, explaining their purpose in bringing features to a comparable range and preventing dominance by certain features. I’d then mention outlier handling – Winsorizing and trimming – emphasizing their role in mitigating the impact of noisy data points. If prompted, I can elaborate on dimensionality reduction techniques such as PCA. Briefly, PCA projects the data to a lower-dimensional space while retaining variance. I would also mention denoising autoencoders as a preprocessing step to remove noise before feeding the data into the GAN.”</p>
<ul>
<li><em>Communication Tip:</em> Briefly explain equations/formulas and their significance. Avoid diving too deep unless explicitly asked.</li>
<li><em>Example Transition:</em> “These preprocessing steps prepare the data for the GAN. Next, let’s discuss architectural modifications.”</li>
</ul></li>
<li><p><strong>Model Architecture Modifications:</strong> “Next, the architecture must be tailored to handle the complexities of the data. For image data, I’d highlight the effectiveness of convolutional architectures like DCGANs. I’d then talk about attention mechanisms, explaining how they enable the model to focus on the most relevant input parts. Progressive Growing GANs are useful because they gradually increase the image resolution. Spectral Normalization is also useful. The purpose is to stabilize the training. Finally, I’ll mention conditional GANs, which allow for guided image generation based on conditioning information.”</p>
<ul>
<li><em>Communication Tip:</em> Use visual cues if possible (e.g., drawing a simple diagram of attention or progressive growing).</li>
<li><em>Example Transition:</em> “With a solid architecture in place, the final piece is refining the training strategy.”</li>
</ul></li>
<li><p><strong>Training Strategies:</strong> “Finally, the training strategy needs to be robust. I would discuss robust loss functions like the Wasserstein loss, highlighting its improved stability compared to the standard GAN loss. I’d also cover the importance of hyperparameter tuning, regularization techniques like weight decay and dropout, and the benefits of early stopping. For very large datasets, I would mention distributed training. And ensemble methods can improve the robustness and stability of the generation process.”</p>
<ul>
<li><em>Communication Tip:</em> Conclude by reiterating the importance of this multi-faceted approach.</li>
</ul></li>
<li><p><strong>Offer more detail when prompted:</strong> “That provides a high-level overview. I’m happy to delve into any of these areas in more detail if you’d like. For example, we could discuss the math behind the Wasserstein loss or different distributed training strategies.”</p></li>
</ol>
<p><em>Communication Tips:</em></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Allow time for the interviewer to process the information.</li>
<li><strong>Check for understanding:</strong> Pause periodically and ask if the interviewer has any questions.</li>
<li><strong>Tailor your response:</strong> Adjust the level of detail based on the interviewer’s background and the specific requirements of the role. If they probe a specific topic, go deeper.</li>
<li><strong>Be practical:</strong> Emphasize the practical implications of each technique and how it would address the specific challenges of noisy, high-dimensional data.</li>
<li><strong>Be confident:</strong> Show that you have a deep understanding of GANs and are capable of applying them to real-world problems.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>