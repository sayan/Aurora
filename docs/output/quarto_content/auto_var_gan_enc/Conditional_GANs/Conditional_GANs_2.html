<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>conditional_gans_2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-3.-conditional-gans-like-traditional-gans-can-suffer-from-issues-such-as-mode-collapse.-what-strategies-would-you-employ-specifically-for-conditional-gans-to-mitigate-mode-collapse-and-what-are-the-potential-pitfalls-of-these-approaches" class="level2">
<h2 class="anchored" data-anchor-id="question-3.-conditional-gans-like-traditional-gans-can-suffer-from-issues-such-as-mode-collapse.-what-strategies-would-you-employ-specifically-for-conditional-gans-to-mitigate-mode-collapse-and-what-are-the-potential-pitfalls-of-these-approaches">Question: 3. Conditional GANs, like traditional GANs, can suffer from issues such as mode collapse. What strategies would you employ specifically for conditional GANs to mitigate mode collapse, and what are the potential pitfalls of these approaches?</h2>
<p><strong>Best Answer</strong></p>
<p>Conditional GANs (cGANs) extend the capabilities of standard GANs by incorporating conditional information, allowing control over the generated output. However, this added complexity can exacerbate the problem of mode collapse. Mode collapse occurs when the generator learns to produce only a limited variety of outputs, often focusing on the most “convincing” or easily generated samples, thus failing to represent the full diversity of the data distribution conditioned on the given input. Here are several strategies I would employ to mitigate mode collapse in cGANs, along with their potential pitfalls:</p>
<p><strong>1. Feature Matching with Conditioning:</strong></p>
<ul>
<li><p><strong>Description:</strong> In feature matching, the generator is trained to match the statistics of the intermediate layer activations of the discriminator for real and generated data <em>conditioned on the input</em>. This encourages the generator to produce outputs that are not only realistic but also share similar feature representations with real data. Specifically, we minimize the distance between the expected feature values on real data <span class="math inline">\(x\)</span> and generated data <span class="math inline">\(G(z,c)\)</span>, where <span class="math inline">\(c\)</span> is the condition.</p>
<p>The loss function can be defined as:</p>
<p><span class="math display">\[
L_{FM} = || \mathbb{E}_{x \sim p_{data}(x)} [f(x|c)] - \mathbb{E}_{z \sim p_{z}(z)} [f(G(z,c)|c)] ||_2^2
\]</span></p>
<p>where <span class="math inline">\(f(x|c)\)</span> represents the activations of an intermediate layer of the discriminator when fed with a real sample <span class="math inline">\(x\)</span> conditioned on <span class="math inline">\(c\)</span>, and <span class="math inline">\(f(G(z,c)|c)\)</span> represents the same for the generated sample <span class="math inline">\(G(z,c)\)</span> conditioned on <span class="math inline">\(c\)</span>.</p></li>
<li><p><strong>Why it helps:</strong> By forcing the generator to match the feature distributions observed in real data, we prevent it from overly specializing in a small subset of modes. Conditioning helps ensure this matching happens for each input condition.</p></li>
<li><p><strong>Pitfalls:</strong> Selecting the appropriate layer for feature matching is crucial. An early layer might capture low-level features irrelevant to the specific modes we want to encourage. A late layer might be too specific and hinder diversity. Furthermore, perfect feature matching doesn’t guarantee perfect sample quality or diversity; the selected features may not be sufficiently comprehensive. Also the expectation of both real and generated data must be estimated by finite samples, so a large batch size is important.</p></li>
</ul>
<p><strong>2. Minibatch Discrimination with Conditioning:</strong></p>
<ul>
<li><p><strong>Description:</strong> Minibatch discrimination helps the generator to produce more diverse outputs by explicitly considering the similarity between generated samples within a minibatch. It computes statistics based on how different the generated samples are from each other and adds this information to the discriminator’s input. In the conditional setting, this is calculated <em>within each condition</em>. We first transform the intermediate layer output of the discriminator <span class="math inline">\(f(x_i)\)</span> to a matrix <span class="math inline">\(T \in R^{A \times B \times C}\)</span>. Then we compute the following: <span class="math display">\[
o(x_i) = \sum_{j=1}^n exp(-||T(f(x_i)) - T(f(x_j))||_{L1})
\]</span> The output <span class="math inline">\(o(x_i)\)</span> is then concatenated with the original features of <span class="math inline">\(f(x_i)\)</span> and fed into the next layer.</p></li>
<li><p><strong>Why it helps:</strong> This encourages the generator to produce outputs that are dissimilar within a batch, thereby increasing diversity. Conditioning ensures that this diversity is enforced separately for each input condition, preventing the generator from mixing modes across different conditions.</p></li>
<li><p><strong>Pitfalls:</strong> Can increase computational complexity. Choosing the appropriate distance metric and the features upon which to calculate the discrimination can be challenging. Overly aggressive minibatch discrimination can lead to the generator producing noisy or unrealistic samples if it focuses too much on dissimilarity at the expense of realism. It is crucial to normalize the similarity scores appropriately, and to choose hyperparameters (like the size of the minibatch) carefully to balance diversity and sample quality.</p></li>
</ul>
<p><strong>3. Auxiliary Classifier GAN (AC-GAN):</strong></p>
<ul>
<li><p><strong>Description:</strong> AC-GAN extends the discriminator to not only distinguish between real and generated samples but also to predict the class label or condition that was used to generate the sample. The loss function is modified to include the classification accuracy of the discriminator:</p>
<p><span class="math display">\[
L_D = \mathbb{E}[log P(S=real|x)] + \mathbb{E}[log P(S=fake|G(z,c))] + \mathbb{E}[log P(C=c|x)] + \mathbb{E}[log P(C=c|G(z,c))]
\]</span></p>
<p>where <span class="math inline">\(S\)</span> represents the source (real or fake), and <span class="math inline">\(C\)</span> represents the class label. The generator’s loss is then:</p>
<p><span class="math display">\[
L_G = \mathbb{E}[log P(S=real|G(z,c))] + \mathbb{E}[log P(C=c|G(z,c))]
\]</span></p></li>
<li><p><strong>Why it helps:</strong> By explicitly training the discriminator to recognize the condition, we provide a stronger signal to the generator to produce outputs that are consistent with the specified condition. This helps to disentangle the generation process and prevent the generator from ignoring the condition and collapsing to a single mode. The generator is now incentivized to fool the discriminator <em>both</em> in terms of realism <em>and</em> class correctness.</p></li>
<li><p><strong>Pitfalls:</strong> AC-GAN relies on accurate classification by the discriminator. If the discriminator struggles to classify the real data accurately, it can mislead the generator and hinder training. It adds complexity to the discriminator architecture and loss function. Imbalanced data across conditions can lead to the discriminator being biased towards certain classes, causing the generator to perform poorly on less frequent conditions. Careful balancing of the training data or adjusting the loss function weights is necessary.</p></li>
</ul>
<p><strong>4. Condition Augmentation:</strong></p>
<ul>
<li><p><strong>Description:</strong> This involves slightly perturbing or augmenting the conditional input provided to the generator. This can be done by adding noise to the condition, interpolating between different conditions, or using domain-specific augmentation techniques.</p></li>
<li><p><strong>Why it helps:</strong> Augmenting the conditions forces the generator to learn a smoother mapping from the condition space to the output space. This can improve robustness and prevent the generator from overfitting to specific condition values, which can contribute to mode collapse. It encourages the generator to generalize better across the condition space, generating more diverse outputs.</p></li>
<li><p><strong>Pitfalls:</strong> Excessive augmentation can lead to the generator producing blurry or unrealistic samples. It can also make the training process more difficult, as the generator needs to learn to be robust to a wider range of input conditions. The type and amount of augmentation need to be carefully tuned for each specific application.</p></li>
</ul>
<p><strong>5. Regularization Techniques (Weight Decay, Dropout, Spectral Normalization):</strong></p>
<ul>
<li><p><strong>Description:</strong> Applying regularization techniques to both the generator and discriminator can help to stabilize training and prevent overfitting. Weight decay penalizes large weights, dropout randomly disables neurons during training, and spectral normalization constrains the Lipschitz constant of the discriminator.</p></li>
<li><p><strong>Why it helps:</strong> Regularization can prevent the generator from memorizing specific training examples, which can contribute to mode collapse. It can also prevent the discriminator from becoming too strong, which can lead to the generator getting stuck in a local minimum. Spectral Normalization, in particular, has been shown to effectively stabilize GAN training by controlling the Lipschitz constant of the discriminator, which can prevent exploding gradients and mode collapse.</p></li>
<li><p><strong>Pitfalls:</strong> Over-regularization can lead to underfitting, resulting in the generator producing blurry or low-quality samples. The regularization strength needs to be carefully tuned for each specific application.</p></li>
</ul>
<p><strong>6. Balancing Generator and Discriminator Capacity:</strong></p>
<ul>
<li><p><strong>Description:</strong> Mode collapse can often stem from an imbalance in the learning capacity of the generator and discriminator. If the discriminator is too powerful, it can easily distinguish real from generated samples, providing little useful feedback to the generator. Conversely, if the generator is too powerful, it might find a narrow region of the data space to exploit.</p></li>
<li><p><strong>Why it helps:</strong> Carefully balancing the complexity of the generator and discriminator architectures, and their corresponding learning rates, can help prevent one from overpowering the other. This encourages a more stable and informative training process. Using techniques like progressively growing GANs (ProGANs) can help incrementally increase the complexity of both networks in a synchronized manner.</p></li>
<li><p><strong>Pitfalls:</strong> Finding the right balance requires careful experimentation and can be computationally expensive. Mismatched capacity can still lead to instability or slow convergence.</p></li>
</ul>
<p><strong>7. Condition Imbalance Awareness and Mitigation</strong></p>
<ul>
<li><p><strong>Description</strong>: In many real-world datasets, the conditions might not be uniformly distributed. Some conditions might be rare, while others are very common. This condition imbalance can cause the generator to perform poorly on the rare conditions and, essentially, lead to a form of mode collapse where it focuses on generating outputs primarily for the dominant conditions.</p></li>
<li><p><strong>Why it helps</strong>: Explicitly addressing condition imbalance can greatly improve cGAN performance. This can involve techniques like:</p>
<ul>
<li><strong>Re-sampling</strong>: Over-sampling rare conditions or under-sampling common conditions to create a more balanced training set.</li>
<li><strong>Class-weighted loss functions</strong>: Applying higher weights to the losses associated with rare conditions, thus penalizing the generator more for failing to generate good outputs for these conditions.</li>
<li><strong>Data augmentation for rare conditions</strong>: Generating synthetic data for rare conditions to increase their representation in the training data.</li>
</ul></li>
<li><p><strong>Pitfalls</strong>:</p>
<ul>
<li>Re-sampling can lead to overfitting on the over-sampled rare conditions if not done carefully.</li>
<li>Determining the optimal weights for class-weighted loss functions can be challenging and might require experimentation.</li>
<li>Data augmentation, if not implemented carefully, can introduce artifacts and biases into the generated data, which can negatively impact the generator’s performance.</li>
</ul></li>
</ul>
<p>In summary, mitigating mode collapse in cGANs requires a multi-faceted approach. The optimal strategy depends on the specific characteristics of the dataset and the architecture of the GAN. It’s often necessary to experiment with different techniques and combinations thereof to find the best solution. Furthermore, continuously monitoring the training process and evaluating the diversity of the generated samples are crucial for identifying and addressing mode collapse effectively.</p>
<p><strong>How to Narrate</strong></p>
<ol type="1">
<li><strong>Introduction (Briefly define cGANs and the problem of mode collapse)</strong>
<ul>
<li>“Conditional GANs allow us to generate data with specific attributes. However, they can suffer from mode collapse, where the generator only produces a limited variety of outputs.”</li>
<li>“I’d like to discuss some strategies I would employ to tackle this in conditional GANs, and talk about potential pitfalls”</li>
</ul></li>
<li><strong>Strategy 1: Feature Matching with Conditioning</strong>
<ul>
<li>“One approach is feature matching, where we encourage the generator to match the statistics of the intermediate layers of the discriminator, conditioned on the input. Basically, we are minimizing <span class="math inline">\(L_{FM} = || \mathbb{E}_{x \sim p_{data}(x)} [f(x|c)] - \mathbb{E}_{z \sim p_{z}(z)} [f(G(z,c)|c)] ||_2^2\)</span>.” <em>(Write down the formula)</em></li>
<li>“This helps the generator to produce outputs sharing similar feature representations with real data for each input condition.”</li>
<li>“The key is to choose the correct intermediate layer. Too early, and it’s irrelevant; too late, and it hinders diversity. Estimation of the expectation value also requires a large batch size.”</li>
</ul></li>
<li><strong>Strategy 2: Minibatch Discrimination with Conditioning</strong>
<ul>
<li>“Another strategy is minibatch discrimination, which increases diversity within a batch. We compute how different the generated samples are from each other <em>within each condition</em>, concatenating that to the input to the discriminator”</li>
<li>“This encourages diversity in the generated outputs.”</li>
<li>“The potential downside is it increases computational complexity, and choosing the correct distance metric is challenging. Overdoing it can lead to noise.”</li>
</ul></li>
<li><strong>Strategy 3: Auxiliary Classifier GAN (AC-GAN)</strong>
<ul>
<li>“AC-GAN extends the discriminator to classify the real/fake data and also classify the input condition, or class label.”</li>
<li>“The loss functions are adjusted to include the classification accuracy. <span class="math inline">\(L_D = \mathbb{E}[log P(S=real|x)] + \mathbb{E}[log P(S=fake|G(z,c))] + \mathbb{E}[log P(C=c|x)] + \mathbb{E}[log P(C=c|G(z,c))]\)</span> and <span class="math inline">\(L_G = \mathbb{E}[log P(S=real|G(z,c))] + \mathbb{E}[log P(C=c|G(z,c))]\)</span>”. <em>(Write down the formula)</em></li>
<li>“This encourages the generator to produce outputs consistent with the specified condition, preventing it from collapsing to a single mode.”</li>
<li>“Pitfalls include relying on accurate classification. If the discriminator struggles, it misleads the generator. Class imbalance is a big concern here too.”</li>
</ul></li>
<li><strong>Strategy 4: Condition Augmentation</strong>
<ul>
<li>“Adding noise to the condition forces the generator to learn a smoother mapping from the condition space to the output space”</li>
<li>“Excessive augmentation can lead to blurry results. The amount has to be tuned”</li>
</ul></li>
<li><strong>Strategy 5: Regularization Techniques</strong>
<ul>
<li>“Applying regularization to both networks can help stabilize training and prevent overfitting.”</li>
<li>“Weight decay, dropout and Spectral normalization are all helpful”</li>
<li>“Over-regularization can lead to underfitting and blurry samples”</li>
</ul></li>
<li><strong>Strategy 6: Balancing Generator and Discriminator Capacity</strong>
<ul>
<li>“An imbalance in learning capacity can lead to mode collapse”</li>
<li>“Carefully balancing network complexity and learning rates is needed”</li>
<li>“Techniques like progressive growing GANs (ProGANs) can help incrementally increase the complexity.”</li>
</ul></li>
<li><strong>Strategy 7: Condition Imbalance Awareness and Mitigation</strong>
<ul>
<li>“Condition imbalance is real-world datasets can cause mode collapse.”</li>
<li>“Re-sampling rare conditions, class-weighted loss functions, and data augmentation for rare conditions”</li>
<li>“Re-sampling can lead to overfitting, and data augmentation can introduce bias if not careful”</li>
</ul></li>
<li><strong>Conclusion</strong>
<ul>
<li>“In summary, mitigating mode collapse requires a multi-faceted approach. The best solution depends on the specific dataset and GAN architecture.”</li>
<li>“It’s often necessary to experiment with different techniques and monitor the training process closely.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips</strong></p>
<ul>
<li><strong>Pause and Engage:</strong> After presenting each strategy, pause briefly and ask the interviewer if they have any questions or want you to elaborate further. This shows engagement and allows them to guide the conversation.</li>
<li><strong>Visual Aids (Optional):</strong> If possible (e.g., in a virtual interview), have a simple diagram or table summarizing the techniques and their trade-offs. This can help the interviewer visualize the information.</li>
<li><strong>Be Concise:</strong> Avoid overly technical jargon or deep dives unless the interviewer specifically requests it. Focus on conveying the main ideas clearly and concisely.</li>
<li><strong>Emphasize Practicality:</strong> Highlight the practical aspects of each technique, such as how to implement it, what parameters to tune, and what common pitfalls to avoid. This demonstrates your hands-on experience.</li>
<li><strong>Acknowledge Limitations:</strong> Be upfront about the limitations of each approach and the challenges involved in mitigating mode collapse. This shows intellectual honesty and a nuanced understanding of the problem.</li>
<li><strong>Explain Equations Clearly:</strong> When presenting equations, walk the interviewer through each term and explain its meaning in plain language. Avoid simply reciting the formula without providing context. For instance, when introducing <span class="math inline">\(L_{FM}\)</span>, say: “Here, we’re calculating the L2 distance between the average feature activations for real images and generated images, both conditioned on the input ‘c’.”</li>
<li><strong>Confidence and Enthusiasm:</strong> Speak with confidence and show genuine enthusiasm for the topic. This will make a positive impression on the interviewer and demonstrate your passion for GANs and machine learning.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>