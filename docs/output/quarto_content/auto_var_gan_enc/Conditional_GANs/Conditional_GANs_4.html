<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>conditional_gans_4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-how-would-you-design-a-system-to-scale-the-training-and-deployment-of-conditional-gans-especially-when-working-with-large-and-messy-datasets-consider-resource-constraints-and-real-time-inference-challenges." class="level2">
<h2 class="anchored" data-anchor-id="question-5.-how-would-you-design-a-system-to-scale-the-training-and-deployment-of-conditional-gans-especially-when-working-with-large-and-messy-datasets-consider-resource-constraints-and-real-time-inference-challenges.">Question: 5. How would you design a system to scale the training and deployment of Conditional GANs, especially when working with large and messy datasets? Consider resource constraints and real-time inference challenges.</h2>
<p><strong>Best Answer</strong></p>
<p>Scaling the training and deployment of Conditional GANs (cGANs) with large, messy datasets under resource constraints and real-time inference requirements is a multifaceted challenge. My approach would encompass data engineering, distributed training, model optimization, and efficient deployment strategies.</p>
<section id="data-preprocessing-and-feature-engineering-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-and-feature-engineering-pipeline">1. Data Preprocessing and Feature Engineering Pipeline</h3>
<ul>
<li><strong>Data Cleaning and Validation:</strong> Address the “messy” data.
<ul>
<li>Implement automated data validation checks to identify and handle missing values, outliers, and inconsistencies. Use techniques like imputation (mean, median, or model-based), outlier detection (Isolation Forest, Z-score), and data type validation.</li>
<li>Example: For missing numerical values, use <span class="math inline">\(x_{imputed} = \frac{1}{N} \sum_{i=1}^{N} x_i\)</span> (mean imputation) or a more sophisticated method if data follows a specific distribution.</li>
</ul></li>
<li><strong>Data Transformation:</strong> Transform raw data into suitable formats.
<ul>
<li>Normalization/Standardization: Scale numerical features using techniques like Min-Max scaling or Z-score standardization to ensure stable training.
<ul>
<li>Min-Max Scaling: <span class="math inline">\(x_{scaled} = \frac{x - x_{min}}{x_{max} - x_{min}}\)</span></li>
<li>Z-score Standardization: <span class="math inline">\(x_{scaled} = \frac{x - \mu}{\sigma}\)</span>, where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
</ul></li>
<li>Categorical Encoding: Convert categorical features using one-hot encoding, label encoding, or embedding layers, especially for high-cardinality features.</li>
</ul></li>
<li><strong>Feature Engineering:</strong> Derive new features that capture essential patterns.
<ul>
<li>Domain Expertise: Involve domain experts to create relevant features. For instance, in image generation, consider features like edges, textures, or shapes.</li>
<li>Automated Feature Generation: Use techniques like polynomial features or feature crossing.</li>
</ul></li>
<li><strong>Data Augmentation:</strong> Increase dataset size by applying transformations.
<ul>
<li>Apply conditional augmentations based on class labels to maintain data integrity.</li>
<li>Example: For image cGANs, augmentations might include rotations, scaling, cropping, and color jittering. Be mindful of the conditional input when augmenting.</li>
</ul></li>
<li><strong>Data Storage:</strong> Utilize scalable and efficient storage solutions.
<ul>
<li>Cloud Storage: Store data on cloud platforms like AWS S3, Google Cloud Storage, or Azure Blob Storage for scalability and accessibility.</li>
<li>Data Lakes: Create a data lake using systems like Hadoop or Spark for storing structured and unstructured data.</li>
</ul></li>
</ul>
</section>
<section id="distributed-training-strategy" class="level3">
<h3 class="anchored" data-anchor-id="distributed-training-strategy">2. Distributed Training Strategy</h3>
<ul>
<li><strong>Model Parallelism:</strong> Distribute the model across multiple devices when the model is too large to fit on a single GPU.
<ul>
<li>Partition layers of the generator and discriminator across multiple GPUs. Carefully manage communication between GPUs to minimize overhead.</li>
</ul></li>
<li><strong>Data Parallelism:</strong> Replicate the model on multiple devices, each processing a different batch of data.
<ul>
<li>Synchronous SGD: Aggregate gradients from all workers after each batch and update the model parameters. Can use Horovod or TensorFlow’s MirroredStrategy.
<ul>
<li>Gradient Aggregation: <span class="math inline">\(\theta_{t+1} = \theta_t - \eta \frac{1}{N} \sum_{i=1}^{N} \nabla L(\theta_t, x_i)\)</span>, where <span class="math inline">\(\theta\)</span> represents model parameters, <span class="math inline">\(\eta\)</span> is the learning rate, <span class="math inline">\(L\)</span> is the loss function, and <span class="math inline">\(N\)</span> is the number of workers.</li>
</ul></li>
<li>Asynchronous SGD: Workers update the model parameters independently without waiting for others, using a parameter server. Can lead to stale gradients; techniques like gradient compression and momentum can help mitigate this.</li>
</ul></li>
<li><strong>Hardware Acceleration:</strong> Leverage specialized hardware.
<ul>
<li>GPUs: Utilize multiple GPUs for faster training. NVIDIA’s DGX systems are purpose-built for deep learning.</li>
<li>TPUs: Consider using TPUs (Tensor Processing Units) on Google Cloud for significant speedups, especially for large models and datasets.</li>
</ul></li>
<li><strong>Communication Optimization:</strong> Reduce communication overhead.
<ul>
<li>Gradient Compression: Compress gradients before transmitting them using techniques like quantization or sparsification.</li>
<li>Ring All-Reduce: Use algorithms like Ring All-Reduce to efficiently aggregate gradients across multiple workers.</li>
</ul></li>
<li><strong>Frameworks:</strong> Use distributed training frameworks.
<ul>
<li>TensorFlow: Leverage TensorFlow’s <code>tf.distribute.Strategy</code> API.</li>
<li>PyTorch: Use PyTorch’s <code>torch.nn.DataParallel</code> or <code>torch.distributed</code> packages.</li>
<li>Horovod: A distributed training framework that supports TensorFlow, PyTorch, and MXNet.</li>
</ul></li>
</ul>
</section>
<section id="model-optimization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="model-optimization-techniques">3. Model Optimization Techniques</h3>
<ul>
<li><strong>Efficient Architectures:</strong> Design lightweight generator and discriminator architectures.
<ul>
<li>MobileNets: Use MobileNet-style architectures for generators and discriminators to reduce the number of parameters and computational complexity.</li>
<li>Shuffling: Implement channel shuffling to reduce the computational complexity.</li>
</ul></li>
<li><strong>Regularization Techniques:</strong> Prevent overfitting and improve generalization.
<ul>
<li>Dropout: Apply dropout layers to reduce overfitting by randomly dropping out neurons during training.</li>
<li>Weight Decay: Add L1 or L2 regularization to the loss function to penalize large weights.
<ul>
<li>L2 Regularization: <span class="math inline">\(Loss_{regularized} = Loss + \lambda ||\theta||_2^2\)</span>, where <span class="math inline">\(\lambda\)</span> is the regularization strength.</li>
</ul></li>
</ul></li>
<li><strong>Quantization:</strong> Reduce model size and improve inference speed by quantizing weights and activations.
<ul>
<li>Post-Training Quantization: Convert floating-point weights and activations to lower precision (e.g., INT8).</li>
<li>Quantization-Aware Training: Train the model with quantization in mind to minimize the accuracy loss.</li>
</ul></li>
<li><strong>Pruning:</strong> Remove unimportant connections from the model to reduce its size and complexity.
<ul>
<li>Magnitude Pruning: Remove connections with small weights.</li>
<li>Structured Pruning: Remove entire filters or channels.</li>
</ul></li>
<li><strong>Knowledge Distillation:</strong> Train a smaller “student” model to mimic the behavior of a larger, more complex “teacher” model. The teacher can be a more accurate but computationally expensive cGAN.</li>
</ul>
</section>
<section id="efficient-deployment-strategy" class="level3">
<h3 class="anchored" data-anchor-id="efficient-deployment-strategy">4. Efficient Deployment Strategy</h3>
<ul>
<li><strong>Model Serving Frameworks:</strong> Utilize frameworks like TensorFlow Serving, TorchServe, or NVIDIA Triton Inference Server.
<ul>
<li>TensorFlow Serving: A flexible, high-performance serving system for machine learning models.</li>
<li>TorchServe: A model serving framework for PyTorch.</li>
<li>NVIDIA Triton Inference Server: A multi-framework inference server that supports TensorFlow, PyTorch, ONNX, and more.</li>
</ul></li>
<li><strong>Hardware Acceleration:</strong> Deploy models on hardware accelerators.
<ul>
<li>GPUs: Use GPUs for accelerated inference.</li>
<li>TPUs: Deploy models on Cloud TPUs for high-throughput inference.</li>
<li>Edge Devices: Deploy models on edge devices like NVIDIA Jetson or Google Coral for real-time inference at the edge.</li>
</ul></li>
<li><strong>Batching:</strong> Process multiple inference requests in a single batch to improve throughput.</li>
<li><strong>Caching:</strong> Cache frequently accessed results to reduce latency.</li>
<li><strong>Model Monitoring:</strong> Implement monitoring systems to detect performance degradation, concept drift, and anomalies.
<ul>
<li>Metrics: Track metrics like inference latency, throughput, and accuracy.</li>
<li>Alerts: Set up alerts to notify when metrics fall below predefined thresholds.</li>
</ul></li>
<li><strong>Real-time API:</strong> Expose the model as a real-time API.
<ul>
<li>REST API: Create a REST API using frameworks like Flask or FastAPI.</li>
<li>gRPC API: Use gRPC for high-performance, low-latency communication.</li>
</ul></li>
<li><strong>Incremental/Continual Learning:</strong> Implement techniques to update the model with new data without retraining from scratch. This is crucial when dealing with constantly evolving “messy” data.
<ul>
<li>Retrain generator and discriminator after certain amount of time to maintain the quality of the model</li>
</ul></li>
</ul>
</section>
<section id="hyperparameter-optimization" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-optimization">5. Hyperparameter Optimization</h3>
<ul>
<li><strong>Efficient Search Strategies:</strong>
<ul>
<li>Bayesian Optimization: Use Bayesian optimization algorithms like Gaussian processes to efficiently search the hyperparameter space.</li>
<li>Hyperband: A bandit-based approach for hyperparameter optimization that quickly discards poorly performing configurations.</li>
<li>Population Based Training (PBT): A technique that evolves a population of models and hyperparameters.</li>
</ul></li>
<li><strong>Automated ML (AutoML):</strong>
<ul>
<li>Use AutoML tools like Google Cloud AutoML or Azure Machine Learning Automated ML to automate the hyperparameter tuning process.</li>
</ul></li>
</ul>
<p><strong>Real-world Considerations:</strong></p>
<ul>
<li><strong>Cost Optimization:</strong> Balance the cost of infrastructure, training, and inference with the desired performance. Explore spot instances or preemptible VMs for cost-effective training.</li>
<li><strong>Security:</strong> Secure the data pipeline and model deployment to protect against unauthorized access and attacks.</li>
<li><strong>Scalability:</strong> Design the system to handle increasing data volumes and inference requests. Use auto-scaling to dynamically adjust resources based on demand.</li>
<li><strong>Reproducibility:</strong> Ensure that the training and deployment process is reproducible by using version control, containerization, and infrastructure-as-code.</li>
<li><strong>Interpretability and Explainability:</strong> While GANs are notoriously difficult to interpret, techniques like feature visualization or attention mechanisms can provide some insights into the model’s decision-making process.</li>
</ul>
<p>By carefully addressing these aspects, a scalable, efficient, and robust system for training and deploying Conditional GANs can be realized, even when dealing with large and messy datasets under resource constraints and real-time inference challenges.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested way to present this answer during an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview:</strong></p>
<ul>
<li>“Scaling cGANs for large, messy datasets with real-time constraints is a complex challenge involving data engineering, distributed training, model optimization, and efficient deployment. I’ll break down my approach into these key areas.”</li>
<li>This sets the stage and provides a roadmap for your detailed explanation.</li>
</ul></li>
<li><p><strong>Discuss Data Preprocessing:</strong></p>
<ul>
<li>“First, we need a robust data pipeline to handle the ‘messy’ data. This includes cleaning, validation, transformation, feature engineering, and augmentation.”</li>
<li>“For data cleaning, automated checks for missing values, outliers, and inconsistencies are essential. For example, missing values can be imputed using the mean, like this:” <span class="math inline">\(&lt;equation&gt;\)</span>x_{imputed} = _{i=1}^{N} x_i$$</li>
<li><strong>Communication Tip:</strong> Avoid diving too deep into formulas unless prompted. Mention the technique, provide a simplified explanation, and offer the formula if they seem interested.</li>
</ul></li>
<li><p><strong>Explain Distributed Training:</strong></p>
<ul>
<li>“Given the large datasets, distributed training is crucial. We can use model parallelism, data parallelism, or a combination of both.”</li>
<li>“In data parallelism with synchronous SGD, gradients are aggregated from all workers after each batch. The parameter update looks like this:” <span class="math inline">\(&lt;equation&gt;\theta_{t+1} = \theta_t - \eta \frac{1}{N} \sum_{i=1}^{N} \nabla L(\theta_t, x_i)\)</span>$</li>
<li>“To reduce communication overhead, gradient compression techniques can be used, and frameworks like TensorFlow’s <code>tf.distribute.Strategy</code> or Horovod can simplify the implementation.”</li>
<li><strong>Communication Tip:</strong> Emphasize the trade-offs between different distributed training approaches. For instance, mention that asynchronous SGD can be faster but may suffer from stale gradients.</li>
</ul></li>
<li><p><strong>Describe Model Optimization:</strong></p>
<ul>
<li>“To meet resource constraints and real-time inference needs, model optimization is vital. This includes using efficient architectures, regularization techniques, and quantization.”</li>
<li>“Quantization, for instance, reduces model size and improves inference speed by converting weights and activations to lower precision. Quantization-aware training can minimize accuracy loss.”</li>
<li>“Regularization, such as L2 regularization, can prevent overfitting:” <span class="math inline">\(&lt;equation&gt;Loss_{regularized} = Loss + \lambda ||\theta||_2^2\)</span>$</li>
<li><strong>Communication Tip:</strong> Focus on the practical benefits of each optimization technique. Highlight how each one addresses the specific challenges of resource constraints and real-time inference.</li>
</ul></li>
<li><p><strong>Outline the Deployment Strategy:</strong></p>
<ul>
<li>“For deployment, model serving frameworks like TensorFlow Serving, TorchServe, or NVIDIA Triton are essential for managing and scaling inference.”</li>
<li>“Hardware acceleration with GPUs or TPUs can significantly improve inference speed. Batching and caching are also effective strategies.”</li>
<li>“Model monitoring is crucial to detect performance degradation. Set up metrics to track inference latency, throughput, and accuracy, and trigger alerts when thresholds are breached.”</li>
</ul></li>
<li><p><strong>Mention Incremental Learning:</strong></p>
<ul>
<li>“Given the ‘messy’ nature of the data and potential concept drift, incremental or continual learning techniques can be used to update the model with new data without retraining from scratch.”</li>
<li><strong>Communication Tip:</strong> This shows that you’re thinking about long-term maintenance and adaptation of the model in a dynamic environment.</li>
</ul></li>
<li><p><strong>Address Hyperparameter Optimization:</strong></p>
<ul>
<li>“Efficient hyperparameter tuning is essential for GANs. Bayesian optimization, Hyperband, and Population Based Training (PBT) are effective techniques for searching the hyperparameter space.”</li>
<li><strong>Communication Tip:</strong> Show familiarity with both traditional and more advanced optimization methods.</li>
</ul></li>
<li><p><strong>Conclude with Real-World Considerations:</strong></p>
<ul>
<li>“Finally, it’s important to consider cost optimization, security, scalability, reproducibility, and interpretability. For instance, using spot instances can significantly reduce training costs, but proper security measures are crucial to protect against unauthorized access.”</li>
<li><strong>Communication Tip:</strong> This demonstrates that you understand the practical aspects of deploying and maintaining a machine learning system in a real-world setting.</li>
</ul></li>
</ol>
<p>By structuring your answer in this way, you can clearly communicate your expertise while keeping the interviewer engaged and informed. Remember to adjust the level of detail based on their questions and interests. Focus on demonstrating a deep understanding of the principles involved and the practical considerations for building a scalable and robust system.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>