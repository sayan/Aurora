<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>conditional_gans_3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-4.-in-scenarios-where-the-provided-conditional-data-is-imbalanced-or-noisy-how-would-you-modify-the-training-process-of-a-conditional-gan-to-ensure-robust-and-meaningful-generation" class="level2">
<h2 class="anchored" data-anchor-id="question-4.-in-scenarios-where-the-provided-conditional-data-is-imbalanced-or-noisy-how-would-you-modify-the-training-process-of-a-conditional-gan-to-ensure-robust-and-meaningful-generation">Question: 4. In scenarios where the provided conditional data is imbalanced or noisy, how would you modify the training process of a Conditional GAN to ensure robust and meaningful generation?</h2>
<p><strong>Best Answer</strong></p>
<p>Addressing imbalanced or noisy conditional data in Conditional GANs (CGANs) requires a multifaceted approach that tackles both the data itself and the training dynamics of the GAN. Here’s a breakdown of strategies:</p>
<p><strong>1. Data Preprocessing and Augmentation:</strong></p>
<ul>
<li><strong>Addressing Imbalance:</strong>
<ul>
<li><strong>Resampling Techniques:</strong>
<ul>
<li><em>Oversampling the minority classes:</em> This involves creating synthetic samples for the under-represented conditional categories. Techniques like SMOTE (Synthetic Minority Over-sampling Technique) can be useful. SMOTE creates new instances by interpolating between existing minority class samples. For a given minority class sample <span class="math inline">\(x_i\)</span>, SMOTE selects a nearest neighbor <span class="math inline">\(x_{zi}\)</span> and creates a new sample <span class="math inline">\(x_{new}\)</span> as: <span class="math display">\[x_{new} = x_i + \lambda (x_{zi} - x_i)\]</span> where <span class="math inline">\(\lambda\)</span> is a random number between 0 and 1.</li>
<li><em>Undersampling the majority classes:</em> Randomly removing samples from the over-represented conditional categories can balance the dataset. However, this might lead to information loss, so techniques like Tomek links or Cluster Centroids can be more effective, removing only redundant or borderline samples. Tomek links identify pairs of instances from different classes that are closest to each other. Removing the majority class instance from the Tomek link can improve classification boundaries.</li>
<li><em>Cost-sensitive learning:</em> Assign higher misclassification costs to the minority classes during training. This can be implemented by weighting the loss function.</li>
</ul></li>
<li><strong>Data Augmentation:</strong> Apply transformations specific to the conditional data domain to increase the representation of minority classes. For example, if the condition is an image, apply rotations, scaling, or color jittering. If it’s text, use back-translation or synonym replacement. Let’s say we augment a conditional image <span class="math inline">\(c\)</span> with a transformation function <span class="math inline">\(T\)</span>. The augmented conditional image <span class="math inline">\(c'\)</span> is given by: <span class="math display">\[c' = T(c)\]</span> The augmented pair <span class="math inline">\((c', x)\)</span> where <span class="math inline">\(x\)</span> is the corresponding real image is then added to the training dataset.</li>
</ul></li>
<li><strong>Handling Noise:</strong>
<ul>
<li><strong>Data Cleaning:</strong> Implement techniques to identify and correct or remove noisy conditional data. This can involve outlier detection, manual inspection (if feasible), or using domain expertise to identify invalid or unlikely conditions.</li>
<li><strong>Robust Statistics:</strong> Instead of relying on mean and standard deviation, consider using robust statistics (e.g., median and interquartile range) to summarize and filter data, as they are less sensitive to outliers.</li>
<li><strong>Conditional Smoothing:</strong> Apply smoothing techniques to the conditional data, such as moving averages or Kalman filters (especially if the conditional data represents a time series). This can reduce the impact of individual noisy data points.</li>
</ul></li>
</ul>
<p><strong>2. Loss Function Modifications:</strong></p>
<ul>
<li><p><strong>Weighted Loss Functions:</strong> Assign different weights to the loss function based on the conditional class. This is especially useful for imbalanced datasets. The generator and discriminator losses can be modified as follows:</p>
<ul>
<li><em>Discriminator Loss:</em> <span class="math display">\[L_D = -E_{x \sim p_{data}(x)}[\log D(x|c)] - E_{z \sim p_z(z)}[\log (1 - D(G(z|c)|c))]\]</span> where <span class="math inline">\(p_{data}(x)\)</span> is the real data distribution, <span class="math inline">\(p_z(z)\)</span> is the prior distribution for the latent vector <span class="math inline">\(z\)</span>, <span class="math inline">\(G(z|c)\)</span> is the generator, <span class="math inline">\(D(x|c)\)</span> is the discriminator, and <span class="math inline">\(c\)</span> is the conditional input. For imbalanced data, you can weight the real and generated samples differently: <span class="math display">\[L_D = -w_{real}E_{x \sim p_{data}(x)}[\log D(x|c)] - w_{fake}E_{z \sim p_z(z)}[\log (1 - D(G(z|c)|c))]\]</span> where <span class="math inline">\(w_{real}\)</span> and <span class="math inline">\(w_{fake}\)</span> are weights inversely proportional to the number of samples in their respective classes or designed to emphasize the under-represented classes.</li>
<li><em>Generator Loss:</em> <span class="math display">\[L_G = -E_{z \sim p_z(z)}[\log D(G(z|c)|c)]\]</span> Similarly, for imbalanced data, you can adjust the generator loss to focus more on generating samples for under-represented classes.</li>
</ul></li>
<li><p><strong>Focal Loss:</strong> Originally designed for object detection, focal loss reduces the weight of easily classified examples and focuses training on hard examples. This can be beneficial when dealing with noisy data or difficult conditional scenarios. The focal loss is defined as: <span class="math display">\[FL(p_t) = -\alpha_t(1 - p_t)^\gamma \log(p_t)\]</span> where <span class="math inline">\(p_t\)</span> is the model’s estimated probability for the correct class, <span class="math inline">\(\gamma\)</span> is a focusing parameter that tunes the rate at which easy examples are down-weighted, and <span class="math inline">\(\alpha_t\)</span> is a weighting factor to address class imbalance.</p></li>
<li><p><strong>Regularization:</strong></p>
<ul>
<li><em>L1/L2 Regularization:</em> Adding L1 or L2 regularization to the generator and discriminator can prevent overfitting to noisy data. This is especially crucial when the noise correlates with the conditional input.</li>
<li><em>Spectral Normalization:</em> Stabilizes the training of the discriminator by normalizing the spectral norm of the weight matrices, which helps prevent exploding gradients.</li>
</ul></li>
</ul>
<p><strong>3. Robust Conditioning Mechanisms:</strong></p>
<ul>
<li><strong>Embedding-Based Conditioning:</strong> Instead of directly feeding noisy conditional data into the generator and discriminator, project it into a lower-dimensional embedding space using a robust encoder. This embedding can then be used as the conditional input. This can help filter out noise and extract meaningful features.</li>
<li><strong>Attention Mechanisms:</strong> Incorporate attention mechanisms into the generator and discriminator. These mechanisms allow the model to selectively attend to relevant parts of the conditional input, effectively ignoring noisy or irrelevant information. The attention mechanism can be seen as a learned weighting of the conditional input features. For example, given a set of conditional features <span class="math inline">\(C\)</span>, the attention weights <span class="math inline">\(\alpha_i\)</span> are computed as: <span class="math display">\[\alpha_i = \frac{\exp(a(C)_i)}{\sum_j \exp(a(C)_j)}\]</span> where <span class="math inline">\(a(C)\)</span> is an attention function that maps the conditional features to a scalar. The attended conditional features <span class="math inline">\(C'\)</span> are then computed as: <span class="math display">\[C' = \sum_i \alpha_i C_i\]</span> The attended features <span class="math inline">\(C'\)</span> are then used by the generator and discriminator.</li>
<li><strong>Adversarial Training of the Conditional Encoder:</strong> Train an encoder adversarially to map noisy conditional inputs to a latent space that is indistinguishable from a latent space generated from clean conditional inputs. This forces the encoder to learn robust representations that are insensitive to noise.</li>
</ul>
<p><strong>4. Training Strategies:</strong></p>
<ul>
<li><strong>Progressive Growing of GANs (PGGAN):</strong> Start by training the GAN on downsampled, less noisy versions of the data and gradually increase the resolution. This can help the model learn the underlying structure of the data before being exposed to the full noise.</li>
<li><strong>Curriculum Learning:</strong> Gradually increase the complexity of the conditional task during training. Start with simpler, less noisy conditional examples and gradually introduce more challenging or noisy examples.</li>
<li><strong>Early Stopping:</strong> Monitor the performance of the GAN on a validation set and stop training when the performance starts to degrade. This can prevent overfitting to noisy data.</li>
<li><strong>Ensemble Methods:</strong> Train multiple CGANs with different architectures or training parameters and combine their outputs. This can improve the robustness and stability of the generation process.</li>
</ul>
<p><strong>5. Evaluation Metrics:</strong></p>
<ul>
<li><strong>Conditional Inception Score (CIS):</strong> A modification of the Inception Score that evaluates the quality and diversity of generated images conditioned on the conditional input. However, be mindful that IS and CIS can be gamed and may not always reflect true quality, especially when dealing with unusual or noisy data.</li>
<li><strong>Fréchet Inception Distance (FID):</strong> Calculates the distance between the feature distributions of the generated and real images in the Inception feature space. Lower FID scores generally indicate better generation quality. However, FID can also be sensitive to noise and might require careful interpretation.</li>
<li><strong>Human Evaluation:</strong> Involve human evaluators to assess the quality, relevance, and diversity of the generated images. This is especially important when the conditional data is noisy or subjective.</li>
<li><strong>Conditional Accuracy:</strong> Measure how well the generated samples match the provided conditional data. This can be done by training a separate classifier to predict the conditional category from the generated samples. A high conditional accuracy indicates that the GAN is generating samples that are relevant to the provided conditions.</li>
</ul>
<p><strong>Real-world Considerations:</strong></p>
<ul>
<li><strong>Computational Cost:</strong> Some of these techniques, such as adversarial training or ensemble methods, can be computationally expensive.</li>
<li><strong>Hyperparameter Tuning:</strong> Many of these techniques require careful hyperparameter tuning to achieve optimal performance.</li>
<li><strong>Domain Expertise:</strong> Leverage domain expertise to inform the data preprocessing and augmentation strategies.</li>
<li><strong>Monitoring and Debugging:</strong> Carefully monitor the training process and debug any issues that arise. GAN training is notoriously unstable, and dealing with noisy or imbalanced data can exacerbate these issues.</li>
</ul>
<p>By combining these techniques, we can train CGANs that are robust to imbalanced or noisy conditional data and generate meaningful and relevant samples. The key is to carefully analyze the specific characteristics of the data and choose the techniques that are most appropriate for the task at hand.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this in an interview:</p>
<ol type="1">
<li><strong>Start with Acknowledgment (Context):</strong>
<ul>
<li>“That’s an excellent question. Dealing with imbalanced or noisy conditional data in CGANs is a common challenge in real-world applications.”</li>
</ul></li>
<li><strong>Overview of the Approach (High-Level):</strong>
<ul>
<li>“My approach to this problem is multi-faceted, focusing on both pre-processing the data and modifying the GAN’s training process to improve robustness.”</li>
</ul></li>
<li><strong>Data Preprocessing (Explain with Examples):</strong>
<ul>
<li>“First, I would address the data imbalance using techniques like oversampling the minority classes with SMOTE or undersampling the majority classes. For example, SMOTE generates new synthetic examples by interpolating between existing minority class samples.”</li>
<li><em>If asked for the equation</em>: “The formula for SMOTE is fairly straightforward: <span class="math display">\[x_{new} = x_i + \lambda (x_{zi} - x_i)\]</span>, where <span class="math inline">\(x_{new}\)</span> is the new sample, <span class="math inline">\(x_i\)</span> is an existing minority class sample, <span class="math inline">\(x_{zi}\)</span> is its nearest neighbor, and <span class="math inline">\(\lambda\)</span> is a random number between 0 and 1.” (Explain the terms briefly.)</li>
<li>“For noisy data, I’d implement cleaning techniques, robust statistics, or conditional smoothing.”</li>
</ul></li>
<li><strong>Loss Function Modifications (Explain the Intuition):</strong>
<ul>
<li>“Next, I would modify the loss function to account for the data imbalance. Weighted loss functions, where we assign higher costs to misclassifying minority classes, can be effective. The idea is to penalize the discriminator more for failing to distinguish real minority class examples.”</li>
<li><em>If asked about weighted loss for Discriminator</em>: “We can modify the discriminator loss: <span class="math display">\[L_D = -w_{real}E_{x \sim p_{data}(x)}[\log D(x|c)] - w_{fake}E_{z \sim p_z(z)}[\log (1 - D(G(z|c)|c))]\]</span>. Here <span class="math inline">\(w_{real}\)</span> and <span class="math inline">\(w_{fake}\)</span> are weights that prioritize real samples and fake samples and would be tuned to emphasize under-represented classes..”</li>
<li>“Focal loss is another option, which focuses the training on ‘hard’ examples and down-weights easy ones.”</li>
</ul></li>
<li><strong>Robust Conditioning Mechanisms (Explain the Purpose):</strong>
<ul>
<li>“To improve robustness to noise, I would use embedding-based conditioning or attention mechanisms. Embedding-based conditioning projects the noisy data into a cleaner latent space. Attention mechanisms allow the model to selectively attend to the most relevant parts of the conditional input and ignore the noise.”</li>
</ul></li>
<li><strong>Training Strategies (Mention Key Techniques):</strong>
<ul>
<li>“For training, I would consider techniques like progressive growing of GANs, curriculum learning, and early stopping to prevent overfitting.”</li>
</ul></li>
<li><strong>Evaluation Metrics (Highlight Limitations):</strong>
<ul>
<li>“Finally, I would evaluate the CGAN using metrics like Conditional Inception Score, Fréchet Inception Distance, and, importantly, human evaluation, acknowledging that automated metrics can be misleading with noisy data.”</li>
</ul></li>
<li><strong>Real-World Considerations (Demonstrate Practicality):</strong>
<ul>
<li>“It’s important to remember the computational cost of these methods and the need for careful hyperparameter tuning. Domain expertise is invaluable for guiding the data preprocessing and augmentation strategies. GAN training can be sensitive, requiring careful monitoring.”</li>
</ul></li>
<li><strong>Conclude with Synthesis:</strong>
<ul>
<li>“In summary, robust CGAN training with imbalanced or noisy data requires a combination of data preprocessing, loss function modifications, robust conditioning mechanisms, and careful training strategies. The specific approach will depend on the nature of the data and the specific goals of the application.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Take your time and allow the interviewer to digest the information.</li>
<li><strong>Use clear and concise language:</strong> Avoid jargon where possible.</li>
<li><strong>Focus on the intuition behind the techniques:</strong> Explain why each technique is used and how it addresses the challenges of imbalanced or noisy data.</li>
<li><strong>Engage the interviewer:</strong> Ask if they have any questions and encourage them to interrupt if they need clarification.</li>
<li><strong>Be prepared to elaborate:</strong> The interviewer may ask you to go into more detail on a particular technique.</li>
<li><strong>Don’t be afraid to admit what you don’t know:</strong> If you’re not familiar with a particular technique, be honest and say so. Then, explain how you would go about learning more about it.</li>
<li><strong>Use “I” statements:</strong> Frame your answer in terms of what <em>you</em> would do. This shows that you are taking ownership of the problem.</li>
<li><strong>Summarize the key points at the end:</strong> This helps to reinforce the information and ensure that the interviewer understands your approach.</li>
<li><strong>Mathematical notation</strong>: Introduce the equation, explain the terms, and then recap the significance.</li>
</ul>
<p>By following these guidelines, you can effectively communicate your expertise and demonstrate your ability to solve challenging problems in the field of GANs.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>