<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>naive_bayes_0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-1.-explain-the-fundamental-concept-of-the-naive-bayes-classifier-and-its-underlying-assumptions.-how-does-it-utilize-bayes-theorem-in-classification-tasks" class="level2">
<h2 class="anchored" data-anchor-id="question-1.-explain-the-fundamental-concept-of-the-naive-bayes-classifier-and-its-underlying-assumptions.-how-does-it-utilize-bayes-theorem-in-classification-tasks">Question: 1. Explain the fundamental concept of the Naive Bayes classifier and its underlying assumptions. How does it utilize Bayes’ theorem in classification tasks?</h2>
<p><strong>Best Answer</strong></p>
<p>The Naive Bayes classifier is a probabilistic machine learning model used for classification tasks. It’s based on applying Bayes’ theorem with strong (naive) independence assumptions between the features. Despite its simplicity and the often unrealistic nature of its assumptions, Naive Bayes classifiers can perform surprisingly well in many real-world situations, particularly in text classification, spam filtering, and sentiment analysis.</p>
<p><strong>1. Bayes’ Theorem</strong></p>
<p>At its core, Naive Bayes utilizes Bayes’ Theorem, which describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Mathematically, Bayes’ theorem is expressed as:</p>
<p><span class="math display">\[P(A|B) = \frac{P(B|A) P(A)}{P(B)}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(A|B)\)</span> is the posterior probability of event A occurring given that event B has occurred.</li>
<li><span class="math inline">\(P(B|A)\)</span> is the likelihood of event B occurring given that event A has occurred.</li>
<li><span class="math inline">\(P(A)\)</span> is the prior probability of event A occurring.</li>
<li><span class="math inline">\(P(B)\)</span> is the prior probability of event B occurring.</li>
</ul>
<p>In the context of classification:</p>
<ul>
<li><span class="math inline">\(A\)</span> represents the class label (e.g., “spam” or “not spam”).</li>
<li><span class="math inline">\(B\)</span> represents the feature values (e.g., the presence of certain words in an email).</li>
<li><span class="math inline">\(P(A|B)\)</span> is the probability of the class given the features. We are trying to estimate this.</li>
<li><span class="math inline">\(P(B|A)\)</span> is the probability of observing the features given the class.</li>
<li><span class="math inline">\(P(A)\)</span> is the prior probability of the class.</li>
<li><span class="math inline">\(P(B)\)</span> is the probability of observing the features (regardless of the class). This often acts as a normalizing constant.</li>
</ul>
<p><strong>2. Naive Bayes Assumption</strong></p>
<p>The “naive” part of Naive Bayes comes from the strong assumption of <em>conditional independence</em> between the features, given the class. This means that the presence or absence of one feature does not affect the presence or absence of any other feature, given the class variable. In mathematical terms, if we have features <span class="math inline">\(x_1, x_2, ..., x_n\)</span>, the assumption is:</p>
<p><span class="math display">\[P(x_1, x_2, ..., x_n | y) = P(x_1|y)P(x_2|y)...P(x_n|y)\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the class variable.</p>
<p>This assumption drastically simplifies the calculation of <span class="math inline">\(P(B|A)\)</span> (or <span class="math inline">\(P(x_1, x_2, ..., x_n | y)\)</span>). Instead of needing to model the joint distribution of all features, we only need to model the conditional distribution of each feature given the class.</p>
<p><strong>3. Naive Bayes for Classification</strong></p>
<p>To classify a new instance, the Naive Bayes classifier calculates the posterior probability for each class given the features of the instance. The instance is then assigned to the class with the highest posterior probability. Mathematically, we want to find the class <span class="math inline">\(\hat{y}\)</span> that maximizes <span class="math inline">\(P(y | x_1, x_2, ..., x_n)\)</span>:</p>
<p><span class="math display">\[\hat{y} = \underset{y}{\operatorname{argmax}} \ P(y | x_1, x_2, ..., x_n)\]</span></p>
<p>Using Bayes’ Theorem and the naive independence assumption, we can rewrite this as:</p>
<p><span class="math display">\[\hat{y} = \underset{y}{\operatorname{argmax}} \ \frac{P(x_1, x_2, ..., x_n | y) P(y)}{P(x_1, x_2, ..., x_n)} = \underset{y}{\operatorname{argmax}} \ P(y) \prod_{i=1}^{n} P(x_i | y)\]</span></p>
<p>Since <span class="math inline">\(P(x_1, x_2, ..., x_n)\)</span> is the same for all classes, it doesn’t affect the argmax, and we can drop it. Thus, the classification rule becomes:</p>
<p><span class="math display">\[\hat{y} = \underset{y}{\operatorname{argmax}} \ P(y) \prod_{i=1}^{n} P(x_i | y)\]</span></p>
<p><strong>4. Estimating Probabilities</strong></p>
<p>The probabilities <span class="math inline">\(P(y)\)</span> and <span class="math inline">\(P(x_i | y)\)</span> are estimated from the training data.</p>
<ul>
<li><span class="math inline">\(P(y)\)</span> is estimated as the proportion of instances belonging to class <span class="math inline">\(y\)</span> in the training set.</li>
<li><span class="math inline">\(P(x_i | y)\)</span> depends on the type of feature <span class="math inline">\(x_i\)</span>. Common distributions used are:
<ul>
<li><strong>Gaussian Naive Bayes:</strong> For continuous features, assume <span class="math inline">\(P(x_i | y)\)</span> follows a Gaussian (normal) distribution. The mean and variance of the Gaussian are estimated from the training data for each class.</li>
<li><strong>Multinomial Naive Bayes:</strong> For discrete features (e.g., word counts in text), assume <span class="math inline">\(P(x_i | y)\)</span> follows a multinomial distribution. The parameters of the multinomial distribution are estimated from the training data. This is common in text classification.</li>
<li><strong>Bernoulli Naive Bayes:</strong> For binary features (e.g., presence/absence of a word), assume <span class="math inline">\(P(x_i | y)\)</span> follows a Bernoulli distribution.</li>
</ul></li>
</ul>
<p><strong>5. Laplace Smoothing (or Additive Smoothing)</strong></p>
<p>A common issue is when a feature value <span class="math inline">\(x_i\)</span> does not occur for a particular class <span class="math inline">\(y\)</span> in the training data. This would result in <span class="math inline">\(P(x_i | y) = 0\)</span>, which would then make the entire product equal to zero, regardless of other feature values. To avoid this, Laplace smoothing (also known as add-one smoothing) is often used. It adds a small constant (usually 1) to the numerator and a corresponding constant to the denominator when estimating probabilities.</p>
<p>For example, for Multinomial Naive Bayes, the smoothed probability estimate becomes:</p>
<p><span class="math display">\[P(x_i | y) = \frac{\text{count}(x_i, y) + \alpha}{\text{count}(y) + \alpha n}\]</span></p>
<p>where: * <span class="math inline">\(\text{count}(x_i, y)\)</span> is the number of times feature <span class="math inline">\(x_i\)</span> appears in class <span class="math inline">\(y\)</span>. * <span class="math inline">\(\text{count}(y)\)</span> is the total number of features in class <span class="math inline">\(y\)</span>. * <span class="math inline">\(\alpha\)</span> is the smoothing parameter (typically 1 for Laplace smoothing). * <span class="math inline">\(n\)</span> is the number of possible features.</p>
<p><strong>6. Advantages and Disadvantages</strong></p>
<ul>
<li><strong>Advantages:</strong>
<ul>
<li>Simple and easy to implement.</li>
<li>Computationally efficient, especially for large datasets.</li>
<li>Performs well in many real-world situations, particularly with high-dimensional data.</li>
<li>Can be used for both binary and multiclass classification.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li>The naive independence assumption is often violated in practice.</li>
<li>Can suffer from the “zero-frequency problem” if a feature value is not seen in the training data for a particular class (addressed by smoothing).</li>
<li>Not as accurate as more complex models when the independence assumption is strongly violated.</li>
</ul></li>
</ul>
<p><strong>7. Real-world Considerations</strong></p>
<ul>
<li><strong>Feature Engineering:</strong> The performance of Naive Bayes heavily relies on feature engineering. Selecting relevant and informative features is crucial.</li>
<li><strong>Data Preprocessing:</strong> Preprocessing steps like removing stop words, stemming, and using TF-IDF weighting can significantly improve performance in text classification.</li>
<li><strong>Handling Continuous Features:</strong> While Gaussian Naive Bayes can handle continuous features, it’s often beneficial to discretize continuous features into bins, especially if the Gaussian assumption is not met.</li>
<li><strong>Model Selection and Tuning:</strong> Choosing the appropriate type of Naive Bayes (Gaussian, Multinomial, Bernoulli) and tuning hyperparameters like the smoothing parameter <span class="math inline">\(\alpha\)</span> can improve performance.</li>
</ul>
<p>In summary, the Naive Bayes classifier is a powerful and efficient classification algorithm based on Bayes’ theorem and the naive independence assumption. Despite its simplicity, it can be surprisingly effective in many real-world applications, especially with careful feature engineering and data preprocessing.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested approach to explaining Naive Bayes in an interview:</p>
<ol type="1">
<li><strong>Start with the basics:</strong>
<ul>
<li>“Naive Bayes is a probabilistic classifier based on Bayes’ theorem. It’s used for classification tasks and is known for its simplicity and efficiency.”</li>
<li>“Despite being ‘naive,’ it often performs surprisingly well in practice, especially for text classification.”</li>
</ul></li>
<li><strong>Explain Bayes’ Theorem:</strong>
<ul>
<li>“The foundation of Naive Bayes is Bayes’ Theorem, which calculates the probability of an event based on prior knowledge.”</li>
<li>Write the formula on the whiteboard: <span class="math display">\[P(A|B) = \frac{P(B|A) P(A)}{P(B)}\]</span></li>
<li>“In the context of classification, A represents the class, and B represents the features. We’re trying to find the probability of a class given the features.”</li>
<li>Explain each term in the equation (<span class="math inline">\(P(A|B)\)</span>, <span class="math inline">\(P(B|A)\)</span>, <span class="math inline">\(P(A)\)</span>, <span class="math inline">\(P(B)\)</span>) in the context of classification.</li>
</ul></li>
<li><strong>Introduce the Naive Assumption:</strong>
<ul>
<li>“The ‘naive’ part comes from the assumption of conditional independence between features, given the class. This means we assume that features are independent of each other, which simplifies calculations.”</li>
<li>Write the conditional independence formula: <span class="math display">\[P(x_1, x_2, ..., x_n | y) = P(x_1|y)P(x_2|y)...P(x_n|y)\]</span></li>
<li>“Of course, this assumption is often not true in reality, but surprisingly, the model still works reasonably well.”</li>
</ul></li>
<li><strong>Describe the Classification Process:</strong>
<ul>
<li>“To classify a new instance, we calculate the posterior probability for each class and choose the class with the highest probability.”</li>
<li>Write the classification rule: <span class="math display">\[\hat{y} = \underset{y}{\operatorname{argmax}} \ P(y) \prod_{i=1}^{n} P(x_i | y)\]</span></li>
<li>“We estimate the probabilities <span class="math inline">\(P(y)\)</span> and <span class="math inline">\(P(x_i | y)\)</span> from the training data. For example, P(y) is simply the proportion of instances belonging to class y.”</li>
</ul></li>
<li><strong>Discuss Probability Estimation and Smoothing:</strong>
<ul>
<li>“The way we estimate <span class="math inline">\(P(x_i | y)\)</span> depends on the type of feature. For continuous features, we can use Gaussian Naive Bayes, assuming a normal distribution. For discrete features like word counts, we can use Multinomial Naive Bayes.”</li>
<li>“A common issue is when a feature value doesn’t appear for a class in the training data, leading to zero probabilities. To avoid this, we use Laplace smoothing (or additive smoothing).”</li>
<li>“Laplace smoothing adds a small constant to the counts to avoid zero probabilities. This ensures that all features have a non-zero probability.”</li>
</ul></li>
<li><strong>Mention Advantages and Disadvantages:</strong>
<ul>
<li>“Naive Bayes has several advantages: it’s simple, efficient, and performs well with high-dimensional data.”</li>
<li>“However, the independence assumption is a limitation, and it might not be as accurate as more complex models when this assumption is strongly violated.”</li>
</ul></li>
<li><strong>Real-world Considerations:</strong>
<ul>
<li>“Feature engineering is very important, as performance relies on good features”</li>
<li>“Data preprocessing, such as removing stop words or stemming for text data, is also crucial.”</li>
<li>“The model type selection also matters.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the explanation. Allow time for the interviewer to process the information.</li>
<li><strong>Engage the interviewer:</strong> Ask if they have any questions along the way. This shows that you’re open to discussion and can adapt your explanation.</li>
<li><strong>Simplify complex equations:</strong> When writing equations, briefly explain what each term represents and why it’s important.</li>
<li><strong>Use analogies:</strong> Relate the concepts to real-world examples to make them easier to understand.</li>
<li><strong>Be honest about limitations:</strong> Acknowledge the limitations of Naive Bayes, such as the independence assumption. This shows that you have a nuanced understanding of the model.</li>
<li><strong>Emphasize practical aspects:</strong> Highlight the practical aspects of using Naive Bayes, such as feature engineering, data preprocessing, and smoothing techniques. This demonstrates your ability to apply the model effectively in real-world scenarios.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>