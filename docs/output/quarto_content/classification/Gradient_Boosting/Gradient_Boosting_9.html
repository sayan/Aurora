<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>gradient_boosting_9</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-10.-how-would-you-address-scalability-issues-when-deploying-gradient-boosting-models-on-massive-datasets-what-are-some-techniques-or-modifications-to-improve-computational-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="question-10.-how-would-you-address-scalability-issues-when-deploying-gradient-boosting-models-on-massive-datasets-what-are-some-techniques-or-modifications-to-improve-computational-efficiency">Question: 10. How would you address scalability issues when deploying gradient boosting models on massive datasets? What are some techniques or modifications to improve computational efficiency?</h2>
<p><strong>Best Answer</strong></p>
<p>Gradient boosting, while powerful, can be computationally expensive and memory-intensive, especially when dealing with massive datasets. Addressing scalability involves several strategies spanning algorithmic modifications, distributed computing, and efficient memory management. Here’s a breakdown of techniques:</p>
<section id="algorithmic-modifications-and-approximations" class="level3">
<h3 class="anchored" data-anchor-id="algorithmic-modifications-and-approximations">1. Algorithmic Modifications and Approximations</h3>
<ul>
<li><p><strong>Histogram-Based Gradient Boosting:</strong></p>
<ul>
<li><p>Traditional gradient boosting algorithms like XGBoost and LightGBM use pre-sorted algorithms to find the best split points. While accurate, this becomes computationally expensive for large datasets.</p></li>
<li><p>Histogram-based algorithms discretize continuous features into a fixed number of bins (histograms). This reduces the complexity of finding the optimal split point because instead of evaluating every possible split, the algorithm only needs to consider the boundaries of these bins.</p></li>
<li><p><strong>Benefits</strong>: Reduces computation cost from <span class="math inline">\(O(n \log n)\)</span> (for pre-sorting) to <span class="math inline">\(O(n)\)</span>, where <span class="math inline">\(n\)</span> is the number of data points. This is a substantial speedup.</p>
<ul>
<li><strong>Mathematical Intuition</strong>: Let’s consider a feature <span class="math inline">\(x_i\)</span> with <span class="math inline">\(n\)</span> unique values. In a traditional approach, finding the best split requires sorting these values, which takes <span class="math inline">\(O(n \log n)\)</span> time. With <span class="math inline">\(k\)</span> bins, we only need to iterate through these <span class="math inline">\(k\)</span> bins to find the best split point. If <span class="math inline">\(k &lt;&lt; n\)</span>, the complexity is reduced.</li>
<li><strong>Example</strong>: LightGBM employs this approach.</li>
</ul></li>
</ul></li>
<li><p><strong>Gradient-Based One-Side Sampling (GOSS):</strong></p>
<ul>
<li><p>GOSS focuses on sampling instances for estimating the information gain. It retains instances with large gradients (since they contribute more to the loss) and randomly samples instances with small gradients.</p></li>
<li><p><strong>Benefits</strong>: Reduces the number of instances used for gradient calculation, thereby speeding up training.</p>
<ul>
<li><p><strong>Mathematical Formulation</strong>: Let <span class="math inline">\(A\)</span> be the set of instances with large gradients, and <span class="math inline">\(B\)</span> be the set of instances with small gradients. GOSS samples a subset of <span class="math inline">\(B\)</span>, say <span class="math inline">\(B'\)</span>, and estimates the information gain using these samples. It can be formulated as:</p>
<p><span class="math display">\[
\text{Gain} \approx \frac{1}{n} \sum_{i \in A} g_i^2 + \frac{(1 - a)}{n} \sum_{i \in B'} g_i^2
\]</span></p>
<p>where <span class="math inline">\(g_i\)</span> represents the gradient of the <span class="math inline">\(i\)</span>-th instance, and <span class="math inline">\(a\)</span> is the sampling ratio for instances with large gradients. The <span class="math inline">\((1-a)\)</span> factor is used to compensate for the sampling bias.</p></li>
<li><p><strong>Example</strong>: LightGBM incorporates GOSS for faster training.</p></li>
</ul></li>
</ul></li>
<li><p><strong>Early Stopping:</strong></p>
<ul>
<li>Monitor the performance of the model on a validation set and stop training when the performance plateaus or starts to degrade.</li>
<li><strong>Benefits</strong>: Prevents overfitting and reduces unnecessary computation.</li>
</ul></li>
<li><p><strong>Subsampling (Stochastic Gradient Boosting):</strong></p>
<ul>
<li><p>Train each tree on a random subset of the data.</p></li>
<li><p><strong>Benefits</strong>: Introduces randomness, reduces variance, and speeds up training.</p>
<ul>
<li><strong>Mathematical Analogy</strong>: Similar to mini-batch gradient descent in neural networks, subsampling reduces the computational cost per iteration.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="parallelization-and-distributed-computing" class="level3">
<h3 class="anchored" data-anchor-id="parallelization-and-distributed-computing">2. Parallelization and Distributed Computing</h3>
<ul>
<li><p><strong>Feature Parallelization:</strong></p>
<ul>
<li>Distribute the features across multiple machines. Each machine calculates the best split point for its subset of features, and then the best split overall is determined.</li>
<li><strong>Benefits</strong>: Accelerates the split finding process, especially when the number of features is large.</li>
</ul></li>
<li><p><strong>Data Parallelization:</strong></p>
<ul>
<li>Partition the data across multiple machines. Each machine builds a local tree, and then these trees are aggregated to form the final model.</li>
<li><strong>Benefits</strong>: Enables training on datasets that are too large to fit in the memory of a single machine.</li>
</ul></li>
<li><p><strong>Tree Parallelization:</strong></p>
<ul>
<li>Parallelize the building of individual trees. For example, different nodes of the tree can be built in parallel.</li>
<li><strong>Benefits</strong>: Exploits parallelism within the tree building process.</li>
</ul></li>
<li><p><strong>Distributed Frameworks:</strong></p>
<ul>
<li>Use frameworks like Apache Spark, Dask, or Ray to distribute the training process across a cluster of machines.</li>
<li><strong>Benefits</strong>: Provides scalability and fault tolerance for training on massive datasets.</li>
<li><strong>Example</strong>: XGBoost and LightGBM have Spark and Dask integrations.</li>
</ul></li>
</ul>
</section>
<section id="memory-management" class="level3">
<h3 class="anchored" data-anchor-id="memory-management">3. Memory Management</h3>
<ul>
<li><p><strong>Data Type Optimization:</strong></p>
<ul>
<li>Use smaller data types (e.g., <code>float32</code> instead of <code>float64</code>) to reduce memory usage.</li>
<li><strong>Benefits</strong>: Significant memory savings, especially for large datasets with many numerical features.</li>
</ul></li>
<li><p><strong>Feature Selection/Reduction:</strong></p>
<ul>
<li>Select the most relevant features and discard the rest. Techniques like PCA, feature importance from a simpler model, or domain knowledge can be used.</li>
<li><strong>Benefits</strong>: Reduces the dimensionality of the data, leading to faster training and lower memory consumption.</li>
</ul></li>
<li><p><strong>Sparse Data Handling:</strong></p>
<ul>
<li>For datasets with many missing values or zero values, use sparse matrix representations.</li>
<li><strong>Benefits</strong>: Reduces memory usage by only storing non-zero values.</li>
</ul></li>
<li><p><strong>Out-of-Core Learning:</strong></p>
<ul>
<li>Process the data in chunks, loading only a portion of the data into memory at a time.</li>
<li><strong>Benefits</strong>: Enables training on datasets that are larger than the available memory.</li>
</ul></li>
</ul>
</section>
<section id="model-complexity-reduction" class="level3">
<h3 class="anchored" data-anchor-id="model-complexity-reduction">4. Model Complexity Reduction</h3>
<ul>
<li><p><strong>Tree Depth Limitation:</strong></p>
<ul>
<li>Limit the maximum depth of the trees to prevent overfitting and reduce model complexity.</li>
<li><strong>Benefits</strong>: Smaller trees require less memory and are faster to evaluate.</li>
</ul></li>
<li><p><strong>Regularization:</strong></p>
<ul>
<li>Apply L1 (Lasso) or L2 (Ridge) regularization to the tree weights to prevent overfitting.</li>
<li><strong>Benefits</strong>: Simpler models that generalize better and require less memory.</li>
<li><strong>Mathematical Definition</strong>: L1 regularization adds a penalty term proportional to the absolute value of the weights:</li>
</ul>
<p><span class="math display">\[
\text{Loss} + \lambda_1 \sum_{j=1}^{p} |w_j|
\]</span></p>
<pre><code>L2 regularization adds a penalty term proportional to the square of the weights:</code></pre>
<p><span class="math display">\[
\text{Loss} + \lambda_2 \sum_{j=1}^{p} w_j^2
\]</span> Where <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span> are the regularization parameters, and <span class="math inline">\(w_j\)</span> are the weights of the model.</p></li>
<li><p><strong>Number of Trees:</strong></p>
<ul>
<li>Reduce the number of trees in the ensemble. Use early stopping to determine the optimal number of trees.</li>
<li><strong>Benefits</strong>: Smaller models that are faster to evaluate and require less memory.</li>
</ul></li>
</ul>
</section>
<section id="real-world-engineering-challenges" class="level3">
<h3 class="anchored" data-anchor-id="real-world-engineering-challenges">5. Real-World Engineering Challenges</h3>
<ul>
<li><p><strong>Data Storage and Access:</strong></p>
<ul>
<li>Efficient data storage formats (e.g., Parquet, ORC) and access patterns are crucial.</li>
<li>Optimize data loading pipelines to minimize I/O overhead.</li>
</ul></li>
<li><p><strong>Infrastructure Costs:</strong></p>
<ul>
<li>Consider the cost of running distributed training jobs on cloud platforms.</li>
<li>Optimize resource allocation to minimize costs.</li>
</ul></li>
<li><p><strong>Model Deployment:</strong></p>
<ul>
<li>Deploy the model to a scalable serving infrastructure (e.g., Kubernetes, AWS SageMaker).</li>
<li>Optimize the model for inference speed and memory usage (e.g., using model quantization or pruning).</li>
</ul></li>
<li><p><strong>Monitoring and Maintenance:</strong></p>
<ul>
<li>Monitor the performance of the model in production and retrain as needed.</li>
<li>Implement automated retraining pipelines to ensure the model stays up-to-date.</li>
</ul></li>
</ul>
<p>In summary, addressing scalability issues in gradient boosting requires a multi-faceted approach, combining algorithmic optimizations, parallelization strategies, efficient memory management, and careful consideration of real-world engineering constraints. Selecting the right combination of techniques depends on the specific characteristics of the dataset and the available resources.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with the problem statement</strong>: “Gradient boosting, while powerful, can be computationally intensive and memory-hungry when dealing with massive datasets. To address scalability, we can consider multiple strategies.”</li>
<li><strong>Overview of categories:</strong> “These strategies fall into several categories: Algorithmic Modifications, Parallelization, Memory Management, and Model Complexity Reduction.” Briefly mention these categories.</li>
<li><strong>Algorithmic Modifications:</strong>
<ul>
<li>“First, we can use algorithmic modifications like Histogram-based Gradient Boosting. Explain that these algorithms discretize the feature space, reducing the computation for finding optimal split points. Mention that LightGBM utilizes this approach and that the time complexity goes down from <span class="math inline">\(O(n \log n)\)</span> to <span class="math inline">\(O(n)\)</span>.”</li>
<li>“Another modification is Gradient-based One-Side Sampling (GOSS) as implemented by LightGBM. Here, we sample instances based on gradient magnitude, focusing on those with large gradients. You can explain the equation in the Best Answer section.”</li>
</ul></li>
<li><strong>Parallelization:</strong>
<ul>
<li>“Parallelization techniques are crucial. We can use feature parallelization, where features are distributed across machines. Data parallelization involves partitioning the data, and each machine builds a local tree. Tree Parallelization involves parallelizing the construction of individual trees.”</li>
<li>“We can utilize distributed frameworks like Apache Spark, Dask, or Ray to distribute the training. Many libraries, like XGBoost and LightGBM, integrate with these frameworks.”</li>
</ul></li>
<li><strong>Memory Management:</strong>
<ul>
<li>“Efficient memory management is also important. We can optimize data types, use feature selection to reduce dimensionality, handle sparse data efficiently, and use out-of-core learning.”</li>
</ul></li>
<li><strong>Model Complexity Reduction:</strong>
<ul>
<li>“Reducing model complexity is also an important step. We can limit the tree depth, apply L1 or L2 regularization, and reduce the number of trees. Explain each option briefly, explaining the L1/L2 regularization using the equations.”</li>
</ul></li>
<li><strong>Real-World Considerations:</strong>
<ul>
<li>“Finally, we need to consider real-world engineering challenges such as efficient data storage formats, infrastructure costs on cloud platforms, deployment to scalable serving infrastructures, and monitoring and maintenance of the deployed model.”</li>
</ul></li>
<li><strong>Concluding Remark:</strong>
<ul>
<li>“In summary, addressing scalability requires a multi-faceted approach. The best combination of techniques depends on the specific data and available resources.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself:</strong> Don’t rush through the answer. Take your time to explain each concept clearly.</li>
<li><strong>Use examples:</strong> Provide specific examples of algorithms and frameworks that implement these techniques.</li>
<li><strong>Engage the interviewer:</strong> Ask if they have any questions or want you to elaborate on a specific area.</li>
<li><strong>Mathematical details:</strong> When explaining equations, keep it high-level. Explain what the variables represent and what the equation aims to achieve without getting bogged down in minute details. You can gauge from their reaction whether to delve deeper.</li>
<li><strong>Balance theoretical and practical aspects:</strong> Show that you understand both the theoretical foundations and the practical implications of these techniques.</li>
<li><strong>Be confident</strong>: Convey your expertise with confidence.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>