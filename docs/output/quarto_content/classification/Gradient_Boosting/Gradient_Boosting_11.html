<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>gradient_boosting_11</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-12.-in-an-operational-setting-where-model-interpretability-and-transparency-are-crucial-how-would-you-explain-the-decisions-made-by-a-gradient-boosting-model-and-what-techniques-could-you-employ-for-model-explainability" class="level2">
<h2 class="anchored" data-anchor-id="question-12.-in-an-operational-setting-where-model-interpretability-and-transparency-are-crucial-how-would-you-explain-the-decisions-made-by-a-gradient-boosting-model-and-what-techniques-could-you-employ-for-model-explainability">Question: 12. In an operational setting where model interpretability and transparency are crucial, how would you explain the decisions made by a gradient boosting model, and what techniques could you employ for model explainability?</h2>
<p><strong>Best Answer</strong></p>
<p>Gradient Boosting Machines (GBMs) are powerful ensemble methods, but they can be complex and difficult to interpret directly. In operational settings where transparency and interpretability are paramount (e.g., finance, healthcare, legal), understanding <em>why</em> a GBM makes a particular prediction is crucial. Here’s a breakdown of techniques for explaining GBM decisions and addressing transparency concerns:</p>
<p><strong>1. Understanding Gradient Boosting’s Complexity:</strong></p>
<p>Gradient boosting builds an ensemble of decision trees sequentially. Each tree corrects the errors of its predecessors by fitting to the residuals. The final prediction is a weighted sum of the predictions of all trees.</p>
<p><span class="math display">\[
\hat{y} = \sum_{t=1}^{T} \alpha_t f_t(x)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\hat{y}\)</span> is the final prediction.</li>
<li><span class="math inline">\(T\)</span> is the total number of trees.</li>
<li><span class="math inline">\(\alpha_t\)</span> is the weight (learning rate) of the <span class="math inline">\(t\)</span>-th tree.</li>
<li><span class="math inline">\(f_t(x)\)</span> is the prediction of the <span class="math inline">\(t\)</span>-th tree for input <span class="math inline">\(x\)</span>.</li>
</ul>
<p>This additive structure makes it challenging to directly trace the influence of individual features on the final prediction.</p>
<p><strong>2. Model-Specific Interpretability Techniques:</strong></p>
<ul>
<li><p><strong>Feature Importance:</strong> This is the most basic technique. It ranks features based on their contribution to reducing the loss function during training. Common measures include:</p>
<ul>
<li><strong>Gain:</strong> The improvement in accuracy brought by a feature to the branches it is on. Features used higher up in the trees (splitting more data) generally have higher gain.</li>
<li><strong>Frequency (Coverage):</strong> The number of times a feature is used to split nodes across all trees.</li>
<li><strong>Weight: The number of times a feature appears in all trees.</strong></li>
<li><strong>Permutation Importance:</strong> After training, randomly permute the values of a single feature and measure the resulting increase in the model’s error. A large increase suggests the feature is important. This is a model-agnostic technique but can be more computationally expensive.</li>
</ul>
<p>Feature importance helps identify which features are most influential, but it doesn’t explain <em>how</em> they influence predictions (directionality). It also doesn’t account for feature interactions.</p></li>
<li><p><strong>Individual Decision Trees:</strong> Examining individual trees within the ensemble can provide insights. However, this becomes impractical as the number of trees increases. Visualizing the first few trees might be helpful for initial understanding.</p></li>
</ul>
<p><strong>3. Model-Agnostic Interpretability Techniques:</strong></p>
<p>These techniques can be applied to any machine learning model, including GBMs, allowing for more flexible and comprehensive explanations.</p>
<ul>
<li><p><strong>Partial Dependence Plots (PDPs):</strong> PDPs visualize the marginal effect of one or two features on the predicted outcome. They show how the predicted value changes as the feature(s) of interest vary, <em>holding all other features constant (on average)</em>.</p>
<p><span class="math display">\[
\hat{f}_i(x_i) = \frac{1}{N} \sum_{j=1}^{N} \hat{f}(x_{i}, x_{c}^{(j)})
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\hat{f}_i(x_i)\)</span> is the partial dependence function for feature <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(x_i\)</span> is the value of feature <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(x_c^{(j)}\)</span> are the values of the other features (complement set) for the <span class="math inline">\(j\)</span>-th data point.</li>
<li><span class="math inline">\(\hat{f}(x_{i}, x_{c}^{(j)})\)</span> is the model’s prediction for the data point where feature <span class="math inline">\(i\)</span> is set to <span class="math inline">\(x_i\)</span> and the other features are set to their observed values.</li>
</ul>
<p>PDPs help understand the relationship between a feature and the prediction, but they can be misleading if features are strongly correlated because the “holding all other features constant” assumption becomes unrealistic.</p></li>
<li><p><strong>Individual Conditional Expectation (ICE) Plots:</strong> ICE plots are similar to PDPs but show the dependence for <em>each individual data point</em> rather than the average effect. This reveals heterogeneity in the feature’s effect across different instances.</p>
<p>Together, ICE plots and PDPs can reveal individual differences in the relationship. ICE plots plot each sample’s relationship to the prediction, while PDPs plots the overall average effect.</p></li>
<li><p><strong>SHAP (SHapley Additive exPlanations) Values:</strong> SHAP values provide a unified measure of feature importance based on game-theoretic Shapley values. They quantify the contribution of each feature to the difference between the actual prediction and the average prediction.</p>
<p>SHAP values satisfy desirable properties like:</p>
<ul>
<li><strong>Local Accuracy:</strong> The sum of the SHAP values for all features equals the difference between the model’s output for a given input and the average model output.</li>
<li><strong>Missingness:</strong> Features that are always zero have SHAP values of zero.</li>
<li><strong>Consistency:</strong> If a feature has a greater impact on the model’s output, its SHAP value will be larger.</li>
</ul>
<p>The SHAP value for feature <span class="math inline">\(i\)</span> is calculated as:</p>
<p><span class="math display">\[
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N| - |S| - 1)!}{|N|!} [f(S \cup \{i\}) - f(S)]
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\phi_i\)</span> is the SHAP value for feature <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(N\)</span> is the set of all features.</li>
<li><span class="math inline">\(S\)</span> is a subset of features not including <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(f(S \cup \{i\})\)</span> is the model’s output when feature <span class="math inline">\(i\)</span> is added to the set <span class="math inline">\(S\)</span>.</li>
<li><span class="math inline">\(f(S)\)</span> is the model’s output when the set of features S are present.</li>
</ul>
<p>SHAP values provide a more complete explanation than feature importance because they account for feature interactions and provide individual explanations. Libraries like <code>shap</code> provide efficient implementations for tree-based models.</p></li>
<li><p><strong>LIME (Local Interpretable Model-Agnostic Explanations):</strong> LIME explains the predictions of any classifier by approximating it locally with an interpretable model (e.g., a linear model). It perturbs the input data, obtains predictions from the GBM for the perturbed data, and then trains a simple model on these perturbed data and predictions. The coefficients of the simple model approximate the local feature importance. LIME highlights which features are most important for <em>that specific prediction</em>.</p></li>
</ul>
<p><strong>4. Deployment Considerations and Trade-offs:</strong></p>
<ul>
<li><strong>Model Complexity vs.&nbsp;Interpretability:</strong> There’s often a trade-off. Simpler models (e.g., linear regression) are inherently more interpretable than complex GBMs. Consider whether the gains in accuracy from a GBM justify the increased difficulty in explanation. Could a more restricted set of features or less trees lead to an acceptable trade-off?</li>
<li><strong>Data Preprocessing:</strong> Transparent and well-documented data preprocessing is crucial. Understanding how features are engineered and transformed is essential for interpreting model behavior.</li>
<li><strong>Regular Monitoring:</strong> Monitor model performance and explanations over time to detect potential drifts or unexpected behavior.</li>
<li><strong>Human-in-the-Loop:</strong> In high-stakes environments, consider incorporating human review into the decision-making process. The explanations provided by these techniques can assist humans in understanding and validating the model’s decisions.</li>
<li><strong>Explainable-by-Design:</strong> Consider using techniques like Explainable Boosting Machines (EBMs), which are inherently more interpretable than standard GBMs while still achieving competitive accuracy.</li>
</ul>
<p><strong>5. Explaining to Stakeholders:</strong></p>
<ul>
<li><strong>Target the Audience:</strong> Tailor the explanation to the audience’s level of technical understanding. Avoid jargon and use visuals (e.g., plots, charts) to illustrate the key findings.</li>
<li><strong>Focus on Key Features:</strong> Highlight the most important features driving the prediction.</li>
<li><strong>Provide Examples:</strong> Use concrete examples to illustrate how the model works and how different features affect the outcome.</li>
<li><strong>Acknowledge Limitations:</strong> Be transparent about the limitations of the model and the explanations. Acknowledge uncertainty and potential biases.</li>
</ul>
<p>In summary, explaining the decisions of a gradient boosting model in an operational setting requires a combination of model-specific and model-agnostic techniques. SHAP values provide a comprehensive and theoretically sound approach, while PDPs and ICE plots offer valuable insights into feature relationships. Careful consideration of deployment considerations and transparent communication are essential for building trust and ensuring responsible use of these powerful models.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Problem:</strong> “Gradient boosting models are incredibly powerful, but their complexity makes them inherently difficult to interpret directly. This is a significant challenge in operational settings, like finance or healthcare, where understanding <em>why</em> a model made a particular decision is crucial for compliance, fairness, and trust.”</p></li>
<li><p><strong>Outline the Approach:</strong> “To address this, we can use a combination of model-specific and model-agnostic interpretability techniques. Model-specific techniques provide insights into the model’s internal structure, while model-agnostic methods allow us to examine the model’s behavior from an external perspective.”</p></li>
<li><p><strong>Explain Model-Specific Techniques (Briefly):</strong> “We can start with basic feature importance, which ranks features based on their contribution to the model’s accuracy. However, this only tells us <em>which</em> features are important, not <em>how</em> they influence the prediction or how they interact. We can use Gain, Permutation Importance or weight to determine feature importance.”</p></li>
<li><p><strong>Dive into Model-Agnostic Techniques (Focus on SHAP):</strong> “For a more complete picture, I’d advocate for using SHAP values. SHAP values leverage game theory to fairly distribute the ‘payout’ (the difference between the prediction and the average prediction) among the features. This gives us a consistent and locally accurate measure of each feature’s contribution.”</p></li>
<li><p><strong>Briefly mention and define Shapley values:</strong> “The Shapley value for a feature represents the average contribution of that feature to the prediction across all possible feature coalitions.” You can introduce the equation here, but say something like “While the equation looks complex, the key takeaway is that it ensures fairness and completeness in attributing feature importance.” <span class="math display">\[ \phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N| - |S| - 1)!}{|N|!} [f(S \cup \{i\}) - f(S)]\]</span></p></li>
<li><p><strong>Mention PDPs and ICE plots:</strong> “We can also use Partial Dependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots to visualize the relationship between individual features and the predicted outcome. PDPs show the average effect, while ICE plots show the effect for each individual instance, revealing heterogeneity.”</p></li>
<li><p><strong>Address Deployment Considerations:</strong> “It’s crucial to consider the trade-off between model complexity and interpretability. We should also ensure transparent data preprocessing, regular monitoring of model behavior, and potentially incorporate human review in high-stakes decisions.”</p></li>
<li><p><strong>Explain Communicating to Stakeholders:</strong> “Finally, communication is key. We need to tailor explanations to the audience, focus on key drivers, provide concrete examples, and acknowledge limitations. Visualizations are incredibly helpful here.”</p></li>
<li><p><strong>Conclude with a Summary:</strong> “In summary, explaining GBM decisions requires a multi-faceted approach, combining different interpretability techniques with careful attention to deployment and communication. Techniques like SHAP offer a powerful and theoretically sound basis for generating explanations, ensuring fairness, and building trust in the model’s predictions.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Take your time to articulate each concept clearly.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you’re in a virtual interview, consider sharing your screen and showing examples of PDPs, ICE plots, or SHAP value visualizations.</li>
<li><strong>Check for Understanding:</strong> Pause periodically to ask if the interviewer has any questions.</li>
<li><strong>Acknowledge Complexity:</strong> Don’t shy away from acknowledging the complexity of the topic, but emphasize that you have a practical understanding of how to apply these techniques.</li>
<li><strong>Be Ready to Elaborate:</strong> The interviewer may ask follow-up questions on specific techniques or scenarios. Be prepared to provide more detailed explanations and examples.</li>
<li><strong>Demonstrate Practical Experience:</strong> If you have experience using these techniques in real-world projects, share those experiences to demonstrate your practical knowledge. “For instance, in my previous role, we used SHAP values to explain credit risk model decisions to regulators, which helped us demonstrate fairness and transparency.”</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>