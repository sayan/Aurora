<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>gradient_boosting_1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-2.-what-are-the-essential-components-required-to-construct-a-gradient-boosting-framework-and-how-do-they-interact" class="level2">
<h2 class="anchored" data-anchor-id="question-2.-what-are-the-essential-components-required-to-construct-a-gradient-boosting-framework-and-how-do-they-interact">Question: 2. What are the essential components required to construct a gradient boosting framework, and how do they interact?</h2>
<p><strong>Best Answer</strong></p>
<p>Gradient boosting is a powerful machine learning technique that combines multiple weak learners (typically decision trees) to create a strong learner. It’s an iterative process that sequentially adds models, each correcting the errors of its predecessors. The “gradient” in gradient boosting refers to the fact that the algorithm optimizes a loss function using gradient descent. Here’s a breakdown of the essential components and their interaction:</p>
<ol type="1">
<li><p><strong>Loss Function (<span class="math inline">\(L(y, F(x))\)</span>):</strong></p>
<ul>
<li><p>The loss function quantifies the difference between the predicted values <span class="math inline">\(F(x)\)</span> and the actual values <span class="math inline">\(y\)</span>. The choice of the loss function depends on the specific problem (regression, classification, ranking, etc.).</p></li>
<li><p><strong>Regression:</strong> Common loss functions include Mean Squared Error (MSE), Mean Absolute Error (MAE), and Huber loss.</p>
<ul>
<li><strong>MSE:</strong> <span class="math inline">\(L(y, F(x)) = \frac{1}{n} \sum_{i=1}^{n} (y_i - F(x_i))^2\)</span></li>
<li><strong>MAE:</strong> <span class="math inline">\(L(y, F(x)) = \frac{1}{n} \sum_{i=1}^{n} |y_i - F(x_i)|\)</span></li>
<li><strong>Huber Loss:</strong> A combination of MSE and MAE, robust to outliers. It’s defined as: <span class="math display">\[
L(y, F(x)) =
\begin{cases}
  \frac{1}{2}(y - F(x))^2 &amp; \text{if } |y - F(x)| \leq \delta \\
  \delta |y - F(x)| - \frac{1}{2}\delta^2 &amp; \text{otherwise}
\end{cases}
\]</span> where <span class="math inline">\(\delta\)</span> is a threshold.</li>
</ul></li>
<li><p><strong>Classification:</strong> Common loss functions include logistic loss (for binary classification) and cross-entropy loss (for multi-class classification).</p>
<ul>
<li><strong>Logistic Loss:</strong> <span class="math inline">\(L(y, F(x)) = \sum_{i=1}^n \log(1 + e^{-y_i F(x_i)})\)</span>, where <span class="math inline">\(y_i \in \{-1, 1\}\)</span>.</li>
<li><strong>Cross-Entropy Loss:</strong> <span class="math inline">\(L(y, F(x)) = - \sum_{i=1}^n \sum_{c=1}^C y_{ic} \log(p_{ic})\)</span>, where <span class="math inline">\(y_{ic}\)</span> is an indicator if sample <span class="math inline">\(i\)</span> belongs to class <span class="math inline">\(c\)</span>, and <span class="math inline">\(p_{ic}\)</span> is the predicted probability of sample <span class="math inline">\(i\)</span> belonging to class <span class="math inline">\(c\)</span>.</li>
</ul></li>
</ul></li>
<li><p><strong>Base Learners (<span class="math inline">\(h_m(x)\)</span>):</strong></p>
<ul>
<li>These are weak learners, typically decision trees, that are sequentially added to the ensemble. Decision trees are popular because they can capture non-linear relationships and handle different data types.</li>
<li>The trees are usually shallow (small depth) to prevent overfitting and to ensure they are weak learners. Common choices include trees with a maximum depth of 3-7. These shallow trees are also called “stumps”.</li>
</ul></li>
<li><p><strong>Additive Model (<span class="math inline">\(F(x)\)</span>):</strong></p>
<ul>
<li>The gradient boosting model is built in an additive manner, with each new base learner added to the existing ensemble.</li>
<li>The model at iteration <em>m</em> can be represented as: <span class="math inline">\(F_m(x) = F_{m-1}(x) + \eta h_m(x)\)</span>, where <span class="math inline">\(F_{m-1}(x)\)</span> is the model from the previous iteration, <span class="math inline">\(h_m(x)\)</span> is the new base learner, and <span class="math inline">\(\eta\)</span> is the learning rate.</li>
</ul></li>
<li><p><strong>Gradient Descent Optimization:</strong></p>
<ul>
<li><p>The core of gradient boosting is using gradient descent to minimize the loss function. At each iteration <em>m</em>, the algorithm calculates the negative gradient of the loss function with respect to the current model’s predictions: <span class="math display">\[r_{im} = - \left[ \frac{\partial L(y_i, F(x_i))}{\partial F(x_i)} \right]_{F(x) = F_{m-1}(x)}\]</span> where <span class="math inline">\(r_{im}\)</span> is the “pseudo-residual” for instance <em>i</em> at iteration <em>m</em>. These pseudo-residuals represent the direction in which we need to adjust the predictions to reduce the loss.</p></li>
<li><p>The base learner <span class="math inline">\(h_m(x)\)</span> is then trained to predict these pseudo-residuals. In other words, we fit the base learner to approximate the negative gradient.</p></li>
<li><p>A key point is that we aren’t directly fitting the residuals (<span class="math inline">\(y_i - F_{m-1}(x_i)\)</span>), but rather the <em>negative gradient</em> of the loss function, allowing for more flexibility in the types of losses we can use. This is especially important for loss functions that are not squared error.</p></li>
</ul></li>
<li><p><strong>Learning Rate (Shrinkage) (<span class="math inline">\(\eta\)</span>):</strong></p>
<ul>
<li>The learning rate scales the contribution of each base learner. It’s a crucial hyperparameter that controls the step size in the gradient descent process.</li>
<li>A smaller learning rate (e.g., 0.01 or 0.001) makes the training process more robust and less prone to overfitting, but it requires more trees (iterations) to achieve good performance. A larger learning rate (e.g., 0.1 or 0.2) can lead to faster training, but it’s more likely to overfit.</li>
<li>The update rule is: <span class="math inline">\(F_m(x) = F_{m-1}(x) + \eta h_m(x)\)</span>.</li>
</ul></li>
<li><p><strong>Subsampling (Stochastic Gradient Boosting):</strong></p>
<ul>
<li>Subsampling involves training each base learner on a random subset of the training data. This technique introduces randomness into the training process, which can help to reduce overfitting and improve generalization.</li>
<li>Two common types of subsampling are:
<ul>
<li><strong>Row Subsampling (Bootstrap aggregating or Bagging):</strong> Randomly sample a fraction of the training instances <em>without replacement</em> for each tree.</li>
<li><strong>Column Subsampling (Feature Subsampling):</strong> Randomly select a subset of features for each tree.</li>
</ul></li>
<li>The subsampling fraction is typically between 0.5 and 0.8.</li>
<li>Subsampling also speeds up the training process since each tree is trained on a smaller dataset.</li>
</ul></li>
</ol>
<p><strong>Interaction of Components:</strong></p>
<p>The components interact in an iterative, sequential process:</p>
<ol type="1">
<li><strong>Initialization:</strong> Initialize the model <span class="math inline">\(F_0(x)\)</span> with a constant value (e.g., the mean of the target variable for regression).</li>
<li><strong>Iteration (for m = 1 to M):</strong>
<ol type="a">
<li><strong>Compute Pseudo-Residuals:</strong> Calculate the negative gradient (pseudo-residuals) <span class="math inline">\(r_{im}\)</span> for each data point.</li>
<li><strong>Fit Base Learner:</strong> Train a base learner <span class="math inline">\(h_m(x)\)</span> to predict the pseudo-residuals.</li>
<li><strong>Update Model:</strong> Update the model <span class="math inline">\(F_m(x) = F_{m-1}(x) + \eta h_m(x)\)</span>.</li>
</ol></li>
<li><strong>Output:</strong> The final gradient boosting model is the sum of all the base learners: <span class="math inline">\(F_M(x) = \sum_{m=0}^{M} \eta h_m(x)\)</span>, where <span class="math inline">\(h_0(x)\)</span> is the initial constant function.</li>
</ol>
<p><strong>Summary:</strong></p>
<p>Gradient boosting combines a loss function (to measure error), base learners (to model the data), gradient descent (to optimize the loss), a learning rate (to prevent overfitting), and optional subsampling (to further reduce overfitting and speed up training). These components work together in an iterative process to build a strong predictive model. The flexibility in choosing the loss function makes gradient boosting applicable to a wide variety of machine learning problems.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guideline on how to present this information in an interview, breaking it down for clarity and impact:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Definition:</strong></p>
<ul>
<li>“Gradient boosting is a powerful ensemble method that combines multiple weak learners, usually decision trees, to create a strong learner. The key idea is to sequentially build models, with each model correcting the errors of its predecessors by using the gradient descent optimization algorithm.”</li>
</ul></li>
<li><p><strong>Introduce the Essential Components:</strong></p>
<ul>
<li>“To construct a gradient boosting framework, we need several essential components. I’ll walk you through each of them.”</li>
</ul></li>
<li><p><strong>Explain the Loss Function:</strong></p>
<ul>
<li>“First, we need a <strong>loss function</strong>. This quantifies the difference between our predictions and the actual values. The specific loss function depends on the problem type. For regression, common choices are Mean Squared Error, Mean Absolute Error, or Huber loss, which is robust to outliers. For classification, we typically use logistic loss or cross-entropy loss.”</li>
<li><em>Optional: Briefly show the equations for MSE, MAE, Huber loss, Logistic Loss, and Cross-Entropy Loss if the interviewer is engaged, but don’t dwell on the mathematical details initially.</em></li>
</ul></li>
<li><p><strong>Explain the Base Learners:</strong></p>
<ul>
<li>“Next, we have the <strong>base learners</strong>. These are the weak learners we’re combining. Decision trees are a popular choice, especially shallow trees or ‘stumps,’ because they are computationally efficient and help prevent overfitting. We keep them weak on purpose.”</li>
</ul></li>
<li><p><strong>Explain Additive Modeling:</strong></p>
<ul>
<li>“Gradient boosting model is an additive model, that is, we build the model in an additive manner by adding the output of each base learner in each iteration. Mathematically it can be written as: <span class="math inline">\(F_m(x) = F_{m-1}(x) + \eta h_m(x)\)</span>”</li>
</ul></li>
<li><p><strong>Explain Gradient Descent:</strong></p>
<ul>
<li>“The ‘gradient’ in gradient boosting comes from using gradient descent to minimize the loss function. At each iteration, we calculate the negative gradient of the loss function with respect to the current model’s predictions. These are called ‘pseudo-residuals’. Then, we train the base learner to predict these pseudo-residuals. It’s important to note that we’re fitting to the <em>negative gradient</em>, not directly to the residuals. This makes the algorithm more flexible.”</li>
<li><em>Optional: Show the equation for computing pseudo-residuals only if the interviewer seems mathematically inclined. Keep it concise:</em>
<ul>
<li><em>“We calculate the pseudo-residuals using this formula: <span class="math inline">\(r_{im} = - \left[ \frac{\partial L(y_i, F(x_i))}{\partial F(x_i)} \right]_{F(x) = F_{m-1}(x)}\)</span>”</em></li>
</ul></li>
</ul></li>
<li><p><strong>Explain the Learning Rate:</strong></p>
<ul>
<li>“The <strong>learning rate</strong>, also known as shrinkage, scales the contribution of each base learner. It acts as a regularizer, preventing overfitting. A smaller learning rate requires more trees but generally leads to better generalization.”</li>
<li><em>Optional: Mention the update rule:</em> “The model is updated as <span class="math inline">\(F_m(x) = F_{m-1}(x) + \eta h_m(x)\)</span>.”</li>
</ul></li>
<li><p><strong>Explain Subsampling:</strong></p>
<ul>
<li>“Optionally, we can use <strong>subsampling</strong>, where we train each base learner on a random subset of the data or features. This introduces randomness, further reducing overfitting and often speeding up training. Row and column subsampling are common approaches.”</li>
</ul></li>
<li><p><strong>Describe the Iterative Process:</strong></p>
<ul>
<li>“The components interact in an iterative process. We start with an initial guess, then iteratively compute pseudo-residuals, fit a base learner to those residuals, and update the model, scaling the contribution of the new learner by the learning rate. We repeat this until we reach a predefined number of iterations or a satisfactory performance level.”</li>
</ul></li>
<li><p><strong>Summarize and Emphasize Key Advantages:</strong></p>
<ul>
<li>“In summary, gradient boosting combines a loss function, weak learners, gradient descent optimization, a learning rate, and optional subsampling. The flexibility in the loss function makes it applicable to various problems, and the sequential, iterative approach allows it to build a very strong model. The learning rate and subsampling are critical for regularization.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pause and Check for Understanding:</strong> After explaining each component, pause briefly to see if the interviewer has any questions. This ensures they are following along and gives you a chance to clarify anything that’s unclear.</li>
<li><strong>Gauge the Interviewer’s Background:</strong> If the interviewer seems less mathematically inclined, focus on the conceptual explanations and avoid getting bogged down in the equations. If they seem comfortable with math, you can delve a bit deeper into the formulas.</li>
<li><strong>Use Analogies:</strong> If appropriate, use analogies to explain the concepts. For example, you could compare gradient boosting to a team of experts, where each expert focuses on correcting the mistakes of the previous experts.</li>
<li><strong>Be Confident and Enthusiastic:</strong> Your enthusiasm for the topic will be contagious and will make your explanation more engaging.</li>
</ul>
<p>By following these steps, you can provide a comprehensive and well-structured answer that demonstrates your deep understanding of gradient boosting.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>