<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>random_forest_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-6.-in-implementing-random-forest-for-a-large-scale-dataset-what-strategies-would-you-adopt-to-handle-scalability-and-what-are-the-challenges-you-might-face" class="level2">
<h2 class="anchored" data-anchor-id="question-6.-in-implementing-random-forest-for-a-large-scale-dataset-what-strategies-would-you-adopt-to-handle-scalability-and-what-are-the-challenges-you-might-face">Question: 6. In implementing Random Forest for a large-scale dataset, what strategies would you adopt to handle scalability and what are the challenges you might face?</h2>
<p><strong>Best Answer</strong></p>
<p>Random Forests are powerful but can be computationally expensive and memory-intensive when applied to large-scale datasets. Addressing scalability requires a multi-faceted approach, encompassing algorithmic optimizations, parallelization strategies, and efficient data handling.</p>
<p><strong>1. Algorithmic Optimizations &amp; Hyperparameter Tuning:</strong></p>
<ul>
<li><strong>Reducing Data Size:</strong>
<ul>
<li><strong>Sampling:</strong> Instead of using the entire dataset for training each tree, consider using a smaller, representative sample. This could involve simple random sampling or more sophisticated techniques like stratified sampling to preserve class distributions. While reducing the sample size decreases the training time for individual trees, careful attention must be paid to avoid introducing bias and ensure sufficient representation of the dataset.</li>
<li><strong>Feature Selection/Reduction:</strong> High dimensionality can significantly impact performance. Employing feature selection techniques (e.g., selecting features based on information gain or Gini impurity) or dimensionality reduction methods (e.g., PCA or t-SNE, applied cautiously to maintain interpretability) can reduce the computational burden. Feature selection can be based on wrapper methods (e.g., recursive feature elimination), filter methods (e.g., based on variance threshold), or embedded methods (e.g., using feature importances from a simpler model).</li>
</ul></li>
<li><strong>Tree Depth Limiting:</strong> The maximum depth of individual trees significantly impacts training time and memory usage. Limiting tree depth through hyperparameter tuning prevents overfitting and reduces computational complexity. The relationship between tree depth, number of trees, and other hyperparameters must be carefully explored using techniques like cross-validation.</li>
</ul>
<p><strong>2. Parallelization Strategies:</strong></p>
<ul>
<li><strong>Tree-Level Parallelism:</strong> The inherent independence of tree construction in a Random Forest makes it highly amenable to parallelization. Each tree can be trained independently on a different subset of the data (with replacement, as in bagging) and potentially a random subset of features.
<ul>
<li><strong>Multiprocessing:</strong> Utilize Python’s <code>multiprocessing</code> library (or similar in other languages) to distribute tree training across multiple CPU cores on a single machine.</li>
<li><strong>Distributed Computing (Spark, Dask):</strong> For truly massive datasets exceeding the capacity of a single machine, leverage distributed computing frameworks like Apache Spark or Dask. These frameworks allow distributing data and computation across a cluster of machines. Spark’s <code>MLlib</code> and Dask-ML provide Random Forest implementations optimized for distributed execution. Spark leverages Resilient Distributed Datasets (RDDs) or DataFrames to distribute data, while Dask uses task scheduling to manage parallel computations on potentially heterogeneous clusters.</li>
<li><strong>Implementation Detail (Spark):</strong> In Spark, one might use the <code>RandomForestClassifier</code> or <code>RandomForestRegressor</code> classes from <code>pyspark.ml.classification</code> and <code>pyspark.ml.regression</code>, respectively. The key parameters to adjust for scalability include the number of trees (<code>numTrees</code>), the maximum depth of the trees (<code>maxDepth</code>), and the level of parallelism (<code>numPartitions</code>). Tuning <code>numPartitions</code> is crucial for balancing the workload across the cluster.</li>
</ul></li>
</ul>
<p><span class="math display">\[
\text{Training Time} \propto \frac{\text{Time per tree}}{\text{Number of Cores}}
\]</span></p>
<ul>
<li><strong>Node-Level Parallelism:</strong> Within each tree, the process of finding the best split at each node can also be parallelized. This is more complex to implement but can provide further speedups.</li>
</ul>
<p><strong>3. Efficient Data Handling and I/O:</strong></p>
<ul>
<li><strong>Data Formats:</strong> Use efficient data formats like Parquet or ORC (especially in distributed computing environments) that support columnar storage and compression. Columnar storage allows for faster retrieval of specific features during tree construction.</li>
<li><strong>Chunking:</strong> Load data in smaller chunks to avoid overwhelming memory. Libraries like <code>pandas</code> provide options for reading CSV files in chunks.</li>
<li><strong>Lazy Evaluation:</strong> In frameworks like Dask, operations are often lazily evaluated. This means computations are only performed when the results are explicitly needed, allowing for optimized execution plans.</li>
<li><strong>Memory Mapping:</strong> For datasets that are larger than available RAM but can fit on disk, consider using memory mapping (e.g., with <code>numpy.memmap</code>) to access data directly from disk without loading the entire dataset into memory.</li>
</ul>
<p><strong>4. Hardware Considerations:</strong></p>
<ul>
<li><strong>Memory:</strong> Ensure sufficient RAM is available on each machine involved in the training process. Insufficient memory can lead to disk swapping, significantly slowing down computation.</li>
<li><strong>CPU:</strong> Employ machines with a high number of cores to maximize the benefits of parallelization.</li>
<li><strong>Storage:</strong> Use fast storage (e.g., SSDs) to reduce I/O bottlenecks.</li>
<li><strong>Network:</strong> In a distributed environment, a high-bandwidth network is crucial for efficient data transfer between machines.</li>
</ul>
<p><strong>5. Challenges:</strong></p>
<ul>
<li><strong>Communication Overhead:</strong> In distributed environments, the communication overhead between machines can become a bottleneck, especially with a large number of small trees. Careful optimization of data partitioning and task scheduling is essential.</li>
<li><strong>Memory Management:</strong> Even with chunking, managing memory efficiently remains a challenge, especially when dealing with high-dimensional data. Profile the memory usage of the training process and identify potential memory leaks.</li>
<li><strong>Data Skew:</strong> If the data is unevenly distributed across the cluster, some machines may become overloaded while others remain idle. This can be mitigated through techniques like data repartitioning or adaptive task scheduling.</li>
<li><strong>Real-time Processing:</strong> While Random Forests can be trained offline, deploying them for real-time predictions can be challenging due to the latency involved in traversing multiple trees. Techniques like tree approximation or distillation can be used to create smaller, faster models for real-time inference.</li>
<li><strong>Integration with Deployment Pipelines</strong>: Incorporating the trained Random Forest model into a production environment requires careful consideration. This often involves serializing the model, deploying it to a serving infrastructure (e.g., using containers or cloud-based services), and setting up monitoring to track performance and identify potential issues.</li>
</ul>
<p><strong>Mathematical Notation and Justification:</strong></p>
<p>Let <span class="math inline">\(D\)</span> be the dataset of size <span class="math inline">\(n\)</span> with <span class="math inline">\(p\)</span> features. Let <span class="math inline">\(T\)</span> be the number of trees in the random forest. Let <span class="math inline">\(d\)</span> be the maximum depth of each tree.</p>
<ul>
<li><p><strong>Time Complexity of Training a Single Tree:</strong> The time complexity of building a single decision tree is approximately <span class="math inline">\(O(n p \log n)\)</span> in the average case, where <span class="math inline">\(n\)</span> is the number of samples and <span class="math inline">\(p\)</span> is the number of features. Feature selection at each node and sorting the data are the dominant operations. Limiting the depth to <span class="math inline">\(d\)</span> changes the time complexity to <span class="math inline">\(O(n p d)\)</span>.</p></li>
<li><p><strong>Time Complexity of Training a Random Forest (without parallelization):</strong> <span class="math inline">\(O(T n p d)\)</span></p></li>
<li><p><strong>Time Complexity of Training a Random Forest (with perfect parallelization):</strong> <span class="math inline">\(O(\frac{T n p d}{C})\)</span>, where <span class="math inline">\(C\)</span> is the number of cores or workers. Note that perfect parallelization is rarely achievable in practice due to communication overhead and synchronization costs.</p></li>
<li><p><strong>Impact of Feature Selection:</strong> If we reduce the number of features from <span class="math inline">\(p\)</span> to <span class="math inline">\(p'\)</span>, where <span class="math inline">\(p' &lt; p\)</span>, the time complexity becomes <span class="math inline">\(O(T n p' d)\)</span>, leading to a significant reduction in training time when <span class="math inline">\(p'\)</span> is substantially smaller than <span class="math inline">\(p\)</span>.</p></li>
</ul>
<p><strong>Real-World Considerations and Corner Cases:</strong></p>
<ul>
<li><strong>Imbalanced Datasets:</strong> Random Forests can be biased towards the majority class in imbalanced datasets. Techniques like oversampling the minority class, undersampling the majority class, or using class weighting can help mitigate this issue.</li>
<li><strong>Categorical Features with High Cardinality:</strong> Handling categorical features with a large number of unique values can be problematic. One-hot encoding can lead to high dimensionality, while other encoding schemes (e.g., target encoding) can introduce bias. Careful preprocessing and feature engineering are essential.</li>
<li><strong>Missing Values:</strong> Random Forests can handle missing values to some extent, but imputation or other missing value handling techniques may be necessary to improve performance.</li>
</ul>
<p><strong>Best Practices:</strong></p>
<ul>
<li><strong>Cross-Validation:</strong> Use cross-validation to tune hyperparameters and evaluate the performance of the Random Forest model.</li>
<li><strong>Feature Importance Analysis:</strong> Analyze feature importances to gain insights into the underlying data and identify potentially irrelevant features.</li>
<li><strong>Monitoring and Alerting:</strong> In a production environment, set up monitoring to track model performance and identify potential issues such as data drift.</li>
</ul>
<p>In summary, scaling Random Forests to large datasets requires a combination of algorithmic optimizations, parallelization strategies, efficient data handling, and careful consideration of hardware resources and potential challenges.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide to deliver this answer effectively in an interview:</p>
<ol type="1">
<li><p><strong>Start with an Overview:</strong> Begin by acknowledging that Random Forests can face scalability challenges with large datasets and emphasize that a multi-pronged approach is needed. “Random Forests are powerful but can be computationally expensive and memory-intensive on large datasets. We need to consider a combination of algorithmic optimizations, parallelization, and efficient data handling.”</p></li>
<li><p><strong>Discuss Algorithmic Optimizations:</strong> Start with the highest-level and most intuitive optimizations. “First, we can look at reducing the amount of data each tree sees. This includes sampling strategies to reduce the number of data points, and feature selection techniques to reduce the dimensionality.” Briefly explain sampling (random, stratified) and feature selection (mention information gain or Gini impurity, and/or PCA cautiously). Don’t get bogged down in the details of PCA unless asked.</p></li>
<li><p><strong>Move to Parallelization:</strong> This is a critical aspect. “The biggest gains come from parallelization due to the independent nature of tree construction. Each tree can be trained independently.” Then, explain the levels of parallelism:</p>
<ul>
<li><strong>Multiprocessing:</strong> “For smaller datasets, we can use multiprocessing libraries to leverage multiple cores on a single machine.”</li>
<li><strong>Distributed Computing:</strong> “For truly massive datasets, we can use distributed computing frameworks like Spark or Dask to distribute data and computation across a cluster.” Mention the key components of each (RDDs/DataFrames for Spark, Task Scheduling for Dask). If you have experience with one, briefly highlight that.</li>
<li><strong>Mention node-level parallelism</strong> briefly as a more advanced optimization.</li>
</ul></li>
<li><p><strong>Introduce Efficient Data Handling:</strong> Emphasize the importance of data formats and I/O. “Efficient data handling is crucial. We should use columnar formats like Parquet or ORC, chunk data to avoid memory overload, and consider lazy evaluation with tools like Dask.”</p></li>
<li><p><strong>Acknowledge Hardware Considerations:</strong> Briefly mention the importance of adequate memory, CPU, and fast storage. “Having enough RAM, CPU cores, and fast storage is essential for good performance.”</p></li>
<li><p><strong>Discuss Challenges:</strong> This shows awareness of real-world complexities. “Despite these optimizations, several challenges can arise. These include communication overhead in distributed environments, memory management issues, data skew, and the complexities of real-time processing.”</p></li>
<li><p><strong>Mathematical Formulation (If Appropriate and Requested):</strong> You can briefly introduce the simplified formulas for time complexity. It’s helpful to have these ready, but don’t force them into the conversation unless the interviewer asks for a deeper dive. Only write this on a whiteboard if asked.</p>
<ul>
<li>Explain the relationship between number of trees <span class="math inline">\(T\)</span>, data size <span class="math inline">\(n\)</span>, features <span class="math inline">\(p\)</span>, tree depth <span class="math inline">\(d\)</span> and cores <span class="math inline">\(C\)</span>.</li>
</ul></li>
<li><p><strong>Real-World Considerations and Best Practices:</strong> “In practice, it’s also important to consider imbalanced datasets, categorical features with high cardinality, and missing values, and use best practices like cross-validation and feature importance analysis.”</p></li>
<li><p><strong>Conclude with Summary:</strong> “In summary, scaling Random Forests requires a holistic approach, combining algorithmic optimizations, parallel processing, efficient data management, and awareness of potential challenges.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush. Speak clearly and deliberately.</li>
<li><strong>Check for Understanding:</strong> After explaining a complex concept like distributed computing, pause and ask the interviewer if they have any questions.</li>
<li><strong>Be Prepared to Elaborate:</strong> The interviewer may ask for more details on specific aspects. Be ready to provide more in-depth explanations and examples.</li>
<li><strong>Be Honest About Limitations:</strong> If you don’t know the answer to a specific question, it’s better to be honest than to bluff. You can say something like, “I haven’t worked with that specific technology before, but I’m familiar with the underlying concepts and would be eager to learn more.”</li>
<li><strong>Enthusiasm:</strong> Show genuine interest in the topic.</li>
</ul>
<p>By following these guidelines, you can present a comprehensive and confident answer that demonstrates your senior-level knowledge and problem-solving abilities.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>