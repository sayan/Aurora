<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>xgboost_12</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-how-does-feature-importance-work-in-xgboost-and-what-are-some-limitations-or-challenges-associated-with-interpreting-feature-importance-metrics" class="level2">
<h2 class="anchored" data-anchor-id="question-how-does-feature-importance-work-in-xgboost-and-what-are-some-limitations-or-challenges-associated-with-interpreting-feature-importance-metrics">Question: How does feature importance work in XGBoost, and what are some limitations or challenges associated with interpreting feature importance metrics?</h2>
<p><strong>Best Answer</strong></p>
<p>XGBoost, or Extreme Gradient Boosting, is a powerful and popular gradient boosting algorithm known for its performance and scalability. Feature importance is a crucial aspect of understanding and interpreting XGBoost models. It helps identify which features have the most significant impact on the model’s predictions. XGBoost offers several methods for calculating feature importance, each with its own nuances and interpretations.</p>
<p>Here’s a breakdown of feature importance in XGBoost, including calculation methods, limitations, and alternative approaches:</p>
<p><strong>1. Feature Importance Calculation Methods:</strong></p>
<p>XGBoost provides three primary methods for calculating feature importance:</p>
<ul>
<li><p><strong>Gain:</strong></p>
<ul>
<li><strong>Definition:</strong> Gain represents the improvement in accuracy brought by a feature to the branches it is on. In other words, it measures the reduction in the loss function when a feature is used to split the data at a node in a decision tree.</li>
<li><strong>Calculation:</strong> The gain for a feature is calculated by summing up the reduction in impurity (e.g., Gini impurity or entropy for classification, mean squared error for regression) across all nodes where that feature is used for splitting.</li>
<li><strong>Formula:</strong> Let <span class="math inline">\(I(T)\)</span> be the impurity of a node <span class="math inline">\(T\)</span>, and let <span class="math inline">\(T_L\)</span> and <span class="math inline">\(T_R\)</span> be the left and right child nodes after a split. The gain <span class="math inline">\(G\)</span> from splitting node <span class="math inline">\(T\)</span> using feature <span class="math inline">\(f\)</span> is: <span class="math display">\[G = I(T) - \frac{N_L}{N_T}I(T_L) - \frac{N_R}{N_T}I(T_R)\]</span> where <span class="math inline">\(N_T\)</span>, <span class="math inline">\(N_L\)</span>, and <span class="math inline">\(N_R\)</span> are the number of instances in node <span class="math inline">\(T\)</span>, <span class="math inline">\(T_L\)</span>, and <span class="math inline">\(T_R\)</span> respectively. The feature importance of feature <span class="math inline">\(f\)</span> is the sum of these gains over all splits using feature <span class="math inline">\(f\)</span>.</li>
<li><strong>Interpretation:</strong> A higher gain indicates that the feature contributes more significantly to improving the model’s accuracy.</li>
</ul></li>
<li><p><strong>Cover:</strong></p>
<ul>
<li><strong>Definition:</strong> Cover measures the number of times a feature is used to split the data across all trees in the ensemble. It represents the relative quantity of observations concerned by a feature.</li>
<li><strong>Calculation:</strong> Cover is calculated by counting the number of observations (or the “coverage”) related to each split where the feature is used. Specifically, it’s the number of data points that pass through a particular node where the split is made using that feature. These values are then summed for each feature across all trees.</li>
<li><strong>Interpretation:</strong> A higher cover value suggests that the feature is used to split a larger proportion of the dataset, indicating its importance in distinguishing between different subsets of data.</li>
</ul></li>
<li><p><strong>Frequency:</strong></p>
<ul>
<li><strong>Definition:</strong> Frequency, also known as “weight,” simply counts the number of times a feature is used as a splitting attribute in the trees of the model.</li>
<li><strong>Calculation:</strong> Frequency is the simplest metric. It just counts how many times each feature appears in all the trees in the boosted tree.</li>
<li><strong>Interpretation:</strong> A higher frequency indicates that the feature is used more often in the tree structures, suggesting its relevance in making predictions.</li>
</ul></li>
</ul>
<p><strong>2. Limitations and Challenges in Interpreting Feature Importance:</strong></p>
<p>While feature importance metrics provide valuable insights, they are not without limitations:</p>
<ul>
<li><p><strong>Bias towards High Cardinality Features:</strong></p>
<ul>
<li>Features with a higher number of unique values (high cardinality) tend to be favored by tree-based models because they offer more opportunities to split the data effectively. This can lead to an overestimation of their importance, even if they are not inherently more informative than other features.</li>
<li><strong>Mitigation:</strong> Techniques like one-hot encoding for categorical features (which increases dimensionality, but addresses the issue of ordinality where it doesn’t exist) can help, as well as careful consideration of feature engineering. Regularization within XGBoost can also penalize complex splits.</li>
</ul></li>
<li><p><strong>Correlation among Features:</strong></p>
<ul>
<li>When features are highly correlated, the importance scores can be misleading. If two features provide similar information, one might be assigned a higher importance score simply because it was chosen earlier in the tree-building process, while the other feature’s importance is underestimated. This doesn’t necessarily mean that the chosen feature is intrinsically more important.</li>
<li><strong>Example:</strong> Consider two features: “temperature in Celsius” and “temperature in Fahrenheit.” These are perfectly correlated. XGBoost might assign high importance to one of them and negligible importance to the other, even though they convey the same information.</li>
<li><strong>Mitigation:</strong> Feature selection techniques (e.g., removing highly correlated features) or dimensionality reduction methods (e.g., PCA) can help address this issue before training the model. Also, consider SHAP values (explained below) which provide a more granular understanding of feature contributions.</li>
</ul></li>
<li><p><strong>Context Dependence:</strong></p>
<ul>
<li>Feature importance is specific to the model and the dataset used to train it. If the model or the data changes, the feature importance scores might also change significantly. Therefore, feature importance should be interpreted in the context of the specific model and dataset.</li>
</ul></li>
<li><p><strong>Lack of Directionality:</strong></p>
<ul>
<li>Traditional feature importance metrics only indicate the magnitude of a feature’s influence but do not reveal the direction (positive or negative) of that influence. It only says how <em>important</em> it is, not <em>how</em> it impacts the prediction.</li>
<li><strong>Mitigation:</strong> Techniques like partial dependence plots (PDPs) and individual conditional expectation (ICE) plots can be used in conjunction with feature importance to understand the direction and nature of the relationship between features and the target variable.</li>
</ul></li>
<li><p><strong>Instability:</strong></p>
<ul>
<li>Small changes in the training data or model parameters can sometimes lead to noticeable changes in the feature importance scores. This instability can make it challenging to draw robust conclusions about feature importance.</li>
<li><strong>Mitigation:</strong> Averaging feature importances across multiple runs with different random seeds (for subsampling and feature selection) or using techniques like permutation importance can help stabilize the results.</li>
</ul></li>
</ul>
<p><strong>3. Alternative Techniques for Feature Interpretation:</strong></p>
<p>To address the limitations of traditional feature importance metrics, alternative techniques can provide more robust and nuanced interpretations:</p>
<ul>
<li><p><strong>SHAP (SHapley Additive exPlanations) Values:</strong></p>
<ul>
<li>SHAP values provide a unified framework for interpreting model predictions based on game-theoretic principles. They quantify the contribution of each feature to the prediction of each instance.</li>
<li><strong>Calculation:</strong> SHAP values are calculated by averaging the marginal contributions of a feature across all possible coalitions of features. This ensures a fair and consistent attribution of feature importance. Formally, the Shapley value for feature <span class="math inline">\(i\)</span> for instance <span class="math inline">\(x\)</span> is given by: <span class="math display">\[\phi_i(x) = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!(|F| - |S| - 1)!}{|F|!} [f_x(S \cup \{i\}) - f_x(S)]\]</span> where:
<ul>
<li><span class="math inline">\(F\)</span> is the set of all features.</li>
<li><span class="math inline">\(S\)</span> is a subset of features excluding feature <span class="math inline">\(i\)</span>.</li>
<li><span class="math inline">\(|S|\)</span> is the number of features in the subset <span class="math inline">\(S\)</span>.</li>
<li><span class="math inline">\(f_x(S)\)</span> is the prediction of the model using only the features in <span class="math inline">\(S\)</span> for instance <span class="math inline">\(x\)</span>. This often requires marginalizing out the features <em>not</em> in <span class="math inline">\(S\)</span>.</li>
</ul></li>
<li><strong>Advantages:</strong>
<ul>
<li><strong>Consistency:</strong> SHAP values satisfy properties like local accuracy, consistency, and missingness, which ensure a reliable and interpretable explanation.</li>
<li><strong>Directionality:</strong> SHAP values can reveal the direction of a feature’s effect on the prediction (positive or negative).</li>
<li><strong>Granularity:</strong> SHAP values provide instance-level explanations, allowing you to understand how each feature contributes to the prediction for a specific instance.</li>
</ul></li>
<li><strong>XGBoost Integration:</strong> The <code>shap</code> Python package provides excellent integration with XGBoost, allowing for efficient computation of SHAP values. TreeSHAP is a fast, tree-optimized method for calculating SHAP values for tree-based models like XGBoost.</li>
</ul></li>
<li><p><strong>Permutation Importance:</strong></p>
<ul>
<li>Permutation importance assesses feature importance by randomly shuffling the values of a feature and measuring the resulting decrease in model performance. A feature is considered important if shuffling its values significantly degrades the model’s performance.</li>
<li><strong>Calculation:</strong>
<ol type="1">
<li>Train the model on the original data.</li>
<li>Calculate a baseline performance score (e.g., accuracy, F1-score, or RMSE) on a validation set.</li>
<li>For each feature:
<ul>
<li>Randomly shuffle the values of the feature in the validation set.</li>
<li>Make predictions using the shuffled data.</li>
<li>Calculate the performance score on the shuffled data.</li>
<li>Calculate the difference between the baseline performance and the performance with the shuffled feature. This difference is the importance score for the feature.</li>
</ul></li>
</ol></li>
<li><strong>Advantages:</strong>
<ul>
<li><strong>Model-agnostic:</strong> Permutation importance can be applied to any machine learning model, not just tree-based models.</li>
<li><strong>Intuitive:</strong> The concept is easy to understand and explain.</li>
<li><strong>Reflects Real-World Impact:</strong> It directly measures the impact of a feature on the model’s predictive performance.</li>
</ul></li>
<li><strong>Disadvantages:</strong>
<ul>
<li><strong>Computationally Expensive:</strong> Can be computationally expensive, especially for large datasets and complex models.</li>
<li><strong>Can be Biased by Correlated Features:</strong> If features are highly correlated, the importance of one feature might be underestimated because shuffling another correlated feature can achieve a similar effect.</li>
</ul></li>
</ul></li>
</ul>
<p><strong>4. Practical Considerations:</strong></p>
<ul>
<li><strong>Data Preprocessing:</strong> Properly handle missing values, scale numerical features, and encode categorical features before training the model. Feature engineering can also play a significant role in improving model performance and interpretability.</li>
<li><strong>Regularization:</strong> Use regularization techniques (L1 and L2 regularization) to prevent overfitting and improve the stability of feature importance scores.</li>
<li><strong>Hyperparameter Tuning:</strong> Optimize the hyperparameters of the XGBoost model using techniques like cross-validation to achieve the best possible performance. The optimal hyperparameters can influence feature importance.</li>
<li><strong>Ensemble Methods:</strong> Ensemble methods, like bagging, can improve the robustness of the feature importance estimations by averaging the feature importances across multiple models trained on different subsets of the data.</li>
</ul>
<p>In summary, feature importance in XGBoost provides a valuable tool for understanding the model’s behavior and identifying the key drivers of its predictions. However, it’s crucial to be aware of the limitations and challenges associated with interpreting feature importance metrics and to consider alternative techniques like SHAP values and permutation importance for a more comprehensive and robust understanding. A combination of these techniques, along with careful data preprocessing and model evaluation, will yield the most meaningful insights.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s how you could present this information in an interview:</p>
<ol type="1">
<li><p><strong>Start with the basics:</strong> “XGBoost offers several ways to determine feature importance, which helps us understand which features most impact the model’s predictions.” Briefly mention the three main methods: Gain, Cover, and Frequency.</p></li>
<li><p><strong>Explain each method simply, then add depth:</strong></p>
<ul>
<li><strong>Gain:</strong> “Gain is the most common. It represents the improvement in model accuracy—specifically, the reduction in the loss function—when a feature is used in a split. The higher the gain, the more useful the feature. Mathematically, it’s the difference in impurity before and after the split, weighted by the number of samples in each child node.” If the interviewer seems engaged, you <em>could</em> show the equation: <span class="math display">\[G = I(T) - \frac{N_L}{N_T}I(T_L) - \frac{N_R}{N_T}I(T_R)\]</span> “But the core idea is simple: features that lead to bigger improvements are more important.”</li>
<li><strong>Cover:</strong> “Cover refers to the number of data points ‘covered’ by a split using a particular feature. Higher cover means the feature is used to split a larger portion of the dataset, indicating its importance in differentiating data subsets.”</li>
<li><strong>Frequency:</strong> “Frequency, or ‘weight’, is simply the number of times a feature is used as a splitting variable across all trees. It’s a raw count, indicating how often the feature is used in the model’s structure.”</li>
</ul></li>
<li><p><strong>Transition to Limitations:</strong> “While these metrics are helpful, they have limitations. It’s crucial to be aware of these to avoid misinterpreting feature importances.”</p></li>
<li><p><strong>Discuss key limitations, highlighting the most significant ones:</strong></p>
<ul>
<li><strong>Bias Towards High Cardinality:</strong> “Features with many unique values can appear artificially important because they offer more split opportunities. It’s like giving them an unfair advantage.” Suggest mitigation strategies: “One-hot encoding, careful feature engineering, and regularization can help mitigate this.”</li>
<li><strong>Correlation:</strong> “If features are highly correlated, the importance might be split somewhat arbitrarily between them. If two features are almost the same, one might get high importance just by chance.” Suggest mitigation strategies: “Consider feature selection to remove redundant features or use dimensionality reduction techniques.”</li>
<li><strong>Context Dependence:</strong> “The importance scores are specific to the dataset and model. If either changes, the feature importance might also change.”</li>
<li><strong>Lack of Directionality:</strong> “Importances don’t tell you <em>how</em> a feature impacts the prediction – just that it’s important. You need other techniques like partial dependence plots to understand the direction of the effect.”</li>
</ul></li>
<li><p><strong>Introduce alternative, more robust techniques:</strong> “To get a more complete picture, it’s helpful to use alternative techniques like SHAP values and permutation importance.”</p></li>
<li><p><strong>Explain SHAP values in more detail:</strong></p>
<ul>
<li>“SHAP values provide a more granular and consistent way to understand feature contributions. They’re based on game theory and quantify each feature’s contribution to <em>each individual prediction</em>.”</li>
<li>“The math behind SHAP values can get complex, but the key idea is that it averages the marginal contribution of a feature across all possible combinations of other features.” If the interviewer looks interested, provide the formula: <span class="math display">\[\phi_i(x) = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!(|F| - |S| - 1)!}{|F|!} [f_x(S \cup \{i\}) - f_x(S)]\]</span></li>
<li>Highlight the benefits: “SHAP values offer consistency, tell you the direction of the impact (positive or negative), and provide instance-level explanations. The <code>shap</code> package integrates nicely with XGBoost and offers efficient calculation.”</li>
</ul></li>
<li><p><strong>Briefly describe Permutation Importance:</strong> “Permutation importance involves shuffling a feature’s values and observing the impact on the model’s performance. If shuffling a feature significantly hurts performance, it’s considered important. It’s model-agnostic but can be computationally expensive and biased by correlated features.”</p></li>
<li><p><strong>Conclude with practical advice:</strong> “In practice, it’s best to use a combination of these techniques, along with careful data preprocessing, regularization, and hyperparameter tuning, to get a reliable understanding of feature importance. No single method is perfect, so triangulating from multiple approaches gives the most robust insights.”</p></li>
</ol>
<p>Throughout your explanation, maintain a conversational tone. Check in with the interviewer periodically by asking, “Does that make sense?” or “Are there any questions about that?” This keeps them engaged and allows you to adjust your explanation based on their understanding. If they ask a clarifying question, address it directly before moving on.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>