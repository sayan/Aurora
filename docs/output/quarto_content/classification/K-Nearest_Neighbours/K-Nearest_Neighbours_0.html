<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>k-nearest_neighbours_0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-what-is-the-k-nearest-neighbors-knn-algorithm-and-how-does-it-work" class="level2">
<h2 class="anchored" data-anchor-id="question-what-is-the-k-nearest-neighbors-knn-algorithm-and-how-does-it-work">Question: What is the K-Nearest Neighbors (KNN) algorithm and how does it work?</h2>
<p><strong>Best Answer</strong></p>
<p>The K-Nearest Neighbors (KNN) algorithm is a non-parametric, lazy learning algorithm used for both classification and regression tasks. It’s “non-parametric” because it doesn’t make any assumptions about the underlying data distribution. “Lazy learning” means it doesn’t build an explicit model during the training phase; instead, it stores the training dataset and performs computations only at the time of prediction.</p>
<p>Here’s a breakdown of how KNN works:</p>
<ol type="1">
<li><p><strong>Data Representation:</strong> Each data point in the dataset is represented as a vector in a feature space. Let’s denote the training dataset as <span class="math inline">\(D = \{(x_i, y_i)\}_{i=1}^{N}\)</span>, where <span class="math inline">\(x_i \in \mathbb{R}^d\)</span> represents the feature vector of the <span class="math inline">\(i\)</span>-th data point, <span class="math inline">\(y_i\)</span> represents the class label (for classification) or the target value (for regression), and <span class="math inline">\(N\)</span> is the total number of data points in the training set.</p></li>
<li><p><strong>Distance Metric:</strong> The algorithm relies on a distance metric to determine the “nearest” neighbors. Common distance metrics include:</p>
<ul>
<li><p><strong>Euclidean Distance:</strong> This is the most commonly used distance metric. The Euclidean distance between two points <span class="math inline">\(x = (x_1, x_2, ..., x_d)\)</span> and <span class="math inline">\(x' = (x'_1, x'_2, ..., x'_d)\)</span> in <span class="math inline">\(d\)</span>-dimensional space is calculated as:</p>
<p><span class="math display">\[d(x, x') = \sqrt{\sum_{j=1}^{d}(x_j - x'_j)^2}\]</span></p></li>
<li><p><strong>Manhattan Distance (L1 Norm):</strong> Also known as city block distance, it calculates the distance as the sum of the absolute differences of their Cartesian coordinates.</p>
<p><span class="math display">\[d(x, x') = \sum_{j=1}^{d}|x_j - x'_j|\]</span></p></li>
<li><p><strong>Minkowski Distance:</strong> This is a generalized distance metric that encompasses both Euclidean and Manhattan distances. It is defined as:</p>
<p><span class="math display">\[d(x, x') = \left(\sum_{j=1}^{d}|x_j - x'_j|^p\right)^{\frac{1}{p}}\]</span></p>
<p>where <span class="math inline">\(p\)</span> is a parameter. When <span class="math inline">\(p = 2\)</span>, it becomes Euclidean distance, and when <span class="math inline">\(p = 1\)</span>, it becomes Manhattan distance.</p></li>
<li><p><strong>Cosine Similarity:</strong> This measures the cosine of the angle between two vectors. It’s often used when the magnitude of the vectors is not as important as their direction.</p>
<p><span class="math display">\[similarity(x, x') = \frac{x \cdot x'}{\|x\| \|x'\|} = \frac{\sum_{j=1}^{d}x_jx'_j}{\sqrt{\sum_{j=1}^{d}x_j^2} \sqrt{\sum_{j=1}^{d}x'_j^2}}\]</span> The distance can then be calculated as <span class="math inline">\(distance = 1 - similarity\)</span>.</p></li>
</ul></li>
<li><p><strong>Choosing K:</strong> The ‘K’ in KNN represents the number of nearest neighbors to consider. The choice of K is crucial and can significantly impact the algorithm’s performance.</p>
<ul>
<li><p>A small value of K (e.g., K=1) makes the algorithm more sensitive to noise and outliers in the data, leading to a more complex decision boundary and potentially overfitting.</p></li>
<li><p>A large value of K smooths the decision boundary and reduces the impact of noise, but it can also lead to underfitting if K is too large and includes points from different classes.</p></li>
<li><p>Cross-validation techniques (e.g., k-fold cross-validation) are typically used to select the optimal value of K.</p></li>
</ul></li>
<li><p><strong>Classification:</strong> For classification, given a new data point <span class="math inline">\(x_{new}\)</span> to classify:</p>
<ul>
<li><p>Calculate the distance between <span class="math inline">\(x_{new}\)</span> and all data points in the training set <span class="math inline">\(D\)</span> using the chosen distance metric.</p></li>
<li><p>Identify the K nearest neighbors of <span class="math inline">\(x_{new}\)</span> based on the calculated distances. Let’s denote the set of K nearest neighbors as <span class="math inline">\(N_K(x_{new})\)</span>.</p></li>
<li><p>Assign the class label to <span class="math inline">\(x_{new}\)</span> based on the majority class among its K nearest neighbors. This is typically done using a voting scheme:</p>
<p><span class="math display">\[y_{new} = \arg\max_{c} \sum_{(x_i, y_i) \in N_K(x_{new})} \mathbb{I}(y_i = c)\]</span></p>
<p>where <span class="math inline">\(c\)</span> represents a class label and <span class="math inline">\(\mathbb{I}(.)\)</span> is the indicator function (1 if the condition is true, 0 otherwise).</p>
<p>In some cases, a weighted voting scheme can be used, where the contribution of each neighbor is weighted by the inverse of its distance to <span class="math inline">\(x_{new}\)</span>:</p>
<p><span class="math display">\[y_{new} = \arg\max_{c} \sum_{(x_i, y_i) \in N_K(x_{new})} w_i \mathbb{I}(y_i = c)\]</span></p>
<p>where <span class="math inline">\(w_i = \frac{1}{d(x_{new}, x_i)}\)</span> is the weight assigned to the <span class="math inline">\(i\)</span>-th neighbor.</p></li>
</ul></li>
<li><p><strong>Regression:</strong> For regression, given a new data point <span class="math inline">\(x_{new}\)</span> to predict:</p>
<ul>
<li><p>Calculate the distance between <span class="math inline">\(x_{new}\)</span> and all data points in the training set <span class="math inline">\(D\)</span>.</p></li>
<li><p>Identify the K nearest neighbors of <span class="math inline">\(x_{new}\)</span>.</p></li>
<li><p>Predict the target value for <span class="math inline">\(x_{new}\)</span> by averaging the target values of its K nearest neighbors:</p>
<p><span class="math display">\[y_{new} = \frac{1}{K} \sum_{(x_i, y_i) \in N_K(x_{new})} y_i\]</span></p>
<p>Similar to classification, a weighted average can be used, where the weights are inversely proportional to the distances:</p>
<p><span class="math display">\[y_{new} = \sum_{(x_i, y_i) \in N_K(x_{new})} w_i y_i\]</span></p>
<p>where <span class="math inline">\(w_i = \frac{\frac{1}{d(x_{new}, x_i)}}{\sum_{(x_j, y_j) \in N_K(x_{new})} \frac{1}{d(x_{new}, x_j)}}\)</span> are the normalized weights.</p></li>
</ul></li>
</ol>
<p><strong>Importance and Considerations:</strong></p>
<ul>
<li><strong>Simplicity:</strong> KNN is easy to understand and implement.</li>
<li><strong>No Training Phase:</strong> Its “lazy learning” nature avoids a computationally expensive training phase.</li>
<li><strong>Adaptability:</strong> It adapts well to different data distributions since it makes no assumptions.</li>
<li><strong>Computational Cost:</strong> Prediction can be slow, especially with large datasets, as it requires calculating distances to all training points.</li>
<li><strong>Curse of Dimensionality:</strong> Performance degrades significantly with high-dimensional data. Feature selection or dimensionality reduction techniques (e.g., PCA) are often necessary. The distances between points become less meaningful as the number of dimensions increases, and the nearest neighbors may not be truly representative.</li>
<li><strong>Feature Scaling:</strong> Feature scaling (e.g., standardization or normalization) is crucial, especially when features have different scales or units. Features with larger scales can dominate the distance calculation.</li>
<li><strong>Memory Usage:</strong> KNN requires storing the entire training dataset in memory.</li>
<li><strong>Choosing the Right Metric:</strong> The choice of distance metric depends on the nature of the data and the problem. Euclidean distance is suitable for continuous data, while Hamming distance is often used for categorical data.</li>
</ul>
<p><strong>Real-World Examples:</strong></p>
<ul>
<li><strong>Recommender Systems:</strong> Recommending products or movies based on the preferences of similar users.</li>
<li><strong>Image Recognition:</strong> Classifying images based on the similarity to known images.</li>
<li><strong>Medical Diagnosis:</strong> Diagnosing diseases based on the symptoms of similar patients.</li>
<li><strong>Anomaly Detection:</strong> Identifying unusual data points that deviate significantly from the norm.</li>
</ul>
<p><strong>How to Narrate</strong></p>
<p>Here’s how to present this answer in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Basics:</strong> “KNN, or K-Nearest Neighbors, is a simple yet powerful algorithm used for both classification and regression. It’s a non-parametric and lazy learning method.”</p></li>
<li><p><strong>Explain the Core Idea:</strong> “The basic idea is to classify or predict the value of a new data point based on the ‘K’ closest data points in the training set. Closeness is defined by a distance metric.”</p></li>
<li><p><strong>Discuss Distance Metrics:</strong> “Common distance metrics include Euclidean distance, which is the straight-line distance, and Manhattan distance, which is the sum of absolute differences. Cosine similarity is another option, especially useful when the direction of the vectors is more important than their magnitude.” At this point, you can write the formula for Euclidean distance on the whiteboard if appropriate (and if the interviewer seems receptive): “For instance, Euclidean distance is calculated as [write the formula].” Avoid delving too deeply unless prompted.</p></li>
<li><p><strong>Explain the Role of K:</strong> “The value of ‘K’ is a crucial parameter. A small K makes the model sensitive to noise, while a large K can smooth out the decision boundary but potentially lead to underfitting. Cross-validation is typically used to find the optimal K.”</p></li>
<li><p><strong>Describe Classification/Regression:</strong> “For classification, we assign the new point to the class that is most frequent among its K nearest neighbors – a majority vote. For regression, we predict the value by averaging the values of its K nearest neighbors.”</p></li>
<li><p><strong>Address Key Considerations:</strong> “While simple, KNN has important considerations. Computationally, it can be expensive for large datasets because we need to calculate distances to all training points. It also suffers from the curse of dimensionality, so feature selection or dimensionality reduction is often necessary. Feature scaling is also critical.”</p></li>
<li><p><strong>Provide Real-World Examples:</strong> “KNN is used in various applications, such as recommender systems, image recognition, and medical diagnosis.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Allow the interviewer to process each point.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you have a whiteboard, use it to illustrate the concept, especially the distance metric.</li>
<li><strong>Engage the Interviewer:</strong> Pause occasionally to ask if they have any questions or if they would like you to elaborate on a specific aspect.</li>
<li><strong>Balance Theory and Practice:</strong> Demonstrate your understanding of the underlying theory while also highlighting practical considerations and real-world applications.</li>
<li><strong>Don’t Overwhelm with Math:</strong> Present the mathematical formulas only if it feels appropriate and relevant to the discussion. Focus on explaining the intuition behind the formulas rather than getting bogged down in the details.</li>
<li><strong>Highlight Senior-Level Knowledge:</strong> Emphasize the challenges associated with KNN, such as the curse of dimensionality and the need for feature scaling. This demonstrates a deeper understanding of the algorithm beyond the basic principles.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>