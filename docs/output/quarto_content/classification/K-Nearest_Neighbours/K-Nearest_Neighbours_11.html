<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>k-nearest_neighbours_11</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-how-do-you-evaluate-the-performance-of-a-knn-model-what-metrics-would-you-use" class="level2">
<h2 class="anchored" data-anchor-id="question-how-do-you-evaluate-the-performance-of-a-knn-model-what-metrics-would-you-use">Question: How do you evaluate the performance of a KNN model? What metrics would you use?</h2>
<p><strong>Best Answer</strong></p>
<p>Evaluating the performance of a K-Nearest Neighbors (KNN) model requires careful consideration of the specific task and the characteristics of the dataset. KNN is a non-parametric algorithm, and its performance can be highly dependent on the choice of distance metric, the value of K, and the nature of the data. The metrics I’d use depend on whether it’s a classification or regression problem.</p>
<p><strong>KNN for Classification:</strong></p>
<p>For classification tasks, common metrics include accuracy, precision, recall, F1-score, and ROC-AUC. Each of these metrics provides different insights into the model’s performance.</p>
<ul>
<li><p><strong>Accuracy:</strong></p>
<ul>
<li>Definition: The ratio of correctly classified instances to the total number of instances.</li>
<li>Formula: <span class="math display">\[
Accuracy = \frac{Number\ of\ Correct\ Predictions}{Total\ Number\ of\ Predictions}
\]</span></li>
<li>Use Case: Suitable for balanced datasets where classes have roughly equal representation.</li>
<li>Limitation: Can be misleading in imbalanced datasets.</li>
</ul></li>
<li><p><strong>Precision:</strong></p>
<ul>
<li>Definition: The ratio of true positives to the total number of instances predicted as positive. Measures how well the model avoids false positives.</li>
<li>Formula: <span class="math display">\[
Precision = \frac{True\ Positives}{True\ Positives + False\ Positives}
\]</span></li>
<li>Use Case: Important when the cost of false positives is high (e.g., medical diagnosis).</li>
</ul></li>
<li><p><strong>Recall (Sensitivity or True Positive Rate):</strong></p>
<ul>
<li>Definition: The ratio of true positives to the total number of actual positive instances. Measures how well the model identifies all positive instances.</li>
<li>Formula: <span class="math display">\[
Recall = \frac{True\ Positives}{True\ Positives + False\ Negatives}
\]</span></li>
<li>Use Case: Important when the cost of false negatives is high (e.g., fraud detection).</li>
</ul></li>
<li><p><strong>F1-Score:</strong></p>
<ul>
<li>Definition: The harmonic mean of precision and recall. Provides a balanced measure of the model’s performance.</li>
<li>Formula: <span class="math display">\[
F1\text{-}Score = 2 \times \frac{Precision \times Recall}{Precision + Recall}
\]</span></li>
<li>Use Case: Useful when you want to balance precision and recall, especially in imbalanced datasets.</li>
</ul></li>
<li><p><strong>Confusion Matrix:</strong></p>
<ul>
<li>A table visualizing the performance of a classification model. Each row represents the actual class, and each column represents the predicted class. It helps in understanding the types of errors the model is making (False Positives, False Negatives, True Positives, True Negatives).</li>
</ul></li>
<li><p><strong>ROC-AUC (Receiver Operating Characteristic - Area Under the Curve):</strong></p>
<ul>
<li>Definition: ROC curve plots the true positive rate (recall) against the false positive rate at various threshold settings. AUC measures the area under the ROC curve.</li>
<li>Interpretation: AUC ranges from 0 to 1. A higher AUC indicates better performance. An AUC of 0.5 suggests performance no better than random guessing.</li>
<li>Use Case: Particularly useful for imbalanced datasets and when you want to evaluate the model’s ability to discriminate between classes across different probability thresholds.</li>
<li>Implementation Details: The ROC curve is created by varying the decision threshold of the classifier and plotting the TPR and FPR. The AUC is then computed as the integral of the curve.</li>
</ul>
<p><em>ROC Calculation</em></p>
<ul>
<li>True Positive Rate (TPR) = <span class="math inline">\(\frac{TP}{TP + FN}\)</span></li>
<li>False Positive Rate (FPR) = <span class="math inline">\(\frac{FP}{FP + TN}\)</span></li>
</ul></li>
<li><p><strong>Log Loss (Cross-Entropy Loss):</strong></p>
<ul>
<li>Definition: Measures the performance of a classification model where the prediction input is a probability value between 0 and 1.</li>
<li>Formula:</li>
</ul>
<p><span class="math display">\[Log Loss = -\frac{1}{N}\sum_{i=1}^{N} (y_i \cdot log(p_i) + (1-y_i) \cdot log(1-p_i))\]</span></p>
<p>Where: * N is the number of observations. * <span class="math inline">\(y_i\)</span> is the actual label for the ith observation (0 or 1). * <span class="math inline">\(p_i\)</span> is the predicted probability that the ith observation belongs to class 1.</p></li>
<li><p><strong>Considerations for Imbalanced Datasets:</strong></p>
<ul>
<li>In imbalanced datasets, accuracy can be misleading. Precision, recall, F1-score, and ROC-AUC are more informative.</li>
<li>Techniques like oversampling the minority class or undersampling the majority class can be used to mitigate the impact of class imbalance.</li>
</ul></li>
</ul>
<p><strong>KNN for Regression:</strong></p>
<p>For regression tasks, common metrics include Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared.</p>
<ul>
<li><strong>Mean Squared Error (MSE):</strong>
<ul>
<li>Definition: The average of the squared differences between the predicted and actual values.</li>
<li>Formula: <span class="math display">\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]</span> where <span class="math inline">\(y_i\)</span> is the actual value and <span class="math inline">\(\hat{y}_i\)</span> is the predicted value.</li>
<li>Use Case: Common metric, sensitive to outliers due to the squared term.</li>
</ul></li>
<li><strong>Root Mean Squared Error (RMSE):</strong>
<ul>
<li>Definition: The square root of the MSE. Provides a more interpretable measure of the average error, as it is in the same units as the target variable.</li>
<li>Formula: <span class="math display">\[
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\]</span></li>
<li>Use Case: Widely used, interpretable, but also sensitive to outliers.</li>
</ul></li>
<li><strong>Mean Absolute Error (MAE):</strong>
<ul>
<li>Definition: The average of the absolute differences between the predicted and actual values.</li>
<li>Formula: <span class="math display">\[
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]</span></li>
<li>Use Case: More robust to outliers compared to MSE and RMSE.</li>
</ul></li>
<li><strong>R-squared (Coefficient of Determination):</strong>
<ul>
<li>Definition: Represents the proportion of the variance in the dependent variable that is predictable from the independent variables.</li>
<li>Formula: <span class="math display">\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]</span> where <span class="math inline">\(\bar{y}\)</span> is the mean of the actual values.</li>
<li>Interpretation: Ranges from 0 to 1. A higher R-squared indicates a better fit of the model to the data.</li>
<li>Use Case: Provides a measure of how well the model explains the variability in the data.</li>
</ul></li>
</ul>
<p><strong>Additional Considerations:</strong></p>
<ul>
<li><p><strong>Cross-Validation:</strong> Always use cross-validation techniques (e.g., k-fold cross-validation) to obtain a more robust estimate of the model’s performance. This helps in assessing how well the model generalizes to unseen data.</p></li>
<li><p><strong>Distance Metric:</strong> The choice of distance metric (e.g., Euclidean, Manhattan, Minkowski) can significantly impact the model’s performance. Experiment with different metrics and choose the one that works best for your data. The Minkowski distance is a generalization of both Euclidean and Manhattan distances.</p></li>
</ul>
<p><em>Minkowski Distance</em> <span class="math display">\[D(x, y) = (\sum_{i=1}^{n} |x_i - y_i|^p)^{\frac{1}{p}}\]</span></p>
<p>When p = 1, it becomes Manhattan distance, and when p = 2, it becomes Euclidean distance.</p>
<ul>
<li><p><strong>Feature Scaling:</strong> KNN is sensitive to the scale of the features. Feature scaling (e.g., standardization or normalization) is often necessary to ensure that all features contribute equally to the distance calculation.</p></li>
<li><p><strong>Hyperparameter Tuning:</strong> The value of K is a crucial hyperparameter. Use techniques like grid search or randomized search to find the optimal value of K that maximizes the model’s performance on a validation set. Also, consider using weighted KNN, where closer neighbors have more influence on the prediction.</p></li>
</ul>
<p><strong>In Summary:</strong></p>
<p>The choice of evaluation metric depends on the specific problem and the priorities of the application. For classification, accuracy is a good starting point, but precision, recall, F1-score, and ROC-AUC provide more detailed insights, especially for imbalanced datasets. For regression, MSE, RMSE, MAE, and R-squared are common choices, each with its own strengths and weaknesses. Always use cross-validation and consider the impact of feature scaling, distance metrics, and hyperparameter tuning on the model’s performance.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide to deliver this answer effectively in an interview:</p>
<ol type="1">
<li><strong>Start with a High-Level Overview:</strong>
<ul>
<li>Begin by stating that evaluating KNN model performance depends on whether it’s a classification or regression problem. This sets the context.</li>
<li><em>“The way I’d evaluate a KNN model really depends on whether we’re using it for classification or regression, as the appropriate metrics differ.”</em></li>
</ul></li>
<li><strong>Discuss Classification Metrics:</strong>
<ul>
<li><strong>Accuracy:</strong> Explain that accuracy is the most intuitive metric but has limitations.
<ul>
<li><em>“For classification, a common starting point is accuracy, which is simply the proportion of correctly classified instances. However, accuracy can be misleading, especially when the classes are imbalanced.”</em></li>
</ul></li>
<li><strong>Precision and Recall:</strong> Define precision and recall, emphasizing when each is more important. Use real-world examples if possible.
<ul>
<li><em>“Precision measures how well our model avoids false positives, while recall measures how well it identifies all actual positives. Precision is crucial when false positives are costly, like in medical diagnosis, whereas recall is vital when missing positive cases is detrimental, such as in fraud detection.”</em></li>
</ul></li>
<li><strong>F1-Score:</strong> Explain the F1-score as a balance between precision and recall.
<ul>
<li><em>“The F1-score is the harmonic mean of precision and recall, offering a balanced view of the model’s performance. It’s particularly useful when we want to balance false positives and false negatives.”</em></li>
</ul></li>
<li><strong>ROC-AUC:</strong> Explain ROC-AUC in detail, highlighting its advantages for imbalanced datasets. You can draw a quick sketch of the ROC curve on a whiteboard if available.
<ul>
<li><em>“ROC-AUC is a more sophisticated metric that plots the true positive rate against the false positive rate at various thresholds. The area under this curve gives us a measure of the model’s ability to discriminate between classes. It’s especially useful for imbalanced datasets because it’s less sensitive to changes in class distribution.”</em></li>
<li><strong>Briefly mention TPR and FPR equations:</strong>
<ul>
<li><em>“The ROC curve is generated by plotting the True Positive Rate (TPR), which is TP/(TP+FN), against the False Positive Rate (FPR), which is FP/(FP+TN), at different classification thresholds.”</em></li>
</ul></li>
</ul></li>
<li><strong>Confusion Matrix:</strong> Explain how confusion matrix is useful for understanding the types of errors.
<ul>
<li><em>“A confusion matrix gives a detailed breakdown of the model’s predictions, showing True Positives, True Negatives, False Positives, and False Negatives. This helps in understanding where the model is making mistakes.”</em></li>
</ul></li>
<li><strong>Log Loss</strong>: Introduce Log Loss as a way to evaluate the probabilities instead of the classes:
<ul>
<li><em>“Log Loss measures the performance of a classification model by evaluating the probabilities of the output. A lower Log Loss indicates higher model’s performance”</em></li>
</ul></li>
</ul></li>
<li><strong>Discuss Regression Metrics:</strong>
<ul>
<li>Introduce MSE, RMSE, MAE, and R-squared. Explain the differences and when to use each.
<ul>
<li><em>“For regression tasks, we commonly use metrics like Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared. MSE calculates the average squared difference between predicted and actual values, while RMSE is just the square root of MSE and is more interpretable because it’s in the same units as the target variable.”</em></li>
<li><em>“MAE, on the other hand, is less sensitive to outliers because it uses absolute differences. R-squared tells us the proportion of variance in the dependent variable that our model can predict – higher R-squared means a better fit.”</em></li>
</ul></li>
</ul></li>
<li><strong>Highlight Additional Considerations:</strong>
<ul>
<li>Stress the importance of cross-validation for robust performance estimation.
<ul>
<li><em>“No matter the task, it’s crucial to use cross-validation to get a reliable estimate of how well our model will generalize to unseen data. K-fold cross-validation is a common technique.”</em></li>
</ul></li>
<li>Mention the impact of distance metrics, feature scaling, and hyperparameter tuning.
<ul>
<li><em>“KNN is sensitive to the choice of distance metric and feature scaling. Experimenting with different metrics like Euclidean, Manhattan, or Minkowski can impact performance. Feature scaling is often necessary to ensure all features contribute equally.”</em></li>
<li><em>“The value of K is a critical hyperparameter. Techniques like grid search help us find the optimal K. Also, one can consider using weighted KNN, where closer neighbors have more influence on the prediction.”</em></li>
</ul></li>
</ul></li>
<li><strong>Summarize and Conclude:</strong>
<ul>
<li>Reiterate that the choice of metric depends on the problem and the goals.
<ul>
<li><em>“In summary, the best way to evaluate a KNN model depends on the specifics of the task. For classification, we look at accuracy, precision, recall, F1-score, and ROC-AUC, especially for imbalanced datasets. For regression, we use MSE, RMSE, MAE, and R-squared. Always use cross-validation and consider the impact of feature scaling, distance metrics, and hyperparameter tuning.”</em></li>
</ul></li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to absorb the information.</li>
<li><strong>Use Simple Language:</strong> Avoid overly technical jargon when possible. Explain concepts in a clear and concise manner.</li>
<li><strong>Provide Context:</strong> Explain why each metric is important and when it should be used.</li>
<li><strong>Engage the Interviewer:</strong> Ask if they have any questions or if they would like you to elaborate on any specific point.</li>
<li><strong>Show Enthusiasm:</strong> Demonstrate your passion for the topic and your understanding of the nuances of model evaluation.</li>
<li><strong>Visual Aids:</strong> If in person and a whiteboard is available, jot down formulas or sketch ROC curves to aid your explanation. This will give the interviewer a good impression.</li>
</ul>
<p>By following this structure and incorporating these tips, you can provide a comprehensive and compelling answer that showcases your expertise in evaluating KNN models.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>