<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>k-nearest_neighbours_10</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-what-considerations-would-you-keep-in-mind-when-deploying-a-knn-model-in-production" class="level2">
<h2 class="anchored" data-anchor-id="question-what-considerations-would-you-keep-in-mind-when-deploying-a-knn-model-in-production">Question: What considerations would you keep in mind when deploying a KNN model in production?</h2>
<p><strong>Best Answer</strong></p>
<p>Deploying a K-Nearest Neighbors (KNN) model in a production environment requires careful consideration of several factors. KNN, while conceptually simple, presents unique challenges regarding scalability, computational cost, storage, and maintainability when applied to real-world, high-volume data. Here’s a breakdown of the key considerations:</p>
<p><strong>1. Scalability and Computational Complexity:</strong></p>
<ul>
<li><p><strong>Search Complexity:</strong> KNN’s prediction phase involves searching for the <em>k</em> nearest neighbors to a query point within the entire training dataset. This process has a time complexity of <span class="math inline">\(O(N)\)</span>, where <span class="math inline">\(N\)</span> is the number of data points in the training set, making it computationally expensive for large datasets.</p></li>
<li><p><strong>Memory Footprint:</strong> KNN requires storing the entire training dataset in memory, which can become prohibitive for massive datasets.</p></li>
<li><p><strong>Mitigation Strategies:</strong></p>
<ul>
<li><strong>Approximate Nearest Neighbor (ANN) Search:</strong> Implement ANN algorithms like KD-trees, Ball trees, or locality-sensitive hashing (LSH) to achieve sub-linear search time (e.g., <span class="math inline">\(O(log N)\)</span> or even better depending on the implementation and data distribution) at the cost of some accuracy. Libraries like Annoy or Faiss are popular choices.</li>
<li><strong>Data Reduction:</strong> Employ techniques like data condensation or prototype selection to reduce the size of the training dataset while preserving its essential structure. However, be mindful of the potential impact on model accuracy.</li>
<li><strong>Distributed Computing:</strong> Distribute the training dataset across multiple machines and perform the nearest neighbor search in parallel. Frameworks like Spark can be used for this purpose.</li>
</ul></li>
</ul>
<p><strong>2. Indexing and Data Structures:</strong></p>
<ul>
<li><p><strong>Choice of Index:</strong> Selecting the appropriate spatial indexing structure (e.g., KD-tree, Ball tree) is crucial for efficient nearest neighbor search. The optimal choice depends on the dimensionality of the data and its distribution. KD-trees tend to perform well for low-dimensional data (typically &lt; 20 dimensions), while Ball trees are more robust to the curse of dimensionality.</p></li>
<li><p><strong>Index Building Cost:</strong> Building the index can be computationally expensive, especially for large datasets. Consider pre-computing the index offline and loading it into memory at runtime. Also, think about how often you would be rebuilding the index.</p></li>
<li><p><strong>Dynamic Data:</strong> If the training dataset is constantly updated, you’ll need to consider how to maintain the index efficiently. Incremental index updates might be necessary, but can be complex to implement. Alternatively, rebuilding the index periodically might be more practical.</p></li>
</ul>
<p><strong>3. Feature Scaling and Distance Metrics:</strong></p>
<ul>
<li><p><strong>Feature Scaling:</strong> KNN is sensitive to the scale of features. Features with larger ranges will dominate the distance calculations, leading to biased results. Apply feature scaling techniques like standardization (Z-score normalization) or min-max scaling to ensure that all features contribute equally.</p>
<ul>
<li><p><strong>Standardization:</strong> Scales features to have zero mean and unit variance:</p>
<p><span class="math display">\[
x' = \frac{x - \mu}{\sigma}
\]</span></p></li>
<li><p><strong>Min-Max Scaling:</strong> Scales features to a range between 0 and 1:</p>
<p><span class="math display">\[
x' = \frac{x - x_{min}}{x_{max} - x_{min}}
\]</span></p></li>
</ul></li>
<li><p><strong>Distance Metric Selection:</strong> The choice of distance metric can significantly impact the performance of KNN. Euclidean distance is a common choice, but other metrics like Manhattan distance, Minkowski distance, or cosine similarity might be more appropriate depending on the nature of the data and the problem.</p>
<ul>
<li><strong>Euclidean Distance:</strong> <span class="math display">\[d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}\]</span></li>
<li><strong>Manhattan Distance:</strong> <span class="math display">\[d(x, y) = \sum_{i=1}^{n}|x_i - y_i|\]</span></li>
<li><strong>Cosine Similarity:</strong> <span class="math display">\[similarity(x,y) = \frac{x \cdot y}{||x|| \cdot ||y||}\]</span></li>
</ul></li>
</ul>
<p><strong>4. Model Retraining and Monitoring:</strong></p>
<ul>
<li><strong>Concept Drift:</strong> KNN models can become stale over time if the underlying data distribution changes (concept drift). Implement a monitoring system to track the model’s performance and retrain the model periodically with fresh data to maintain accuracy.</li>
<li><strong>Data Versioning:</strong> Keep track of the data used to train each version of the model to ensure reproducibility and facilitate debugging.</li>
<li><strong>Performance Metrics:</strong> Monitor key performance metrics like accuracy, precision, recall, F1-score, and response time to detect degradation in model performance. Also, consider monitoring metrics specific to KNN, such as the average distance to the nearest neighbors.</li>
</ul>
<p><strong>5. Online vs.&nbsp;Batch Processing:</strong></p>
<ul>
<li><strong>Real-time Prediction:</strong> If real-time predictions are required, KNN might not be the best choice due to its computational cost. Consider using approximate nearest neighbor search or switching to a more efficient model type.</li>
<li><strong>Batch Processing:</strong> For batch processing scenarios, where predictions can be made offline, KNN can be a viable option. You can pre-compute the nearest neighbors for a set of query points and store the results for later retrieval.</li>
</ul>
<p><strong>6. Parameter Tuning:</strong></p>
<ul>
<li><strong>Optimal Value of <em>k</em>:</strong> Selecting the optimal value of <em>k</em> is crucial for achieving good performance. Use techniques like cross-validation to tune the value of <em>k</em> and avoid overfitting or underfitting.</li>
<li><strong>Weighting Schemes:</strong> Consider using distance-weighted KNN, where closer neighbors have a greater influence on the prediction. This can improve the accuracy of the model.</li>
</ul>
<p><strong>7. Handling Missing Values:</strong></p>
<ul>
<li><strong>Imputation:</strong> KNN can be sensitive to missing values. Impute missing values using techniques like mean imputation, median imputation, or KNN imputation (using other features to predict the missing values).</li>
<li><strong>Distance Metrics:</strong> Use distance metrics that can handle missing values directly, such as the Gower distance.</li>
</ul>
<p><strong>8. Security and Privacy:</strong></p>
<ul>
<li><strong>Data Leakage:</strong> Be mindful of potential data leakage issues, especially when dealing with sensitive data. Avoid storing Personally Identifiable Information (PII) in the training dataset.</li>
<li><strong>Adversarial Attacks:</strong> KNN models can be vulnerable to adversarial attacks, where carefully crafted input samples can fool the model. Implement defense mechanisms like adversarial training or input validation to mitigate this risk.</li>
</ul>
<p><strong>9. Model Explainability:</strong></p>
<ul>
<li><strong>Explainable Predictions:</strong> KNN provides some inherent explainability, as you can inspect the nearest neighbors that contributed to a particular prediction. However, for complex datasets, it might be challenging to understand why a particular neighbor was chosen. Consider using techniques like feature importance analysis to gain further insights into the model’s behavior.</li>
</ul>
<p>By carefully considering these factors, you can successfully deploy a KNN model in production and ensure that it performs reliably and efficiently.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with a High-Level Overview:</strong>
<ul>
<li>“Deploying KNN in production requires careful consideration, balancing its simplicity with the challenges of scalability and real-time performance.”</li>
<li>“While conceptually straightforward, KNN introduces specific hurdles in production, especially with large datasets and stringent latency requirements.”</li>
</ul></li>
<li><strong>Address Scalability and Computational Complexity:</strong>
<ul>
<li>“One of the primary concerns is scalability. KNN’s prediction phase has a time complexity of O(N), where N is the size of the training dataset. This can become a bottleneck for large datasets.”</li>
<li>“To mitigate this, we can explore Approximate Nearest Neighbor (ANN) search algorithms, such as KD-trees, Ball trees, or LSH. While introducing some approximation, they offer sub-linear search times, improving performance significantly. For example, using libraries like Faiss or Annoy can be really beneficial.”</li>
<li>“Alternatively, data reduction techniques or distributed computing frameworks like Spark can also be leveraged.”</li>
</ul></li>
<li><strong>Explain Indexing and Data Structures:</strong>
<ul>
<li>“The choice of indexing structure is crucial. KD-trees are suitable for lower-dimensional data, whereas Ball trees handle higher dimensionality better.”</li>
<li>“The index-building cost needs consideration. Pre-computing the index offline and loading it at runtime is a good practice.”</li>
<li>“If the data is dynamic, we need to consider strategies for maintaining the index – either incremental updates or periodic rebuilding.”</li>
</ul></li>
<li><strong>Discuss Feature Scaling and Distance Metrics:</strong>
<ul>
<li>“KNN is sensitive to feature scaling. It’s essential to normalize or standardize the features to prevent features with larger ranges from dominating the distance calculations. We can use standardization shown by this equation: <span class="math inline">\(&lt;equation&gt; x' = \frac{x - \mu}{\sigma} &lt;/equation&gt;\)</span>. Also Min-Max Scaling might work as well: <span class="math inline">\(&lt;equation&gt; x' = \frac{x - x_{min}}{x_{max} - x_{min}} &lt;/equation&gt;\)</span>.”</li>
<li>“The choice of distance metric also matters. Euclidean distance is common, but Manhattan distance or cosine similarity might be more appropriate depending on the data characteristics. For example, Euclidean Distance is: <span class="math display">\[d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}\]</span>. And Manhattan Distance is: <span class="math display">\[d(x, y) = \sum_{i=1}^{n}|x_i - y_i|\]</span>. Finally, Cosine Similarity can be calculated by: <span class="math display">\[similarity(x,y) = \frac{x \cdot y}{||x|| \cdot ||y||}\]</span>.”</li>
</ul></li>
<li><strong>Cover Model Retraining and Monitoring:</strong>
<ul>
<li>“Model retraining is crucial due to concept drift. We need to monitor the model’s performance over time and retrain it with fresh data periodically.”</li>
<li>“Data versioning is also important for reproducibility and debugging.”</li>
<li>“We should monitor metrics such as accuracy, precision, recall, F1-score, and response time to detect performance degradation. Also, consider monitoring KNN-specific metrics like the average distance to the nearest neighbors.”</li>
</ul></li>
<li><strong>Address Online vs.&nbsp;Batch Processing:</strong>
<ul>
<li>“If real-time predictions are needed, KNN’s computational cost can be a limitation. ANN search or alternative models might be more suitable.”</li>
<li>“For batch processing, KNN can be a viable option, where nearest neighbors can be pre-computed.”</li>
</ul></li>
<li><strong>Mention Parameter Tuning:</strong>
<ul>
<li>“The value of ‘k’ is a critical parameter. Techniques like cross-validation should be used to tune ‘k’ and avoid overfitting or underfitting.”</li>
<li>“Distance-weighted KNN, where closer neighbors have a greater influence, can also improve accuracy.”</li>
</ul></li>
<li><strong>Briefly Touch on Remaining Considerations:</strong>
<ul>
<li>“Other important aspects include handling missing values, security and privacy concerns, and model explainability.”</li>
</ul></li>
<li><strong>Summarize:</strong>
<ul>
<li>“In summary, deploying KNN in production involves addressing scalability, indexing, feature scaling, model retraining, and monitoring, among other considerations. A careful approach is needed to ensure efficient and reliable performance.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to process the information.</li>
<li><strong>Use Signposting:</strong> Use phrases like “First,” “Secondly,” “Another important aspect is,” to guide the interviewer through your answer.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask the interviewer if they have any questions.</li>
<li><strong>Be Prepared to Elaborate:</strong> The interviewer might ask you to go into more detail on a specific aspect. Be ready to provide more technical information or real-world examples.</li>
<li><strong>Maintain Eye Contact:</strong> Engage with the interviewer and show that you are confident in your knowledge.</li>
<li><strong>Mathematical Notations:</strong> When presenting equations, explain the symbols clearly and concisely. Avoid getting bogged down in excessive mathematical detail unless prompted.</li>
<li><strong>Real-World Considerations:</strong> Emphasize the practical aspects of deploying KNN in production, such as the trade-offs between accuracy and performance, and the challenges of maintaining the model over time.</li>
</ul>
<p>By following these guidelines, you can effectively communicate your expertise and demonstrate your ability to deploy KNN models in a production environment.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>