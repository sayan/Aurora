<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>support_vector_machines_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-6.-svms-tend-to-be-challenged-by-large-scale-datasets.-what-techniques-or-algorithms-would-you-consider-to-scale-svm-training-to-very-large-datasets" class="level2">
<h2 class="anchored" data-anchor-id="question-6.-svms-tend-to-be-challenged-by-large-scale-datasets.-what-techniques-or-algorithms-would-you-consider-to-scale-svm-training-to-very-large-datasets">Question: 6. SVMs tend to be challenged by large-scale datasets. What techniques or algorithms would you consider to scale SVM training to very large datasets?</h2>
<p><strong>Best Answer</strong></p>
<p>Support Vector Machines (SVMs), while powerful, face scalability issues with large datasets due to their computational complexity. The training complexity of a standard SVM is generally between <span class="math inline">\(O(n^2)\)</span> and <span class="math inline">\(O(n^3)\)</span>, where <span class="math inline">\(n\)</span> is the number of data points. This stems from the need to compute the kernel matrix and solve a quadratic programming problem. To address this, several techniques and algorithms can be employed:</p>
<ol type="1">
<li><strong>Sequential Minimal Optimization (SMO):</strong>
<ul>
<li><p><strong>Explanation:</strong> SMO breaks down the large quadratic programming problem into a series of smaller quadratic programming problems that can be solved analytically. Instead of optimizing all Lagrange multipliers at once, SMO optimizes two multipliers at a time, which significantly reduces the computational burden.</p></li>
<li><p><strong>Mathematical Formulation:</strong> The SVM optimization problem can be expressed as: <span class="math display">\[
\begin{aligned}
&amp; \min_{\alpha} \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j K(x_i, x_j) - \sum_{i=1}^{n} \alpha_i \\
&amp; \text{subject to } 0 \leq \alpha_i \leq C, \sum_{i=1}^{n} \alpha_i y_i = 0
\end{aligned}
\]</span> where <span class="math inline">\(\alpha_i\)</span> are the Lagrange multipliers, <span class="math inline">\(y_i\)</span> are the class labels, <span class="math inline">\(K(x_i, x_j)\)</span> is the kernel function, and <span class="math inline">\(C\)</span> is the regularization parameter. SMO iteratively solves for two <span class="math inline">\(\alpha\)</span> values while keeping the others fixed.</p></li>
<li><p><strong>Why it helps:</strong> By solving smaller subproblems analytically, SMO avoids the need for a numerical quadratic programming solver for the entire dataset. This makes it much more efficient for large datasets.</p></li>
<li><p><strong>Implementation:</strong> Many SVM libraries (e.g., scikit-learn’s <code>SVC</code> with specific settings) utilize SMO or its variations.</p></li>
</ul></li>
<li><strong>Stochastic Gradient Descent (SGD) for SVM (e.g., Pegasos):</strong>
<ul>
<li><strong>Explanation:</strong> Pegasos (Primal Estimated sub-GrAdient SOlver for SVM) is an online learning algorithm that uses stochastic gradient descent to train the SVM model. It iteratively updates the model parameters based on randomly selected data points.</li>
<li><strong>Mathematical Formulation:</strong> The objective function for Pegasos is: <span class="math display">\[
\min_{w} \frac{1}{2} ||w||^2 + \lambda \sum_{i=1}^{n} \max(0, 1 - y_i (w^T x_i))
\]</span> where <span class="math inline">\(w\)</span> is the weight vector, <span class="math inline">\(\lambda\)</span> is the regularization parameter, <span class="math inline">\(x_i\)</span> are the data points, and <span class="math inline">\(y_i\)</span> are the class labels. The update rule for the weight vector is: <span class="math display">\[
w_{t+1} = w_t - \eta_t \nabla L(w_t, x_i, y_i)
\]</span> where <span class="math inline">\(\eta_t\)</span> is the learning rate and <span class="math inline">\(\nabla L\)</span> is the sub-gradient of the loss function.</li>
<li><strong>Why it helps:</strong> SGD has a lower computational cost per iteration compared to traditional SVM solvers. By updating the model based on a small subset (or even a single instance) of the data, each iteration is very fast, allowing for quicker convergence, especially in early training stages.</li>
<li><strong>Real-world considerations:</strong> Choosing the right learning rate schedule is crucial for convergence.</li>
</ul></li>
<li><strong>Kernel Approximation Methods (e.g., Nyström, Random Kitchen Sinks):</strong>
<ul>
<li><p><strong>Explanation:</strong> These methods approximate the kernel matrix with a lower-rank matrix, reducing the computational complexity. They transform the original data into a new feature space where the kernel function can be efficiently computed or approximated.</p></li>
<li><p><strong>Nyström Method:</strong> Approximates the kernel matrix <span class="math inline">\(K\)</span> by sampling a subset of columns and rows. Given a subset of indices <span class="math inline">\(S\)</span> with <span class="math inline">\(|S| = l\)</span>, the kernel matrix is approximated as: <span class="math display">\[
K \approx K_{n,l} K_{l,l}^{-1} K_{l,n}
\]</span> where <span class="math inline">\(K_{n,l}\)</span> contains the intersection of all rows and the <span class="math inline">\(l\)</span> selected columns, and <span class="math inline">\(K_{l,l}\)</span> is the intersection of the <span class="math inline">\(l\)</span> selected rows and columns.</p></li>
<li><p><strong>Random Kitchen Sinks (RKS):</strong> Explicitly maps data to a lower-dimensional feature space using random Fourier features, allowing for linear SVMs to approximate non-linear kernels. It relies on Bochner’s theorem:</p>
<p><span class="math display">\[
K(x, y) = p(x - y) = \int e^{iw^T(x-y)} d\Omega(w)
\]</span></p>
<p>where <span class="math inline">\(K(x, y)\)</span> is a translation-invariant kernel, <span class="math inline">\(p(z)\)</span> is a positive definite function, and <span class="math inline">\(\Omega(w)\)</span> is a probability distribution. RKS approximates this integral using Monte Carlo methods with randomly sampled <span class="math inline">\(w_i\)</span> and phases <span class="math inline">\(b_i\)</span>:</p>
<p><span class="math display">\[
z(x) = [\cos(w_1^T x + b_1), ..., \cos(w_D^T x + b_D), \sin(w_1^T x + b_1), ..., \sin(w_D^T x + b_D)]
\]</span></p>
<p>where <span class="math inline">\(z(x)\)</span> is the approximate feature map and <span class="math inline">\(D\)</span> is the number of random features.</p></li>
<li><p><strong>Why it helps:</strong> Kernel approximation reduces both memory requirements and computational time. The approximate kernel can be computed more quickly, and the reduced feature space allows for faster training of the SVM.</p></li>
<li><p><strong>Real-world considerations:</strong> The accuracy of the approximation depends on the number of sampled points or random features. A trade-off exists between accuracy and computational efficiency.</p></li>
</ul></li>
<li><strong>Decomposition Methods (e.g., Chunking, Working Set Selection):</strong>
<ul>
<li><strong>Explanation:</strong> These methods break the training data into smaller chunks and iteratively optimize the SVM model on subsets of the data. They focus on identifying and optimizing the most important support vectors.</li>
<li><strong>Chunking:</strong> Solves the SVM optimization problem by repeatedly selecting subsets of the data (chunks) and optimizing the Lagrange multipliers for those subsets while keeping the multipliers for the remaining data fixed.</li>
<li><strong>Working Set Selection:</strong> Selects a subset of the data points (the working set) to optimize in each iteration. The selection criteria are designed to choose the most promising data points for improving the objective function.</li>
<li><strong>Why it helps:</strong> By focusing on smaller subsets of the data, these methods reduce the memory footprint and computational cost of each iteration.</li>
<li><strong>Real-world considerations:</strong> The choice of the chunk size or working set size can affect the convergence rate and the final accuracy of the model.</li>
</ul></li>
<li><strong>Parallelization:</strong>
<ul>
<li><strong>Explanation:</strong> Distribute the computation across multiple processors or machines. This can be applied to various stages of SVM training, such as kernel matrix computation or optimization.</li>
<li><strong>Techniques:</strong>
<ul>
<li><strong>Data Parallelism:</strong> Partition the data across multiple machines and train a local SVM model on each machine. The local models are then combined to create a global model.</li>
<li><strong>Task Parallelism:</strong> Distribute different tasks of the SVM training process (e.g., kernel computation, optimization) across multiple processors.</li>
</ul></li>
<li><strong>Why it helps:</strong> Parallelization can significantly reduce the training time, especially for very large datasets.</li>
<li><strong>Real-world considerations:</strong> Requires careful coordination and communication between processors or machines.</li>
</ul></li>
<li><strong>Linear SVM:</strong>
<ul>
<li><strong>Explanation:</strong> If the data is linearly separable or approximately linearly separable, using a linear kernel can drastically reduce the computational cost. Linear SVMs have a much simpler optimization problem.</li>
<li><strong>Mathematical Formulation:</strong> The decision function for a linear SVM is: <span class="math display">\[
f(x) = w^T x + b
\]</span> where <span class="math inline">\(w\)</span> is the weight vector and <span class="math inline">\(b\)</span> is the bias term.</li>
<li><strong>Why it helps:</strong> Training a linear SVM is much faster than training a non-linear SVM with a kernel function like RBF or polynomial, as it avoids the computational cost of kernel evaluations.</li>
<li><strong>Real-world considerations:</strong> May not be suitable for datasets with complex non-linear relationships. Feature engineering or dimensionality reduction techniques may be needed to improve performance.</li>
</ul></li>
<li><strong>Out-of-Core Learning:</strong>
<ul>
<li><strong>Explanation:</strong> This approach involves processing the data in chunks that fit into memory, allowing the algorithm to handle datasets that are larger than the available RAM.</li>
<li><strong>Techniques:</strong> Mini-batch learning or incremental learning strategies are employed to update the model parameters based on the chunks of data.</li>
<li><strong>Why it helps:</strong> Out-of-core learning enables the training of SVM models on extremely large datasets that cannot be loaded into memory at once.</li>
<li><strong>Real-world considerations:</strong> Requires careful management of data input/output operations to minimize overhead and ensure efficient processing.</li>
</ul></li>
</ol>
<p>By combining these techniques, it is possible to scale SVM training to handle very large datasets effectively, balancing computational efficiency with model accuracy. The choice of technique depends on the specific characteristics of the dataset, the available computational resources, and the desired level of accuracy.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to present this information effectively in an interview:</p>
<ol type="1">
<li><p><strong>Start with Acknowledging the Challenge:</strong> Begin by acknowledging the interviewer’s point: “Yes, SVMs can struggle with very large datasets due to their inherent computational complexity, typically between O(n^2) and O(n^3) primarily stemming from kernel computations and quadratic programming.”</p></li>
<li><p><strong>Overview of Solutions:</strong> “To address this, there are several algorithmic and optimization strategies we can consider. These broadly fall into categories like decomposition methods, stochastic optimization, kernel approximations, parallelization, and, in some cases, simply using a linear SVM.”</p></li>
<li><p><strong>SMO Explanation:</strong> “One common approach is Sequential Minimal Optimization or SMO. Explain that this breaks down the large optimization problem into smaller, analytically solvable subproblems. You can mention the equation, but don’t get bogged down in the derivation. Focus on the ‘why’: ‘SMO avoids needing a full numerical quadratic programming solver by optimizing two Lagrange multipliers at a time, which is far more efficient.’”</p></li>
<li><p><strong>Discuss Pegasos (SGD):</strong> “Another powerful technique is using Stochastic Gradient Descent, such as the Pegasos algorithm. This method updates the model parameters iteratively, based on small, randomly selected subsets of data or even single points.” Briefly show the SGD update rule, but focus on the benefit, stating: “This drastically reduces the computational cost per iteration, leading to quicker convergence, especially in the earlier phases of training.” Emphasize the importance of learning rate tuning.</p></li>
<li><p><strong>Introduce Kernel Approximation:</strong> “Kernel approximation techniques, such as Nyström or Random Kitchen Sinks, provide another avenue for scaling. Briefly explain Nyström as approximating the kernel matrix by sampling and Random Kitchen Sinks using random Fourier Features to map data into a lower-dimensional space where linear SVMs can approximate non-linear kernels.” Avoid diving too deep into the math unless prompted. Highlight the tradeoff: “While kernel approximation reduces computational cost and memory requirements, it’s essential to balance the level of approximation with acceptable model accuracy.”</p></li>
<li><p><strong>Mention Decomposition Methods:</strong> “Decomposition methods, like chunking or working set selection, involve breaking the data into smaller, manageable chunks. The optimization process then concentrates on subsets of the data, minimizing the computational burden in each iteration.”</p></li>
<li><p><strong>Parallelization Strategy</strong> Then move to “If computational resources allow, parallelization can drastically reduce the training time. Data parallelism involves partitioning the data across multiple machines, where each machine trains a local SVM. These local models are then combined to form a global model”</p></li>
<li><p><strong>Discuss Linear SVMs:</strong> “If the data is approximately linearly separable, a linear SVM provides a very efficient alternative. It avoids the computationally intensive kernel evaluations altogether.” Acknowledge the limitations: “However, this approach requires careful consideration, as it might not be suitable for datasets with complex non-linear relationships.”</p></li>
<li><p><strong>Out-of-Core Learning:</strong> “For extremely large datasets that cannot fit into memory, out-of-core learning can be used. This approach processes the data in chunks, updating the model incrementally.”</p></li>
<li><p><strong>Conclusion:</strong> “In summary, the choice of the best technique really depends on the dataset’s characteristics, available computing resources, and the desired accuracy. Often a combination of these techniques is used.”</p></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace:</strong> Don’t rush. Give the interviewer time to process the information.</li>
<li><strong>Mathematical Notation:</strong> Introduce any mathematical notation before using it. If showing equations, briefly explain the components and purpose.</li>
<li><strong>Why vs.&nbsp;How:</strong> Spend more time explaining <em>why</em> a method works rather than getting bogged down in the minutiae of <em>how</em> it’s implemented. Focus on the high-level concepts.</li>
<li><strong>Real-World Context:</strong> Always tie back to real-world considerations, such as the trade-offs between accuracy and efficiency or the importance of parameter tuning.</li>
<li><strong>Gauge Interest:</strong> Pay attention to the interviewer’s body language and verbal cues. If they seem particularly interested in a specific technique, be prepared to delve deeper. If they seem overwhelmed, move on to the next point.</li>
<li><strong>Ask Questions:</strong> After your explanation, ask if the interviewer has any specific follow-up questions or would like you to elaborate on any particular technique.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>