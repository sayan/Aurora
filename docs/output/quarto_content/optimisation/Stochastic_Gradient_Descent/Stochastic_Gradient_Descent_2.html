<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>stochastic_gradient_descent_2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-3.-derive-at-a-high-level-the-expectation-and-variance-of-the-gradient-estimate-in-sgd.-how-do-these-statistical-properties-influence-the-convergence-behavior-of-the-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="question-3.-derive-at-a-high-level-the-expectation-and-variance-of-the-gradient-estimate-in-sgd.-how-do-these-statistical-properties-influence-the-convergence-behavior-of-the-algorithm">Question: 3. Derive, at a high level, the expectation and variance of the gradient estimate in SGD. How do these statistical properties influence the convergence behavior of the algorithm?</h2>
<p><strong>Best Answer</strong></p>
<p>Stochastic Gradient Descent (SGD) is an iterative optimization algorithm used to minimize a loss function, especially in the context of training machine learning models. Instead of computing the gradient of the loss function with respect to all data points (as in Batch Gradient Descent), SGD estimates the gradient using a single data point or a small batch of data points. This makes it computationally efficient, especially for large datasets.</p>
<p>Let’s delve into the expectation and variance of the gradient estimate in SGD and how they impact convergence.</p>
<p><strong>1. Expectation of the Stochastic Gradient</strong></p>
<p>Let’s assume we want to minimize a loss function <span class="math inline">\(L(\theta)\)</span> where <span class="math inline">\(\theta\)</span> represents the parameters of our model. The loss function is typically an average over the losses computed for each data point in the dataset:</p>
<p><span class="math display">\[
L(\theta) = \frac{1}{N} \sum_{i=1}^{N} L_i(\theta)
\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the total number of data points, and <span class="math inline">\(L_i(\theta)\)</span> is the loss for the <span class="math inline">\(i\)</span>-th data point.</p>
<p>The gradient of the loss function is:</p>
<p><span class="math display">\[
\nabla L(\theta) = \frac{1}{N} \sum_{i=1}^{N} \nabla L_i(\theta)
\]</span></p>
<p>In SGD, we approximate this gradient using a single data point (or a mini-batch). Let’s consider the single data point case for simplicity. The stochastic gradient, denoted as <span class="math inline">\(g(\theta)\)</span>, is given by:</p>
<p><span class="math display">\[
g(\theta) = \nabla L_i(\theta)
\]</span></p>
<p>where <span class="math inline">\(i\)</span> is chosen uniformly at random from <span class="math inline">\(\{1, 2, ..., N\}\)</span>.</p>
<p>Now, let’s compute the expected value of the stochastic gradient:</p>
<p><span class="math display">\[
\mathbb{E}[g(\theta)] = \mathbb{E}[\nabla L_i(\theta)] = \frac{1}{N} \sum_{i=1}^{N} \nabla L_i(\theta)
\]</span></p>
<p>Comparing this with the full gradient, we see that:</p>
<p><span class="math display">\[
\mathbb{E}[g(\theta)] = \nabla L(\theta)
\]</span></p>
<p>This demonstrates that the stochastic gradient is an unbiased estimator of the full gradient. On average, it points in the same direction as the true gradient, which is a crucial property for convergence.</p>
<p><strong>2. Variance of the Stochastic Gradient</strong></p>
<p>The variance of the stochastic gradient measures its variability around its expected value. It’s given by:</p>
<p><span class="math display">\[
\text{Var}(g(\theta)) = \mathbb{E}[||g(\theta) - \mathbb{E}[g(\theta)]||^2]
\]</span></p>
<p>Substituting <span class="math inline">\(\mathbb{E}[g(\theta)] = \nabla L(\theta)\)</span>, we get:</p>
<p><span class="math display">\[
\text{Var}(g(\theta)) = \mathbb{E}[||\nabla L_i(\theta) - \nabla L(\theta)||^2]
\]</span></p>
<p>Expanding this, we have:</p>
<p><span class="math display">\[
\text{Var}(g(\theta)) = \frac{1}{N} \sum_{i=1}^{N} ||\nabla L_i(\theta) - \nabla L(\theta)||^2
\]</span></p>
<p>The variance is non-negative. If all the individual gradients <span class="math inline">\(\nabla L_i(\theta)\)</span> were identical, the variance would be zero. However, in practice, the variance is often substantial due to the variability in the data.</p>
<p>For a mini-batch of size <span class="math inline">\(B\)</span>, the stochastic gradient becomes:</p>
<p><span class="math display">\[
g_B(\theta) = \frac{1}{B} \sum_{i \in \text{batch}} \nabla L_i(\theta)
\]</span></p>
<p>The expectation remains unbiased: <span class="math inline">\(\mathbb{E}[g_B(\theta)] = \nabla L(\theta)\)</span>.</p>
<p>The variance, assuming the gradients are independent, becomes:</p>
<p><span class="math display">\[
\text{Var}(g_B(\theta)) = \frac{1}{B} \text{Var}(g(\theta))
\]</span></p>
<p>This shows that increasing the batch size <em>reduces</em> the variance of the gradient estimate.</p>
<p><strong>3. Impact on Convergence Behavior</strong></p>
<p>The expectation and variance of the stochastic gradient significantly influence the convergence behavior of SGD:</p>
<ul>
<li><p><strong>Expectation (Unbiasedness):</strong> The fact that <span class="math inline">\(\mathbb{E}[g(\theta)] = \nabla L(\theta)\)</span> ensures that, on average, SGD moves towards the minimum of the loss function. Without this unbiasedness, SGD would consistently move in a wrong direction, preventing convergence.</p></li>
<li><p><strong>Variance:</strong> High variance in the stochastic gradient leads to noisy updates. This noise has several consequences:</p>
<ul>
<li><strong>Slower Convergence:</strong> The noisy updates can cause the algorithm to take more steps to reach the minimum. It may oscillate around the minimum rather than converging directly.</li>
<li><strong>Oscillations:</strong> The high variance can cause the algorithm to jump around the parameter space, making it difficult to settle into a local minimum.</li>
<li><strong>Escape from Local Minima:</strong> Ironically, the noise introduced by the high variance can sometimes be beneficial. It can help the algorithm escape from poor local minima by “kicking” it out of the basin of attraction of these minima.</li>
</ul></li>
<li><p><strong>Learning Rate:</strong> The learning rate <span class="math inline">\(\alpha\)</span> magnifies the effect of the stochastic gradient. A high learning rate with a high-variance gradient leads to large, unstable updates. A small learning rate stabilizes the updates but can slow down convergence.</p></li>
<li><p><strong>Batch Size:</strong> Increasing the batch size <span class="math inline">\(B\)</span> reduces the variance, leading to more stable convergence. However, it also increases the computational cost per iteration. There is a trade-off: smaller batches are faster per iteration but more noisy and require more iterations, while larger batches are slower per iteration but more stable and require fewer iterations.</p></li>
<li><p><strong>Adaptive Learning Rates:</strong> Techniques like Adam, RMSprop, and AdaGrad adapt the learning rate for each parameter based on the historical gradients. These methods effectively reduce the impact of high variance by scaling the updates appropriately. For example, Adam maintains estimates of both the first moment (mean) and the second moment (uncentered variance) of the gradients and uses these estimates to adapt the learning rate.</p>
<p>Adam update rule (simplified):</p>
<p><span class="math display">\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
\]</span></p>
<p><span class="math display">\[
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
\]</span></p>
<p><span class="math display">\[
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}
\]</span></p>
<p><span class="math display">\[
\hat{v}_t = \frac{v_t}{1 - \beta_2^t}
\]</span></p>
<p><span class="math display">\[
\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
\]</span></p>
<p>Where <span class="math inline">\(m_t\)</span> and <span class="math inline">\(v_t\)</span> are estimates of the first and second moments of the gradients, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are decay rates, <span class="math inline">\(g_t\)</span> is the gradient at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\alpha\)</span> is the learning rate, and <span class="math inline">\(\epsilon\)</span> is a small constant for numerical stability.</p></li>
</ul>
<p>In summary, the statistical properties of the stochastic gradient – its unbiasedness and its variance – play a crucial role in the behavior of SGD. Understanding these properties helps in tuning hyperparameters such as learning rate and batch size, and in selecting appropriate optimization algorithms for different machine learning tasks. Modern optimizers like Adam are designed to mitigate the issues caused by high variance, leading to faster and more stable convergence.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer in an interview:</p>
<ol type="1">
<li><strong>Start with the Basics (SGD Context):</strong>
<ul>
<li>“Stochastic Gradient Descent is an optimization algorithm used to minimize loss functions, especially in machine learning. Unlike Batch Gradient Descent, which uses the entire dataset, SGD estimates the gradient using a single data point or a mini-batch, making it computationally efficient for large datasets.”</li>
</ul></li>
<li><strong>Introduce the Expectation of the Stochastic Gradient:</strong>
<ul>
<li>“Let’s first consider the expected value of the stochastic gradient. The key is that SGD provides an unbiased estimate of the true gradient.”</li>
<li>“Mathematically, if <span class="math inline">\(L(\theta)\)</span> is our loss function, and <span class="math inline">\(L_i(\theta)\)</span> is the loss for a single data point, then the stochastic gradient <span class="math inline">\(g(\theta) = \nabla L_i(\theta)\)</span>. The expected value of <span class="math inline">\(g(\theta)\)</span> is <span class="math inline">\(\mathbb{E}[g(\theta)] = \frac{1}{N} \sum_{i=1}^{N} \nabla L_i(\theta)\)</span>, which equals the full gradient <span class="math inline">\(\nabla L(\theta)\)</span>. This means, on average, SGD moves in the correct direction.”</li>
<li>“The takeaway here is that the stochastic gradient provides an unbiased estimate of the full gradient, ensuring we are generally moving towards the minimum of the loss function.”</li>
</ul></li>
<li><strong>Discuss the Variance of the Stochastic Gradient:</strong>
<ul>
<li>“Now, let’s talk about the variance. While SGD is unbiased, it can have high variance, which affects convergence.”</li>
<li>“The variance is <span class="math inline">\(\text{Var}(g(\theta)) = \mathbb{E}[||\nabla L_i(\theta) - \nabla L(\theta)||^2]\)</span>. This measures how much the individual gradients vary from the full gradient. A high variance means the updates are noisy.”</li>
<li>“Increasing the batch size to <span class="math inline">\(B\)</span> reduces the variance by a factor of <span class="math inline">\(1/B\)</span>, i.e.&nbsp;<span class="math inline">\(\text{Var}(g_B(\theta)) = \frac{1}{B} \text{Var}(g(\theta))\)</span>, leading to more stable updates, but with increased computational cost per iteration.”</li>
</ul></li>
<li><strong>Explain the Impact on Convergence:</strong>
<ul>
<li>“The statistical properties - expectation and variance - significantly influence convergence behavior.”</li>
<li>“The unbiasedness (expectation) ensures we are generally moving in the right direction. However, high variance leads to slower convergence, oscillations around the minimum, and can make it harder to settle into a good solution.”</li>
<li>“However, this high variance also allows the algorithm to escape from local minima, as the noise can ‘kick’ the parameters out of poor solutions.”</li>
<li>“The learning rate plays a crucial role. A smaller learning rate can dampen the effect of high variance but can also slow down convergence.”</li>
</ul></li>
<li><strong>Mention Mitigation Strategies (Adaptive Learning Rates):</strong>
<ul>
<li>“Modern optimizers like Adam, RMSprop, and AdaGrad adapt the learning rate for each parameter, mitigating the effects of high variance and leading to faster and more stable convergence.”</li>
<li>“For example, Adam estimates both the mean and uncentered variance of the gradients to adjust the learning rate adaptively. This allows it to navigate the parameter space more efficiently compared to standard SGD.”</li>
<li>“Ultimately, understanding these statistical properties helps us tune hyperparameters, select appropriate optimizers, and improve the training process of machine learning models.”</li>
</ul></li>
<li><strong>Concluding Remarks (Practical Considerations):</strong>
<ul>
<li>“In practice, choosing the right batch size, learning rate, and optimizer involves balancing computational cost with convergence stability. Adaptive methods are often preferred due to their robustness to high variance and automatic tuning of learning rates.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Pause after each key point to allow the interviewer to process the information.</li>
<li><strong>Use Visual Aids (if available):</strong> If you are in a virtual interview, consider sharing a whiteboard or screen to sketch the equations or diagrams.</li>
<li><strong>Engage the Interviewer:</strong> Ask if they have any questions or if they would like you to elaborate on a specific point.</li>
<li><strong>Avoid Jargon:</strong> While demonstrating technical depth is crucial, avoid unnecessary jargon that might confuse the interviewer.</li>
<li><strong>Highlight Practical Implications:</strong> Connect the theoretical concepts to real-world considerations and practical applications to showcase your understanding and experience.</li>
</ul>
<p>By following this narration guide, you can deliver a clear, concise, and comprehensive answer that showcases your expertise in SGD and its statistical properties.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>