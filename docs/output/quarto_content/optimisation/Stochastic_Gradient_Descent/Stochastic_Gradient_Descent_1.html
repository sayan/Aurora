<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>stochastic_gradient_descent_1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-2.-how-do-the-choice-of-learning-rate-and-batch-size-affect-the-convergence-properties-of-sgd-what-strategies-would-you-recommend-for-tuning-these-hyperparameters" class="level2">
<h2 class="anchored" data-anchor-id="question-2.-how-do-the-choice-of-learning-rate-and-batch-size-affect-the-convergence-properties-of-sgd-what-strategies-would-you-recommend-for-tuning-these-hyperparameters">Question: 2. How do the choice of learning rate and batch size affect the convergence properties of SGD? What strategies would you recommend for tuning these hyperparameters?</h2>
<p><strong>Best Answer</strong></p>
<p>The learning rate and batch size are arguably the two most critical hyperparameters in Stochastic Gradient Descent (SGD) and its variants. They significantly influence the convergence speed, stability, and the final performance of a trained model.</p>
<p><strong>Impact of Learning Rate</strong></p>
<p>The learning rate, denoted as <span class="math inline">\(\alpha\)</span> or <span class="math inline">\(\eta\)</span>, determines the step size taken in the direction of the negative gradient during each iteration of the optimization process.</p>
<ul>
<li><p><strong>Large Learning Rate:</strong></p>
<ul>
<li><strong>Pros:</strong> Can lead to faster initial convergence.</li>
<li><strong>Cons:</strong> May cause the optimization process to overshoot the minimum, leading to oscillations around the optimal solution or even divergence. The loss function may fail to decrease consistently.</li>
<li>Mathematically, if the learning rate is too large, the update step <span class="math display">\[
\theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t)
\]</span> can result in <span class="math inline">\(\theta_{t+1}\)</span> being further away from the optimal <span class="math inline">\(\theta^*\)</span> than <span class="math inline">\(\theta_t\)</span>. Here, <span class="math inline">\(J(\theta)\)</span> is the cost function.</li>
</ul></li>
<li><p><strong>Small Learning Rate:</strong></p>
<ul>
<li><strong>Pros:</strong> More likely to converge to a (local) minimum. Reduces the risk of overshooting.</li>
<li><strong>Cons:</strong> Convergence can be very slow, requiring many iterations. May get stuck in a local minimum early in training.</li>
<li>Theoretically, with a sufficiently small learning rate and under certain assumptions (e.g., convexity, smoothness), SGD is guaranteed to converge. However, the convergence rate can be impractically slow.</li>
</ul></li>
</ul>
<p><strong>Impact of Batch Size</strong></p>
<p>The batch size, <span class="math inline">\(B\)</span>, determines the number of data points used to compute the gradient estimate in each iteration.</p>
<ul>
<li><p><strong>Large Batch Size (closer to full batch):</strong></p>
<ul>
<li><strong>Pros:</strong> Provides a more accurate estimate of the true gradient, leading to more stable convergence. Can leverage optimized matrix operations for faster computation per iteration.</li>
<li><strong>Cons:</strong> Each iteration is computationally expensive. Can get stuck in sharp, unfavorable local minima, particularly in highly non-convex landscapes. Poorer generalization performance in some cases, potentially due to converging to flatter minima.</li>
<li>The gradient estimate with a large batch size is: <span class="math display">\[
\nabla J_B(\theta) = \frac{1}{B} \sum_{i=1}^B \nabla J(\theta; x_i, y_i)
\]</span> where <span class="math inline">\((x_i, y_i)\)</span> are the data points in the batch. The variance of this estimate is lower compared to smaller batch sizes.</li>
</ul></li>
<li><p><strong>Small Batch Size (including mini-batch and online SGD):</strong></p>
<ul>
<li><strong>Pros:</strong> Computationally cheaper per iteration. Introduces noise in the gradient estimate, which can help escape sharp local minima and potentially lead to better generalization.</li>
<li><strong>Cons:</strong> Noisy gradient estimates can lead to erratic convergence and oscillations. Requires more iterations to converge.</li>
<li>The noisy gradient can be seen as a form of regularization, preventing overfitting to the training data.</li>
<li>The variance of the gradient estimate is higher: <span class="math display">\[
Var(\nabla J_B(\theta)) \propto \frac{\sigma^2}{B}
\]</span> where <span class="math inline">\(\sigma^2\)</span> represents the variance of individual gradients. This shows the inverse relationship between batch size and variance.</li>
</ul></li>
</ul>
<p><strong>Strategies for Tuning Learning Rate and Batch Size</strong></p>
<p>Given their significant impact, careful tuning of the learning rate and batch size is crucial. Here are some recommended strategies:</p>
<ol type="1">
<li><p><strong>Learning Rate Scheduling/Decay:</strong></p>
<ul>
<li><strong>Concept:</strong> Adjust the learning rate during training. Start with a larger learning rate for faster initial progress and gradually reduce it as the optimization approaches a minimum.</li>
<li><strong>Techniques:</strong>
<ul>
<li><strong>Step Decay:</strong> Reduce the learning rate by a factor (e.g., 0.1 or 0.5) every few epochs.</li>
<li><strong>Exponential Decay:</strong> <span class="math inline">\(\alpha_t = \alpha_0 e^{-kt}\)</span>, where <span class="math inline">\(\alpha_0\)</span> is the initial learning rate, <span class="math inline">\(k\)</span> is a decay constant, and <span class="math inline">\(t\)</span> is the iteration number or epoch.</li>
<li><strong>Inverse Time Decay:</strong> <span class="math inline">\(\alpha_t = \frac{\alpha_0}{1 + kt}\)</span>.</li>
<li><strong>Cosine Annealing:</strong> <span class="math inline">\(\alpha_t = \frac{\alpha_0}{2} (1 + \cos(\frac{t}{T}\pi))\)</span>, where <span class="math inline">\(T\)</span> is the total number of iterations. This allows for cyclical increasing and decreasing learning rates.</li>
</ul></li>
<li><strong>Benefits:</strong> Improves convergence stability and helps fine-tune the model towards the end of training.</li>
</ul></li>
<li><p><strong>Adaptive Learning Rates:</strong></p>
<ul>
<li><strong>Concept:</strong> Adjust the learning rate for each parameter individually based on the historical gradients.</li>
<li><strong>Algorithms:</strong>
<ul>
<li><strong>AdaGrad:</strong> Adapts the learning rate based on the sum of squared gradients. Parameters with frequently large gradients have their learning rates decreased more. <span class="math display">\[
\alpha_{t,i} = \frac{\alpha}{\sqrt{G_{t,ii} + \epsilon}}
\]</span> where <span class="math inline">\(G_t\)</span> is a diagonal matrix where each diagonal element <span class="math inline">\(G_{t,ii}\)</span> is the sum of the squares of the gradients w.r.t. <span class="math inline">\(\theta_i\)</span> up to time <span class="math inline">\(t\)</span>, and <span class="math inline">\(\epsilon\)</span> is a small constant to prevent division by zero.</li>
<li><strong>RMSProp:</strong> Similar to AdaGrad, but uses a moving average of squared gradients, which mitigates AdaGrad’s tendency to excessively decrease the learning rate. <span class="math display">\[
v_{t} = \beta v_{t-1} + (1 - \beta) (\nabla J(\theta_t))^2
\]</span> <span class="math display">\[
\alpha_{t,i} = \frac{\alpha}{\sqrt{v_{t} + \epsilon}}
\]</span></li>
<li><strong>Adam:</strong> Combines the benefits of RMSProp and momentum. It computes adaptive learning rates for each parameter using both the first moment (mean) and the second moment (variance) of the gradients. <span class="math display">\[
m_{t} = \beta_1 m_{t-1} + (1 - \beta_1) \nabla J(\theta_t)
\]</span> <span class="math display">\[
v_{t} = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla J(\theta_t))^2
\]</span> <span class="math display">\[
\hat{m}_{t} = \frac{m_t}{1 - \beta_1^t}
\]</span> <span class="math display">\[
\hat{v}_{t} = \frac{v_t}{1 - \beta_2^t}
\]</span> <span class="math display">\[
\alpha_{t,i} = \frac{\alpha}{\sqrt{\hat{v}_{t}} + \epsilon} \hat{m}_t
\]</span></li>
</ul></li>
<li><strong>Benefits:</strong> Often leads to faster and more robust convergence compared to fixed learning rates. Adam is a popular default choice.</li>
</ul></li>
<li><p><strong>Batch Size Tuning:</strong></p>
<ul>
<li><strong>Grid Search or Random Search:</strong> Experiment with different batch sizes (e.g., 32, 64, 128, 256, 512) to find the optimal value for the specific problem and hardware.</li>
<li><strong>Learning Rate Scaling:</strong> When increasing the batch size, consider increasing the learning rate proportionally. A common heuristic is the <em>linear scaling rule</em>: if you multiply the batch size by <span class="math inline">\(k\)</span>, multiply the learning rate by <span class="math inline">\(k\)</span>. However, this may require further tuning.</li>
<li><strong>Considerations:</strong>
<ul>
<li>Smaller batch sizes may require more epochs to converge.</li>
<li>Larger batch sizes may require more memory.</li>
</ul></li>
</ul></li>
<li><p><strong>Learning Rate Range Test:</strong></p>
<ul>
<li><strong>Concept:</strong> Increase the learning rate linearly or exponentially during a pre-training phase and plot the loss as a function of the learning rate. Identify the learning rate range where the loss decreases most rapidly.</li>
<li><strong>Benefits:</strong> Provides valuable information for selecting a suitable initial learning rate and a maximum learning rate for cyclical learning rate schedules.</li>
</ul></li>
<li><p><strong>Cross-Validation:</strong></p>
<ul>
<li>Use k-fold cross-validation to evaluate the performance of different learning rate and batch size combinations. This helps to avoid overfitting to the validation set and provides a more reliable estimate of the generalization performance.</li>
</ul></li>
<li><p><strong>Early Stopping:</strong></p>
<ul>
<li>Monitor the performance on a validation set and stop training when the performance starts to degrade. This prevents overfitting and can save training time.</li>
</ul></li>
</ol>
<p><strong>Real-World Considerations</strong></p>
<ul>
<li><strong>Hardware:</strong> The optimal batch size is often limited by the available GPU memory. Gradient accumulation can be used to simulate larger batch sizes when memory is a constraint.</li>
<li><strong>Dataset Size:</strong> For smaller datasets, smaller batch sizes are often preferred to provide more frequent updates and prevent overfitting. For very large datasets, larger batch sizes can be more efficient.</li>
<li><strong>Model Architecture:</strong> Complex models may require smaller learning rates and batch sizes to prevent instability during training.</li>
</ul>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to present this information in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Importance:</strong> “The learning rate and batch size are two of the most crucial hyperparameters in SGD. They significantly affect how quickly and reliably our model learns.”</p></li>
<li><p><strong>Explain Learning Rate Effects:</strong> “Let’s start with the learning rate. A high learning rate can lead to rapid initial progress but risks overshooting the optimal solution, causing oscillations or even divergence. Mathematically, we can represent the update step as <span class="math inline">\(\theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t)\)</span>. If <span class="math inline">\(\alpha\)</span> is too large, the new parameters might be further away from the optimum. Conversely, a small learning rate ensures convergence but can be painfully slow or get stuck in a local minima.”</p></li>
<li><p><strong>Explain Batch Size Effects:</strong> “Now, let’s consider the batch size. Using a large batch provides a more accurate, but computationally expensive, gradient estimate. The formula for the gradient estimate is <span class="math inline">\(\nabla J_B(\theta) = \frac{1}{B} \sum_{i=1}^B \nabla J(\theta; x_i, y_i)\)</span>. Smaller batch sizes introduce more noise, which can help escape sharp local minima but also make the convergence more erratic. The variance of the gradient is inversely proportional to the batch size.”</p></li>
<li><p><strong>Transition to Tuning Strategies:</strong> “Given these effects, tuning the learning rate and batch size requires careful consideration. I typically use a combination of strategies…”</p></li>
<li><p><strong>Discuss Learning Rate Scheduling:</strong> “One effective approach is learning rate scheduling. The idea is to start with a larger rate for initial progress and then gradually reduce it. Common techniques include step decay, exponential decay, and cosine annealing. For example, exponential decay follows the formula <span class="math inline">\(\alpha_t = \alpha_0 e^{-kt}\)</span>.”</p></li>
<li><p><strong>Discuss Adaptive Learning Rates:</strong> “Another powerful approach is using adaptive learning rates, like AdaGrad, RMSProp, and Adam. These algorithms adjust the learning rate for each parameter individually. Adam, for instance, combines the benefits of RMSProp and momentum and is often a good default choice.” (If asked, be prepared to go into more detail about the formulas for these algorithms.)</p></li>
<li><p><strong>Discuss Batch Size Tuning:</strong> “For batch size, I usually experiment with different values using grid search or random search. When increasing the batch size, it’s often beneficial to increase the learning rate proportionally. Also, remember to consider the hardware limitations, especially GPU memory.”</p></li>
<li><p><strong>Discuss Learning Rate Range Test, Cross-Validation and Early Stopping:</strong> “Other techniques, like the learning rate range test can help to identify optimal values. Rigorous tuning often includes cross-validation to avoid overfitting, and early stopping to prevent wasting resources.”</p></li>
<li><p><strong>Mention Real-World Considerations:</strong> “In practice, the optimal choices also depend on the dataset size, model architecture, and available hardware resources.”</p></li>
</ol>
<p><strong>Communication Tips</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Give the interviewer time to absorb the information.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you’re in a virtual interview, consider sharing a screen with a few key equations or diagrams.</li>
<li><strong>Check for Understanding:</strong> Periodically ask if the interviewer has any questions.</li>
<li><strong>Avoid Jargon:</strong> While demonstrating technical depth is important, avoid overly complex jargon. Focus on clear and concise explanations.</li>
<li><strong>Show Enthusiasm:</strong> Convey your interest and passion for the topic.</li>
<li><strong>Maths Communication:</strong> When discussing equations, walk the interviewer through the logic. Explain what each symbol represents and why the equation is important. Avoid simply stating formulas without context. Say things like “This equation shows…” or “Notice how the learning rate is affected by…”</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>