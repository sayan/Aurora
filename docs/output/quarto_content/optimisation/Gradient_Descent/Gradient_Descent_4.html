<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>gradient_descent_4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-in-a-scenario-where-you-are-dealing-with-messy-real-world-data-and-a-large-scale-model-what-challenges-could-arise-when-using-gradient-descent-how-would-you-address-issues-related-to-scalability-data-noise-and-potential-deployment-in-production" class="level2">
<h2 class="anchored" data-anchor-id="question-5.-in-a-scenario-where-you-are-dealing-with-messy-real-world-data-and-a-large-scale-model-what-challenges-could-arise-when-using-gradient-descent-how-would-you-address-issues-related-to-scalability-data-noise-and-potential-deployment-in-production">Question: 5. In a scenario where you are dealing with messy, real-world data and a large-scale model, what challenges could arise when using gradient descent? How would you address issues related to scalability, data noise, and potential deployment in production?</h2>
<p><strong>Best Answer</strong></p>
<p>When applying gradient descent to train large-scale models with messy, real-world data, several challenges arise across various aspects of the training pipeline. These challenges span from data preprocessing and optimization dynamics to computational scalability and deployment considerations.</p>
<section id="data-quality-and-noisy-gradients" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-and-noisy-gradients">1. Data Quality and Noisy Gradients</h3>
<p><strong>Challenge:</strong> Real-world data is often incomplete, inconsistent, and contains outliers. This leads to noisy gradients, where the gradient computed from a mini-batch is a poor estimate of the true gradient of the loss function. Noisy gradients cause the optimization process to become unstable, oscillate, and converge slowly (or not at all).</p>
<p><strong>Addressing Noisy Gradients:</strong></p>
<ul>
<li><p><strong>Robust Preprocessing:</strong></p>
<ul>
<li><strong>Outlier Removal/Capping:</strong> Identify and remove or cap extreme values in the dataset. Techniques include using the Interquartile Range (IQR) method, Z-score analysis, or domain-specific heuristics.</li>
<li><strong>Imputation:</strong> Handle missing values using mean/median imputation, k-Nearest Neighbors imputation, or model-based imputation (e.g., using a simple neural network to predict missing values).</li>
<li><strong>Data Smoothing:</strong> Apply smoothing techniques such as moving averages or Savitzky-Golay filters to reduce noise in time-series data.</li>
</ul></li>
<li><p><strong>Gradient Clipping:</strong> Prevents exploding gradients by limiting the magnitude of the gradient during backpropagation. The gradient <span class="math inline">\(g\)</span> is clipped as follows:</p>
<p><span class="math display">\[
g' = \begin{cases}
g \cdot \frac{\theta}{\|g\|} &amp; \text{if } \|g\| &gt; \theta \\
g &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>where <span class="math inline">\(\theta\)</span> is a predefined threshold, and <span class="math inline">\(\|g\|\)</span> denotes the norm of the gradient vector.</p></li>
<li><p><strong>Batch Size Tuning:</strong> Experiment with different batch sizes to find a balance. Larger batch sizes provide more stable gradient estimates but require more memory and computation per iteration. Smaller batch sizes introduce more noise but can help escape sharp local minima.</p></li>
<li><p><strong>Gradient Averaging/Accumulation:</strong> Accumulate gradients over multiple mini-batches before updating the model parameters. This effectively increases the batch size without the memory overhead.</p></li>
</ul>
</section>
<section id="optimization-challenges" class="level3">
<h3 class="anchored" data-anchor-id="optimization-challenges">2. Optimization Challenges</h3>
<p><strong>Challenge:</strong> Large-scale models often have non-convex loss landscapes with saddle points, plateaus, and sharp minima. Gradient descent can get stuck in these regions, leading to suboptimal solutions.</p>
<p><strong>Addressing Optimization Challenges:</strong></p>
<ul>
<li><p><strong>Momentum:</strong> Adds a memory of past gradients to smooth out the optimization path and accelerate convergence, especially in high-curvature directions. The update rule is:</p>
<p><span class="math display">\[
v_t = \beta v_{t-1} + (1 - \beta) \nabla L(\theta_{t-1}) \\
\theta_t = \theta_{t-1} - \alpha v_t
\]</span></p>
<p>where <span class="math inline">\(v_t\)</span> is the velocity vector, <span class="math inline">\(\beta\)</span> is the momentum coefficient (typically 0.9), <span class="math inline">\(\nabla L(\theta_{t-1})\)</span> is the gradient of the loss function <span class="math inline">\(L\)</span> with respect to the parameters <span class="math inline">\(\theta\)</span> at iteration <span class="math inline">\(t-1\)</span>, and <span class="math inline">\(\alpha\)</span> is the learning rate.</p></li>
<li><p><strong>Adaptive Learning Rate Methods:</strong> Adjust the learning rate for each parameter based on its historical gradients. Popular methods include:</p>
<ul>
<li><p><strong>Adam (Adaptive Moment Estimation):</strong> Combines momentum and RMSprop. It computes both the exponentially decaying average of past gradients (<span class="math inline">\(m_t\)</span>) and the exponentially decaying average of squared past gradients (<span class="math inline">\(v_t\)</span>):</p>
<p><span class="math display">\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla L(\theta_{t-1}) \\
v_t = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla L(\theta_{t-1}))^2 \\
\hat{m}_t = \frac{m_t}{1 - \beta_1^t} \\
\hat{v}_t = \frac{v_t}{1 - \beta_2^t} \\
\theta_t = \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\]</span></p>
<p>where <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are decay rates (typically 0.9 and 0.999, respectively), <span class="math inline">\(\epsilon\)</span> is a small constant to prevent division by zero, and <span class="math inline">\(\alpha\)</span> is the learning rate.</p></li>
<li><p><strong>RMSprop (Root Mean Square Propagation):</strong> Divides the learning rate by the root mean square of past gradients:</p>
<p><span class="math display">\[
v_t = \beta v_{t-1} + (1 - \beta) (\nabla L(\theta_{t-1}))^2 \\
\theta_t = \theta_{t-1} - \frac{\alpha}{\sqrt{v_t} + \epsilon} \nabla L(\theta_{t-1})
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is the decay rate (typically 0.9) and <span class="math inline">\(\epsilon\)</span> is a small constant.</p></li>
</ul></li>
<li><p><strong>Learning Rate Scheduling:</strong> Adjust the learning rate during training to improve convergence. Common schedules include:</p>
<ul>
<li><strong>Step Decay:</strong> Reduce the learning rate by a constant factor every few epochs.</li>
<li><strong>Exponential Decay:</strong> Decay the learning rate exponentially over time. <span class="math inline">\(\alpha_t = \alpha_0 e^{-kt}\)</span>, where <span class="math inline">\(\alpha_0\)</span> is the initial learning rate, <span class="math inline">\(k\)</span> is the decay rate, and <span class="math inline">\(t\)</span> is the iteration number.</li>
<li><strong>Cosine Annealing:</strong> Vary the learning rate following a cosine function.</li>
</ul></li>
</ul>
</section>
<section id="scalability" class="level3">
<h3 class="anchored" data-anchor-id="scalability">3. Scalability</h3>
<p><strong>Challenge:</strong> Processing large datasets with complex models requires significant computational resources and time. Mini-batch gradient descent helps, but even mini-batches can be slow with very large datasets.</p>
<p><strong>Addressing Scalability:</strong></p>
<ul>
<li><strong>Mini-Batch Gradient Descent:</strong> Compute gradients using small subsets (mini-batches) of the data. This reduces the computational cost per iteration.</li>
<li><strong>Distributed Computing:</strong> Distribute the training workload across multiple machines or GPUs. Frameworks like TensorFlow, PyTorch, and Horovod support distributed training.
<ul>
<li><strong>Data Parallelism:</strong> Divide the dataset among multiple workers, each training a copy of the model on its subset of the data. Gradients are aggregated across workers to update the global model parameters.</li>
<li><strong>Model Parallelism:</strong> Divide the model itself across multiple workers, with each worker responsible for training a portion of the model. This is useful for very large models that do not fit into the memory of a single machine.</li>
</ul></li>
<li><strong>Hardware Acceleration:</strong> Utilize GPUs or specialized hardware accelerators (e.g., TPUs) to speed up the computation of gradients.</li>
<li><strong>Mixed Precision Training:</strong> Use lower precision floating-point numbers (e.g., FP16) to reduce memory usage and speed up computations.</li>
</ul>
</section>
<section id="feature-scaling-and-normalization" class="level3">
<h3 class="anchored" data-anchor-id="feature-scaling-and-normalization">4. Feature Scaling and Normalization</h3>
<p><strong>Challenge:</strong> Features with different scales can cause gradient descent to converge slowly or get stuck.</p>
<p><strong>Addressing Feature Scaling and Normalization:</strong></p>
<ul>
<li><p><strong>Standardization (Z-score normalization):</strong> Scale features to have zero mean and unit variance.</p>
<p><span class="math display">\[
x' = \frac{x - \mu}{\sigma}
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation of the feature.</p></li>
<li><p><strong>Min-Max Scaling:</strong> Scale features to a range between 0 and 1.</p>
<p><span class="math display">\[
x' = \frac{x - x_{min}}{x_{max} - x_{min}}
\]</span></p>
<p>where <span class="math inline">\(x_{min}\)</span> and <span class="math inline">\(x_{max}\)</span> are the minimum and maximum values of the feature, respectively.</p></li>
<li><p><strong>Batch Normalization:</strong> Normalize the activations of each layer during training. This can help to stabilize training and improve generalization. Batch norm transforms are inserted after a fully connected or convolutional layer, and before the activation function.</p>
<p><span class="math display">\[
\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i \\
\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2 \\
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} \\
y_i = \gamma \hat{x}_i + \beta
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is the input activation, <span class="math inline">\(\mu_B\)</span> is the batch mean, <span class="math inline">\(\sigma_B^2\)</span> is the batch variance, <span class="math inline">\(\epsilon\)</span> is a small constant, <span class="math inline">\(\gamma\)</span> is a scale parameter, and <span class="math inline">\(\beta\)</span> is a shift parameter.</p></li>
</ul>
</section>
<section id="deployment-and-monitoring" class="level3">
<h3 class="anchored" data-anchor-id="deployment-and-monitoring">5. Deployment and Monitoring</h3>
<p><strong>Challenge:</strong> Deploying a large-scale model into production requires careful monitoring to ensure it performs as expected. Changes in the data distribution (concept drift) or unexpected inputs can degrade performance.</p>
<p><strong>Addressing Deployment and Monitoring:</strong></p>
<ul>
<li><strong>Monitoring Key Metrics:</strong> Track metrics such as loss, accuracy, and prediction latency in real-time.</li>
<li><strong>Alerting:</strong> Set up alerts to notify when metrics fall below predefined thresholds.</li>
<li><strong>A/B Testing:</strong> Compare the performance of the new model against the existing model using A/B testing.</li>
<li><strong>Shadow Deployment:</strong> Deploy the new model alongside the existing model, but without serving traffic to it. This allows you to monitor the new model’s performance in a production environment without impacting users.</li>
<li><strong>Continuous Integration/Continuous Deployment (CI/CD):</strong> Automate the process of building, testing, and deploying models.</li>
<li><strong>Regular Retraining:</strong> Retrain the model periodically with new data to adapt to changes in the data distribution.</li>
<li><strong>Input Validation:</strong> Validate input data to ensure it conforms to the expected format and range. Reject or preprocess invalid inputs to prevent unexpected behavior.</li>
</ul>
<p>In summary, dealing with messy, real-world data and large-scale models requires a comprehensive approach that addresses data quality, optimization dynamics, computational scalability, and deployment considerations. By applying robust preprocessing techniques, advanced optimization algorithms, distributed computing frameworks, and careful monitoring, it’s possible to train and deploy high-performing models in production.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a suggested way to present this answer during an interview:</p>
<ol type="1">
<li><p><strong>Start with a High-Level Overview:</strong></p>
<ul>
<li>“When dealing with real-world data and large models, we face several challenges. These broadly fall into data quality issues leading to noisy gradients, optimization difficulties in complex loss landscapes, scalability problems with large datasets, the necessity of proper feature scaling, and the challenges of monitoring and maintaining performance in a production environment.”</li>
</ul></li>
<li><p><strong>Address Data Quality and Noisy Gradients:</strong></p>
<ul>
<li>“Real-world data is often messy. To combat this, I’d employ robust preprocessing techniques. For example, to handle outliers, I could use IQR or Z-score methods. For missing data, imputation techniques like k-NN or model-based methods are useful. Furthermore, techniques like gradient clipping can prevent exploding gradients. Gradient clipping works by…” (Explain the gradient clipping equation).</li>
</ul></li>
<li><p><strong>Discuss Optimization Challenges:</strong></p>
<ul>
<li>“Optimization can be tricky due to non-convex loss landscapes. I’d use techniques like momentum to smooth out the optimization path. The update rule for momentum is given by…” (Explain the momentum equations). “Adaptive learning rate methods like Adam and RMSprop are also invaluable. Adam, for instance, combines momentum with RMSprop and involves…” (Explain the Adam equations briefly, focusing on the intuition).</li>
</ul></li>
<li><p><strong>Explain Scalability Solutions:</strong></p>
<ul>
<li>“Scalability is crucial. Mini-batch gradient descent is a must, and distributed computing is essential for very large datasets. Data parallelism and model parallelism are common strategies. Data parallelism involves…, while model parallelism…” (Briefly explain the difference). “Hardware acceleration with GPUs and mixed precision training also play a key role.”</li>
</ul></li>
<li><p><strong>Address Feature Scaling and Normalization:</strong></p>
<ul>
<li>“Feature scaling is important. Standardization, or Z-score normalization, scales features to have zero mean and unit variance. The formula is…” (Present the standardization equation). “Min-Max scaling is also useful, where the formula is…” (Present the Min-Max scaling equation). “Batch normalization is crucial to normalize activations during training, stablizing training and improving generalization. Batch norm transforms the inputs by…”(Present batch norm equations).</li>
</ul></li>
<li><p><strong>Discuss Deployment and Monitoring:</strong></p>
<ul>
<li>“Finally, deployment requires careful monitoring. Key metrics like loss, accuracy, and latency should be tracked. A/B testing and shadow deployment are valuable for comparing model performance. CI/CD pipelines and regular retraining are vital for maintaining performance over time. We should always be validating input data, and setting up alerts on deviations from the norm.”</li>
</ul></li>
<li><p><strong>Summarize and Invite Questions:</strong></p>
<ul>
<li>“So, in summary, tackling these challenges requires a multifaceted approach from data cleaning to advanced optimization techniques and robust deployment strategies. I have experience with all the methodologies described above. Do you have any specific areas you’d like me to elaborate on?”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Allow time for the interviewer to digest the information.</li>
<li><strong>Check for Understanding:</strong> Pause occasionally and ask if they have any questions or if you should elaborate on a particular point.</li>
<li><strong>Focus on Intuition:</strong> When explaining mathematical concepts, start with the intuition behind the formula before diving into the details.</li>
<li><strong>Use Visual Aids (If Possible):</strong> If you’re in a virtual interview, consider using a whiteboard or screen sharing to illustrate key concepts or equations.</li>
<li><strong>Relate to Experience:</strong> Whenever possible, relate the concepts to your past experiences or projects to demonstrate practical application.</li>
<li><strong>Stay Confident:</strong> Even if you don’t know all the answers, confidently explain the approaches you would take to find a solution.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>