<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>rmsprop_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-in-a-practical-implementation-how-would-you-adapt-rmsprop-to-a-mini-batch-gradient-descent-scenario-and-what-computational-considerations-e.g.-memory-or-processing-overhead-might-be-important-when-scaling-to-very-large-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="question-in-a-practical-implementation-how-would-you-adapt-rmsprop-to-a-mini-batch-gradient-descent-scenario-and-what-computational-considerations-e.g.-memory-or-processing-overhead-might-be-important-when-scaling-to-very-large-neural-networks">Question: In a practical implementation, how would you adapt RMSprop to a mini-batch gradient descent scenario, and what computational considerations (e.g., memory or processing overhead) might be important when scaling to very large neural networks?</h2>
<p><strong>Best Answer</strong></p>
<p>RMSprop (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm designed to address the diminishing learning rates and oscillations that can occur with standard gradient descent, particularly in complex and high-dimensional spaces. It inherently lends itself well to mini-batch gradient descent, which is crucial for training large neural networks efficiently.</p>
<p><strong>RMSprop in Mini-Batch Gradient Descent</strong></p>
<p>The fundamental idea behind RMSprop is to adjust the learning rate for each parameter individually based on the historical magnitude of its gradients. In a mini-batch setting, this involves computing the gradients across each mini-batch and updating the moving averages of squared gradients.</p>
<p>The algorithm can be summarized as follows:</p>
<ol type="1">
<li><p><strong>Initialization:</strong> Initialize the parameters <span class="math inline">\(\theta\)</span>, learning rate <span class="math inline">\(\alpha\)</span>, decay rate <span class="math inline">\(\rho\)</span> (typically 0.9), and a small constant <span class="math inline">\(\epsilon\)</span> (e.g., <span class="math inline">\(10^{-8}\)</span>) to prevent division by zero. Also, initialize the moving average of squared gradients, <span class="math inline">\(s\)</span>, to zero: <span class="math inline">\(s_0 = 0\)</span>.</p></li>
<li><p><strong>For each mini-batch:</strong></p>
<ul>
<li>Compute the gradient of the objective function <span class="math inline">\(L\)</span> with respect to the parameters <span class="math inline">\(\theta\)</span> using the current mini-batch: <span class="math inline">\(g_t = \nabla_{\theta} L(\theta)\)</span>.</li>
<li>Update the moving average of squared gradients: <span class="math display">\[s_t = \rho s_{t-1} + (1 - \rho) g_t^2\]</span></li>
<li>Update the parameters: <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{s_t} + \epsilon} g_t\]</span></li>
</ul></li>
</ol>
<p>Here’s a breakdown of the key elements:</p>
<ul>
<li><span class="math inline">\(\theta\)</span>: The model parameters to be optimized.</li>
<li><span class="math inline">\(\alpha\)</span>: The global learning rate.</li>
<li><span class="math inline">\(\rho\)</span>: The decay rate for the moving average (controls the influence of past gradients).</li>
<li><span class="math inline">\(g_t\)</span>: The gradient calculated on the current mini-batch.</li>
<li><span class="math inline">\(s_t\)</span>: The moving average of squared gradients.</li>
<li><span class="math inline">\(\epsilon\)</span>: A small constant added for numerical stability.</li>
</ul>
<p><strong>Why This Works</strong></p>
<p>RMSprop effectively normalizes the gradients by dividing them by the square root of the moving average of squared gradients. This adaptive learning rate helps:</p>
<ul>
<li>Reduce oscillations in directions with large gradients.</li>
<li>Increase the learning rate in directions with small gradients.</li>
<li>Allows for a higher overall learning rate <span class="math inline">\(\alpha\)</span> because the algorithm automatically dampens oscillations.</li>
</ul>
<p><strong>Computational Considerations for Large Neural Networks</strong></p>
<p>When scaling RMSprop to very large neural networks, several computational considerations become important:</p>
<ol type="1">
<li><p><strong>Memory Overhead:</strong> RMSprop requires storing a moving average <span class="math inline">\(s\)</span> for each parameter in the network. For a network with millions or billions of parameters, this can lead to significant memory overhead. Specifically, the memory needed is the same as the number of parameters. For example, a model with 1 billion parameters, using 4 bytes per parameter (float32), will require approximately 4 GB of memory just to store the RMSprop moving average.</p></li>
<li><p><strong>Vectorization:</strong> It is essential to vectorize the computations to leverage the parallel processing capabilities of modern hardware (CPUs and GPUs). The gradient updates, moving average updates, and parameter updates should all be performed using vectorized operations (e.g., using NumPy in Python or optimized tensor operations in deep learning frameworks like TensorFlow or PyTorch). This significantly speeds up the training process.</p></li>
<li><p><strong>GPU Utilization:</strong> GPUs are particularly well-suited for the matrix and vector operations involved in deep learning. Ensure that all tensors and computations are performed on the GPU. Profile the code to identify any bottlenecks that might prevent full GPU utilization (e.g., data transfer between CPU and GPU).</p></li>
<li><p><strong>Parallelization:</strong> For extremely large models, consider distributing the training across multiple GPUs or machines. Techniques like data parallelism (where each GPU processes a different mini-batch) or model parallelism (where different parts of the model are trained on different GPUs) can be used. Libraries such as Horovod or PyTorch’s DistributedDataParallel are useful for implementing distributed training.</p></li>
<li><p><strong>Data Type Precision:</strong> Using lower precision data types (e.g., float16 or bfloat16) can reduce memory consumption and potentially speed up computations on GPUs that support these data types. However, care must be taken to avoid numerical instability, which can occur when using lower precision, especially when gradients become very small. Techniques like gradient scaling can help mitigate this issue.</p></li>
<li><p><strong>Memory Access Bottlenecks:</strong> Memory access can become a bottleneck when dealing with large models. Optimize data layouts to ensure contiguous memory access, which improves performance. Techniques like tiling or blocking can also be used to reduce the number of memory accesses.</p></li>
<li><p><strong>Synchronisation Overhead:</strong> In distributed training, synchronizing gradients or parameters across multiple devices introduces overhead. Strategies like asynchronous updates or gradient compression can reduce the communication costs.</p></li>
<li><p><strong>Batch Size Optimization:</strong> Mini-batch size can significantly impact training performance and memory requirements. A larger mini-batch size generally leads to more stable gradient estimates but requires more memory. Experiment with different mini-batch sizes to find the optimal balance between convergence speed and memory usage.</p></li>
</ol>
<p><strong>Implementation Example (Python/NumPy)</strong></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rmsprop(theta, dtheta, s, alpha, rho, epsilon):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Performs the RMSprop update.</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">  Args:</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">    theta: Current parameters (NumPy array).</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">    dtheta: Gradient of the loss with respect to theta (NumPy array).</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">    s: Moving average of squared gradients (NumPy array).</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">    alpha: Learning rate (float).</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    rho: Decay rate for moving average (float).</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">    epsilon: Small constant for numerical stability (float).</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">  Returns:</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Updated parameters (NumPy array).</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Updated moving average of squared gradients (NumPy array).</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  s <span class="op">=</span> rho <span class="op">*</span> s <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> rho) <span class="op">*</span> dtheta<span class="op">**</span><span class="dv">2</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  theta <span class="op">=</span> theta <span class="op">-</span> alpha <span class="op">/</span> (np.sqrt(s) <span class="op">+</span> epsilon) <span class="op">*</span> dtheta</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> theta, s</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage:</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.random.randn(<span class="dv">1000</span>)  <span class="co"># Example parameters</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>dtheta <span class="op">=</span> np.random.randn(<span class="dv">1000</span>) <span class="co"># Example gradients</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> np.zeros_like(theta)       <span class="co"># Initialize moving average</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.001</span>                 <span class="co"># Learning rate</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>rho <span class="op">=</span> <span class="fl">0.9</span>                     <span class="co"># Decay rate</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>epsilon <span class="op">=</span> <span class="fl">1e-8</span>                <span class="co"># Numerical stability constant</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>theta_new, s_new <span class="op">=</span> rmsprop(theta, dtheta, s, alpha, rho, epsilon)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Updated parameters:"</span>, theta_new[:<span class="dv">5</span>]) <span class="co">#print first five elements</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Conclusion</strong></p>
<p>RMSprop is a powerful optimization algorithm that adapts well to mini-batch gradient descent scenarios, making it suitable for training large neural networks. However, careful consideration of memory overhead, vectorization, GPU utilization, parallelization, and data type precision is crucial for efficient and scalable training. By addressing these computational challenges, one can effectively train very large neural networks using RMSprop and achieve state-of-the-art performance.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this in an interview:</p>
<ol type="1">
<li><p><strong>Start with the Basics:</strong> “RMSprop is an adaptive learning rate optimization algorithm designed to improve upon standard gradient descent. It’s particularly effective in mini-batch scenarios, which are crucial for training large neural networks.”</p></li>
<li><p><strong>Explain the Algorithm (Formula Emphasis):</strong> “The core idea is to maintain a moving average of squared gradients to normalize the learning rate for each parameter. The update rules are as follows:”</p>
<ul>
<li>“First, we compute the gradient for the mini-batch. Then, we update the moving average of squared gradients using this formula: <span class="math inline">\(&lt;equation&gt; s_t = \rho s_{t-1} + (1 - \rho) g_t^2 &lt;/equation&gt;\)</span>. The <span class="math inline">\(\rho\)</span> parameter controls the decay rate of the moving average.”</li>
<li>“Finally, we update the parameters using: <span class="math inline">\(&lt;equation&gt;\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{s_t} + \epsilon} g_t&lt;/equation&gt;\)</span>. Here, <span class="math inline">\(\alpha\)</span> is the learning rate and <span class="math inline">\(\epsilon\)</span> prevents division by zero.”</li>
</ul>
<p><em>Slow down</em> and point to each term in the equations, briefly explaining its role.</p></li>
<li><p><strong>Why RMSprop is Important:</strong> “This adaptive learning rate helps dampen oscillations, especially in directions with large gradients, and allows for a higher overall learning rate.”</p></li>
<li><p><strong>Computational Challenges (Memory, Speed):</strong> “When scaling to large neural networks, several computational considerations become important. Firstly, memory overhead is a concern because we need to store the moving average <span class="math inline">\(s\)</span> for each parameter. For a model with billions of parameters, this can require several gigabytes of memory.”</p></li>
<li><p><strong>Strategies to Overcome Challenges (Vectorization, GPUs, Parallelization):</strong> “To address these challenges, it’s critical to use vectorized operations to maximize the parallel processing capabilities of GPUs. Distributing the training across multiple GPUs or machines using data or model parallelism can also be very effective.”</p></li>
<li><p><strong>Advanced Considerations (Data Type Precision, Memory Access):</strong> “More advanced techniques include using lower precision data types like float16 to reduce memory usage and optimizing memory access patterns to avoid bottlenecks. In distributed training, you need to be aware of synchronization overhead. Choosing an appropriate batch size to fit in memory while providing good gradient estimates is also important.”</p></li>
<li><p><strong>Summarize and Conclude:</strong> “In summary, RMSprop is a powerful algorithm for training large neural networks, but careful attention must be paid to computational considerations such as memory usage, parallelization, and data type precision to achieve optimal performance.”</p></li>
</ol>
<p>Throughout the narration:</p>
<ul>
<li><strong>Pause Briefly After Equations:</strong> Give the interviewer a moment to process the formulas.</li>
<li><strong>Use Hand Gestures:</strong> Use hand gestures to emphasize key points or to visually represent the concepts (e.g., showing how the learning rate is adjusted).</li>
<li><strong>Check for Understanding:</strong> Periodically check for understanding by asking, “Does that make sense?” or “Are there any questions so far?”</li>
<li><strong>Maintain Eye Contact:</strong> Maintain eye contact to engage the interviewer and convey confidence.</li>
<li><strong>Be Prepared to Elaborate:</strong> Be prepared to provide more details or examples if the interviewer asks follow-up questions.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>