<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>adagrad_2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-3.-potential-drawbacks-what-are-the-limitations-of-using-adagrad-particularly-in-the-context-of-deep-learning-and-how-can-these-issues-be-mitigated" class="level2">
<h2 class="anchored" data-anchor-id="question-3.-potential-drawbacks-what-are-the-limitations-of-using-adagrad-particularly-in-the-context-of-deep-learning-and-how-can-these-issues-be-mitigated">Question: 3. Potential Drawbacks: What are the limitations of using Adagrad, particularly in the context of deep learning, and how can these issues be mitigated?</h2>
<p><strong>Best Answer</strong></p>
<p>Adagrad (Adaptive Gradient Algorithm) is an adaptive learning rate optimization algorithm. While it was an important advancement, especially for dealing with sparse data, it has limitations, particularly within the context of deep learning. The primary drawback stems from its monotonically decreasing learning rate. This can lead to premature convergence or the algorithm halting before it reaches an optimal solution.</p>
<p>Here’s a breakdown of the issues and potential mitigation strategies:</p>
<p><strong>1. Monotonically Decreasing Learning Rate:</strong></p>
<ul>
<li><p><strong>The Problem:</strong> Adagrad adapts the learning rate for each parameter based on the historical sum of squared gradients. Specifically, the update rule is:</p>
<p><span class="math display">\[
\theta_{t+1, i} = \theta_{t, i} - \frac{\eta}{\sqrt{G_{t, ii} + \epsilon}} \cdot g_{t, i}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\theta_{t, i}\)</span> is the <span class="math inline">\(i\)</span>-th parameter at time step <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\eta\)</span> is the initial global learning rate.</li>
<li><span class="math inline">\(G_t\)</span> is a diagonal matrix where each element <span class="math inline">\(G_{t, ii} = \sum_{\tau=1}^{t} (g_{\tau, i})^2\)</span> is the sum of the squares of the past gradients for parameter <span class="math inline">\(i\)</span> up to time step <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(g_{t, i}\)</span> is the gradient of the objective function with respect to the <span class="math inline">\(i\)</span>-th parameter at time step <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\epsilon\)</span> is a small smoothing term (e.g., <span class="math inline">\(10^{-8}\)</span>) to prevent division by zero.</li>
</ul>
<p>The key is that <span class="math inline">\(G_{t, ii}\)</span> accumulates the <em>sum</em> of squared gradients over time. Since the sum is always increasing (or at least non-decreasing), the effective learning rate for each parameter, <span class="math inline">\(\frac{\eta}{\sqrt{G_{t, ii} + \epsilon}}\)</span>, is monotonically decreasing.</p></li>
<li><p><strong>Why It’s a Problem:</strong> In deep learning, especially with complex loss landscapes, the algorithm might encounter regions where further updates are necessary to escape saddle points or local minima, or to fine-tune the parameters for optimal performance. If the learning rate has shrunk too much due to the accumulation of squared gradients, the updates become too small to make significant progress, leading to premature convergence. The algorithm essentially “stops learning” too early. This is especially problematic in later layers of deep networks that might require fine-tuning after the earlier layers have converged.</p></li>
</ul>
<p><strong>2. Sensitivity to Initial Learning Rate:</strong></p>
<ul>
<li>Adagrad’s performance is somewhat sensitive to the initial global learning rate, <span class="math inline">\(\eta\)</span>. If <span class="math inline">\(\eta\)</span> is too large, the initial updates might be too aggressive, causing oscillations. If <span class="math inline">\(\eta\)</span> is too small, the algorithm might converge very slowly, or get stuck early. While this is true of many optimizers, the accumulating sum of squared gradients in Adagrad amplifies this sensitivity over time.</li>
</ul>
<p><strong>Mitigation Strategies:</strong></p>
<p>Several strategies can be employed to mitigate these issues:</p>
<ol type="1">
<li><p><strong>RMSProp (Root Mean Square Propagation):</strong></p>
<ul>
<li><p><strong>How it works:</strong> RMSProp modifies Adagrad by using a <em>decaying average</em> of past squared gradients instead of the cumulative sum. This “forgets” very old gradients, preventing the learning rate from shrinking too aggressively. The update rule becomes:</p>
<p><span class="math display">\[
\begin{aligned}
v_{t, i} &amp;= \beta v_{t-1, i} + (1 - \beta) (g_{t, i})^2 \\
\theta_{t+1, i} &amp;= \theta_{t, i} - \frac{\eta}{\sqrt{v_{t, i} + \epsilon}} \cdot g_{t, i}
\end{aligned}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(v_{t, i}\)</span> is the moving average of squared gradients for parameter <span class="math inline">\(i\)</span> at time step <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\beta\)</span> is the decay rate (typically close to 1, e.g., 0.9 or 0.99).</li>
</ul></li>
<li><p><strong>Why it helps:</strong> By using a decaying average, RMSProp prevents the denominator from growing indefinitely, allowing the learning rate to remain reasonably large throughout training. This allows the network to continue learning and escape local minima/saddle points later in training.</p></li>
</ul></li>
<li><p><strong>Adam (Adaptive Moment Estimation):</strong></p>
<ul>
<li><p><strong>How it works:</strong> Adam combines ideas from both RMSProp and Momentum. It maintains both a moving average of the gradients (first moment) and a moving average of the squared gradients (second moment). The update rule involves bias correction to account for the fact that the moving averages are initialized to zero.</p>
<p><span class="math display">\[
\begin{aligned}
m_{t, i} &amp;= \beta_1 m_{t-1, i} + (1 - \beta_1) g_{t, i} \\
v_{t, i} &amp;= \beta_2 v_{t-1, i} + (1 - \beta_2) (g_{t, i})^2 \\
\hat{m}_{t, i} &amp;= \frac{m_{t, i}}{1 - \beta_1^t} \\
\hat{v}_{t, i} &amp;= \frac{v_{t, i}}{1 - \beta_2^t} \\
\theta_{t+1, i} &amp;= \theta_{t, i} - \frac{\eta}{\sqrt{\hat{v}_{t, i}} + \epsilon} \cdot \hat{m}_{t, i}
\end{aligned}
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(m_{t, i}\)</span> is the moving average of the gradients (first moment estimate).</li>
<li><span class="math inline">\(v_{t, i}\)</span> is the moving average of the squared gradients (second moment estimate).</li>
<li><span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are decay rates (typically 0.9 and 0.999, respectively).</li>
<li><span class="math inline">\(\hat{m}_{t, i}\)</span> and <span class="math inline">\(\hat{v}_{t, i}\)</span> are bias-corrected moment estimates.</li>
</ul></li>
<li><p><strong>Why it helps:</strong> Adam is often more robust than Adagrad because it considers both the first and second moments of the gradients, allowing it to adapt the learning rate more effectively. The bias correction term also helps in the initial stages of training when the moving averages are still warming up.</p></li>
</ul></li>
<li><p><strong>Learning Rate Scheduling:</strong></p>
<ul>
<li><p><strong>How it works:</strong> Instead of relying solely on Adagrad’s adaptive learning rate, a global learning rate schedule can be applied. This involves manually adjusting the learning rate during training based on a predefined schedule. Common schedules include:</p>
<ul>
<li><em>Step Decay:</em> Reduce the learning rate by a factor (e.g., 0.1) every few epochs.</li>
<li><em>Exponential Decay:</em> Reduce the learning rate exponentially: <span class="math inline">\(\eta_t = \eta_0 e^{-kt}\)</span>, where <span class="math inline">\(\eta_0\)</span> is the initial learning rate, <span class="math inline">\(k\)</span> is a decay constant, and <span class="math inline">\(t\)</span> is the iteration number.</li>
<li><em>Cosine Annealing:</em> Vary the learning rate according to a cosine function.</li>
<li><em>Cyclical Learning Rates (CLR):</em> Periodically increase and decrease the learning rate between two bounds.</li>
</ul></li>
<li><p><strong>Why it helps:</strong> Learning rate scheduling allows for a more controlled decay of the learning rate. By combining it with Adagrad, you can get the benefits of adaptive learning rates for individual parameters, along with a global learning rate schedule to prevent premature convergence. Cyclical learning rates, in particular, can help the optimizer escape local minima by periodically “kicking” it out of the current solution.</p></li>
</ul></li>
<li><p><strong>Learning Rate Restarts (e.g., SGDR - Stochastic Gradient Descent with Restarts):</strong></p>
<ul>
<li><p><strong>How it works:</strong> This involves periodically resetting the learning rate to a higher value (often the initial learning rate). This “restarts” the optimization process, allowing the algorithm to explore different regions of the loss landscape. SGDR often uses a cosine annealing schedule <em>within</em> each restart cycle.</p></li>
<li><p><strong>Why it helps:</strong> Restarts can help the optimizer escape sharp local minima and find broader, flatter minima that generalize better. It’s like giving the optimizer a “fresh start” every so often.</p></li>
</ul></li>
<li><p><strong>Combining with Momentum:</strong></p>
<ul>
<li><strong>How it works:</strong> While Adagrad does not natively incorporate momentum, it’s possible to use a separate momentum term along with Adagrad updates. The momentum term helps the optimizer accelerate in relevant directions and dampen oscillations.</li>
<li><strong>Why it helps:</strong> Momentum can help Adagrad overcome the “slowdown” effect caused by its decaying learning rate, by adding a “push” in the direction of the previous updates.</li>
</ul></li>
</ol>
<p><strong>Real-World Considerations:</strong></p>
<ul>
<li><strong>Choice of Optimizer:</strong> In practice, Adam or its variants (e.g., AdamW) are often preferred over Adagrad for most deep learning tasks due to their robustness and adaptive learning rate capabilities. However, Adagrad can still be useful in specific scenarios where the data is very sparse and the initial learning rate is carefully tuned.</li>
<li><strong>Hyperparameter Tuning:</strong> The hyperparameters of the chosen mitigation strategy (e.g., <span class="math inline">\(\beta\)</span> for RMSProp, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> for Adam, decay rate for learning rate scheduling) need to be tuned appropriately for the specific problem. Grid search or more advanced hyperparameter optimization techniques can be used.</li>
<li><strong>Monitoring Training:</strong> It’s essential to monitor the training process (e.g., training loss, validation loss, accuracy) to detect premature convergence or other issues. Visualizing the learning curves can provide valuable insights into the behavior of the optimizer.</li>
</ul>
<p>In summary, while Adagrad offered an early solution to adaptive learning rates, its monotonically decreasing learning rate can be a significant limitation in deep learning. RMSProp, Adam, learning rate scheduling, and restarts are effective techniques for mitigating this issue and improving the convergence and generalization performance of deep neural networks.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to deliver this answer verbally in an interview:</p>
<ol type="1">
<li><strong>Start with the Basics:</strong>
<ul>
<li>“Adagrad is an adaptive learning rate optimizer, which means it adjusts the learning rate for each parameter individually during training.”</li>
<li>“A key advantage of Adagrad is that it can automatically adapt the learning rate based on the historical gradients for each parameter, which is especially helpful when dealing with sparse data.”</li>
</ul></li>
<li><strong>Highlight the Main Drawback:</strong>
<ul>
<li>“However, Adagrad has a significant limitation: its learning rate decreases monotonically throughout training. This is because it accumulates the sum of squared gradients in the denominator of the update rule.”</li>
</ul></li>
<li><strong>Explain the Math (Carefully):</strong>
<ul>
<li>“The update rule looks like this: <span class="math inline">\(\theta_{t+1, i} = \theta_{t, i} - \frac{\eta}{\sqrt{G_{t, ii} + \epsilon}} \cdot g_{t, i}\)</span>. Where <span class="math inline">\(G_{t,ii}\)</span> is the sum of squared gradients up to time t. The important thing is that as training goes on, <span class="math inline">\(G\)</span> gets bigger, so the fraction gets smaller.”</li>
<li>“The key takeaway is that <span class="math inline">\(G_{t, ii}\)</span> represents the sum of squared gradients for each parameter <em>i</em> over time. Because this value only increases, the effective learning rate continuously decreases.”</li>
<li><strong>Pause to gauge understanding.</strong> “Does that make sense so far?”</li>
</ul></li>
<li><strong>Explain Why the Decreasing LR is Bad:</strong>
<ul>
<li>“The problem is that this can lead to premature convergence. In deep learning, we often need to fine-tune parameters later in training, or escape saddle points. If the learning rate has become too small, the updates will be too small to make progress.”</li>
<li>“Effectively, the model stops learning too early.”</li>
</ul></li>
<li><strong>Introduce Mitigation Strategies (RMSProp &amp; Adam):</strong>
<ul>
<li>“To address this issue, several modifications to Adagrad have been proposed. Two popular ones are RMSProp and Adam.”</li>
<li>“RMSProp uses a <em>decaying average</em> of past squared gradients, so it ‘forgets’ old gradients. This prevents the learning rate from becoming too small.”</li>
<li>“Adam is even more sophisticated. It combines the ideas of RMSProp with momentum, using moving averages of both the gradients and the squared gradients.”</li>
</ul></li>
<li><strong>Explain Learning Rate Scheduling:</strong>
<ul>
<li>“Another approach is to use learning rate scheduling. This involves manually adjusting the learning rate during training based on a predefined schedule.”</li>
<li>“For example, we could use a step decay, reducing the learning rate by a factor every few epochs. Or we could use cyclical learning rates, which periodically increase and decrease the learning rate.”</li>
</ul></li>
<li><strong>Introduce Learning Rate Restarts:</strong>
<ul>
<li>“Learning Rate Restarts like SGDR take the idea of cyclical learning rates further, by periodically reseting the learning rate to a much higher value, essentially restarting the optimization process, and this helps escape sharp minima”</li>
</ul></li>
<li><strong>Discuss Real-World Considerations:</strong>
<ul>
<li>“In practice, Adam or AdamW are often preferred over Adagrad for most deep learning tasks, as they’re generally more robust and require less tuning. However, Adagrad can still be useful in specific scenarios with very sparse data.”</li>
<li>“Regardless of the optimizer, hyperparameter tuning and monitoring the training process are crucial for achieving good performance.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Start high-level and gradually add detail.</strong> Don’t dive into the equations immediately.</li>
<li><strong>Use visuals if possible.</strong> If you’re in a virtual interview, consider sharing your screen and using a whiteboard to sketch the update rules. If in-person, ask if it would be helpful to write them out.</li>
<li><strong>Check for understanding frequently.</strong> Pause after explaining a key concept or equation and ask, “Does that make sense?” or “Any questions about that?”</li>
<li><strong>Use analogies.</strong> Explain the monotonically decreasing learning rate as “putting the brakes on too early.”</li>
<li><strong>Be confident but not arrogant.</strong> Acknowledge the limitations of Adagrad without dismissing it entirely.</li>
<li><strong>Practice your explanation beforehand.</strong> The more familiar you are with the material, the more clearly you’ll be able to explain it.</li>
</ul>
<p>By following these guidelines, you can deliver a comprehensive and clear explanation of Adagrad’s limitations and how to mitigate them, demonstrating your senior-level knowledge and communication skills.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>