<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>adagrad_4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-5.-real-world-deployment-imagine-you-are-deploying-a-machine-learning-model-on-high-dimensional-messy-real-world-data-that-includes-outliers-and-non-stationary-behaviors.-how-would-you-integrate-adagrad-into-your-training-pipeline-and-what-modifications-or-additional-techniques-would-you-consider-to-ensure-robust-and-scalable-performance" class="level2">
<h2 class="anchored" data-anchor-id="question-5.-real-world-deployment-imagine-you-are-deploying-a-machine-learning-model-on-high-dimensional-messy-real-world-data-that-includes-outliers-and-non-stationary-behaviors.-how-would-you-integrate-adagrad-into-your-training-pipeline-and-what-modifications-or-additional-techniques-would-you-consider-to-ensure-robust-and-scalable-performance">Question: 5. Real-World Deployment: Imagine you are deploying a machine learning model on high-dimensional, messy, real-world data that includes outliers and non-stationary behaviors. How would you integrate Adagrad into your training pipeline, and what modifications or additional techniques would you consider to ensure robust and scalable performance?</h2>
<p><strong>Best Answer</strong></p>
<p>Deploying a machine learning model with Adagrad on high-dimensional, messy, real-world data requires careful consideration of data preprocessing, algorithm selection (and potential modifications), monitoring, and scaling. Here’s a detailed approach:</p>
<p><strong>1. Data Preprocessing and Exploration:</strong></p>
<ul>
<li><strong>Understanding the Data:</strong> The first step involves thorough exploratory data analysis (EDA) to understand the data’s characteristics, identify potential outliers, missing values, and non-stationary behavior. Tools like histograms, scatter plots, and time series decomposition can be invaluable.</li>
<li><strong>Outlier Handling:</strong> Outliers can significantly impact Adagrad (and other optimizers), leading to unstable training. Strategies include:
<ul>
<li><strong>Removal:</strong> Deleting extreme outliers. Use domain knowledge or statistical methods (e.g., IQR method, z-score) to identify them.</li>
<li><strong>Transformation:</strong> Applying transformations like log, Box-Cox, or Yeo-Johnson to reduce the influence of outliers by compressing the data’s range.</li>
<li><strong>Winsorizing/Capping:</strong> Replacing outlier values with values at a specified percentile (e.g., 95th percentile).</li>
</ul></li>
<li><strong>Missing Value Imputation:</strong> Choose an appropriate imputation strategy:
<ul>
<li><strong>Mean/Median Imputation:</strong> Simple but can distort distributions.</li>
<li><strong>K-Nearest Neighbors (KNN) Imputation:</strong> More sophisticated, imputing values based on similar data points.</li>
<li><strong>Model-Based Imputation:</strong> Training a model to predict missing values.</li>
</ul></li>
<li><strong>Normalization/Scaling:</strong> Essential for high-dimensional data to ensure all features contribute equally and to improve convergence.
<ul>
<li><strong>Standardization (Z-score normalization):</strong> Scales features to have a mean of 0 and a standard deviation of 1. Sensitive to outliers. <span class="math display">\[x_{scaled} = \frac{x - \mu}{\sigma}\]</span> where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation.</li>
<li><strong>Min-Max Scaling:</strong> Scales features to a range between 0 and 1. Sensitive to outliers. <span class="math display">\[x_{scaled} = \frac{x - x_{min}}{x_{max} - x_{min}}\]</span></li>
<li><strong>RobustScaler:</strong> Uses median and interquartile range, making it robust to outliers. <span class="math display">\[x_{scaled} = \frac{x - Q_1}{Q_3 - Q_1}\]</span> where <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_3\)</span> are the first and third quartiles, respectively. This is often preferred for messy real-world data.</li>
</ul></li>
<li><strong>Handling Non-Stationarity:</strong> If the data exhibits non-stationary behavior (e.g., time series data with trends or seasonality), consider:
<ul>
<li><strong>Differencing:</strong> Subtracting consecutive values to remove trends.</li>
<li><strong>Decomposition:</strong> Separating the data into trend, seasonality, and residual components.</li>
<li><strong>Rolling Statistics:</strong> Using rolling mean and standard deviation as features.</li>
</ul></li>
</ul>
<p><strong>2. Algorithm Selection and Modification (Considering Alternatives to Adagrad):</strong></p>
<p>While Adagrad adapts the learning rate for each parameter, its aggressive learning rate decay can lead to premature stopping, especially in non-convex optimization landscapes common in deep learning. Thus, it’s important to consider alternatives or modifications:</p>
<ul>
<li><strong>Alternatives to Adagrad:</strong>
<ul>
<li><strong>RMSProp:</strong> Addresses Adagrad’s decaying learning rate by using an exponentially decaying average of squared gradients. Often a better starting point than Adagrad. <span class="math display">\[v_t = \beta v_{t-1} + (1 - \beta) (\nabla J(\theta_t))^2\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{v_t} + \epsilon} \nabla J(\theta_t)\]</span> where <span class="math inline">\(v_t\)</span> is the exponentially decaying average of squared gradients, <span class="math inline">\(\beta\)</span> is the decay rate (e.g., 0.9), <span class="math inline">\(\eta\)</span> is the learning rate, <span class="math inline">\(\nabla J(\theta_t)\)</span> is the gradient of the cost function <span class="math inline">\(J\)</span> with respect to parameters <span class="math inline">\(\theta\)</span> at time <span class="math inline">\(t\)</span>, and <span class="math inline">\(\epsilon\)</span> is a small constant (e.g., <span class="math inline">\(10^{-8}\)</span>) to prevent division by zero.</li>
<li><strong>Adam:</strong> Combines RMSProp’s adaptive learning rates with momentum. Generally a robust and widely used optimizer. <span class="math display">\[m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla J(\theta_t)\]</span> <span class="math display">\[v_t = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla J(\theta_t))^2\]</span> <span class="math display">\[\hat{m}_t = \frac{m_t}{1 - \beta_1^t}\]</span> <span class="math display">\[\hat{v}_t = \frac{v_t}{1 - \beta_2^t}\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t\]</span> where <span class="math inline">\(m_t\)</span> and <span class="math inline">\(v_t\)</span> are the exponentially decaying averages of the gradients and squared gradients, respectively, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are the decay rates (e.g., 0.9 and 0.999), and <span class="math inline">\(\hat{m}_t\)</span> and <span class="math inline">\(\hat{v}_t\)</span> are bias-corrected estimates.</li>
<li><strong>AdamW:</strong> An improvement over Adam that decouples weight decay from the optimization, leading to better generalization.</li>
</ul></li>
<li><strong>Modifications to Adagrad (if chosen):</strong>
<ul>
<li><strong>Learning Rate Clipping:</strong> Prevent the learning rate from becoming excessively small by setting a minimum value.</li>
<li><strong>Gradient Clipping:</strong> Limit the magnitude of the gradients to prevent exploding gradients, especially common with outliers or non-stationary data. Can be implemented as norm clipping or value clipping.</li>
</ul></li>
</ul>
<p><strong>3. Training Pipeline Integration:</strong></p>
<ul>
<li><strong>Mini-Batch Gradient Descent:</strong> Use mini-batch gradient descent rather than full batch to reduce noise and improve convergence speed. The mini-batch size should be tuned.</li>
<li><strong>Learning Rate Scheduling:</strong> Even with Adagrad’s adaptive learning rates, a learning rate schedule can be beneficial.
<ul>
<li><strong>Time-Based Decay:</strong> Linearly or exponentially decay the learning rate over time.</li>
<li><strong>Step Decay:</strong> Reduce the learning rate by a factor every few epochs.</li>
<li><strong>Cosine Annealing:</strong> Vary the learning rate following a cosine function, allowing for exploration and refinement.</li>
</ul></li>
<li><strong>Early Stopping:</strong> Monitor the validation loss and stop training when it starts to increase to prevent overfitting.</li>
<li><strong>Regularization:</strong> Apply L1 or L2 regularization to prevent overfitting, particularly important with high-dimensional data.
<ul>
<li><strong>L1 Regularization (Lasso):</strong> Adds a penalty proportional to the absolute value of the weights. Encourages sparsity. <span class="math display">\[L1 = \lambda \sum_{i=1}^{n} |w_i|\]</span></li>
<li><strong>L2 Regularization (Ridge):</strong> Adds a penalty proportional to the square of the weights. Shrinks weights towards zero. <span class="math display">\[L2 = \lambda \sum_{i=1}^{n} w_i^2\]</span></li>
<li><strong>Elastic Net:</strong> A combination of L1 and L2 regularization.</li>
</ul></li>
</ul>
<p><strong>4. Monitoring and Adjustment:</strong></p>
<ul>
<li><strong>Track Training and Validation Loss:</strong> Monitor the loss curves to identify potential issues like overfitting, underfitting, or oscillations.</li>
<li><strong>Monitor Gradient Norms:</strong> Track the norms of the gradients to detect exploding or vanishing gradients.</li>
<li><strong>Learning Rate Visualization:</strong> Plot the learning rates of individual parameters to understand how Adagrad is adapting them.</li>
<li><strong>Experiment Tracking:</strong> Use tools like TensorBoard, Weights &amp; Biases, or MLflow to track experiments, hyperparameters, and metrics, allowing for systematic optimization.</li>
</ul>
<p><strong>5. Scalability and Distributed Training:</strong></p>
<ul>
<li><strong>Data Parallelism:</strong> Distribute the data across multiple machines or GPUs, with each machine training a copy of the model on a subset of the data. Gradients are aggregated to update the model parameters. Horovod and PyTorch’s DistributedDataParallel are common choices.</li>
<li><strong>Model Parallelism:</strong> Partition the model across multiple devices, suitable for very large models that cannot fit on a single device.</li>
<li><strong>Asynchronous Updates:</strong> In distributed training, asynchronous updates can lead to stale gradients. Techniques like gradient compression can mitigate this.</li>
<li><strong>Batch Size Optimization:</strong> The batch size should be adjusted for distributed training to maximize throughput without sacrificing convergence. Larger batch sizes often require higher learning rates.</li>
</ul>
<p><strong>6. Implementation Details and Corner Cases:</strong></p>
<ul>
<li><strong>Numerical Stability:</strong> Adagrad involves dividing by the square root of accumulated squared gradients. Add a small epsilon value (e.g., <span class="math inline">\(10^{-8}\)</span>) to the denominator to prevent division by zero.</li>
<li><strong>Initialization:</strong> Proper initialization of model weights is crucial for stable training. He initialization or Xavier initialization are common choices.</li>
<li><strong>Hardware Acceleration:</strong> Utilize GPUs or TPUs to accelerate training.</li>
<li><strong>Regularly Save Checkpoints:</strong> Save model checkpoints periodically to allow for resuming training in case of interruptions.</li>
</ul>
<p>In summary, deploying a model with Adagrad (or an alternative like Adam) on messy, high-dimensional data demands a comprehensive strategy encompassing careful preprocessing, thoughtful algorithm selection and potential modification, rigorous monitoring, and attention to scalability. A key aspect is understanding the data’s characteristics and adapting the training pipeline accordingly. While Adagrad can be useful, a more modern optimizer like AdamW is often a better starting point for real-world problems.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a step-by-step guide on how to articulate this to an interviewer:</p>
<ol type="1">
<li><p><strong>Start with the Big Picture:</strong></p>
<ul>
<li>“Deploying a model on messy, real-world data is challenging, and it requires a multi-faceted approach beyond just choosing an optimizer. We need to think about data quality, algorithm robustness, monitoring, and scalability.”</li>
</ul></li>
<li><p><strong>Address Data Preprocessing:</strong></p>
<ul>
<li>“The first crucial step is data preprocessing. I’d begin with exploratory data analysis to understand the data’s distributions, identify outliers, and check for missing values or non-stationary behavior.”</li>
<li>“To handle outliers, I’d consider removal, transformation (like log or Box-Cox), or Winsorizing. For missing data, I’d use appropriate imputation techniques like KNN imputation.”</li>
<li>“Normalization is also essential. While standardization is common, RobustScaler might be preferable due to its resilience to outliers.”</li>
<li>“If dealing with time series data, I’d address non-stationarity using differencing, decomposition, or rolling statistics.”</li>
</ul></li>
<li><p><strong>Discuss Algorithm Selection (and Alternatives):</strong></p>
<ul>
<li>“While Adagrad adapts learning rates per parameter, its aggressive decay can be problematic. Therefore, I’d also consider RMSProp, Adam, or AdamW, which often perform better in practice.”</li>
<li>“If Adagrad is the starting point, I’d consider modifications like learning rate clipping or gradient clipping to improve stability.”</li>
</ul></li>
<li><p><strong>Describe the Training Pipeline:</strong></p>
<ul>
<li>“I’d use mini-batch gradient descent and incorporate a learning rate schedule, possibly time-based decay, step decay, or cosine annealing. Early stopping based on validation loss is also crucial.”</li>
<li>“Regularization (L1 or L2) is essential to prevent overfitting in high-dimensional spaces.”</li>
</ul></li>
<li><p><strong>Emphasize Monitoring:</strong></p>
<ul>
<li>“I’d continuously monitor training and validation loss curves, gradient norms, and potentially even visualize individual parameter learning rates to diagnose issues.”</li>
<li>“Experiment tracking tools like TensorBoard or Weights &amp; Biases are invaluable for systematically optimizing hyperparameters.”</li>
</ul></li>
<li><p><strong>Address Scalability:</strong></p>
<ul>
<li>“For large datasets, I’d consider data parallelism using frameworks like Horovod or PyTorch’s DistributedDataParallel. Model parallelism might be needed for extremely large models.”</li>
<li>“Be aware of the challenges of asynchronous updates in distributed training and techniques to mitigate them.”</li>
</ul></li>
<li><p><strong>Mention Implementation Details:</strong></p>
<ul>
<li>“Numerical stability is important, so I’d add a small epsilon to the denominator in Adagrad’s update rule. Proper weight initialization (He or Xavier) is also crucial.”</li>
<li>“Hardware acceleration with GPUs or TPUs is a must, and I’d regularly save checkpoints to allow for resuming training.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace Yourself:</strong> Don’t rush through the explanation. Allow the interviewer to interject with questions.</li>
<li><strong>Use Visual Aids (if possible):</strong> If you’re in a virtual interview, consider sharing your screen to show code snippets or diagrams.</li>
<li><strong>Explain Equations Clearly:</strong> When discussing equations, explain the purpose of each term and why it’s important. For example, when presenting the Adam update rule, explain the role of momentum and the bias correction terms.</li>
<li><strong>Ask Questions:</strong> Engage the interviewer by asking questions like, “Have you encountered similar challenges in your work?” or “What are your thoughts on using RobustScaler in this scenario?”</li>
<li><strong>Be Honest About Trade-offs:</strong> Acknowledge that there are trade-offs involved in each decision and that the best approach depends on the specific characteristics of the data and the model.</li>
<li><strong>Stay High-Level (Unless Asked to Dive Deeper):</strong> Initially, keep the explanation at a high level. If the interviewer wants more detail on a specific aspect, be prepared to dive deeper. For example, if they ask about the specifics of gradient clipping, you can then explain the different types (norm clipping vs.&nbsp;value clipping).</li>
<li><strong>Summarize:</strong> At the end, provide a concise summary of your approach. “In summary, I’d focus on robust data preprocessing, careful algorithm selection with potential modifications, continuous monitoring, and a scalable training pipeline.”</li>
</ul>
<p>By following this approach, you can demonstrate your senior-level expertise and your ability to tackle real-world machine learning challenges.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>