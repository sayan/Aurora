<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>nesterov_accelerated_gradient_5</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-5d3fd86dc4559d58e199c8cc4a79ed5b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-discuss-how-the-choice-of-momentum-and-learning-rate-parameters-in-nag-can-affect-its-performance.-how-would-you-go-about-tuning-these-parameters-for-a-new-problem-and-what-diagnostic-measures-would-you-use-to-decide-if-the-algorithm-is-converging-appropriately" class="level2">
<h2 class="anchored" data-anchor-id="question-discuss-how-the-choice-of-momentum-and-learning-rate-parameters-in-nag-can-affect-its-performance.-how-would-you-go-about-tuning-these-parameters-for-a-new-problem-and-what-diagnostic-measures-would-you-use-to-decide-if-the-algorithm-is-converging-appropriately">Question: Discuss how the choice of momentum and learning rate parameters in NAG can affect its performance. How would you go about tuning these parameters for a new problem, and what diagnostic measures would you use to decide if the algorithm is converging appropriately?</h2>
<p><strong>Best Answer</strong></p>
<p>Nesterov Accelerated Gradient (NAG) is a momentum-based optimization algorithm designed to accelerate the training of machine learning models, particularly deep neural networks. The crucial parameters are the learning rate (<span class="math inline">\(\eta\)</span>) and the momentum coefficient (<span class="math inline">\(\beta\)</span>). The interplay between these parameters profoundly impacts NAG’s convergence speed, stability, and ability to escape local optima.</p>
<ol type="1">
<li><p><strong>Understanding the Parameters and Their Interaction:</strong></p>
<ul>
<li><strong>Learning Rate (<span class="math inline">\(\eta\)</span>)</strong>: This parameter controls the step size during optimization. A higher learning rate allows for faster initial progress but risks overshooting the minimum and potentially diverging. A smaller learning rate guarantees more stable convergence, but it may lead to slow progress, especially in regions with small gradients.</li>
<li><strong>Momentum Coefficient (<span class="math inline">\(\beta\)</span>)</strong>: This parameter determines the contribution of the past gradients to the current update. It helps to smooth out the optimization trajectory and accelerate learning in relevant directions by accumulating momentum. Typically, <span class="math inline">\(\beta\)</span> is set between 0 and 1 (e.g., 0.9 or 0.99). In NAG, the momentum is applied <em>before</em> calculating the gradient, providing a “look-ahead” capability.</li>
</ul>
<p>The update rule for NAG can be expressed as follows:</p>
<p>First, the “look-ahead” position is calculated: <span class="math display">\[
\theta_{temp} = \theta_{t-1} - \beta v_{t-1}
\]</span></p>
<p>Then, the gradient is evaluated at the look-ahead position: <span class="math display">\[
\nabla J(\theta_{temp})
\]</span></p>
<p>Finally, the velocity and parameters are updated: <span class="math display">\[
v_t = \beta v_{t-1} + \eta \nabla J(\theta_{temp})
\]</span> <span class="math display">\[
\theta_t = \theta_{t-1} - v_t
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\theta_t\)</span> represents the parameters at time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(v_t\)</span> is the velocity (accumulated gradients) at time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(J(\theta)\)</span> is the objective function (loss)</li>
</ul>
<p><strong>Interaction</strong>: The learning rate and momentum coefficient have a complex interaction. A high momentum coupled with a high learning rate can lead to oscillations or divergence. Conversely, a low momentum with a low learning rate results in slow convergence. The correct balance is critical. NAG’s “look-ahead” mechanism aims to make the updates more informed than standard momentum, which should theoretically allow for larger effective learning rates, but tuning is still crucial.</p></li>
<li><p><strong>Tuning Strategies for <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\beta\)</span>:</strong></p>
<p>Tuning these parameters for a new problem requires a systematic approach. Here are several methods:</p>
<ul>
<li><p><strong>Grid Search</strong>: Define a range of values for both <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\beta\)</span>. For example:</p>
<ul>
<li><span class="math inline">\(\eta \in \{0.1, 0.01, 0.001, 0.0001\}\)</span></li>
<li><span class="math inline">\(\beta \in \{0.9, 0.95, 0.99\}\)</span></li>
</ul>
<p>Train the model for a fixed number of epochs for each combination of parameters and evaluate the performance on a validation set. Choose the combination that yields the best validation performance. This method is computationally expensive but thorough.</p></li>
<li><p><strong>Random Search</strong>: Similar to grid search, but instead of testing every combination, randomly sample values from predefined ranges for <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\beta\)</span>. This method can often be more efficient than grid search, especially when some parameters are more important than others.</p></li>
<li><p><strong>Adaptive Optimization Algorithms</strong>: Consider using adaptive learning rate algorithms like Adam or RMSProp as baselines. These algorithms automatically adjust the learning rate for each parameter, often requiring less manual tuning. If Adam/RMSProp perform significantly better, it suggests that manually tuning NAG may not be worth the effort.</p></li>
<li><p><strong>Learning Rate Scheduling</strong>: Implement a learning rate schedule that gradually reduces the learning rate during training. Common schedules include:</p>
<ul>
<li><strong>Step Decay</strong>: Reduce the learning rate by a factor (e.g., 0.1) every few epochs.</li>
<li><strong>Exponential Decay</strong>: <span class="math inline">\(\eta_t = \eta_0 * e^{-kt}\)</span>, where <span class="math inline">\(\eta_0\)</span> is the initial learning rate, <span class="math inline">\(k\)</span> is the decay rate, and <span class="math inline">\(t\)</span> is the iteration number.</li>
<li><strong>Cosine Annealing</strong>: Vary the learning rate following a cosine function, smoothly decreasing and potentially increasing it throughout training.</li>
</ul>
<p>Combining learning rate scheduling with NAG can further improve convergence.</p></li>
</ul></li>
<li><p><strong>Diagnostic Measures for Convergence:</strong></p>
<p>To determine if NAG is converging appropriately, monitor the following metrics:</p>
<ul>
<li><p><strong>Loss Curve</strong>: Plot the loss on the training and validation sets as a function of epochs.</p>
<ul>
<li><strong>Ideal Scenario</strong>: The loss should decrease smoothly and consistently on both sets. The validation loss should plateau or slightly increase after a certain point.</li>
<li><strong>Oscillations</strong>: If the loss oscillates wildly, it indicates that the learning rate is too high. Reduce <span class="math inline">\(\eta\)</span>. Also consider increasing <span class="math inline">\(\beta\)</span> slightly to smooth out updates.</li>
<li><strong>Stalling</strong>: If the loss plateaus prematurely, the learning rate may be too low, or the optimization may be stuck in a local minimum. Increase <span class="math inline">\(\eta\)</span> or adjust <span class="math inline">\(\beta\)</span>.</li>
<li><strong>Divergence</strong>: If the loss increases exponentially, the learning rate is far too high. Reduce <span class="math inline">\(\eta\)</span> drastically.</li>
</ul></li>
<li><p><strong>Gradient Norm</strong>: Monitor the norm of the gradient <span class="math inline">\(||\nabla J(\theta)||\)</span>. A decreasing gradient norm indicates that the optimization is progressing towards a minimum. If the gradient norm plateaus, it suggests that the optimization has stalled. A large or increasing gradient norm can indicate divergence.</p></li>
<li><p><strong>Parameter Updates</strong>: Examine the magnitude of the parameter updates <span class="math inline">\(||\Delta \theta||\)</span>. Small updates suggest that the learning rate is too low or the optimization is nearing convergence. Large updates, especially if accompanied by oscillating loss, indicate instability.</p></li>
<li><p><strong>Validation Performance</strong>: The ultimate measure of convergence is the performance on a held-out validation set. Monitor metrics such as accuracy, F1-score, or AUC, depending on the problem. Early stopping can be used to prevent overfitting: stop training when the validation performance starts to degrade.</p></li>
</ul></li>
<li><p><strong>Handling Convergence Issues:</strong></p>
<ul>
<li><p><strong>Stalling</strong>:</p>
<ul>
<li><strong>Increase Learning Rate</strong>: Gradually increase the learning rate to escape the local minimum.</li>
<li><strong>Adjust Momentum</strong>: Reduce the momentum coefficient to allow for more exploration.</li>
<li><strong>Restart Optimization</strong>: Occasionally, restarting the optimization from a different initial point can help.</li>
</ul></li>
<li><p><strong>Oscillations</strong>:</p>
<ul>
<li><strong>Reduce Learning Rate</strong>: Decrease the learning rate to stabilize the optimization.</li>
<li><strong>Increase Momentum</strong>: Increase the momentum coefficient to smooth out the updates.</li>
<li><strong>Gradient Clipping</strong>: Clip the gradients to a maximum value to prevent excessively large updates. This can be particularly useful when dealing with exploding gradients in recurrent neural networks.</li>
</ul></li>
<li><p><strong>Divergence</strong>:</p>
<ul>
<li><strong>Reduce Learning Rate Drastically</strong>: Decrease the learning rate by an order of magnitude.</li>
<li><strong>Check for Numerical Instability</strong>: Ensure that the loss function and gradients are computed correctly and that there are no numerical issues (e.g., division by zero, taking the logarithm of a negative number).</li>
<li><strong>Regularization</strong>: Increase regularization (e.g., L1 or L2 regularization) to prevent overfitting and stabilize training.</li>
</ul></li>
</ul></li>
<li><p><strong>Advanced Considerations</strong></p></li>
</ol>
<ul>
<li><strong>Adaptive Momentum</strong>: Techniques like “Nesterov momentum with adaptive restarts” have been proposed. This involves periodically resetting the momentum term when the optimization appears to be stuck.</li>
<li><strong>Second-Order Methods</strong>: While more computationally expensive, techniques like L-BFGS can sometimes achieve faster convergence and require less manual tuning.</li>
<li><strong>Batch Size</strong>: The batch size can also affect the optimal learning rate and momentum. Larger batch sizes often allow for larger learning rates.</li>
</ul>
<p>In summary, tuning <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\beta\)</span> for NAG requires a combination of systematic search strategies, careful monitoring of diagnostic metrics, and a good understanding of how these parameters interact to affect the optimization process.</p>
<p><strong>How to Narrate</strong></p>
<ol type="1">
<li><p><strong>Introduction (20 seconds)</strong>:</p>
<ul>
<li>“Nesterov Accelerated Gradient, or NAG, is a momentum-based optimization algorithm. Its key parameters, learning rate (eta) and momentum coefficient (beta), significantly influence its performance.”</li>
<li>“I’ll explain how these parameters interact, discuss tuning strategies, and outline diagnostic measures for assessing convergence.”</li>
</ul></li>
<li><p><strong>Explain Parameters and Their Interaction (1 minute 30 seconds)</strong>:</p>
<ul>
<li>“The learning rate, denoted as <span class="math inline">\(\eta\)</span>, controls the step size. A high learning rate can speed up initial progress, but risks overshooting. A small learning rate guarantees more stable convergence, but slows down progress. I can show this with the update equations…”</li>
<li>Walk the interviewer through the NAG update equations, explaining each term (<span class="math inline">\(v_t\)</span>, <span class="math inline">\(\theta_t\)</span>, <span class="math inline">\(J(\theta)\)</span>) and how the momentum term influences the gradient update, mentioning the ‘look-ahead’ aspect. “Notice the look-ahead component, which is <span class="math inline">\(\theta_{temp}\)</span>. This is what makes NAG different.”</li>
<li>“Beta, or <span class="math inline">\(\beta\)</span>, determines the contribution of past gradients. It helps smooth the optimization trajectory. It typically falls between 0.9 and 0.99. High momentum with a high learning rate can lead to oscillations, while low momentum with a low learning rate can lead to slow convergence. This interplay is crucial.”</li>
</ul></li>
<li><p><strong>Discuss Tuning Strategies (2 minutes)</strong>:</p>
<ul>
<li>“For tuning, I’d start with a systematic approach. Grid search is one option, where we define a range of values for both parameters and evaluate performance on a validation set for each combination. This is thorough but computationally expensive. For example learning rate in <span class="math inline">\(\{0.1, 0.01, 0.001, 0.0001\}\)</span> and momentum in <span class="math inline">\(\{0.9, 0.95, 0.99\}\)</span>.”</li>
<li>“Random search is another option; often more efficient, especially if some parameters are more important than others. We randomly sample values from the ranges.”</li>
<li>“Adaptive methods, like Adam, serve as good baselines. If Adam performs much better, it may not be worth extensive tuning of NAG. Mention the use of learning rate schedules, like step decay, exponential decay, or cosine annealing to dynamically change the learning rate.”</li>
</ul></li>
<li><p><strong>Outline Diagnostic Measures (2 minutes)</strong>:</p>
<ul>
<li>“To monitor convergence, I’d primarily look at the loss curve on the training and validation sets. A smoothly decreasing loss is ideal. Oscillations indicate a high learning rate, while plateaus suggest a learning rate that’s too low, or a possible local minimum.”</li>
<li>“The gradient norm, denoted as <span class="math inline">\(||\nabla J(\theta)||\)</span>, is also crucial. A decreasing norm means we’re approaching a minimum. Parameter updates, <span class="math inline">\(||\Delta \theta||\)</span>, tell us about the step size. Small updates suggest a low learning rate, large updates, and oscillations suggest instability.”</li>
<li>“Ultimately, validation performance on held-out data matters most. Early stopping prevents overfitting when validation performance degrades.”</li>
</ul></li>
<li><p><strong>Address Handling Convergence Issues (1 minute)</strong>:</p>
<ul>
<li>“If training stalls, I might increase the learning rate gradually, reduce the momentum, or restart the optimization from a different point. For oscillations, I’d reduce the learning rate, increase the momentum, or apply gradient clipping. If the loss diverges, I’d drastically reduce the learning rate, check for numerical instability, and increase regularization.”</li>
</ul></li>
<li><p><strong>Advanced Considerations and Conclusion (30 seconds)</strong>:</p>
<ul>
<li>“More advanced strategies include adaptive momentum and second-order methods like L-BFGS. Also, the batch size can influence optimal learning rates and momentum.”</li>
<li>“In summary, tuning NAG involves systematic search, careful monitoring, and understanding the interplay between the learning rate and momentum to achieve optimal convergence.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace</strong>: Speak clearly and deliberately. Avoid rushing.</li>
<li><strong>Emphasis</strong>: Emphasize key terms like “learning rate,” “momentum,” “loss curve,” and “validation performance.”</li>
<li><strong>Visual Aids</strong>: If possible, use a whiteboard to draw simple diagrams of the loss curve or illustrate the gradient update steps.</li>
<li><strong>Engagement</strong>: Encourage the interviewer to ask questions. Pause briefly after each section to check for understanding.</li>
<li><strong>Mathematical Sections</strong>: When presenting equations, explain each term concisely. Avoid getting bogged down in excessive detail. Focus on the intuition.</li>
<li><strong>Confidence</strong>: Present your knowledge confidently, but remain open to feedback and suggestions. Acknowledge that tuning optimization algorithms is often an iterative process.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>