<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>mini_batch_gradient_descent_1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap-a37d0bf9d509de95c1ba4621f20add8c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="question-2.-how-does-the-choice-of-mini-batch-size-influence-the-convergence-properties-and-stability-of-the-optimization-process-include-a-discussion-on-the-mathematical-implications-such-as-variance-reduction-and-estimation-bias." class="level2">
<h2 class="anchored" data-anchor-id="question-2.-how-does-the-choice-of-mini-batch-size-influence-the-convergence-properties-and-stability-of-the-optimization-process-include-a-discussion-on-the-mathematical-implications-such-as-variance-reduction-and-estimation-bias.">Question: 2. How does the choice of mini-batch size influence the convergence properties and stability of the optimization process? Include a discussion on the mathematical implications such as variance reduction and estimation bias.</h2>
<p><strong>Best Answer</strong></p>
<p>The mini-batch size is a crucial hyperparameter in training machine learning models, particularly neural networks, using mini-batch gradient descent. It significantly impacts the convergence properties, stability, and computational efficiency of the optimization process. The choice of mini-batch size involves a trade-off between several factors, including gradient estimation accuracy, computational cost, and the ability to escape local optima.</p>
<p><strong>1. Mathematical Implications</strong></p>
<ul>
<li><strong>Gradient Estimation and Variance:</strong> Mini-batch gradient descent aims to approximate the full gradient (calculated over the entire dataset) by computing the gradient over a smaller subset (mini-batch) of data. Let <span class="math inline">\(L(\theta)\)</span> be the loss function we want to minimize, where <span class="math inline">\(\theta\)</span> represents the model parameters. The full gradient is given by:</li>
</ul>
<p><span class="math display">\[
\nabla L(\theta) = \frac{1}{N} \sum_{i=1}^{N} \nabla L_i(\theta)
\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the size of the entire dataset and <span class="math inline">\(L_i(\theta)\)</span> is the loss for the <span class="math inline">\(i\)</span>-th data point.</p>
<p>In mini-batch gradient descent, we approximate this gradient using a mini-batch of size <span class="math inline">\(B\)</span>:</p>
<p><span class="math display">\[
\nabla \hat{L}(\theta) = \frac{1}{B} \sum_{i \in \mathcal{B}} \nabla L_i(\theta)
\]</span></p>
<p>where <span class="math inline">\(\mathcal{B}\)</span> is the set of indices in the mini-batch.</p>
<p>The variance of the mini-batch gradient estimator is:</p>
<p><span class="math display">\[
Var[\nabla \hat{L}(\theta)] = \frac{1}{B} Var[\nabla L_i(\theta)]
\]</span></p>
<p>This equation shows that as the mini-batch size <span class="math inline">\(B\)</span> increases, the variance of the gradient estimate decreases. Smaller batch sizes introduce more noise into the gradient estimate, leading to higher variance. Larger batch sizes provide a more stable and accurate estimate of the true gradient, leading to lower variance.</p>
<ul>
<li><p><strong>Bias:</strong> Ideally, the mini-batch gradient should be an unbiased estimator of the full gradient. That is, the expected value of the mini-batch gradient should equal the full gradient. In practice, this is often the case, especially when the mini-batches are chosen randomly. However, bias can creep in under certain circumstances. For instance, if the data within each mini-batch is not independently and identically distributed (i.i.d.) due to some inherent structure in the data or a non-random sampling procedure, then the mini-batch gradient can become biased. Furthermore, certain normalization techniques, such as Batch Normalization, introduce a subtle bias due to the estimation of batch statistics, which can affect convergence, particularly with small batch sizes.</p></li>
<li><p><strong>Law of Large Numbers:</strong> The rationale behind using mini-batches is rooted in the law of large numbers. As the batch size increases, the sample mean (mini-batch gradient) converges to the population mean (full gradient). This convergence reduces the stochasticity in the optimization process.</p></li>
</ul>
<p><strong>2. Impact on Convergence Properties</strong></p>
<ul>
<li><strong>Small Batch Sizes (e.g., 1-32):</strong>
<ul>
<li><strong>Pros:</strong>
<ul>
<li><strong>Escaping Local Optima:</strong> The higher variance in the gradient estimate acts as a regularizer, helping the optimization process escape sharp local minima and saddle points. The added noise can “kick” the optimization trajectory out of undesirable regions.</li>
<li><strong>Faster Initial Progress:</strong> Due to frequent updates, the model can initially make faster progress, especially when the learning rate is well-tuned.</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li><strong>Noisy Convergence:</strong> The high variance leads to noisy convergence, making it harder to reach a stable minimum. The optimization trajectory oscillates significantly.</li>
<li><strong>Lower Computational Efficiency:</strong> More frequent updates require more computation overall, and may not fully utilize parallel processing capabilities.</li>
<li><strong>Requires Fine-Tuning:</strong> Can be very sensitive to learning rate.</li>
</ul></li>
</ul></li>
<li><strong>Large Batch Sizes (e.g., 256-8192 or more):</strong>
<ul>
<li><strong>Pros:</strong>
<ul>
<li><strong>Stable Convergence:</strong> The lower variance leads to more stable and smoother convergence. The gradient estimate is more accurate, guiding the optimization process more directly towards the minimum.</li>
<li><strong>Higher Computational Efficiency:</strong> Can take advantage of vectorized operations and parallel processing, leading to faster training times, especially on GPUs or TPUs. The overhead of data loading and gradient computation is amortized over more examples per update.</li>
</ul></li>
<li><strong>Cons:</strong>
<ul>
<li><strong>Risk of Getting Stuck in Local Optima:</strong> The reduced noise can prevent the optimization process from escaping sharp local minima, leading to sub-optimal solutions.</li>
<li><strong>Slower Initial Progress:</strong> Requires more data to compute each gradient update, leading to slower initial progress.</li>
<li><strong>Generalization Gap:</strong> Models trained with very large batch sizes sometimes exhibit a “generalization gap,” meaning that they perform well on the training data but generalize poorly to unseen data.</li>
</ul></li>
</ul></li>
</ul>
<p><strong>3. Impact on Learning Rate Selection</strong></p>
<p>The optimal learning rate is highly dependent on the mini-batch size.</p>
<ul>
<li><p><strong>Small Batch Sizes:</strong> Typically require smaller learning rates to avoid overshooting the minimum due to the high variance in the gradient estimate. Techniques like learning rate annealing or adaptive learning rate methods (e.g., Adam, RMSprop) are crucial for stable convergence.</p></li>
<li><p><strong>Large Batch Sizes:</strong> Can often benefit from larger learning rates because the gradient estimate is more accurate. However, simply increasing the learning rate proportionally to the batch size is not always optimal and can lead to instability. Techniques like LARS (Layer-wise Adaptive Rate Scaling) have been developed to automatically adjust the learning rate for each layer based on the norm of the weights and gradients, enabling stable training with very large batch sizes.</p></li>
</ul>
<p><strong>4. Real-World Considerations</strong></p>
<ul>
<li><p><strong>Hardware Limitations:</strong> The choice of mini-batch size is often constrained by the available memory on the GPU or TPU. Larger batch sizes require more memory to store the intermediate activations and gradients.</p></li>
<li><p><strong>Dataset Characteristics:</strong> The optimal mini-batch size can depend on the characteristics of the dataset. For example, if the dataset is highly redundant, larger batch sizes may be more effective.</p></li>
<li><p><strong>Specific Architectures:</strong> Some neural network architectures, such as those with batch normalization, are more sensitive to the choice of mini-batch size. Batch normalization relies on estimating the mean and variance of the activations within each mini-batch. When the batch size is too small, these estimates become unreliable, which can degrade performance.</p></li>
<li><p><strong>Distributed Training:</strong> In distributed training scenarios, where the data is split across multiple devices, the mini-batch size on each device affects the communication overhead. Larger batch sizes reduce the frequency of communication, but can also lead to slower overall convergence if the global batch size becomes too large.</p></li>
</ul>
<p><strong>5. Conclusion</strong></p>
<p>Choosing the right mini-batch size involves a careful trade-off between computational efficiency, gradient estimation accuracy, and the ability to escape local optima. There is no one-size-fits-all answer, and the optimal mini-batch size often needs to be determined empirically through experimentation and hyperparameter tuning. Modern optimization techniques and hardware advancements are continually pushing the boundaries of what is possible with large batch sizes, but understanding the fundamental principles underlying the mini-batch size is crucial for effectively training machine learning models.</p>
<p><strong>How to Narrate</strong></p>
<p>Here’s a guide on how to articulate this answer during an interview:</p>
<ol type="1">
<li><strong>Start with the Basic Definition:</strong>
<ul>
<li>“Mini-batch size is a hyperparameter that determines the number of data samples used in each iteration to compute the gradient estimate during training.”</li>
<li>“It sits at the heart of mini-batch gradient descent, which is one of the foundational algorithms of ML.”</li>
</ul></li>
<li><strong>Explain the Trade-off:</strong>
<ul>
<li>“The choice of mini-batch size involves a trade-off. Smaller batches introduce more noise but can help escape local optima, while larger batches provide a more accurate gradient estimate but might get stuck and consume more memory.”</li>
</ul></li>
<li><strong>Introduce the Mathematical Perspective (Variance):</strong>
<ul>
<li>“From a mathematical standpoint, we’re approximating the full gradient with the gradient computed on a mini-batch. The variance of this estimate is inversely proportional to the batch size. Therefore, smaller batches lead to higher variance.”</li>
<li>“I can write out the equations to illustrate this: (Write out variance equation… but don’t belabor it unless asked). This shows how batch size inversely impacts the variance in gradient estimation.”</li>
</ul></li>
<li><strong>Bias (Mention it Briefly):</strong>
<ul>
<li>“Ideally, the mini-batch gradient should be an unbiased estimator. However, issues like non-i.i.d. data or the use of Batch Normalization can introduce bias, especially with small batch sizes.”</li>
</ul></li>
<li><strong>Discuss the Convergence Properties:</strong>
<ul>
<li>“Small batch sizes offer the advantage of potentially escaping local optima due to the added noise. However, they can also result in noisy convergence and require careful tuning of the learning rate.”</li>
<li>“Conversely, large batch sizes lead to more stable convergence and are computationally efficient, but they might get stuck in local optima and sometimes exhibit a ‘generalization gap’.”</li>
</ul></li>
<li><strong>Connect to Learning Rate Selection:</strong>
<ul>
<li>“The learning rate is intimately tied to the batch size. Smaller batches usually require smaller learning rates, while larger batches might benefit from larger ones, although this is not always a straightforward scaling.”</li>
<li>“Techniques like LARS have been developed to adaptively adjust learning rates for large batch sizes.”</li>
</ul></li>
<li><strong>Discuss Real-World Considerations:</strong>
<ul>
<li>“In practice, the choice of mini-batch size is also influenced by hardware limitations, such as GPU memory. Dataset characteristics and specific architectures like those using batch normalization also play a role.”</li>
<li>“In distributed training, the mini-batch size per device affects communication overhead, adding another layer of complexity.”</li>
</ul></li>
<li><strong>Summarize:</strong>
<ul>
<li>“In summary, choosing the right mini-batch size is about balancing various factors, and it often requires empirical experimentation to find what works best for a given problem and setup.”</li>
</ul></li>
</ol>
<p><strong>Communication Tips:</strong></p>
<ul>
<li><strong>Pace yourself.</strong> Don’t rush through the explanation.</li>
<li><strong>Use visual cues.</strong> If you’re in person, use hand gestures to emphasize key points. If you’re remote, use a whiteboard or screen sharing to illustrate concepts.</li>
<li><strong>Check for understanding.</strong> Pause periodically and ask if the interviewer has any questions.</li>
<li><strong>Tailor the depth.</strong> Gauge the interviewer’s knowledge level and adjust your explanation accordingly. If they seem less familiar with the concepts, focus on the high-level ideas and avoid getting too deep into the mathematical details.</li>
<li><strong>Be confident but not arrogant.</strong> Show that you understand the topic thoroughly, but also be open to learning and discussing different perspectives.</li>
<li><strong>Stay practical.</strong> Ground your explanation in real-world applications and considerations.</li>
<li><strong>Practice, practice, practice!</strong> Rehearse your answer beforehand to ensure that you can deliver it smoothly and confidently.</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>